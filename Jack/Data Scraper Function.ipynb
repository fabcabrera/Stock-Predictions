{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb9c2572-f70c-4de3-b7e5-46970c9abd4f",
   "metadata": {},
   "source": [
    "# Stock Data Scraper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0db3fd3-03a0-497b-9a68-d2f494f06568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "#%pip install pytrends\n",
    "import pytrends\n",
    "from pytrends.request import TrendReq\n",
    "#%pip install pageviewapi\n",
    "import pageviewapi\n",
    "#%pip install yfinance\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbe7bb34-8317-4329-b018-5e092df305ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Big_scraper(kw_list_1, kw_list_2, ticker, start,end):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description:\n",
    "    ------------\n",
    "    \n",
    "    The function initially grabs historical, indexed, hourly data for when the keyword \n",
    "    was searched most as shown on Google Trends' Interest Over Time section.\n",
    "    It then cleans the data to show daily hits on the keyword in Google news.\n",
    "\n",
    "    \n",
    "    input:\n",
    "    -----\n",
    "    kw_list_1: List of up to 5 key words that will be scraped from google trends for the dates given.\n",
    "             Here, the scraping will pull the total posted items in google news that contains\n",
    "             one of the key words.\n",
    "    \n",
    "    kw_list_2: List of wikipedia article titles (unlimited length) that will pull the amount of\n",
    "            views the article recieved each day. \n",
    "\n",
    "    ticker: the ticker abriviation of the desired stock. Must be netered in as an all capitalized string \n",
    "    example Apple Inc. woud be \"AAPL\"\n",
    "             \n",
    "    start: the start of the desired timeline you want scrape. Date Must be entered in as \"YYYYMMDD\"\n",
    "    \n",
    "    end: the end of the desired timeline you want scrape. Date Must be entered in as \"YYYYMMDD\"\n",
    "             \n",
    "    return:\n",
    "    -------\n",
    "    \n",
    "    combined: a dataframe containing the sum of the daily keyword hits in google news (key words labeled _x),\n",
    "    \n",
    "    data frame cointaing stock info including open, close, high, low prices of the stock,\n",
    "    as well as the stocks daily trading volume and the amount if there was a split or dividend \n",
    "    preformed on the stock that day,\n",
    "    \n",
    "    and the sum of how many times key word wikipedia pages were viewed in a day (key words labeled _y)\n",
    "    \"\"\"\n",
    "    \n",
    "    year_s = int(start[0:4])\n",
    "    month_s = int(start[4:6])\n",
    "    day_s = int(start[6:8])\n",
    "    year_e = int(end[0:4])\n",
    "    month_e = int(end[4:6])\n",
    "    day_e = int(end[6:8])\n",
    "    \n",
    "    starter = pd.to_datetime(f\"'{year_s}-{month_s}-{day_s}'\")\n",
    "    ender = pd.to_datetime(f\"'{year_e}-{month_e}-{day_e}'\")\n",
    "    \n",
    "    \n",
    "    pytrends = TrendReq(hl='en-US', tz=360, retries=10)\n",
    "    jeff = pytrends.get_historical_interest(kw_list_1, \\\n",
    "                                 year_start = year_s, month_start = month_s, day_start = day_s, hour_start = 1, \\\n",
    "                                 year_end = year_e, month_end = month_e, day_end = day_e, hour_end = 23, \\\n",
    "                                 cat = 0, geo = '', gprop = 'news', sleep = 60)\n",
    "    \n",
    "    jeff = jeff.iloc[:, 0:-1] # eliminates the isPartial Column\n",
    "    jeff = jeff.reset_index().drop_duplicates(subset = \"date\") #removing duplicates from the index\n",
    "    jeff = jeff.groupby(pd.Grouper(key=\"date\", freq=\"D\")).mean() # coverts to the mean of daily scores\n",
    "\n",
    "    dow = yf.Ticker(\"^DJI\")\n",
    "    dow_h = dow.history(start=starter, end=ender)\n",
    "    dow_h = pd.DataFrame(dow_h)\n",
    "    dow_names = {\"Open\":\"dow_open\",\"Close\":\"dow_close\",\"Low\": \"dow_low\",\n",
    "    'High':'dow_high','Volume':'dow_vol'}\n",
    "    dow_h=dow_h.rename(dow_names, axis=1).drop([\"Dividends\",\"Stock Splits\"], axis=1)\n",
    "\n",
    "    nas = yf.Ticker(\"^IXIC\")\n",
    "    nas_h = nas.history(start=starter, end=ender)\n",
    "    nas_h = pd.DataFrame(nas_h)\n",
    "    nas_names = {\"Open\":\"nas_open\", \"Close\":\"nas_close\", \"Low\": \"nas_low\",\n",
    "    'High':'nas_high','Volume':'nas_vol'}\n",
    "    nas_h=nas_h.rename(nas_names, axis=1).drop([\"Dividends\",\"Stock Splits\"], axis=1)\n",
    "\n",
    "    market = dow_h.merge(nas_h,left_index=True, right_index=True, how=\"left\")\n",
    "    \n",
    "    tick = yf.Ticker(ticker)\n",
    "    hist = tick.history(start=starter, end=ender)\n",
    "    hist = pd.DataFrame(hist)\n",
    "    \n",
    "    combined = jeff.merge(hist, left_index=True, right_index=True, how=\"left\")\n",
    "    combined = combined.merge(market, left_index=True, right_index=True, how=\"left\")  \n",
    "    \n",
    "    d = pd.DataFrame()\n",
    "    for key_word in kw_list_2:\n",
    "        geoff = pageviewapi.per_article('en.wikipedia', key_word, start, end,\n",
    "                                    access='all-access', agent='all-agents', granularity='daily')\n",
    "        dicty = dict(geoff)\n",
    "        views = pd.DataFrame(dicty[\"items\"])\n",
    "        views[\"timestamp\"] = pd.to_datetime((views[\"timestamp\"]), format=\"%Y%m%d%H\")\n",
    "        views = views.set_index(\"timestamp\")\n",
    "        page = pd.Series(views[\"views\"])\n",
    "        d[key_word] = page\n",
    "        \n",
    "    combined = combined.merge(d, left_index=True, right_index=True, how=\"left\") \n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "243826e6-d950-4c2d-8e16-746f1b816167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apple</th>\n",
       "      <th>Apple Inc._x</th>\n",
       "      <th>IPhone_x</th>\n",
       "      <th>MacBook</th>\n",
       "      <th>MacOS</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>...</th>\n",
       "      <th>dow_low</th>\n",
       "      <th>dow_close</th>\n",
       "      <th>dow_vol</th>\n",
       "      <th>nas_open</th>\n",
       "      <th>nas_high</th>\n",
       "      <th>nas_low</th>\n",
       "      <th>nas_close</th>\n",
       "      <th>nas_vol</th>\n",
       "      <th>Apple Inc._y</th>\n",
       "      <th>IPhone_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-12-01</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.434783</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>167.266892</td>\n",
       "      <td>170.083311</td>\n",
       "      <td>164.320648</td>\n",
       "      <td>164.560349</td>\n",
       "      <td>152052500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34006.980469</td>\n",
       "      <td>34022.039062</td>\n",
       "      <td>496000000.0</td>\n",
       "      <td>15752.269531</td>\n",
       "      <td>15816.820312</td>\n",
       "      <td>15243.929688</td>\n",
       "      <td>15254.049805</td>\n",
       "      <td>6.266020e+09</td>\n",
       "      <td>14391</td>\n",
       "      <td>8014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-02</th>\n",
       "      <td>20.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.958333</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>158.538019</td>\n",
       "      <td>163.991063</td>\n",
       "      <td>157.599213</td>\n",
       "      <td>163.551620</td>\n",
       "      <td>136739200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34076.250000</td>\n",
       "      <td>34639.789062</td>\n",
       "      <td>466900000.0</td>\n",
       "      <td>15181.820312</td>\n",
       "      <td>15444.540039</td>\n",
       "      <td>15150.120117</td>\n",
       "      <td>15381.320312</td>\n",
       "      <td>5.390100e+09</td>\n",
       "      <td>14364</td>\n",
       "      <td>8072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-03</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.541667</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>163.811298</td>\n",
       "      <td>164.750104</td>\n",
       "      <td>159.516766</td>\n",
       "      <td>161.634064</td>\n",
       "      <td>118023100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34264.570312</td>\n",
       "      <td>34580.078125</td>\n",
       "      <td>439550000.0</td>\n",
       "      <td>15428.709961</td>\n",
       "      <td>15470.360352</td>\n",
       "      <td>14931.059570</td>\n",
       "      <td>15085.469727</td>\n",
       "      <td>5.859520e+09</td>\n",
       "      <td>13359</td>\n",
       "      <td>7546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-04</th>\n",
       "      <td>15.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.875000</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11606</td>\n",
       "      <td>7311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-05</th>\n",
       "      <td>17.375000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.625000</td>\n",
       "      <td>1.041667</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12245</td>\n",
       "      <td>7586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-06</th>\n",
       "      <td>14.291667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.416667</td>\n",
       "      <td>3.708333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.080946</td>\n",
       "      <td>167.666390</td>\n",
       "      <td>164.070964</td>\n",
       "      <td>165.109650</td>\n",
       "      <td>107497000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34633.429688</td>\n",
       "      <td>35227.031250</td>\n",
       "      <td>416720000.0</td>\n",
       "      <td>15117.629883</td>\n",
       "      <td>15281.990234</td>\n",
       "      <td>14931.610352</td>\n",
       "      <td>15225.150391</td>\n",
       "      <td>5.095960e+09</td>\n",
       "      <td>13862</td>\n",
       "      <td>8381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-07</th>\n",
       "      <td>16.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.875000</td>\n",
       "      <td>2.583333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>168.864855</td>\n",
       "      <td>171.361674</td>\n",
       "      <td>168.125791</td>\n",
       "      <td>170.962173</td>\n",
       "      <td>120405400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35423.988281</td>\n",
       "      <td>35719.429688</td>\n",
       "      <td>474940000.0</td>\n",
       "      <td>15510.910156</td>\n",
       "      <td>15720.089844</td>\n",
       "      <td>15507.660156</td>\n",
       "      <td>15686.919922</td>\n",
       "      <td>5.091220e+09</td>\n",
       "      <td>14563</td>\n",
       "      <td>8188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-08</th>\n",
       "      <td>15.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.875000</td>\n",
       "      <td>2.791667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>171.910980</td>\n",
       "      <td>175.736109</td>\n",
       "      <td>170.482792</td>\n",
       "      <td>174.857224</td>\n",
       "      <td>116998900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35602.648438</td>\n",
       "      <td>35754.750000</td>\n",
       "      <td>387650000.0</td>\n",
       "      <td>15690.650391</td>\n",
       "      <td>15792.639648</td>\n",
       "      <td>15618.879883</td>\n",
       "      <td>15786.990234</td>\n",
       "      <td>4.600800e+09</td>\n",
       "      <td>14027</td>\n",
       "      <td>7697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-09</th>\n",
       "      <td>18.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.208333</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>174.687436</td>\n",
       "      <td>176.525091</td>\n",
       "      <td>173.698690</td>\n",
       "      <td>174.337875</td>\n",
       "      <td>108923700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35577.140625</td>\n",
       "      <td>35754.691406</td>\n",
       "      <td>353020000.0</td>\n",
       "      <td>15720.540039</td>\n",
       "      <td>15796.049805</td>\n",
       "      <td>15511.120117</td>\n",
       "      <td>15517.370117</td>\n",
       "      <td>4.484230e+09</td>\n",
       "      <td>13975</td>\n",
       "      <td>7590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-10</th>\n",
       "      <td>22.208333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.208333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>174.987069</td>\n",
       "      <td>179.401443</td>\n",
       "      <td>174.467727</td>\n",
       "      <td>179.221664</td>\n",
       "      <td>115402700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35710.429688</td>\n",
       "      <td>35970.988281</td>\n",
       "      <td>361200000.0</td>\n",
       "      <td>15629.589844</td>\n",
       "      <td>15677.599609</td>\n",
       "      <td>15477.849609</td>\n",
       "      <td>15630.599609</td>\n",
       "      <td>4.395460e+09</td>\n",
       "      <td>12530</td>\n",
       "      <td>7226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-11</th>\n",
       "      <td>14.208333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.375000</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11235</td>\n",
       "      <td>6981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-12</th>\n",
       "      <td>15.708333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.291667</td>\n",
       "      <td>2.541667</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11840</td>\n",
       "      <td>6805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-13</th>\n",
       "      <td>19.291667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.458333</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.889532</td>\n",
       "      <td>181.898256</td>\n",
       "      <td>175.306648</td>\n",
       "      <td>175.516388</td>\n",
       "      <td>153237000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35609.531250</td>\n",
       "      <td>35650.949219</td>\n",
       "      <td>441110000.0</td>\n",
       "      <td>15621.269531</td>\n",
       "      <td>15637.059570</td>\n",
       "      <td>15408.250000</td>\n",
       "      <td>15413.280273</td>\n",
       "      <td>4.549170e+09</td>\n",
       "      <td>13919</td>\n",
       "      <td>7691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-14</th>\n",
       "      <td>21.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>1.458333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14161</td>\n",
       "      <td>7677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Apple  Apple Inc._x   IPhone_x   MacBook     MacOS  \\\n",
       "date                                                                 \n",
       "2021-12-01  17.000000           0.0  19.434783  2.000000  0.260870   \n",
       "2021-12-02  20.916667           0.0  24.958333  1.166667  0.000000   \n",
       "2021-12-03  16.000000           0.0  16.541667  2.625000  0.250000   \n",
       "2021-12-04  15.666667           0.0  23.875000  1.375000  0.000000   \n",
       "2021-12-05  17.375000           0.0  20.625000  1.041667  0.291667   \n",
       "2021-12-06  14.291667           0.0  18.416667  3.708333  0.000000   \n",
       "2021-12-07  16.500000           0.0  17.875000  2.583333  0.000000   \n",
       "2021-12-08  15.083333           0.0  23.875000  2.791667  0.000000   \n",
       "2021-12-09  18.041667           0.0  28.208333  2.375000  0.000000   \n",
       "2021-12-10  22.208333           0.0  24.208333  0.666667  0.000000   \n",
       "2021-12-11  14.208333           0.0  36.375000  3.083333  0.375000   \n",
       "2021-12-12  15.708333           0.0  23.291667  2.541667  0.291667   \n",
       "2021-12-13  19.291667           0.0  17.458333  2.625000  0.000000   \n",
       "2021-12-14  21.666667           0.0  22.333333  1.458333  0.416667   \n",
       "\n",
       "                  Open        High         Low       Close       Volume  ...  \\\n",
       "date                                                                     ...   \n",
       "2021-12-01  167.266892  170.083311  164.320648  164.560349  152052500.0  ...   \n",
       "2021-12-02  158.538019  163.991063  157.599213  163.551620  136739200.0  ...   \n",
       "2021-12-03  163.811298  164.750104  159.516766  161.634064  118023100.0  ...   \n",
       "2021-12-04         NaN         NaN         NaN         NaN          NaN  ...   \n",
       "2021-12-05         NaN         NaN         NaN         NaN          NaN  ...   \n",
       "2021-12-06  164.080946  167.666390  164.070964  165.109650  107497000.0  ...   \n",
       "2021-12-07  168.864855  171.361674  168.125791  170.962173  120405400.0  ...   \n",
       "2021-12-08  171.910980  175.736109  170.482792  174.857224  116998900.0  ...   \n",
       "2021-12-09  174.687436  176.525091  173.698690  174.337875  108923700.0  ...   \n",
       "2021-12-10  174.987069  179.401443  174.467727  179.221664  115402700.0  ...   \n",
       "2021-12-11         NaN         NaN         NaN         NaN          NaN  ...   \n",
       "2021-12-12         NaN         NaN         NaN         NaN          NaN  ...   \n",
       "2021-12-13  180.889532  181.898256  175.306648  175.516388  153237000.0  ...   \n",
       "2021-12-14         NaN         NaN         NaN         NaN          NaN  ...   \n",
       "\n",
       "                 dow_low     dow_close      dow_vol      nas_open  \\\n",
       "date                                                                \n",
       "2021-12-01  34006.980469  34022.039062  496000000.0  15752.269531   \n",
       "2021-12-02  34076.250000  34639.789062  466900000.0  15181.820312   \n",
       "2021-12-03  34264.570312  34580.078125  439550000.0  15428.709961   \n",
       "2021-12-04           NaN           NaN          NaN           NaN   \n",
       "2021-12-05           NaN           NaN          NaN           NaN   \n",
       "2021-12-06  34633.429688  35227.031250  416720000.0  15117.629883   \n",
       "2021-12-07  35423.988281  35719.429688  474940000.0  15510.910156   \n",
       "2021-12-08  35602.648438  35754.750000  387650000.0  15690.650391   \n",
       "2021-12-09  35577.140625  35754.691406  353020000.0  15720.540039   \n",
       "2021-12-10  35710.429688  35970.988281  361200000.0  15629.589844   \n",
       "2021-12-11           NaN           NaN          NaN           NaN   \n",
       "2021-12-12           NaN           NaN          NaN           NaN   \n",
       "2021-12-13  35609.531250  35650.949219  441110000.0  15621.269531   \n",
       "2021-12-14           NaN           NaN          NaN           NaN   \n",
       "\n",
       "                nas_high       nas_low     nas_close       nas_vol  \\\n",
       "date                                                                 \n",
       "2021-12-01  15816.820312  15243.929688  15254.049805  6.266020e+09   \n",
       "2021-12-02  15444.540039  15150.120117  15381.320312  5.390100e+09   \n",
       "2021-12-03  15470.360352  14931.059570  15085.469727  5.859520e+09   \n",
       "2021-12-04           NaN           NaN           NaN           NaN   \n",
       "2021-12-05           NaN           NaN           NaN           NaN   \n",
       "2021-12-06  15281.990234  14931.610352  15225.150391  5.095960e+09   \n",
       "2021-12-07  15720.089844  15507.660156  15686.919922  5.091220e+09   \n",
       "2021-12-08  15792.639648  15618.879883  15786.990234  4.600800e+09   \n",
       "2021-12-09  15796.049805  15511.120117  15517.370117  4.484230e+09   \n",
       "2021-12-10  15677.599609  15477.849609  15630.599609  4.395460e+09   \n",
       "2021-12-11           NaN           NaN           NaN           NaN   \n",
       "2021-12-12           NaN           NaN           NaN           NaN   \n",
       "2021-12-13  15637.059570  15408.250000  15413.280273  4.549170e+09   \n",
       "2021-12-14           NaN           NaN           NaN           NaN   \n",
       "\n",
       "            Apple Inc._y  IPhone_y  \n",
       "date                                \n",
       "2021-12-01         14391      8014  \n",
       "2021-12-02         14364      8072  \n",
       "2021-12-03         13359      7546  \n",
       "2021-12-04         11606      7311  \n",
       "2021-12-05         12245      7586  \n",
       "2021-12-06         13862      8381  \n",
       "2021-12-07         14563      8188  \n",
       "2021-12-08         14027      7697  \n",
       "2021-12-09         13975      7590  \n",
       "2021-12-10         12530      7226  \n",
       "2021-12-11         11235      6981  \n",
       "2021-12-12         11840      6805  \n",
       "2021-12-13         13919      7691  \n",
       "2021-12-14         14161      7677  \n",
       "\n",
       "[14 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example pull\n",
    "kw_list_1 = [\"Apple\", \"Apple Inc.\", \"IPhone\", \"MacBook\", \"MacOS\"]\n",
    "kw_list_2 = [\"Apple Inc.\", \"IPhone\"]\n",
    "Big_scraper(kw_list_1,kw_list_2,\"AAPL\",\"20211201\",\"20211214\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1299e6-0a3d-4293-a49b-10cc2fa46db5",
   "metadata": {},
   "source": [
    "## Individual Functions (with examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70b75c51-9afc-46dd-9689-e675759ac26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_trends(kw_list, start, end):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description:\n",
    "    ------------\n",
    "    \n",
    "    The function initially grabs historical, indexed, hourly data for when the keyword \n",
    "    was searched most as shown on Google Trends' Interest Over Time section.\n",
    "    It then cleans the data to show daily hits on the keyword in Google news.\n",
    "\n",
    "    \n",
    "    input:\n",
    "    -----\n",
    "    kw_list: List of up to 5 key words that will be scraped from the timeline given to the function.\n",
    "             Here, the scraping will pull the total posted items in google news. the contains\n",
    "             one of the key words.\n",
    "             \n",
    "    start: the start of the desired timeline you want scrape. Date Must be entered in as \"YYYYMMDD\"\n",
    "    \n",
    "    end: Self explanetory, Date Must be entered in as \"YYYYMMDD\"\n",
    "    \n",
    "             \n",
    "    return:\n",
    "    -------\n",
    "    \n",
    "    jeff: a dataframe containing the mean of the daily google trends index score for up to 5 keywords\n",
    "    \"\"\"\n",
    "    year_s = int(start[0:4])\n",
    "    month_s = int(start[4:6])\n",
    "    day_s = int(start[6:8])\n",
    "    year_e = int(end[0:4])\n",
    "    month_e = int(end[4:6])\n",
    "    day_e = int(end[6:8])\n",
    "      \n",
    "    pytrends = TrendReq(hl='en-US', tz=360, retries=10)\n",
    "    jeff = pytrends.get_historical_interest(kw_list, \\\n",
    "                                 year_start = year_s, month_start = month_s, day_start = day_s, hour_start = 1, \\\n",
    "                                 year_end = year_e, month_end = month_e, day_end = day_e, hour_end = 23, \\\n",
    "                                 cat = 0, geo = '', gprop = 'news', sleep = 60)\n",
    "    \n",
    "    jeff = jeff.iloc[:, 0:-1] # eliminates the isPartial Column\n",
    "    jeff = jeff.reset_index().drop_duplicates(subset = \"date\") #removing duplicates from the index\n",
    "    jeff = jeff.groupby(pd.Grouper(key=\"date\", freq=\"D\")).sum() # coverts to the sum of daily posts\n",
    "    \n",
    "    return jeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75ff70b7-82ad-40d4-8973-5a4a079c5e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apple</th>\n",
       "      <th>Apple Inc.</th>\n",
       "      <th>IPhone</th>\n",
       "      <th>MacBook</th>\n",
       "      <th>MacOS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>347</td>\n",
       "      <td>0</td>\n",
       "      <td>518</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02</th>\n",
       "      <td>451</td>\n",
       "      <td>0</td>\n",
       "      <td>433</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-03</th>\n",
       "      <td>412</td>\n",
       "      <td>0</td>\n",
       "      <td>467</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>424</td>\n",
       "      <td>0</td>\n",
       "      <td>382</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05</th>\n",
       "      <td>456</td>\n",
       "      <td>0</td>\n",
       "      <td>445</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Apple  Apple Inc.  IPhone  MacBook  MacOS\n",
       "date                                                 \n",
       "2021-01-01    347           0     518       26      0\n",
       "2021-01-02    451           0     433       45      0\n",
       "2021-01-03    412           0     467       25      0\n",
       "2021-01-04    424           0     382       49      0\n",
       "2021-01-05    456           0     445       32      0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeff1= google_trends(kw_list_1, \"20210101\",\"20210114\")\n",
    "jeff1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e6891dd-52ad-4e33-be9d-e6923df9534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_stats(ticker: str, start: str, end: str):\n",
    "    \"\"\"\n",
    "    Description: Scrapes historial daily stock data from the Yahoo Fince sight\n",
    "    and returns a dataframe containing daily open, close, high, low prices of the stock,\n",
    "    as well as the stocks daily trading volume and the amount if there was a split or dividend \n",
    "    preformed on the stock that day.\n",
    "    \n",
    "    inputs:\n",
    "    ------\n",
    "    ticker: the ticker abriviation of the desired stock. Must be netered in as an all capitalized string \n",
    "    example Apple Inc. woud be \"AAPL\"\n",
    "    \n",
    "    start: the start of the desired timeline you want scrape. Date Must be entered in as \"YYYYMMDD\"\n",
    "    \n",
    "    end: Self explanetory, Date Must be entered in as \"YYYYMMDD\"\n",
    "    \n",
    "    return:\n",
    "    ------\n",
    "    hist: dataframe containing open, close, high, low prices of the stock,\n",
    "    as well as the stocks daily trading volume and the amount if there was a split or dividend \n",
    "    preformed on the stock that day. \n",
    "    \n",
    "    As well as the open close, high, low, volume, of the NASDAQ and DOW Jones Indudtiral Average\n",
    "    \n",
    "    \"\"\"\n",
    "    year_s = int(start[0:4])\n",
    "    month_s = int(start[4:6])\n",
    "    day_s = int(start[6:8])\n",
    "    year_e = int(end[0:4])\n",
    "    month_e = int(end[4:6])\n",
    "    day_e = int(end[6:8])\n",
    "    \n",
    "    starter = pd.to_datetime(f\"'{year_s}-{month_s}-{day_s}'\")\n",
    "    ender = pd.to_datetime(f\"'{year_e}-{month_e}-{day_e}'\")\n",
    "    \n",
    "    dow = yf.Ticker(\"^DJI\")\n",
    "    dow_h = dow.history(start=starter, end=ender)\n",
    "    dow_h = pd.DataFrame(dow_h)\n",
    "    dow_names = {\"Open\":\"dow_open\",\"Close\":\"dow_close\",\"Low\": \"dow_low\",\n",
    "    'High':'dow_high','Volume':'dow_vol'}\n",
    "    dow_h=dow_h.rename(dow_names, axis=1).drop([\"Dividends\",\"Stock Splits\"], axis=1)\n",
    "\n",
    "    nas = yf.Ticker(\"^IXIC\")\n",
    "    nas_h = nas.history(start = starter, end = ender)\n",
    "    nas_h = pd.DataFrame(nas_h)\n",
    "    nas_names = {\"Open\":\"nas_open\", \"Close\":\"nas_close\", \"Low\": \"nas_low\",\n",
    "    'High':'nas_high','Volume':'nas_vol'}\n",
    "    nas_h=nas_h.rename(nas_names, axis=1).drop([\"Dividends\",\"Stock Splits\"], axis=1)\n",
    "\n",
    "    market = dow_h.merge(nas_h,left_index=True, right_index=True, how=\"left\")\n",
    "\n",
    "\n",
    "    tick = yf.Ticker(ticker)\n",
    "    hist = tick.history(start=starter, end=ender)\n",
    "    hist = pd.DataFrame(hist)\n",
    "\n",
    "    hist = hist.merge(market,left_index=True, right_index=True, how=\"left\")\n",
    "    \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42f09f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>dow_open</th>\n",
       "      <th>dow_high</th>\n",
       "      <th>dow_low</th>\n",
       "      <th>dow_close</th>\n",
       "      <th>dow_vol</th>\n",
       "      <th>nas_open</th>\n",
       "      <th>nas_high</th>\n",
       "      <th>nas_low</th>\n",
       "      <th>nas_close</th>\n",
       "      <th>nas_vol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>132.533082</td>\n",
       "      <td>132.622413</td>\n",
       "      <td>125.823047</td>\n",
       "      <td>128.453461</td>\n",
       "      <td>143301900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30627.470703</td>\n",
       "      <td>30674.279297</td>\n",
       "      <td>29881.820312</td>\n",
       "      <td>30223.890625</td>\n",
       "      <td>475080000</td>\n",
       "      <td>12958.519531</td>\n",
       "      <td>12958.719727</td>\n",
       "      <td>12543.240234</td>\n",
       "      <td>12698.450195</td>\n",
       "      <td>6546740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05</th>\n",
       "      <td>127.937286</td>\n",
       "      <td>130.766226</td>\n",
       "      <td>127.480679</td>\n",
       "      <td>130.041611</td>\n",
       "      <td>97664900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30204.250000</td>\n",
       "      <td>30504.890625</td>\n",
       "      <td>30141.779297</td>\n",
       "      <td>30391.599609</td>\n",
       "      <td>350910000</td>\n",
       "      <td>12665.650391</td>\n",
       "      <td>12828.269531</td>\n",
       "      <td>12665.650391</td>\n",
       "      <td>12818.959961</td>\n",
       "      <td>6904420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-06</th>\n",
       "      <td>126.775939</td>\n",
       "      <td>130.081327</td>\n",
       "      <td>125.445840</td>\n",
       "      <td>125.664215</td>\n",
       "      <td>155088000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30362.779297</td>\n",
       "      <td>31022.650391</td>\n",
       "      <td>30313.070312</td>\n",
       "      <td>30829.400391</td>\n",
       "      <td>500430000</td>\n",
       "      <td>12666.150391</td>\n",
       "      <td>12909.629883</td>\n",
       "      <td>12649.990234</td>\n",
       "      <td>12740.790039</td>\n",
       "      <td>7648340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-07</th>\n",
       "      <td>127.411196</td>\n",
       "      <td>130.657029</td>\n",
       "      <td>126.914892</td>\n",
       "      <td>129.952271</td>\n",
       "      <td>109578200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30901.179688</td>\n",
       "      <td>31193.400391</td>\n",
       "      <td>30897.859375</td>\n",
       "      <td>31041.130859</td>\n",
       "      <td>427810000</td>\n",
       "      <td>12867.339844</td>\n",
       "      <td>13090.910156</td>\n",
       "      <td>12867.339844</td>\n",
       "      <td>13067.480469</td>\n",
       "      <td>6777010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-08</th>\n",
       "      <td>131.451110</td>\n",
       "      <td>131.649643</td>\n",
       "      <td>129.267374</td>\n",
       "      <td>131.073929</td>\n",
       "      <td>105158200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31069.580078</td>\n",
       "      <td>31140.669922</td>\n",
       "      <td>30793.269531</td>\n",
       "      <td>31097.970703</td>\n",
       "      <td>381150000</td>\n",
       "      <td>13160.219727</td>\n",
       "      <td>13208.089844</td>\n",
       "      <td>13036.549805</td>\n",
       "      <td>13201.980469</td>\n",
       "      <td>7223660000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close     Volume  \\\n",
       "Date                                                                    \n",
       "2021-01-04  132.533082  132.622413  125.823047  128.453461  143301900   \n",
       "2021-01-05  127.937286  130.766226  127.480679  130.041611   97664900   \n",
       "2021-01-06  126.775939  130.081327  125.445840  125.664215  155088000   \n",
       "2021-01-07  127.411196  130.657029  126.914892  129.952271  109578200   \n",
       "2021-01-08  131.451110  131.649643  129.267374  131.073929  105158200   \n",
       "\n",
       "            Dividends  Stock Splits      dow_open      dow_high       dow_low  \\\n",
       "Date                                                                            \n",
       "2021-01-04          0             0  30627.470703  30674.279297  29881.820312   \n",
       "2021-01-05          0             0  30204.250000  30504.890625  30141.779297   \n",
       "2021-01-06          0             0  30362.779297  31022.650391  30313.070312   \n",
       "2021-01-07          0             0  30901.179688  31193.400391  30897.859375   \n",
       "2021-01-08          0             0  31069.580078  31140.669922  30793.269531   \n",
       "\n",
       "               dow_close    dow_vol      nas_open      nas_high       nas_low  \\\n",
       "Date                                                                            \n",
       "2021-01-04  30223.890625  475080000  12958.519531  12958.719727  12543.240234   \n",
       "2021-01-05  30391.599609  350910000  12665.650391  12828.269531  12665.650391   \n",
       "2021-01-06  30829.400391  500430000  12666.150391  12909.629883  12649.990234   \n",
       "2021-01-07  31041.130859  427810000  12867.339844  13090.910156  12867.339844   \n",
       "2021-01-08  31097.970703  381150000  13160.219727  13208.089844  13036.549805   \n",
       "\n",
       "               nas_close     nas_vol  \n",
       "Date                                  \n",
       "2021-01-04  12698.450195  6546740000  \n",
       "2021-01-05  12818.959961  6904420000  \n",
       "2021-01-06  12740.790039  7648340000  \n",
       "2021-01-07  13067.480469  6777010000  \n",
       "2021-01-08  13201.980469  7223660000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeff2= stock_stats(\"AAPL\", \"20210101\",\"20210114\")\n",
    "jeff2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0da18c01-703e-4323-9697-b86a78e09865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_scraper(kw_list: list, start_date: str, end_date: str):\n",
    "    '''\n",
    "    Description: Pulls the sum of how many times a wikipedia page was viewed that day\n",
    "    \n",
    "    inputs:\n",
    "    ------\n",
    "    \n",
    "    kw_list: list of wikipedia page names to be scrpapped, can be of unlimted length\n",
    "    \n",
    "    start_date: the start of the desired timeline you want scrape. Date Must be entered in as \"YYYYMMDD\"\n",
    "    \n",
    "    end_date: the end of the desired timeline you want scrape. Date Must be entered in as \"YYYYMMDD\"\n",
    "    \n",
    "    '''\n",
    "    d = pd.DataFrame()\n",
    "    for key_word in kw_list:\n",
    "        geoff = pageviewapi.per_article('en.wikipedia', key_word, start_date, end_date,\n",
    "                                    access='all-access', agent='all-agents', granularity='daily')\n",
    "        dicty = dict(geoff)\n",
    "        views = pd.DataFrame(dicty[\"items\"])\n",
    "        views[\"timestamp\"] = pd.to_datetime((views[\"timestamp\"]), format=\"%Y%m%d%H\")\n",
    "        views = views.set_index(\"timestamp\")\n",
    "        page = pd.Series(views[\"views\"])\n",
    "        d[key_word] = page\n",
    "        \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb35e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_list = [\"Apple\", \"Apple Inc.\", \"IPhone\", \"MacBook\", \"MacOS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec0b9af6-fffd-4f9d-ad31-75181a05fb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apple</th>\n",
       "      <th>Apple Inc.</th>\n",
       "      <th>IPhone</th>\n",
       "      <th>MacBook</th>\n",
       "      <th>MacOS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-12-01</th>\n",
       "      <td>8237</td>\n",
       "      <td>14391</td>\n",
       "      <td>8014</td>\n",
       "      <td>704</td>\n",
       "      <td>133006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-02</th>\n",
       "      <td>8299</td>\n",
       "      <td>14364</td>\n",
       "      <td>8072</td>\n",
       "      <td>619</td>\n",
       "      <td>42741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-03</th>\n",
       "      <td>8040</td>\n",
       "      <td>13359</td>\n",
       "      <td>7546</td>\n",
       "      <td>559</td>\n",
       "      <td>37979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-04</th>\n",
       "      <td>7673</td>\n",
       "      <td>11606</td>\n",
       "      <td>7311</td>\n",
       "      <td>604</td>\n",
       "      <td>26680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-05</th>\n",
       "      <td>7810</td>\n",
       "      <td>12245</td>\n",
       "      <td>7586</td>\n",
       "      <td>588</td>\n",
       "      <td>26376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Apple  Apple Inc.  IPhone  MacBook   MacOS\n",
       "timestamp                                             \n",
       "2021-12-01   8237       14391    8014      704  133006\n",
       "2021-12-02   8299       14364    8072      619   42741\n",
       "2021-12-03   8040       13359    7546      559   37979\n",
       "2021-12-04   7673       11606    7311      604   26680\n",
       "2021-12-05   7810       12245    7586      588   26376"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeff3 = wiki_scraper(kw_list, '20211201', '20211231')\n",
    "jeff3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66645712-5568-4bf4-9747-5ad4a2c8ed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joiner(google_trends, yahoo_finace, wiki_pagecount):\n",
    "    \"\"\"\n",
    "    Description: joins all stock data sets into one dataframe, after they have been cleaned and variables added\n",
    "    \n",
    "    input:\n",
    "    ------\n",
    "    google_trends: data frame counting daily hit counts for google news stories on specific key words\n",
    "    \n",
    "    yahoo_finace: data frame cointaing stock info including open, close, high, low prices of the stock,\n",
    "    as well as the stocks daily trading volume and the amount if there was a split or dividend \n",
    "    preformed on the stock that day.\n",
    "    \n",
    "    wiki_pagecount: the sum of how many times key wikipedia pages were viewed in a day\n",
    "    \"\"\"\n",
    "    \n",
    "    combined = google_trends.merge(yahoo_finace, left_index=True, right_index=True, how=\"left\")\n",
    "    combined = combined.merge(wiki_pagecount, left_index=True, right_index=True, how=\"left\")\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236ab656",
   "metadata": {},
   "source": [
    "### Data Scraper Without Google Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1758a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Market_scraper(kw_list_2, ticker, start,end):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description:\n",
    "    ------------\n",
    "    \n",
    "    The function initially grabs historical, indexed, hourly data for when the keyword \n",
    "    was searched most as shown on Google Trends' Interest Over Time section.\n",
    "    It then cleans the data to show daily hits on the keyword in Google news.\n",
    "\n",
    "    \n",
    "    input:\n",
    "    -----\n",
    "    ### kw_list_1: List of up to 5 key words that will be scraped from google trends for the dates given.\n",
    "             Here, the scraping will pull the total posted items in google news that contains\n",
    "             one of the key words ### removed to be edited and replaced later .\n",
    "    \n",
    "    kw_list_2: List of wikipedia article titles (unlimited length) that will pull the amount of\n",
    "            views the article recieved each day. \n",
    "\n",
    "    ticker: the ticker abriviation of the desired stock. Must be netered in as an all capitalized string \n",
    "    example Apple Inc. woud be \"AAPL\"\n",
    "             \n",
    "    start: the start of the desired timeline you want scrape. Date Must be entered in as \"YYYYMMDD\"\n",
    "    \n",
    "    end: the end of the desired timeline you want scrape. Date Must be entered in as \"YYYYMMDD\"\n",
    "             \n",
    "    return:\n",
    "    -------\n",
    "    \n",
    "    ### combined: a dataframe containing the sum of the daily keyword hits in google news (key words labeled _x) ### to be edited,\n",
    "    \n",
    "    the individual stock info including open, close, high, low prices of the stock,\n",
    "    as well as the stocks daily trading volume and the amount if there was a split or dividend \n",
    "    preformed on the stock that day,\n",
    "\n",
    "    as well as the open close, high, low, volume, of the NASDAQ and DOW Jones Indudtiral Average\n",
    "    \n",
    "    and the sum of how many times key word wikipedia pages were viewed in a day (key words labeled _y)\n",
    "    \"\"\"\n",
    "    \n",
    "    year_s = int(start[0:4])\n",
    "    month_s = int(start[4:6])\n",
    "    day_s = int(start[6:8])\n",
    "    year_e = int(end[0:4])\n",
    "    month_e = int(end[4:6])\n",
    "    day_e = int(end[6:8])\n",
    "    \n",
    "    starter = pd.to_datetime(f\"'{year_s}-{month_s}-{day_s}'\")\n",
    "    ender = pd.to_datetime(f\"'{year_e}-{month_e}-{day_e}'\")\n",
    "    \n",
    "    dow = yf.Ticker(\"^DJI\")\n",
    "    dow_h = dow.history(start=starter, end=ender)\n",
    "    dow_h = pd.DataFrame(dow_h)\n",
    "    dow_names = {\"Open\":\"dow_open\",\"Close\":\"dow_close\",\"Low\": \"dow_low\",\n",
    "    'High':'dow_high','Volume':'dow_vol'}\n",
    "    dow_h=dow_h.rename(dow_names, axis=1).drop([\"Dividends\",\"Stock Splits\"], axis=1)\n",
    "\n",
    "    nas = yf.Ticker(\"^IXIC\")\n",
    "    nas_h = nas.history(start=starter, end=ender)\n",
    "    nas_h = pd.DataFrame(nas_h)\n",
    "    nas_names = {\"Open\":\"nas_open\", \"Close\":\"nas_close\", \"Low\": \"nas_low\",\n",
    "    'High':'nas_high','Volume':'nas_vol'}\n",
    "    nas_h=nas_h.rename(nas_names, axis=1).drop([\"Dividends\",\"Stock Splits\"], axis=1)\n",
    "\n",
    "    market = dow_h.merge(nas_h,left_index=True, right_index=True, how=\"left\")\n",
    "    \n",
    "    \n",
    "    tick = yf.Ticker(ticker)\n",
    "    hist = tick.history(start=starter, end=ender)\n",
    "    hist = pd.DataFrame(hist)\n",
    "    \n",
    "    combined = hist.merge(market, left_index=True, right_index=True, how=\"left\") \n",
    "\n",
    "    d = pd.DataFrame()\n",
    "    for key_word in kw_list_2:\n",
    "        geoff = pageviewapi.per_article('en.wikipedia', key_word, start, end,\n",
    "                                    access='all-access', agent='all-agents', granularity='daily')\n",
    "        dicty = dict(geoff)\n",
    "        views = pd.DataFrame(dicty[\"items\"])\n",
    "        views[\"timestamp\"] = pd.to_datetime((views[\"timestamp\"]), format=\"%Y%m%d%H\")\n",
    "        views = views.set_index(\"timestamp\")\n",
    "        page = pd.Series(views[\"views\"])\n",
    "        d[key_word] = page\n",
    "        \n",
    "    combined = combined.merge(d, left_index=True, right_index=True, how=\"right\") \n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36421aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>dow_open</th>\n",
       "      <th>dow_high</th>\n",
       "      <th>dow_low</th>\n",
       "      <th>...</th>\n",
       "      <th>nas_open</th>\n",
       "      <th>nas_high</th>\n",
       "      <th>nas_low</th>\n",
       "      <th>nas_close</th>\n",
       "      <th>nas_vol</th>\n",
       "      <th>Apple</th>\n",
       "      <th>Apple Inc.</th>\n",
       "      <th>IPhone</th>\n",
       "      <th>MacBook</th>\n",
       "      <th>MacOS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2636</td>\n",
       "      <td>12694</td>\n",
       "      <td>7252</td>\n",
       "      <td>511</td>\n",
       "      <td>24790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2857</td>\n",
       "      <td>14297</td>\n",
       "      <td>7816</td>\n",
       "      <td>618</td>\n",
       "      <td>27483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2952</td>\n",
       "      <td>15899</td>\n",
       "      <td>8019</td>\n",
       "      <td>698</td>\n",
       "      <td>28429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>132.533082</td>\n",
       "      <td>132.622413</td>\n",
       "      <td>125.823047</td>\n",
       "      <td>128.453461</td>\n",
       "      <td>143301900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30627.470703</td>\n",
       "      <td>30674.279297</td>\n",
       "      <td>29881.820312</td>\n",
       "      <td>...</td>\n",
       "      <td>12958.519531</td>\n",
       "      <td>12958.719727</td>\n",
       "      <td>12543.240234</td>\n",
       "      <td>12698.450195</td>\n",
       "      <td>6.546740e+09</td>\n",
       "      <td>3529</td>\n",
       "      <td>17389</td>\n",
       "      <td>8188</td>\n",
       "      <td>691</td>\n",
       "      <td>35098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05</th>\n",
       "      <td>127.937286</td>\n",
       "      <td>130.766226</td>\n",
       "      <td>127.480679</td>\n",
       "      <td>130.041611</td>\n",
       "      <td>97664900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30204.250000</td>\n",
       "      <td>30504.890625</td>\n",
       "      <td>30141.779297</td>\n",
       "      <td>...</td>\n",
       "      <td>12665.650391</td>\n",
       "      <td>12828.269531</td>\n",
       "      <td>12665.650391</td>\n",
       "      <td>12818.959961</td>\n",
       "      <td>6.904420e+09</td>\n",
       "      <td>3365</td>\n",
       "      <td>17277</td>\n",
       "      <td>7997</td>\n",
       "      <td>707</td>\n",
       "      <td>35234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close       Volume  \\\n",
       "timestamp                                                                 \n",
       "2021-01-01         NaN         NaN         NaN         NaN          NaN   \n",
       "2021-01-02         NaN         NaN         NaN         NaN          NaN   \n",
       "2021-01-03         NaN         NaN         NaN         NaN          NaN   \n",
       "2021-01-04  132.533082  132.622413  125.823047  128.453461  143301900.0   \n",
       "2021-01-05  127.937286  130.766226  127.480679  130.041611   97664900.0   \n",
       "\n",
       "            Dividends  Stock Splits      dow_open      dow_high       dow_low  \\\n",
       "timestamp                                                                       \n",
       "2021-01-01        NaN           NaN           NaN           NaN           NaN   \n",
       "2021-01-02        NaN           NaN           NaN           NaN           NaN   \n",
       "2021-01-03        NaN           NaN           NaN           NaN           NaN   \n",
       "2021-01-04        0.0           0.0  30627.470703  30674.279297  29881.820312   \n",
       "2021-01-05        0.0           0.0  30204.250000  30504.890625  30141.779297   \n",
       "\n",
       "            ...      nas_open      nas_high       nas_low     nas_close  \\\n",
       "timestamp   ...                                                           \n",
       "2021-01-01  ...           NaN           NaN           NaN           NaN   \n",
       "2021-01-02  ...           NaN           NaN           NaN           NaN   \n",
       "2021-01-03  ...           NaN           NaN           NaN           NaN   \n",
       "2021-01-04  ...  12958.519531  12958.719727  12543.240234  12698.450195   \n",
       "2021-01-05  ...  12665.650391  12828.269531  12665.650391  12818.959961   \n",
       "\n",
       "                 nas_vol  Apple  Apple Inc.  IPhone  MacBook  MacOS  \n",
       "timestamp                                                            \n",
       "2021-01-01           NaN   2636       12694    7252      511  24790  \n",
       "2021-01-02           NaN   2857       14297    7816      618  27483  \n",
       "2021-01-03           NaN   2952       15899    8019      698  28429  \n",
       "2021-01-04  6.546740e+09   3529       17389    8188      691  35098  \n",
       "2021-01-05  6.904420e+09   3365       17277    7997      707  35234  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple = Market_scraper(kw_list_1,\"AAPL\",\"20210101\",\"20211231\")\n",
    "apple.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f3178e",
   "metadata": {},
   "source": [
    "## Variable Calculation, Wiki Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0312e638",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_list = [\"Apple Inc.\", \"IPhone\", \"MacBook\", \"MacOS\", \"Apple Watch\"]\n",
    "\n",
    "apple_wiki = wiki_scraper(kw_list, \"20190101\", \"20220425\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "717f4bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_wiki[\"Wiki_total\"] = (apple_wiki[\"Apple Inc.\"] + apple_wiki[\"IPhone\"] + apple_wiki[\"MacBook\"] + apple_wiki[\"MacOS\"] + apple_wiki[\"Apple Watch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a7a926e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apple Inc.</th>\n",
       "      <th>IPhone</th>\n",
       "      <th>MacBook</th>\n",
       "      <th>MacOS</th>\n",
       "      <th>Apple Watch</th>\n",
       "      <th>Wiki_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>9342</td>\n",
       "      <td>8377</td>\n",
       "      <td>713</td>\n",
       "      <td>3258</td>\n",
       "      <td>1864</td>\n",
       "      <td>23554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02</th>\n",
       "      <td>12458</td>\n",
       "      <td>9109</td>\n",
       "      <td>881</td>\n",
       "      <td>4518</td>\n",
       "      <td>2472</td>\n",
       "      <td>29438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>17971</td>\n",
       "      <td>10870</td>\n",
       "      <td>865</td>\n",
       "      <td>4525</td>\n",
       "      <td>2513</td>\n",
       "      <td>36744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>16865</td>\n",
       "      <td>9986</td>\n",
       "      <td>855</td>\n",
       "      <td>4828</td>\n",
       "      <td>2368</td>\n",
       "      <td>34902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-05</th>\n",
       "      <td>13002</td>\n",
       "      <td>9762</td>\n",
       "      <td>849</td>\n",
       "      <td>4120</td>\n",
       "      <td>3189</td>\n",
       "      <td>30922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Apple Inc.  IPhone  MacBook  MacOS  Apple Watch  Wiki_total\n",
       "timestamp                                                              \n",
       "2019-01-01        9342    8377      713   3258         1864       23554\n",
       "2019-01-02       12458    9109      881   4518         2472       29438\n",
       "2019-01-03       17971   10870      865   4525         2513       36744\n",
       "2019-01-04       16865    9986      855   4828         2368       34902\n",
       "2019-01-05       13002    9762      849   4120         3189       30922"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_wiki.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7d6e7bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Momentum_1\n",
    "apple_wiki[\"Wiki_Moment_1\"] =  (apple_wiki[\"Wiki_total\"] / apple_wiki[\"Wiki_total\"].shift(7)) * 100\n",
    "# Momentum_2\n",
    "apple_wiki[\"Wiki_Moment_2\"] =  (apple_wiki[\"Wiki_total\"] - apple_wiki[\"Wiki_total\"].shift(7)) * 100\n",
    "\n",
    "# Momentum_1_s three day shift (instead of 7)\n",
    "apple_wiki[\"Wiki_Moment_1_s\"] =  (apple_wiki[\"Wiki_total\"] / apple_wiki[\"Wiki_total\"].shift(3)) * 100\n",
    "# Momentum_2_s\n",
    "apple_wiki[\"Wiki_Moment_2_s\"] =  (apple_wiki[\"Wiki_total\"] - apple_wiki[\"Wiki_total\"].shift(3)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "669b9baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2019-01-01             NaN\n",
       "2019-01-02    25025.000000\n",
       "2019-01-03    29058.000000\n",
       "2019-01-04    31159.500000\n",
       "2019-01-05    31100.125000\n",
       "                  ...     \n",
       "2022-04-21    56468.607143\n",
       "2022-04-22    55352.892857\n",
       "2022-04-23    55864.035714\n",
       "2022-04-24    54365.285714\n",
       "2022-04-25    55309.571429\n",
       "Name: Wiki_EMA, Length: 1211, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Moving average\n",
    "apple_wiki[\"Wiki_MAvg\"] = apple_wiki[\"Wiki_total\"].rolling(\"7d\").mean()\n",
    "# Disparity\n",
    "apple_wiki[\"Disparity\"] = (apple_wiki[\"Wiki_total\"]/apple_wiki[\"Wiki_MAvg\"]) * 100\n",
    "# Rate of Change Normal Way\n",
    "apple_wiki[\"Wiki_ROC\"] = (apple_wiki[\"Wiki_total\"]-apple_wiki[\"Wiki_total\"].shift(7))/(apple_wiki[\"Wiki_total\"].shift(7)) *100\n",
    "apple_wiki[\"Wiki_ROC_s\"] = (apple_wiki[\"Wiki_total\"]-apple_wiki[\"Wiki_total\"].shift(3))/(apple_wiki[\"Wiki_total\"].shift(3)) *100\n",
    "#Rate of Change Paper Way (doesn't make sense but just in case)\n",
    "apple_wiki['Wiki_Rocp'] = (apple_wiki[\"Wiki_total\"]/apple_wiki[\"Wiki_Moment_2\"]) *100\n",
    "# Exponential Moving Average\n",
    "apple_wiki[\"Wiki_EMA\"] = (apple_wiki[\"Wiki_total\"]-apple_wiki[\"Wiki_MAvg\"].shift(1))*(2/(7+1))+apple_wiki[\"Wiki_MAvg\"].shift(1)\n",
    "apple_wiki[\"Wiki_EMA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c16d8f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2019-01-01    0\n",
       "2019-01-02    1\n",
       "2019-01-03    1\n",
       "2019-01-04    1\n",
       "2019-01-05    0\n",
       "             ..\n",
       "2022-04-21    0\n",
       "2022-04-22    0\n",
       "2022-04-23    1\n",
       "2022-04-24    0\n",
       "2022-04-25    1\n",
       "Name: Wiki_MAvg_Move, Length: 1211, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_wiki[\"Wiki_MAvg_Move\"] = apple_wiki[\"Wiki_MAvg\"] > apple_wiki[\"Wiki_MAvg\"].shift(1) \n",
    "apple_wiki[\"Wiki_MAvg_Move\"] = apple_wiki[\"Wiki_MAvg_Move\"].replace({True:1,False: 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0f7c6ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apple Inc.</th>\n",
       "      <th>IPhone</th>\n",
       "      <th>MacBook</th>\n",
       "      <th>MacOS</th>\n",
       "      <th>Apple Watch</th>\n",
       "      <th>Wiki_total</th>\n",
       "      <th>Wiki_Moment_1</th>\n",
       "      <th>Wiki_Moment_2</th>\n",
       "      <th>Wiki_Moment_1_s</th>\n",
       "      <th>Wiki_Moment_2_s</th>\n",
       "      <th>Wiki_MAvg</th>\n",
       "      <th>Disparity</th>\n",
       "      <th>Wiki_ROC</th>\n",
       "      <th>Wiki_ROC_s</th>\n",
       "      <th>Wiki_Rocp</th>\n",
       "      <th>Wiki_EMA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>9342</td>\n",
       "      <td>8377</td>\n",
       "      <td>713</td>\n",
       "      <td>3258</td>\n",
       "      <td>1864</td>\n",
       "      <td>23554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23554.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02</th>\n",
       "      <td>12458</td>\n",
       "      <td>9109</td>\n",
       "      <td>881</td>\n",
       "      <td>4518</td>\n",
       "      <td>2472</td>\n",
       "      <td>29438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26496.0</td>\n",
       "      <td>111.103563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25025.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>17971</td>\n",
       "      <td>10870</td>\n",
       "      <td>865</td>\n",
       "      <td>4525</td>\n",
       "      <td>2513</td>\n",
       "      <td>36744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29912.0</td>\n",
       "      <td>122.840332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29058.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>16865</td>\n",
       "      <td>9986</td>\n",
       "      <td>855</td>\n",
       "      <td>4828</td>\n",
       "      <td>2368</td>\n",
       "      <td>34902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148.178653</td>\n",
       "      <td>1134800.0</td>\n",
       "      <td>31159.5</td>\n",
       "      <td>112.010783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.178653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31159.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-05</th>\n",
       "      <td>13002</td>\n",
       "      <td>9762</td>\n",
       "      <td>849</td>\n",
       "      <td>4120</td>\n",
       "      <td>3189</td>\n",
       "      <td>30922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.041103</td>\n",
       "      <td>148400.0</td>\n",
       "      <td>31112.0</td>\n",
       "      <td>99.389303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.041103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31100.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Apple Inc.  IPhone  MacBook  MacOS  Apple Watch  Wiki_total  \\\n",
       "timestamp                                                                 \n",
       "2019-01-01        9342    8377      713   3258         1864       23554   \n",
       "2019-01-02       12458    9109      881   4518         2472       29438   \n",
       "2019-01-03       17971   10870      865   4525         2513       36744   \n",
       "2019-01-04       16865    9986      855   4828         2368       34902   \n",
       "2019-01-05       13002    9762      849   4120         3189       30922   \n",
       "\n",
       "            Wiki_Moment_1  Wiki_Moment_2  Wiki_Moment_1_s  Wiki_Moment_2_s  \\\n",
       "timestamp                                                                    \n",
       "2019-01-01            NaN            NaN              NaN              NaN   \n",
       "2019-01-02            NaN            NaN              NaN              NaN   \n",
       "2019-01-03            NaN            NaN              NaN              NaN   \n",
       "2019-01-04            NaN            NaN       148.178653        1134800.0   \n",
       "2019-01-05            NaN            NaN       105.041103         148400.0   \n",
       "\n",
       "            Wiki_MAvg   Disparity  Wiki_ROC  Wiki_ROC_s  Wiki_Rocp   Wiki_EMA  \n",
       "timestamp                                                                      \n",
       "2019-01-01    23554.0  100.000000       NaN         NaN        NaN        NaN  \n",
       "2019-01-02    26496.0  111.103563       NaN         NaN        NaN  25025.000  \n",
       "2019-01-03    29912.0  122.840332       NaN         NaN        NaN  29058.000  \n",
       "2019-01-04    31159.5  112.010783       NaN   48.178653        NaN  31159.500  \n",
       "2019-01-05    31112.0   99.389303       NaN    5.041103        NaN  31100.125  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_wiki.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e476cb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Wiki_variables(df):\n",
    "    '''\n",
    "    Description: Returns new wiki variables from original dataframe imported from wiki_scraper\n",
    "\n",
    "    Warning: You must calcualte Wiki_Total First, the sum of all the wiki pages daily hit counts\n",
    "    \n",
    "    '''\n",
    "    # Momentum_1\n",
    "    df[\"Wiki_Moment_1\"] =  (df[\"Wiki_total\"] / df[\"Wiki_total\"].shift(7)) * 100\n",
    "    # Momentum_2\n",
    "    df[\"Wiki_Moment_2\"] =  (df[\"Wiki_total\"] - df[\"Wiki_total\"].shift(7)) * 100\n",
    "    # Momentum_1_s three day shift (instead of 7)\n",
    "    df[\"Wiki_Moment_1_s\"] =  (df[\"Wiki_total\"] / df[\"Wiki_total\"].shift(3)) * 100\n",
    "    # Momentum_2_s\n",
    "    df[\"Wiki_Moment_2_s\"] =  (df[\"Wiki_total\"] - df[\"Wiki_total\"].shift(3)) * 100\n",
    "    # Moving average\n",
    "    df[\"Wiki_MAvg\"] = df[\"Wiki_total\"].rolling(\"7d\").mean()\n",
    "    # Moving average 3 day\n",
    "    df[\"Wiki_MAvg_s\"] = df[\"Wiki_total\"].rolling(\"3d\").mean()\n",
    "    # Disparity\n",
    "    df[\"Wiki_Disparity\"] = (df[\"Wiki_total\"]/df[\"Wiki_MAvg\"]) * 100\n",
    "    # Disparity 3 day\n",
    "    df[\"Wiki_Disparity_s\"] = (df[\"Wiki_total\"]/df[\"Wiki_MAvg_s\"]) * 100\n",
    "    # Rate of Change Normal Way\n",
    "    df[\"Wiki_ROC\"] = (df[\"Wiki_total\"]-df[\"Wiki_total\"].shift(7))/(df[\"Wiki_total\"].shift(7)) *100\n",
    "    df[\"Wiki_ROC_s\"] = (df[\"Wiki_total\"]-df[\"Wiki_total\"].shift(3))/(df[\"Wiki_total\"].shift(3)) *100\n",
    "    #Rate of Change Paper Way (doesn't make sense but just in case)\n",
    "    df['Wiki_Rocp'] = (df[\"Wiki_total\"]/df[\"Wiki_Moment_2\"]) *100\n",
    "    # Exponential Moving Average\n",
    "    df[\"Wiki_EMA\"] = (df[\"Wiki_total\"]-df[\"Wiki_MAvg\"].shift(1))*(2/(7+1))+df[\"Wiki_MAvg\"].shift(1)\n",
    "\n",
    "    # calculating the Relative Strength Index, based on 14 day window\n",
    "    df[\"Wiki_diff\"] = df[\"Wiki_total\"].diff(1)\n",
    "    df[\"Wiki_gain\"] = df[\"Wiki_diff\"].clip(lower=0).round(2) #keeps all values above or below a given threshold, lower=lower bound\n",
    "    df[\"Wiki_loss\"] = df[\"Wiki_diff\"].clip(upper=0).round(2)\n",
    "    df['Wiki_avg_gain'] = df['Wiki_gain'].rolling(14).mean()\n",
    "    df['Wiki_avg_loss'] = df['Wiki_loss'].rolling(14).mean()\n",
    "    df['Wiki_rs'] = df['Wiki_avg_gain'] / df['Wiki_avg_loss']\n",
    "    df['Wiki_RSI'] = 100 - (100 / (1.0 + df['Wiki_rs']))\n",
    "\n",
    "    # Calculatiing the Move Variables \n",
    "    df[\"Wiki_Move\"] = df[\"Wiki_total\"] > df[\"Wiki_total\"].shift(1) \n",
    "    df[\"Wiki_Move\"] = df[\"Wiki_Move\"].replace({True:1,False: 0})\n",
    "    \n",
    "      \n",
    "    df[\"Wiki_MAvg_Move\"] = df[\"Wiki_MAvg\"] > df[\"Wiki_MAvg\"].shift(1) \n",
    "    df[\"Wiki_MAvg_Move\"] = df[\"Wiki_MAvg_Move\"].replace({True:1,False: 0})\n",
    "    df[\"Wiki_MAvg_s_Move\"] = df[\"Wiki_MAvg_s\"] > df[\"Wiki_MAvg_s\"].shift(1) \n",
    "    df[\"Wiki_MAvg_s_Move\"] = df[\"Wiki_MAvg_s_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "    df[\"Wiki_EMA_Move\"] = df[\"Wiki_EMA\"] > df[\"Wiki_EMA\"].shift(1) \n",
    "    df[\"Wiki_EMA_Move\"] = df[\"Wiki_EMA_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "    df[\"Wiki_Disparity_Move\"] = df[\"Wiki_Disparity\"] > df[\"Wiki_Disparity\"].shift(1) \n",
    "    df[\"Wiki_Disparity_Move\"] = df[\"Wiki_Disparity_Move\"].replace({True:1,False: 0})\n",
    "    df[\"Wiki_Disparity_s_Move\"] = df[\"Wiki_Disparity_s\"] > df[\"Wiki_Disparity_s\"].shift(1) \n",
    "    df[\"Wiki_Disparity_s_Move\"] = df[\"Wiki_Disparity_s_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "    df[\"Wiki_RSI_Move\"] = df[\"Wiki_RSI\"] > df[\"Wiki_RSI\"].shift(1) \n",
    "    df[\"Wiki_RSI_Move\"] = df[\"Wiki_RSI_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028e0118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Google_variables(df):\n",
    "    # Momentum 1\n",
    "    df[\"Google_Moment_1\"] =  (df[\"Google_total\"] / df[\"Google_total\"].shift(7)) * 100\n",
    "    # Momentum_2\n",
    "    df[\"Google_Moment_2\"] =  (df[\"Google_total\"] - df[\"Google_total\"].shift(7)) * 100\n",
    "    # Momentum_1_s three day shift (instead of 7)\n",
    "    df[\"Google_Moment_1_s\"] =  (df[\"Google_total\"] / df[\"Google_total\"].shift(3)) * 100\n",
    "    # Momentum_2_s\n",
    "    df[\"Google_Moment_2_s\"] =  (df[\"Google_total\"] - df[\"Google_total\"].shift(3)) * 100\n",
    "    # Moving average\n",
    "    df[\"Google_MAvg\"] = df[\"Google_total\"].rolling(\"7d\").mean()\n",
    "    # Disparity\n",
    "    df[\"Disparity\"] = (df[\"Google_total\"]/df[\"Google_MAvg\"]) * 100\n",
    "    # Rate of Change Normal Way\n",
    "    df[\"Google_ROC\"] = (df[\"Google_total\"]-df[\"Google_total\"].shift(7))/(df[\"Google_total\"].shift(7)) *100\n",
    "    df[\"Google_ROC_s\"] = (df[\"Google_total\"]-df[\"Google_total\"].shift(3))/(df[\"Google_total\"].shift(3)) *100\n",
    "    #Rate of Change Paper Way (doesn't make sense but just in case)\n",
    "    df['Google_Rocp'] = (df[\"Google_total\"]/df[\"Google_Moment_2\"]) *100\n",
    "    # Exponential Moving Average\n",
    "    df[\"Google_EMA\"] = (df[\"Google_total\"]-df[\"Google_MAvg\"].shift(1))*(2/(7+1))+df[\"Google_MAvg\"].shift(1)\n",
    "\n",
    "    # calculating the Relative Strength Index, based on 14 day window\n",
    "    df[\"Google_diff\"] = df[\"Google_total\"].diff(1)\n",
    "    df[\"Google_gain\"] = df[\"Google_diff\"].clip(lower=0).round(2) #keeps all values above or below a given threshold, lower=lower bound\n",
    "    df[\"Google_loss\"] = df[\"Google_diff\"].clip(upper=0).round(2)\n",
    "    df['Google_avg_gain'] = df['Google_gain'].rolling(14).mean()\n",
    "    df['Google_avg_loss'] = df['Google_loss'].rolling(14).mean()\n",
    "    df['Google_rs'] = df['Google_avg_gain'] / df['Google_avg_loss']\n",
    "    df['Google_RSI'] = 100 - (100 / (1.0 + df['Google_rs']))\n",
    "\n",
    "    # Calculatiing the Move Variables \n",
    "    df[\"Google_Move\"] = df[\"Google_total\"] > df[\"Google_total\"].shift(1) \n",
    "    df[\"Google_Move\"] = df[\"Google_Move\"].replace({True:1,False: 0})\n",
    "    \n",
    "    df[\"Google_MAvg_Move\"] = df[\"Google_MAvg\"] > df[\"Google_MAvg\"].shift(1) \n",
    "    df[\"Google_MAvg_Move\"] = df[\"Google_MAvg_Move\"].replace({True:1,False: 0})\n",
    "    df[\"Google_MAvg_s_Move\"] = df[\"Google_MAvg_s\"] > df[\"Google_MAvg_s\"].shift(1) \n",
    "    df[\"Google_MAvg_s_Move\"] = df[\"Google_MAvg_s_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "    df[\"Google_EMA_Move\"] = df[\"Google_EMA\"] > df[\"Google_EMA\"].shift(1) \n",
    "    df[\"Google_EMA_Move\"] = df[\"Google_EMA_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "    df[\"Google_Disparity_Move\"] = df[\"Google_Disparity\"] > df[\"Google_Disparity\"].shift(1) \n",
    "    df[\"Google_Disparity_Move\"] = df[\"Google_Disparity_Move\"].replace({True:1,False: 0})\n",
    "    df[\"Google_Disparity_s_Move\"] = df[\"Google_Disparity_s\"] > df[\"Google_Disparity_s\"].shift(1) \n",
    "    df[\"Google_Disparity_s_Move\"] = df[\"Google_Disparity_s_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "    df[\"Google_RSI_Move\"] = df[\"Google_RSI\"] > df[\"Google_RSI\"].shift(1) \n",
    "    df[\"Google_RSI_Move\"] = df[\"Google_RSI_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b960002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stock_variables(df):\n",
    "    # Momentum 1\n",
    "    df[\"Stock_Moment_1\"] =  (df[\"Close\"] / df[\"Close\"].shift(5)) * 100\n",
    "    # Momentum_2\n",
    "    df[\"Stock_Moment_2\"] =  (df[\"Close\"] - df[\"Close\"].shift(5)) * 100\n",
    "    # Momentum_1_s three day shift (instead of 5)\n",
    "    df[\"Stock_Moment_1_s\"] =  (df[\"Close\"] / df[\"Close\"].shift(3)) * 100\n",
    "    # Momentum_2_s\n",
    "    df[\"Stock_Moment_2_s\"] =  (df[\"Close\"] - df[\"Close\"].shift(3)) * 100\n",
    "    # Moving average\n",
    "    df[\"Stock_MAvg\"] = df[\"Close\"].rolling(\"5d\").mean()\n",
    "    # Disparity\n",
    "    df[\"Disparity\"] = (df[\"Close\"]/df[\"Stock_MAvg\"]) * 100\n",
    "    # Rate of Change Normal Way\n",
    "    df[\"Stock_ROC\"] = (df[\"Close\"]-df[\"Close\"].shift(5))/(df[\"Close\"].shift(5)) *100\n",
    "    df[\"Stock_ROC_s\"] = (df[\"Close\"]-df[\"Close\"].shift(3))/(df[\"Close\"].shift(3)) *100\n",
    "    #Rate of Change Paper Way (doesn't make sense but just in case)\n",
    "    df['Stock_Rocp'] = (df[\"Close\"]/df[\"Stock_Moment_2\"]) *100\n",
    "    # Exponential Moving Average\n",
    "    df[\"Stock_EMA\"] = (df[\"Close\"]-df[\"Stock_MAvg\"].shift(1))*(2/(5+1))+df[\"Stock_MAvg\"].shift(1)\n",
    "\n",
    "    # calculating the Relative Strength Index, based on 14 day window\n",
    "    df[\"Stock_diff\"] = df[\"Close\"].diff(1)\n",
    "    df[\"Stock_gain\"] = df[\"Stock_diff\"].clip(lower=0).round(2) #keeps all values above or below a given threshold, lower=lower bound\n",
    "    df[\"Stock_loss\"] = df[\"Stock_diff\"].clip(upper=0).round(2)\n",
    "    df['Stock_avg_gain'] = df['Stock_gain'].rolling(14).mean()\n",
    "    df['Stock_avg_loss'] = df['Stock_loss'].rolling(14).mean()\n",
    "    df['Stock_rs'] = df['Stock_avg_gain'] / df['Stock_avg_loss']\n",
    "    df['Stock_RSI'] = 100 - (100 / (1.0 + df['Stock_rs']))\n",
    "\n",
    "    # Calculatiing the Move Variables \n",
    "    df[\"Stock_Move\"] = df[\"Close\"] > df[\"Close\"].shift(1) \n",
    "    df[\"Stock_Move\"] = df[\"Stock_Move\"].replace({True:1,False: 0})\n",
    "    \n",
    "    df[\"Stock_MAvg_Move\"] = df[\"Stock_MAvg\"] > df[\"Stock_MAvg\"].shift(1) \n",
    "    df[\"Stock_MAvg_Move\"] = df[\"Stock_MAvg_Move\"].replace({True:1,False: 0})\n",
    "    df[\"Stock_MAvg_s_Move\"] = df[\"Stock_MAvg_s\"] > df[\"Stock_MAvg_s\"].shift(1) \n",
    "    df[\"Stock_MAvg_s_Move\"] = df[\"Stock_MAvg_s_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "    df[\"Stock_EMA_Move\"] = df[\"Stock_EMA\"] > df[\"Stock_EMA\"].shift(1) \n",
    "    df[\"Stock_EMA_Move\"] = df[\"Stock_EMA_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "    df[\"Stock_Disparity_Move\"] = df[\"Stock_Disparity\"] > df[\"Stock_Disparity\"].shift(1) \n",
    "    df[\"Stock_Disparity_Move\"] = df[\"Stock_Disparity_Move\"].replace({True:1,False: 0})\n",
    "    df[\"Stock_Disparity_s_Move\"] = df[\"Stock_Disparity_s\"] > df[\"Stock_Disparity_s\"].shift(1) \n",
    "    df[\"Stock_Disparity_s_Move\"] = df[\"Stock_Disparity_s_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "    df[\"Stock_RSI_Move\"] = df[\"Stock_RSI\"] > df[\"Stock_RSI\"].shift(1) \n",
    "    df[\"Stock_RSI_Move\"] = df[\"Stock_RSI_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a164bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NASDAQ_variables(df):\n",
    "    # Momentum 1\n",
    "    df[\"nas_Moment_1\"] =  (df[\"nas_close\"] / df[\"nas_close\"].shift(5)) * 100\n",
    "    # Momentum_2\n",
    "    df[\"nas_Moment_2\"] =  (df[\"nas_close\"] - df[\"nas_close\"].shift(5)) * 100\n",
    "    # Momentum_1_s three day shift (instead of 5)\n",
    "    df[\"nas_Moment_1_s\"] =  (df[\"nas_close\"] / df[\"nas_close\"].shift(3)) * 100\n",
    "    # Momentum_2_s\n",
    "    df[\"nas_Moment_2_s\"] =  (df[\"nas_close\"] - df[\"nas_close\"].shift(3)) * 100\n",
    "    # Moving average\n",
    "    df[\"nas_MAvg\"] = df[\"nas_close\"].rolling(\"5d\").mean()\n",
    "    # Disparity\n",
    "    df[\"Disparity\"] = (df[\"nas_close\"]/df[\"nas_MAvg\"]) * 100\n",
    "    # Rate of Change Normal Way\n",
    "    df[\"nas_ROC\"] = (df[\"nas_close\"]-df[\"nas_close\"].shift(5))/(df[\"nas_close\"].shift(5)) *100\n",
    "    df[\"nas_ROC_s\"] = (df[\"nas_close\"]-df[\"nas_close\"].shift(3))/(df[\"nas_close\"].shift(3)) *100\n",
    "    #Rate of Change Paper Way (doesn't make sense but just in case)\n",
    "    df['nas_Rocp'] = (df[\"nas_close\"]/df[\"nas_Moment_2\"]) *100\n",
    "    # Exponential Moving Average\n",
    "    df[\"nas_EMA\"] = (df[\"nas_close\"]-df[\"nas_MAvg\"].shift(1))*(2/(5+1))+df[\"nas_MAvg\"].shift(1)\n",
    "\n",
    "    # calculating the Relative Strength Index, based on 14 day window\n",
    "    df[\"nas_diff\"] = df[\"nas_close\"].diff(1)\n",
    "    df[\"nas_gain\"] = df[\"nas_diff\"].clip(lower=0).round(2) #keeps all values above or below a given threshold, lower=lower bound\n",
    "    df[\"nas_loss\"] = df[\"nas_diff\"].clip(upper=0).round(2)\n",
    "    df['nas_avg_gain'] = df['nas_gain'].rolling(14).mean()\n",
    "    df['nas_avg_loss'] = df['nas_loss'].rolling(14).mean()\n",
    "    df['nas_rs'] = df['nas_avg_gain'] / df['nas_avg_loss']\n",
    "    df['nas_RSI'] = 100 - (100 / (1.0 + df['nas_rs']))\n",
    "\n",
    "    # Calculatiing the Move Variables \n",
    "    df[\"nas_Move\"] = df[\"nas_close\"] > df[\"nas_close\"].shift(1) \n",
    "    df[\"nas_Move\"] = df[\"nas_Move\"].replace({True:1,False: 0})\n",
    "    \n",
    "    df[\"nas_MAvg_Move\"] = df[\"nas_MAvg\"] > df[\"nas_MAvg\"].shift(1) \n",
    "    df[\"nas_MAvg_Move\"] = df[\"nas_MAvg_Move\"].replace({True:1,False: 0})\n",
    "    df[\"nas_MAvg_s_Move\"] = df[\"nas_MAvg_s\"] > df[\"nas_MAvg_s\"].shift(1) \n",
    "    df[\"nas_MAvg_s_Move\"] = df[\"nas_MAvg_s_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "    df[\"nas_EMA_Move\"] = df[\"nas_EMA\"] > df[\"nas_EMA\"].shift(1) \n",
    "    df[\"nas_EMA_Move\"] = df[\"nas_EMA_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "    df[\"nas_Disparity_Move\"] = df[\"nas_Disparity\"] > df[\"nas_Disparity\"].shift(1) \n",
    "    df[\"nas_Disparity_Move\"] = df[\"nas_Disparity_Move\"].replace({True:1,False: 0})\n",
    "    df[\"nas_Disparity_s_Move\"] = df[\"nas_Disparity_s\"] > df[\"nas_Disparity_s\"].shift(1) \n",
    "    df[\"nas_Disparity_s_Move\"] = df[\"nas_Disparity_s_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "    df[\"nas_RSI_Move\"] = df[\"nas_RSI\"] > df[\"nas_RSI\"].shift(1) \n",
    "    df[\"nas_RSI_Move\"] = df[\"nas_RSI_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503aaa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dowDAQ_variables(df):\n",
    "    # Momentum 1\n",
    "    df[\"dow_Moment_1\"] =  (df[\"dow_close\"] / df[\"dow_close\"].shift(5)) * 100\n",
    "    # Momentum_2\n",
    "    df[\"dow_Moment_2\"] =  (df[\"dow_close\"] - df[\"dow_close\"].shift(5)) * 100\n",
    "    # Momentum_1_s three day shift (instead of 5)\n",
    "    df[\"dow_Moment_1_s\"] =  (df[\"dow_close\"] / df[\"dow_close\"].shift(3)) * 100\n",
    "    # Momentum_2_s\n",
    "    df[\"dow_Moment_2_s\"] =  (df[\"dow_close\"] - df[\"dow_close\"].shift(3)) * 100\n",
    "    # Moving average\n",
    "    df[\"dow_MAvg\"] = df[\"dow_close\"].rolling(\"5d\").mean()\n",
    "    # Disparity\n",
    "    df[\"Disparity\"] = (df[\"dow_close\"]/df[\"dow_MAvg\"]) * 100\n",
    "    # Rate of Change Normal Way\n",
    "    df[\"dow_ROC\"] = (df[\"dow_close\"]-df[\"dow_close\"].shift(5))/(df[\"dow_close\"].shift(5)) *100\n",
    "    df[\"dow_ROC_s\"] = (df[\"dow_close\"]-df[\"dow_close\"].shift(3))/(df[\"dow_close\"].shift(3)) *100\n",
    "    #Rate of Change Paper Way (doesn't make sense but just in case)\n",
    "    df['dow_Rocp'] = (df[\"dow_close\"]/df[\"dow_Moment_2\"]) *100\n",
    "    # Exponential Moving Average\n",
    "    df[\"dow_EMA\"] = (df[\"dow_close\"]-df[\"dow_MAvg\"].shift(1))*(2/(5+1))+df[\"dow_MAvg\"].shift(1)\n",
    "\n",
    "    # calculating the Relative Strength Index, based on 14 day window\n",
    "    df[\"dow_diff\"] = df[\"dow_close\"].diff(1)\n",
    "    df[\"dow_gain\"] = df[\"dow_diff\"].clip(lower=0).round(2) #keeps all values above or below a given threshold, lower=lower bound\n",
    "    df[\"dow_loss\"] = df[\"dow_diff\"].clip(upper=0).round(2)\n",
    "    df['dow_avg_gain'] = df['dow_gain'].rolling(14).mean()\n",
    "    df['dow_avg_loss'] = df['dow_loss'].rolling(14).mean()\n",
    "    df['dow_rs'] = df['dow_avg_gain'] / df['dow_avg_loss']\n",
    "    df['dow_RSI'] = 100 - (100 / (1.0 + df['dow_rs']))\n",
    "\n",
    "    # Calculatiing the Move Variables \n",
    "    df[\"dow_Move\"] = df[\"dow_close\"] > df[\"dow_close\"].shift(1) \n",
    "    df[\"dow_Move\"] = df[\"dow_Move\"].replace({True:1,False: 0})\n",
    "    \n",
    "    df[\"dow_MAvg_Move\"] = df[\"dow_MAvg\"] > df[\"dow_MAvg\"].shift(1) \n",
    "    df[\"dow_MAvg_Move\"] = df[\"dow_MAvg_Move\"].replace({True:1,False: 0})\n",
    "    df[\"dow_MAvg_s_Move\"] = df[\"dow_MAvg_s\"] > df[\"dow_MAvg_s\"].shift(1) \n",
    "    df[\"dow_MAvg_s_Move\"] = df[\"dow_MAvg_s_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "    df[\"dow_EMA_Move\"] = df[\"dow_EMA\"] > df[\"dow_EMA\"].shift(1) \n",
    "    df[\"dow_EMA_Move\"] = df[\"dow_EMA_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "    df[\"dow_Disparity_Move\"] = df[\"dow_Disparity\"] > df[\"dow_Disparity\"].shift(1) \n",
    "    df[\"dow_Disparity_Move\"] = df[\"dow_Disparity_Move\"].replace({True:1,False: 0})\n",
    "    df[\"dow_Disparity_s_Move\"] = df[\"dow_Disparity_s\"] > df[\"dow_Disparity_s\"].shift(1) \n",
    "    df[\"dow_Disparity_s_Move\"] = df[\"dow_Disparity_s_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "    df[\"dow_RSI_Move\"] = df[\"dow_RSI\"] > df[\"dow_RSI\"].shift(1) \n",
    "    df[\"dow_RSI_Move\"] = df[\"dow_RSI_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
