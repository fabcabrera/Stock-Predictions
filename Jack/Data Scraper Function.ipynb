{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb9c2572-f70c-4de3-b7e5-46970c9abd4f",
   "metadata": {},
   "source": [
    "# Stock Data Scraper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0db3fd3-03a0-497b-9a68-d2f494f06568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "#%pip install pytrends\n",
    "import pytrends\n",
    "from pytrends.request import TrendReq\n",
    "#%pip install pageviewapi\n",
    "import pageviewapi\n",
    "#%pip install yfinance\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbe7bb34-8317-4329-b018-5e092df305ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Big_scraper(kw_list_1, kw_list_2, ticker, start,end):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description:\n",
    "    ------------\n",
    "    \n",
    "    The function initially grabs historical, indexed, hourly data for when the keyword \n",
    "    was searched most as shown on Google Trends' Interest Over Time section.\n",
    "    It then cleans the data to show daily hits on the keyword in Google news.\n",
    "\n",
    "    \n",
    "    input:\n",
    "    -----\n",
    "    kw_list_1: List of up to 5 key words that will be scraped from google trends for the dates given.\n",
    "             Here, the scraping will pull the total posted items in google news that contains\n",
    "             one of the key words.\n",
    "    \n",
    "    kw_list_2: List of wikipedia article titles (unlimited length) that will pull the amount of\n",
    "            views the article recieved each day. \n",
    "\n",
    "    ticker: the ticker abriviation of the desired stock. Must be netered in as an all capitalized string \n",
    "    example Apple Inc. woud be \"AAPL\"\n",
    "             \n",
    "    start: the start of the desired timeline you want scrape. Date Must be entered in as \"YYYYMMDD\"\n",
    "    \n",
    "    end: the end of the desired timeline you want scrape. Date Must be entered in as \"YYYYMMDD\"\n",
    "             \n",
    "    return:\n",
    "    -------\n",
    "    \n",
    "    combined: a dataframe containing the sum of the daily keyword hits in google news (key words labeled _x),\n",
    "    \n",
    "    data frame cointaing stock info including open, close, high, low prices of the stock,\n",
    "    as well as the stocks daily trading volume and the amount if there was a split or dividend \n",
    "    preformed on the stock that day,\n",
    "    \n",
    "    and the sum of how many times key word wikipedia pages were viewed in a day (key words labeled _y)\n",
    "    \"\"\"\n",
    "    \n",
    "    year_s = int(start[0:4])\n",
    "    month_s = int(start[4:6])\n",
    "    day_s = int(start[6:8])\n",
    "    year_e = int(end[0:4])\n",
    "    month_e = int(end[4:6])\n",
    "    day_e = int(end[6:8])\n",
    "    \n",
    "    starter = pd.to_datetime(f\"'{year_s}-{month_s}-{day_s}'\")\n",
    "    ender = pd.to_datetime(f\"'{year_e}-{month_e}-{day_e}'\")\n",
    "    \n",
    "    \n",
    "    pytrends = TrendReq(hl='en-US', tz=360, retries=10)\n",
    "    jeff = pytrends.get_historical_interest(kw_list_1, \\\n",
    "                                 year_start = year_s, month_start = month_s, day_start = day_s, hour_start = 1, \\\n",
    "                                 year_end = year_e, month_end = month_e, day_end = day_e, hour_end = 23, \\\n",
    "                                 cat = 0, geo = '', gprop = 'news', sleep = 60)\n",
    "    \n",
    "    jeff = jeff.iloc[:, 0:-1] # eliminates the isPartial Column\n",
    "    jeff = jeff.reset_index().drop_duplicates(subset = \"date\") #removing duplicates from the index\n",
    "    jeff = jeff.groupby(pd.Grouper(key=\"date\", freq=\"D\")).sum() # coverts to the sum of daily posts\n",
    "    \n",
    "    tick = yf.Ticker(ticker)\n",
    "    hist = tick.history(start=starter, end=ender)\n",
    "    hist = pd.DataFrame(hist)\n",
    "    \n",
    "    combined = jeff.merge(hist, left_index=True, right_index=True, how=\"left\") \n",
    "    \n",
    "    d = pd.DataFrame()\n",
    "    for key_word in kw_list_2:\n",
    "        geoff = pageviewapi.per_article('en.wikipedia', key_word, start, end,\n",
    "                                    access='all-access', agent='all-agents', granularity='daily')\n",
    "        dicty = dict(geoff)\n",
    "        views = pd.DataFrame(dicty[\"items\"])\n",
    "        views[\"timestamp\"] = pd.to_datetime((views[\"timestamp\"]), format=\"%Y%m%d%H\")\n",
    "        views = views.set_index(\"timestamp\")\n",
    "        page = pd.Series(views[\"views\"])\n",
    "        d[key_word] = page\n",
    "        \n",
    "    combined = combined.merge(d, left_index=True, right_index=True, how=\"left\") \n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "243826e6-d950-4c2d-8e16-746f1b816167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apple</th>\n",
       "      <th>Apple Inc._x</th>\n",
       "      <th>IPhone_x</th>\n",
       "      <th>MacBook</th>\n",
       "      <th>MacOS</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Apple Inc._y</th>\n",
       "      <th>IPhone_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-12-01</th>\n",
       "      <td>382</td>\n",
       "      <td>0</td>\n",
       "      <td>447</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>167.266892</td>\n",
       "      <td>170.083311</td>\n",
       "      <td>164.320648</td>\n",
       "      <td>164.560349</td>\n",
       "      <td>152052500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14391</td>\n",
       "      <td>8014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-02</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>599</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>158.538019</td>\n",
       "      <td>163.991063</td>\n",
       "      <td>157.599213</td>\n",
       "      <td>163.551620</td>\n",
       "      <td>136739200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14364</td>\n",
       "      <td>8072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-03</th>\n",
       "      <td>377</td>\n",
       "      <td>0</td>\n",
       "      <td>397</td>\n",
       "      <td>63</td>\n",
       "      <td>6</td>\n",
       "      <td>163.811298</td>\n",
       "      <td>164.750104</td>\n",
       "      <td>159.516766</td>\n",
       "      <td>161.634064</td>\n",
       "      <td>118023100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13359</td>\n",
       "      <td>7546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-04</th>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "      <td>573</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11606</td>\n",
       "      <td>7311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-05</th>\n",
       "      <td>417</td>\n",
       "      <td>0</td>\n",
       "      <td>495</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12245</td>\n",
       "      <td>7586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-06</th>\n",
       "      <td>343</td>\n",
       "      <td>0</td>\n",
       "      <td>442</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>164.080946</td>\n",
       "      <td>167.666390</td>\n",
       "      <td>164.070964</td>\n",
       "      <td>165.109650</td>\n",
       "      <td>107497000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13862</td>\n",
       "      <td>8381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-07</th>\n",
       "      <td>397</td>\n",
       "      <td>0</td>\n",
       "      <td>429</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>168.864855</td>\n",
       "      <td>171.361674</td>\n",
       "      <td>168.125791</td>\n",
       "      <td>170.962173</td>\n",
       "      <td>120405400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14563</td>\n",
       "      <td>8188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-08</th>\n",
       "      <td>369</td>\n",
       "      <td>0</td>\n",
       "      <td>558</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>171.910980</td>\n",
       "      <td>175.736109</td>\n",
       "      <td>170.482792</td>\n",
       "      <td>174.857224</td>\n",
       "      <td>116998900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14027</td>\n",
       "      <td>7697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-09</th>\n",
       "      <td>413</td>\n",
       "      <td>0</td>\n",
       "      <td>623</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>174.687436</td>\n",
       "      <td>176.525091</td>\n",
       "      <td>173.698690</td>\n",
       "      <td>174.337875</td>\n",
       "      <td>108923700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13975</td>\n",
       "      <td>7590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-10</th>\n",
       "      <td>526</td>\n",
       "      <td>0</td>\n",
       "      <td>591</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>174.987069</td>\n",
       "      <td>179.401443</td>\n",
       "      <td>174.467727</td>\n",
       "      <td>179.221664</td>\n",
       "      <td>115402700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12530</td>\n",
       "      <td>7226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-11</th>\n",
       "      <td>340</td>\n",
       "      <td>0</td>\n",
       "      <td>853</td>\n",
       "      <td>73</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11235</td>\n",
       "      <td>6981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-12</th>\n",
       "      <td>364</td>\n",
       "      <td>0</td>\n",
       "      <td>557</td>\n",
       "      <td>71</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11840</td>\n",
       "      <td>6805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-13</th>\n",
       "      <td>470</td>\n",
       "      <td>0</td>\n",
       "      <td>408</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>180.889532</td>\n",
       "      <td>181.898256</td>\n",
       "      <td>175.306648</td>\n",
       "      <td>175.516388</td>\n",
       "      <td>153237000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13919</td>\n",
       "      <td>7691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-14</th>\n",
       "      <td>527</td>\n",
       "      <td>0</td>\n",
       "      <td>535</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14161</td>\n",
       "      <td>7677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Apple  Apple Inc._x  IPhone_x  MacBook  MacOS        Open  \\\n",
       "date                                                                    \n",
       "2021-12-01    382             0       447       46      6  167.266892   \n",
       "2021-12-02    502             0       599       28      0  158.538019   \n",
       "2021-12-03    377             0       397       63      6  163.811298   \n",
       "2021-12-04    365             0       573       33      0         NaN   \n",
       "2021-12-05    417             0       495       25      7         NaN   \n",
       "2021-12-06    343             0       442       89      0  164.080946   \n",
       "2021-12-07    397             0       429       62      0  168.864855   \n",
       "2021-12-08    369             0       558       66      0  171.910980   \n",
       "2021-12-09    413             0       623       57      0  174.687436   \n",
       "2021-12-10    526             0       591       16      0  174.987069   \n",
       "2021-12-11    340             0       853       73      9         NaN   \n",
       "2021-12-12    364             0       557       71      7         NaN   \n",
       "2021-12-13    470             0       408       59      0  180.889532   \n",
       "2021-12-14    527             0       535       33     10         NaN   \n",
       "\n",
       "                  High         Low       Close       Volume  Dividends  \\\n",
       "date                                                                     \n",
       "2021-12-01  170.083311  164.320648  164.560349  152052500.0        0.0   \n",
       "2021-12-02  163.991063  157.599213  163.551620  136739200.0        0.0   \n",
       "2021-12-03  164.750104  159.516766  161.634064  118023100.0        0.0   \n",
       "2021-12-04         NaN         NaN         NaN          NaN        NaN   \n",
       "2021-12-05         NaN         NaN         NaN          NaN        NaN   \n",
       "2021-12-06  167.666390  164.070964  165.109650  107497000.0        0.0   \n",
       "2021-12-07  171.361674  168.125791  170.962173  120405400.0        0.0   \n",
       "2021-12-08  175.736109  170.482792  174.857224  116998900.0        0.0   \n",
       "2021-12-09  176.525091  173.698690  174.337875  108923700.0        0.0   \n",
       "2021-12-10  179.401443  174.467727  179.221664  115402700.0        0.0   \n",
       "2021-12-11         NaN         NaN         NaN          NaN        NaN   \n",
       "2021-12-12         NaN         NaN         NaN          NaN        NaN   \n",
       "2021-12-13  181.898256  175.306648  175.516388  153237000.0        0.0   \n",
       "2021-12-14         NaN         NaN         NaN          NaN        NaN   \n",
       "\n",
       "            Stock Splits  Apple Inc._y  IPhone_y  \n",
       "date                                              \n",
       "2021-12-01           0.0         14391      8014  \n",
       "2021-12-02           0.0         14364      8072  \n",
       "2021-12-03           0.0         13359      7546  \n",
       "2021-12-04           NaN         11606      7311  \n",
       "2021-12-05           NaN         12245      7586  \n",
       "2021-12-06           0.0         13862      8381  \n",
       "2021-12-07           0.0         14563      8188  \n",
       "2021-12-08           0.0         14027      7697  \n",
       "2021-12-09           0.0         13975      7590  \n",
       "2021-12-10           0.0         12530      7226  \n",
       "2021-12-11           NaN         11235      6981  \n",
       "2021-12-12           NaN         11840      6805  \n",
       "2021-12-13           0.0         13919      7691  \n",
       "2021-12-14           NaN         14161      7677  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example pull\n",
    "kw_list_1 = [\"Apple\", \"Apple Inc.\", \"IPhone\", \"MacBook\", \"MacOS\"]\n",
    "kw_list_2 = [\"Apple Inc.\", \"IPhone\"]\n",
    "Big_scraper(kw_list_1,kw_list_2,\"AAPL\",\"20211201\",\"20211214\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1299e6-0a3d-4293-a49b-10cc2fa46db5",
   "metadata": {},
   "source": [
    "## Individual Functions (with examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70b75c51-9afc-46dd-9689-e675759ac26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_trends(kw_list, year_start, month_start, year_end, month_end, day_end, day_start=1, hour_start=0, hour_end=23):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description:\n",
    "    ------------\n",
    "    \n",
    "    The function initially grabs historical, indexed, hourly data for when the keyword \n",
    "    was searched most as shown on Google Trends' Interest Over Time section.\n",
    "    It then cleans the data to show daily hits on the keyword in Google news.\n",
    "\n",
    "    \n",
    "    input:\n",
    "    -----\n",
    "    kw_list: List of up to 5 key words that will be scraped from the timeline given to the function.\n",
    "             Here, the scraping will pull the total posted items in google news. the contains\n",
    "             one of the key words.\n",
    "             \n",
    "    Rest of the varibles are self-explatory and used to set the timeline to scrape the key words. \n",
    "    \n",
    "    Plug in as decribed \n",
    "    year_start / end: YYYY int\n",
    "    month_start / end: M int\n",
    "    day_start /  end: D int\n",
    "    hour_start / end: H int\n",
    "    \n",
    "             \n",
    "    return:\n",
    "    -------\n",
    "    \n",
    "    jeff: a dataframe containing the sum of the daily keyword hits in google news\n",
    "    \"\"\"\n",
    "    \n",
    "    pytrends = TrendReq(hl='en-US', tz=360, retries=10)\n",
    "    jeff = pytrends.get_historical_interest(kw_list, \\\n",
    "                                 year_start = year_start, month_start = month_start, day_start = day_start, hour_start = hour_start, \\\n",
    "                                 year_end = year_end, month_end = month_end, day_end = day_end, hour_end = hour_end, \\\n",
    "                                 cat = 0, geo = '', gprop = 'news', sleep = 60)\n",
    "    \n",
    "    jeff = jeff.iloc[:, 0:-1] # eliminates the isPartial Column\n",
    "    jeff = jeff.reset_index().drop_duplicates(subset = \"date\") #removing duplicates from the index\n",
    "    jeff = jeff.groupby(pd.Grouper(key=\"date\", freq=\"D\")).sum() # coverts to the sum of daily posts\n",
    "    \n",
    "    return jeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75ff70b7-82ad-40d4-8973-5a4a079c5e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "jeff1= google_trends(kw_list, 2021, 12, 2021, 12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90280f1a-b947-4a23-8afb-90607da772a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_list = [\"Apple\", \"Apple Inc.\", \"IPhone\", \"MacBook\", \"MacOS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e6891dd-52ad-4e33-be9d-e6923df9534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_stats(ticker: str, start_date: str, end_date: str):\n",
    "    \"\"\"\n",
    "    Description: Scrapes historial daily stock data from the Yahoo Fince sight\n",
    "    and returns a dataframe containing daily open, close, high, low prices of the stock,\n",
    "    as well as the stocks daily trading volume and the amount if there was a split or dividend \n",
    "    preformed on the stock that day.\n",
    "    \n",
    "    inputs:\n",
    "    ------\n",
    "    ticker: the ticker abriviation of the desired stock. Must be netered in as an all capitalized string \n",
    "    example Apple Inc. woud be \"AAPL\"\n",
    "    \n",
    "    start_date: the start of the desired timeline you want scrape. Date Must be entered in as \"YYYY-MM-DD\"\n",
    "    \n",
    "    end_date: Self explanetory, Date Must be entered in as \"YYYY-MM-DD\"\n",
    "    \n",
    "    return:\n",
    "    ------\n",
    "    hist: dataframe containing open, close, high, low prices of the stock,\n",
    "    as well as the stocks daily trading volume and the amount if there was a split or dividend \n",
    "    preformed on the stock that day. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    tick = yf.Ticker(ticker)\n",
    "    hist = tick.history(start=start_date, end=end_date)\n",
    "    hist = pd.DataFrame(hist)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b90c06b1-dd25-4301-a4d8-adf89b435698",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'larry' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-60f6fa68a86e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjeff4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstock_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AAPL\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlarry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2021-12-31\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'larry' is not defined"
     ]
    }
   ],
   "source": [
    "jeff4 = stock_stats(\"AAPL\", larry, \"2021-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0da18c01-703e-4323-9697-b86a78e09865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_scraper(kw_list: list, start_date: str, end_date: str):\n",
    "    '''\n",
    "    Description: Pulls the sum of how many times a wikipedia page was viewed that day\n",
    "    \n",
    "    inputs:\n",
    "    ------\n",
    "    \n",
    "    kw_list: list of wikipedia page names to be scrpapped, can be of unlimted length\n",
    "    \n",
    "    start_date: the start of the desired timeline you want scrape. Date Must be entered in as \"YYYYMMDD\"\n",
    "    \n",
    "    end_date: the end of the desired timeline you want scrape. Date Must be entered in as \"YYYYMMDD\"\n",
    "    \n",
    "    '''\n",
    "    d = pd.DataFrame()\n",
    "    for key_word in kw_list:\n",
    "        geoff = pageviewapi.per_article('en.wikipedia', key_word, start_date, end_date,\n",
    "                                    access='all-access', agent='all-agents', granularity='daily')\n",
    "        dicty = dict(geoff)\n",
    "        views = pd.DataFrame(dicty[\"items\"])\n",
    "        views[\"timestamp\"] = pd.to_datetime((views[\"timestamp\"]), format=\"%Y%m%d%H\")\n",
    "        views = views.set_index(\"timestamp\")\n",
    "        page = pd.Series(views[\"views\"])\n",
    "        d[key_word] = page\n",
    "        \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec0b9af6-fffd-4f9d-ad31-75181a05fb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apple</th>\n",
       "      <th>Apple Inc.</th>\n",
       "      <th>IPhone</th>\n",
       "      <th>MacBook</th>\n",
       "      <th>MacOS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-12-01</th>\n",
       "      <td>8237</td>\n",
       "      <td>14391</td>\n",
       "      <td>8014</td>\n",
       "      <td>704</td>\n",
       "      <td>133006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-02</th>\n",
       "      <td>8299</td>\n",
       "      <td>14364</td>\n",
       "      <td>8072</td>\n",
       "      <td>619</td>\n",
       "      <td>42741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-03</th>\n",
       "      <td>8040</td>\n",
       "      <td>13359</td>\n",
       "      <td>7546</td>\n",
       "      <td>559</td>\n",
       "      <td>37979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-04</th>\n",
       "      <td>7673</td>\n",
       "      <td>11606</td>\n",
       "      <td>7311</td>\n",
       "      <td>604</td>\n",
       "      <td>26680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-05</th>\n",
       "      <td>7810</td>\n",
       "      <td>12245</td>\n",
       "      <td>7586</td>\n",
       "      <td>588</td>\n",
       "      <td>26376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Apple  Apple Inc.  IPhone  MacBook   MacOS\n",
       "timestamp                                             \n",
       "2021-12-01   8237       14391    8014      704  133006\n",
       "2021-12-02   8299       14364    8072      619   42741\n",
       "2021-12-03   8040       13359    7546      559   37979\n",
       "2021-12-04   7673       11606    7311      604   26680\n",
       "2021-12-05   7810       12245    7586      588   26376"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeff3 = wiki_scraper(kw_list, '20211201', '20211231')\n",
    "jeff3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66645712-5568-4bf4-9747-5ad4a2c8ed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joiner(google_trends, yahoo_finace, wiki_pagecount):\n",
    "    \"\"\"\n",
    "    Description: joins all stock data sets into one dataframe\n",
    "    \n",
    "    input:\n",
    "    ------\n",
    "    google_trends: data frame counting daily hit counts for google news stories on specific key words\n",
    "    \n",
    "    yahoo_finace: data frame cointaing stock info including open, close, high, low prices of the stock,\n",
    "    as well as the stocks daily trading volume and the amount if there was a split or dividend \n",
    "    preformed on the stock that day.\n",
    "    \n",
    "    wiki_pagecount: the sum of how many times key wikipedia pages were viewed in a day\n",
    "    \"\"\"\n",
    "    \n",
    "    combined = google_trends.merge(yahoo_finace, left_index=True, right_index=True, how=\"left\")\n",
    "    combined = combined.merge(wiki_pagecount, left_index=True, right_index=True, how=\"left\")\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8fab25a-878e-4562-a6d6-28085574e543",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jeff2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-6ed33863bdb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjoiner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjeff1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjeff2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjeff3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'jeff2' is not defined"
     ]
    }
   ],
   "source": [
    "joiner(jeff1,jeff2,jeff3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
