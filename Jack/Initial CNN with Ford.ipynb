{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a1a9e62",
   "metadata": {},
   "source": [
    "# Initial CNN Model Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "be98f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense, Normalization\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "581b3306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, InputLayer\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "4907d179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import (\n",
    "    linear_model, metrics, neural_network, pipeline, model_selection\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f922ed4b",
   "metadata": {},
   "source": [
    "### Part 1 Figuuring out how to deal with NaNs\n",
    "Come to the coclusion just to use test data set Ford_1 for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4b12719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ford = pd.read_csv(\"Ford_Cleaned_Date.csv\")\n",
    "Ford.date = pd.to_datetime(Ford.date)\n",
    "Ford = Ford.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "282fb5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(801, 169)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ford = Ford.iloc[14:, :]\n",
    "Ford.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ba29efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "380faec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ford</th>\n",
       "      <th>F-150</th>\n",
       "      <th>Ford Bronco_x</th>\n",
       "      <th>Ford Mustang_x</th>\n",
       "      <th>Ford Stock</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Ford Motor Company</th>\n",
       "      <th>Ford Mustang_y</th>\n",
       "      <th>Ford F Series</th>\n",
       "      <th>Ford Bronco_y</th>\n",
       "      <th>Lincoln Navigator</th>\n",
       "      <th>Lincoln Aviator</th>\n",
       "      <th>Ford GT</th>\n",
       "      <th>dow_open</th>\n",
       "      <th>dow_high</th>\n",
       "      <th>dow_low</th>\n",
       "      <th>dow_close</th>\n",
       "      <th>dow_vol</th>\n",
       "      <th>nas_open</th>\n",
       "      <th>nas_high</th>\n",
       "      <th>nas_low</th>\n",
       "      <th>nas_close</th>\n",
       "      <th>nas_vol</th>\n",
       "      <th>Wiki_total</th>\n",
       "      <th>Google_total</th>\n",
       "      <th>Stock_total</th>\n",
       "      <th>Nas_total</th>\n",
       "      <th>Dow_total</th>\n",
       "      <th>Wiki_Moment_1</th>\n",
       "      <th>Wiki_Moment_2</th>\n",
       "      <th>Wiki_Moment_1_s</th>\n",
       "      <th>Wiki_Moment_2_s</th>\n",
       "      <th>Wiki_MAvg</th>\n",
       "      <th>Wiki_MAvg_s</th>\n",
       "      <th>Wiki_Disparity</th>\n",
       "      <th>Wiki_Disparity_s</th>\n",
       "      <th>Wiki_ROC</th>\n",
       "      <th>Wiki_ROC_s</th>\n",
       "      <th>Wiki_Rocp</th>\n",
       "      <th>Wiki_EMA</th>\n",
       "      <th>Wiki_diff</th>\n",
       "      <th>Wiki_gain</th>\n",
       "      <th>Wiki_loss</th>\n",
       "      <th>Wiki_avg_gain</th>\n",
       "      <th>Wiki_avg_loss</th>\n",
       "      <th>Wiki_rs</th>\n",
       "      <th>Wiki_RSI</th>\n",
       "      <th>Wiki_Move</th>\n",
       "      <th>Wiki_MAvg_Move</th>\n",
       "      <th>Wiki_MAvg_s_Move</th>\n",
       "      <th>Wiki_EMA_Move</th>\n",
       "      <th>Wiki_Disparity_Move</th>\n",
       "      <th>Wiki_Disparity_s_Move</th>\n",
       "      <th>Wiki_RSI_Move</th>\n",
       "      <th>Google_Moment_1</th>\n",
       "      <th>Google_Moment_2</th>\n",
       "      <th>Google_Moment_1_s</th>\n",
       "      <th>Google_Moment_2_s</th>\n",
       "      <th>Google_MAvg</th>\n",
       "      <th>Google_MAvg_s</th>\n",
       "      <th>Google_Disparity</th>\n",
       "      <th>Google_Disparity_s</th>\n",
       "      <th>Google_ROC</th>\n",
       "      <th>Google_ROC_s</th>\n",
       "      <th>Google_Rocp</th>\n",
       "      <th>Google_EMA</th>\n",
       "      <th>Google_diff</th>\n",
       "      <th>Google_gain</th>\n",
       "      <th>Google_loss</th>\n",
       "      <th>Google_avg_gain</th>\n",
       "      <th>Google_avg_loss</th>\n",
       "      <th>Google_rs</th>\n",
       "      <th>Google_RSI</th>\n",
       "      <th>Google_Move</th>\n",
       "      <th>Google_MAvg_Move</th>\n",
       "      <th>Google_MAvg_s_Move</th>\n",
       "      <th>Google_EMA_Move</th>\n",
       "      <th>Google_Disparity_Move</th>\n",
       "      <th>Google_Disparity_s_Move</th>\n",
       "      <th>Google_RSI_Move</th>\n",
       "      <th>Stock_Moment_1</th>\n",
       "      <th>Stock_Moment_2</th>\n",
       "      <th>Stock_Moment_1_s</th>\n",
       "      <th>Stock_Moment_2_s</th>\n",
       "      <th>Stock_MAvg</th>\n",
       "      <th>Stock_MAvg_s</th>\n",
       "      <th>Stock_Disparity</th>\n",
       "      <th>Stock_Disparity_s</th>\n",
       "      <th>Stock_ROC</th>\n",
       "      <th>Stock_ROC_s</th>\n",
       "      <th>Stock_Rocp</th>\n",
       "      <th>Stock_EMA</th>\n",
       "      <th>Stock_diff</th>\n",
       "      <th>Stock_gain</th>\n",
       "      <th>Stock_loss</th>\n",
       "      <th>Stock_avg_gain</th>\n",
       "      <th>Stock_avg_loss</th>\n",
       "      <th>Stock_rs</th>\n",
       "      <th>Stock_RSI</th>\n",
       "      <th>Stock_Move</th>\n",
       "      <th>Stock_MAvg_Move</th>\n",
       "      <th>Stock_MAvg_s_Move</th>\n",
       "      <th>Stock_EMA_Move</th>\n",
       "      <th>Stock_Disparity_Move</th>\n",
       "      <th>Stock_Disparity_s_Move</th>\n",
       "      <th>Stock_RSI_Move</th>\n",
       "      <th>Nas_Moment_1</th>\n",
       "      <th>Nas_Moment_2</th>\n",
       "      <th>Nas_Moment_1_s</th>\n",
       "      <th>Nas_Moment_2_s</th>\n",
       "      <th>Nas_MAvg</th>\n",
       "      <th>Nas_MAvg_s</th>\n",
       "      <th>Nas_Disparity</th>\n",
       "      <th>Nas_Disparity_s</th>\n",
       "      <th>Nas_ROC</th>\n",
       "      <th>Nas_ROC_s</th>\n",
       "      <th>Nas_Rocp</th>\n",
       "      <th>Nas_EMA</th>\n",
       "      <th>Nas_diff</th>\n",
       "      <th>Nas_gain</th>\n",
       "      <th>Nas_loss</th>\n",
       "      <th>Nas_avg_gain</th>\n",
       "      <th>Nas_avg_loss</th>\n",
       "      <th>Nas_rs</th>\n",
       "      <th>Nas_RSI</th>\n",
       "      <th>Nas_Move</th>\n",
       "      <th>Nas_MAvg_Move</th>\n",
       "      <th>Nas_MAvg_s_Move</th>\n",
       "      <th>Nas_EMA_Move</th>\n",
       "      <th>Nas_Disparity_Move</th>\n",
       "      <th>Nas_Disparity_s_Move</th>\n",
       "      <th>Nas_RSI_Move</th>\n",
       "      <th>Dow_Moment_1</th>\n",
       "      <th>Dow_Moment_2</th>\n",
       "      <th>Dow_Moment_1_s</th>\n",
       "      <th>Dow_Moment_2_s</th>\n",
       "      <th>Dow_MAvg</th>\n",
       "      <th>Dow_MAvg_s</th>\n",
       "      <th>Dow_Disparity</th>\n",
       "      <th>Dow_Disparity_s</th>\n",
       "      <th>Dow_ROC</th>\n",
       "      <th>Dow_ROC_s</th>\n",
       "      <th>Dow_Rocp</th>\n",
       "      <th>Dow_EMA</th>\n",
       "      <th>Dow_diff</th>\n",
       "      <th>Dow_gain</th>\n",
       "      <th>Dow_loss</th>\n",
       "      <th>Dow_avg_gain</th>\n",
       "      <th>Dow_avg_loss</th>\n",
       "      <th>Dow_rs</th>\n",
       "      <th>Dow_RSI</th>\n",
       "      <th>Dow_Move</th>\n",
       "      <th>Dow_MAvg_Move</th>\n",
       "      <th>Dow_MAvg_s_Move</th>\n",
       "      <th>Dow_EMA_Move</th>\n",
       "      <th>Dow_Disparity_Move</th>\n",
       "      <th>Dow_Disparity_s_Move</th>\n",
       "      <th>Dow_RSI_Move</th>\n",
       "      <th>target_1</th>\n",
       "      <th>target_2</th>\n",
       "      <th>target_3</th>\n",
       "      <th>target_4</th>\n",
       "      <th>target_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ford  F-150  Ford Bronco_x  Ford Mustang_x  Ford Stock  Open  High  Low  \\\n",
       "0     0      0              0               0           0     6     6    6   \n",
       "\n",
       "   Close  Volume  Dividends  Stock Splits  Ford Motor Company  Ford Mustang_y  \\\n",
       "0      6       6          6             6                   0               0   \n",
       "\n",
       "   Ford F Series  Ford Bronco_y  Lincoln Navigator  Lincoln Aviator  Ford GT  \\\n",
       "0              0              0                  0                0        0   \n",
       "\n",
       "   dow_open  dow_high  dow_low  dow_close  dow_vol  nas_open  nas_high  \\\n",
       "0         4         4        4          4        4         4         4   \n",
       "\n",
       "   nas_low  nas_close  nas_vol  Wiki_total  Google_total  Stock_total  \\\n",
       "0        4          4        4           0             0            6   \n",
       "\n",
       "   Nas_total  Dow_total  Wiki_Moment_1  Wiki_Moment_2  Wiki_Moment_1_s  \\\n",
       "0          4          4              0              0                0   \n",
       "\n",
       "   Wiki_Moment_2_s  Wiki_MAvg  Wiki_MAvg_s  Wiki_Disparity  Wiki_Disparity_s  \\\n",
       "0                0          0            0               0                 0   \n",
       "\n",
       "   Wiki_ROC  Wiki_ROC_s  Wiki_Rocp  Wiki_EMA  Wiki_diff  Wiki_gain  Wiki_loss  \\\n",
       "0         0           0          0         0          0          0          0   \n",
       "\n",
       "   Wiki_avg_gain  Wiki_avg_loss  Wiki_rs  Wiki_RSI  Wiki_Move  Wiki_MAvg_Move  \\\n",
       "0              0              0        0         0          0               0   \n",
       "\n",
       "   Wiki_MAvg_s_Move  Wiki_EMA_Move  Wiki_Disparity_Move  \\\n",
       "0                 0              0                    0   \n",
       "\n",
       "   Wiki_Disparity_s_Move  Wiki_RSI_Move  Google_Moment_1  Google_Moment_2  \\\n",
       "0                      0              0                0                0   \n",
       "\n",
       "   Google_Moment_1_s  Google_Moment_2_s  Google_MAvg  Google_MAvg_s  \\\n",
       "0                  0                  0            0              0   \n",
       "\n",
       "   Google_Disparity  Google_Disparity_s  Google_ROC  Google_ROC_s  \\\n",
       "0                 0                   0           0             0   \n",
       "\n",
       "   Google_Rocp  Google_EMA  Google_diff  Google_gain  Google_loss  \\\n",
       "0            0           0            0            0            0   \n",
       "\n",
       "   Google_avg_gain  Google_avg_loss  Google_rs  Google_RSI  Google_Move  \\\n",
       "0                0                0          0           0            0   \n",
       "\n",
       "   Google_MAvg_Move  Google_MAvg_s_Move  Google_EMA_Move  \\\n",
       "0                 0                   0                0   \n",
       "\n",
       "   Google_Disparity_Move  Google_Disparity_s_Move  Google_RSI_Move  \\\n",
       "0                      0                        0                0   \n",
       "\n",
       "   Stock_Moment_1  Stock_Moment_2  Stock_Moment_1_s  Stock_Moment_2_s  \\\n",
       "0              11              11                11                11   \n",
       "\n",
       "   Stock_MAvg  Stock_MAvg_s  Stock_Disparity  Stock_Disparity_s  Stock_ROC  \\\n",
       "0           0             0                6                  6         11   \n",
       "\n",
       "   Stock_ROC_s  Stock_Rocp  Stock_EMA  Stock_diff  Stock_gain  Stock_loss  \\\n",
       "0           11          11          6          11          11          11   \n",
       "\n",
       "   Stock_avg_gain  Stock_avg_loss  Stock_rs  Stock_RSI  Stock_Move  \\\n",
       "0              76              76        76         76           0   \n",
       "\n",
       "   Stock_MAvg_Move  Stock_MAvg_s_Move  Stock_EMA_Move  Stock_Disparity_Move  \\\n",
       "0                0                  0               0                     0   \n",
       "\n",
       "   Stock_Disparity_s_Move  Stock_RSI_Move  Nas_Moment_1  Nas_Moment_2  \\\n",
       "0                       0               0             7             7   \n",
       "\n",
       "   Nas_Moment_1_s  Nas_Moment_2_s  Nas_MAvg  Nas_MAvg_s  Nas_Disparity  \\\n",
       "0               7               7         0           0              4   \n",
       "\n",
       "   Nas_Disparity_s  Nas_ROC  Nas_ROC_s  Nas_Rocp  Nas_EMA  Nas_diff  Nas_gain  \\\n",
       "0                4        7          7         7        4         7         7   \n",
       "\n",
       "   Nas_loss  Nas_avg_gain  Nas_avg_loss  Nas_rs  Nas_RSI  Nas_Move  \\\n",
       "0         7            46            46      46       46         0   \n",
       "\n",
       "   Nas_MAvg_Move  Nas_MAvg_s_Move  Nas_EMA_Move  Nas_Disparity_Move  \\\n",
       "0              0                0             0                   0   \n",
       "\n",
       "   Nas_Disparity_s_Move  Nas_RSI_Move  Dow_Moment_1  Dow_Moment_2  \\\n",
       "0                     0             0             7             7   \n",
       "\n",
       "   Dow_Moment_1_s  Dow_Moment_2_s  Dow_MAvg  Dow_MAvg_s  Dow_Disparity  \\\n",
       "0               7               7         0           0              4   \n",
       "\n",
       "   Dow_Disparity_s  Dow_ROC  Dow_ROC_s  Dow_Rocp  Dow_EMA  Dow_diff  Dow_gain  \\\n",
       "0                4        7          7         7        4         7         7   \n",
       "\n",
       "   Dow_loss  Dow_avg_gain  Dow_avg_loss  Dow_rs  Dow_RSI  Dow_Move  \\\n",
       "0         7            46            46      46       46         0   \n",
       "\n",
       "   Dow_MAvg_Move  Dow_MAvg_s_Move  Dow_EMA_Move  Dow_Disparity_Move  \\\n",
       "0              0                0             0                   0   \n",
       "\n",
       "   Dow_Disparity_s_Move  Dow_RSI_Move  target_1  target_2  target_3  target_4  \\\n",
       "0                     0             0         0         0         0         0   \n",
       "\n",
       "   target_5  \n",
       "0         0  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Ford.isna().sum()).T\n",
    "# we see that the gain, average gain, average loss and loss columns are causing large numbers of NA's\n",
    "# will need to come back and solve this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "62aa2414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any infinitly large or small values\n",
    "# Ford.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Drop remanining NaN or null values\n",
    "#Ford = Ford.dropna()\n",
    "#Ford.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "0b9c763c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_3</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Wiki_total</th>\n",
       "      <th>Google_total</th>\n",
       "      <th>nas_close</th>\n",
       "      <th>dow_close</th>\n",
       "      <th>Close</th>\n",
       "      <th>nas_vol</th>\n",
       "      <th>dow_vol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-23</th>\n",
       "      <td>1</td>\n",
       "      <td>45196900.0</td>\n",
       "      <td>14836.0</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>7025.770020</td>\n",
       "      <td>24575.619141</td>\n",
       "      <td>7.562010</td>\n",
       "      <td>2.274420e+09</td>\n",
       "      <td>318600000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-24</th>\n",
       "      <td>1</td>\n",
       "      <td>79516400.0</td>\n",
       "      <td>15219.0</td>\n",
       "      <td>32.625000</td>\n",
       "      <td>7073.459961</td>\n",
       "      <td>24553.240234</td>\n",
       "      <td>7.797754</td>\n",
       "      <td>2.400290e+09</td>\n",
       "      <td>320170000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-25</th>\n",
       "      <td>0</td>\n",
       "      <td>53098800.0</td>\n",
       "      <td>14645.0</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>7164.859863</td>\n",
       "      <td>24737.199219</td>\n",
       "      <td>8.033502</td>\n",
       "      <td>2.440840e+09</td>\n",
       "      <td>376890000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-28</th>\n",
       "      <td>1</td>\n",
       "      <td>42116300.0</td>\n",
       "      <td>14390.0</td>\n",
       "      <td>21.958333</td>\n",
       "      <td>7085.680176</td>\n",
       "      <td>24528.220703</td>\n",
       "      <td>7.852159</td>\n",
       "      <td>2.435480e+09</td>\n",
       "      <td>347170000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-29</th>\n",
       "      <td>1</td>\n",
       "      <td>30485000.0</td>\n",
       "      <td>14412.0</td>\n",
       "      <td>24.750000</td>\n",
       "      <td>7028.290039</td>\n",
       "      <td>24579.960938</td>\n",
       "      <td>7.942830</td>\n",
       "      <td>2.089690e+09</td>\n",
       "      <td>330870000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target_3      Volume  Wiki_total  Google_total    nas_close  \\\n",
       "date                                                                      \n",
       "2019-01-23         1  45196900.0     14836.0     19.500000  7025.770020   \n",
       "2019-01-24         1  79516400.0     15219.0     32.625000  7073.459961   \n",
       "2019-01-25         0  53098800.0     14645.0     35.500000  7164.859863   \n",
       "2019-01-28         1  42116300.0     14390.0     21.958333  7085.680176   \n",
       "2019-01-29         1  30485000.0     14412.0     24.750000  7028.290039   \n",
       "\n",
       "               dow_close     Close       nas_vol      dow_vol  \n",
       "date                                                           \n",
       "2019-01-23  24575.619141  7.562010  2.274420e+09  318600000.0  \n",
       "2019-01-24  24553.240234  7.797754  2.400290e+09  320170000.0  \n",
       "2019-01-25  24737.199219  8.033502  2.440840e+09  376890000.0  \n",
       "2019-01-28  24528.220703  7.852159  2.435480e+09  347170000.0  \n",
       "2019-01-29  24579.960938  7.942830  2.089690e+09  330870000.0  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ford 1, Basic Varaibles,  \n",
    "Ford_1 = Ford[Ford.columns.drop(list(Ford.filter(regex='Move')))]\n",
    "Ford_1 = Ford_1[[\"target_3\", \"Volume\", \n",
    "                \"Wiki_total\", \"Google_total\", \n",
    "                \"nas_close\", \"dow_close\",\n",
    "                 \"Close\", \"nas_vol\", \n",
    "                 \"dow_vol\"\n",
    "                 ]]\n",
    "Ford_1.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "8cf48137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(801, 9)\n",
      "(795, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "target_3          int64\n",
       "Volume          float64\n",
       "Wiki_total      float64\n",
       "Google_total    float64\n",
       "nas_close       float64\n",
       "dow_close       float64\n",
       "Close           float64\n",
       "nas_vol         float64\n",
       "dow_vol         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Ford_1.shape)\n",
    "print(Ford_1.dropna().shape)\n",
    "Ford_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "2b154f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ford_1 = Ford_1.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2377d6ae",
   "metadata": {},
   "source": [
    "## Part 2, Setting up Data to be useable with tensor flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "2d9628c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = to_categorical(Ford_1['target_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b2a1c13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "082fc153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volume</th>\n",
       "      <th>Wiki_total</th>\n",
       "      <th>Google_total</th>\n",
       "      <th>nas_close</th>\n",
       "      <th>dow_close</th>\n",
       "      <th>Close</th>\n",
       "      <th>nas_vol</th>\n",
       "      <th>dow_vol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-23</th>\n",
       "      <td>45196900.0</td>\n",
       "      <td>14836.0</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>7025.770020</td>\n",
       "      <td>24575.619141</td>\n",
       "      <td>7.562010</td>\n",
       "      <td>2.274420e+09</td>\n",
       "      <td>318600000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-24</th>\n",
       "      <td>79516400.0</td>\n",
       "      <td>15219.0</td>\n",
       "      <td>32.625000</td>\n",
       "      <td>7073.459961</td>\n",
       "      <td>24553.240234</td>\n",
       "      <td>7.797754</td>\n",
       "      <td>2.400290e+09</td>\n",
       "      <td>320170000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-25</th>\n",
       "      <td>53098800.0</td>\n",
       "      <td>14645.0</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>7164.859863</td>\n",
       "      <td>24737.199219</td>\n",
       "      <td>8.033502</td>\n",
       "      <td>2.440840e+09</td>\n",
       "      <td>376890000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-28</th>\n",
       "      <td>42116300.0</td>\n",
       "      <td>14390.0</td>\n",
       "      <td>21.958333</td>\n",
       "      <td>7085.680176</td>\n",
       "      <td>24528.220703</td>\n",
       "      <td>7.852159</td>\n",
       "      <td>2.435480e+09</td>\n",
       "      <td>347170000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-29</th>\n",
       "      <td>30485000.0</td>\n",
       "      <td>14412.0</td>\n",
       "      <td>24.750000</td>\n",
       "      <td>7028.290039</td>\n",
       "      <td>24579.960938</td>\n",
       "      <td>7.942830</td>\n",
       "      <td>2.089690e+09</td>\n",
       "      <td>330870000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Volume  Wiki_total  Google_total    nas_close     dow_close  \\\n",
       "date                                                                          \n",
       "2019-01-23  45196900.0     14836.0     19.500000  7025.770020  24575.619141   \n",
       "2019-01-24  79516400.0     15219.0     32.625000  7073.459961  24553.240234   \n",
       "2019-01-25  53098800.0     14645.0     35.500000  7164.859863  24737.199219   \n",
       "2019-01-28  42116300.0     14390.0     21.958333  7085.680176  24528.220703   \n",
       "2019-01-29  30485000.0     14412.0     24.750000  7028.290039  24579.960938   \n",
       "\n",
       "               Close       nas_vol      dow_vol  \n",
       "date                                             \n",
       "2019-01-23  7.562010  2.274420e+09  318600000.0  \n",
       "2019-01-24  7.797754  2.400290e+09  320170000.0  \n",
       "2019-01-25  8.033502  2.440840e+09  376890000.0  \n",
       "2019-01-28  7.852159  2.435480e+09  347170000.0  \n",
       "2019-01-29  7.942830  2.089690e+09  330870000.0  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ford_1 = Ford_1.drop('target_3', axis=1)\n",
    "Ford_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ccca909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into training sets \n",
    "column_indices = {name: i for i, name in enumerate(Ford_1.columns)}\n",
    "\n",
    "n = len(Ford_1)\n",
    "train_f1 = Ford_1[0:int(n*0.7)]\n",
    "val_f1 = Ford_1[int(n*0.7):int(n*0.9)]\n",
    "test_f1 = Ford_1[int(n*0.9):]\n",
    "\n",
    "train_f1t = target[0:int(n*0.7)]\n",
    "val_f1t = target[int(n*0.7):int(n*0.9)]\n",
    "test_f1t = target[int(n*0.9):]\n",
    "\n",
    "num_features = Ford_1.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "70f97d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seporating out all non binary varibles to be normalized\n",
    "f_list = [\"Volume\", \n",
    "            \"Wiki_total\", \"Google_total\", \n",
    "            \"nas_close\", \"dow_close\",\n",
    "            \"Close\", \"nas_vol\", \n",
    "            \"dow_vol\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "566204bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the data, may come back later to take normalization with moving averages to avoid allwoing\n",
    "# the training set to have access to futre traing data, makes model more realistic\n",
    "train_f1_mean = train_f1.mean()\n",
    "train_f1_std = train_f1.std()\n",
    "\n",
    "train_f1 = (train_f1 - train_f1_mean) / train_f1_std\n",
    "val_f1 = (val_f1 - train_f1_mean) / train_f1_std\n",
    "test_f1 = (test_f1 - train_f1_mean) / train_f1_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "30570790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volume</th>\n",
       "      <th>Wiki_total</th>\n",
       "      <th>Google_total</th>\n",
       "      <th>nas_close</th>\n",
       "      <th>dow_close</th>\n",
       "      <th>Close</th>\n",
       "      <th>nas_vol</th>\n",
       "      <th>dow_vol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-23</th>\n",
       "      <td>-0.473952</td>\n",
       "      <td>0.189679</td>\n",
       "      <td>-0.916326</td>\n",
       "      <td>-1.297693</td>\n",
       "      <td>-1.103138</td>\n",
       "      <td>-0.380935</td>\n",
       "      <td>-0.737715</td>\n",
       "      <td>-0.275269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-24</th>\n",
       "      <td>0.585682</td>\n",
       "      <td>0.295486</td>\n",
       "      <td>1.135943</td>\n",
       "      <td>-1.274274</td>\n",
       "      <td>-1.112043</td>\n",
       "      <td>-0.252455</td>\n",
       "      <td>-0.662000</td>\n",
       "      <td>-0.262992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-25</th>\n",
       "      <td>-0.229977</td>\n",
       "      <td>0.136914</td>\n",
       "      <td>1.585487</td>\n",
       "      <td>-1.229390</td>\n",
       "      <td>-1.038843</td>\n",
       "      <td>-0.123973</td>\n",
       "      <td>-0.637608</td>\n",
       "      <td>0.180554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-28</th>\n",
       "      <td>-0.569067</td>\n",
       "      <td>0.066468</td>\n",
       "      <td>-0.531933</td>\n",
       "      <td>-1.268273</td>\n",
       "      <td>-1.121999</td>\n",
       "      <td>-0.222804</td>\n",
       "      <td>-0.640832</td>\n",
       "      <td>-0.051854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-29</th>\n",
       "      <td>-0.928190</td>\n",
       "      <td>0.072546</td>\n",
       "      <td>-0.095419</td>\n",
       "      <td>-1.296455</td>\n",
       "      <td>-1.101410</td>\n",
       "      <td>-0.173389</td>\n",
       "      <td>-0.848835</td>\n",
       "      <td>-0.179319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-09</th>\n",
       "      <td>-0.617261</td>\n",
       "      <td>-0.208961</td>\n",
       "      <td>-1.489658</td>\n",
       "      <td>2.078112</td>\n",
       "      <td>2.567628</td>\n",
       "      <td>2.202245</td>\n",
       "      <td>0.244007</td>\n",
       "      <td>-0.292395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-12</th>\n",
       "      <td>-0.621355</td>\n",
       "      <td>-0.178297</td>\n",
       "      <td>-1.861021</td>\n",
       "      <td>2.053465</td>\n",
       "      <td>2.545661</td>\n",
       "      <td>2.132575</td>\n",
       "      <td>0.438723</td>\n",
       "      <td>-0.206689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-13</th>\n",
       "      <td>-0.277611</td>\n",
       "      <td>-0.060887</td>\n",
       "      <td>-0.681781</td>\n",
       "      <td>2.125210</td>\n",
       "      <td>2.518552</td>\n",
       "      <td>2.036107</td>\n",
       "      <td>0.420755</td>\n",
       "      <td>-0.229288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-14</th>\n",
       "      <td>-0.329436</td>\n",
       "      <td>-0.315597</td>\n",
       "      <td>0.236853</td>\n",
       "      <td>2.057315</td>\n",
       "      <td>2.539889</td>\n",
       "      <td>2.057544</td>\n",
       "      <td>0.361859</td>\n",
       "      <td>-0.300841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-15</th>\n",
       "      <td>-0.689698</td>\n",
       "      <td>-0.154815</td>\n",
       "      <td>-0.193146</td>\n",
       "      <td>2.146159</td>\n",
       "      <td>2.661292</td>\n",
       "      <td>2.057544</td>\n",
       "      <td>0.530432</td>\n",
       "      <td>-0.266824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>556 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Volume  Wiki_total  Google_total  nas_close  dow_close  \\\n",
       "date                                                                   \n",
       "2019-01-23 -0.473952    0.189679     -0.916326  -1.297693  -1.103138   \n",
       "2019-01-24  0.585682    0.295486      1.135943  -1.274274  -1.112043   \n",
       "2019-01-25 -0.229977    0.136914      1.585487  -1.229390  -1.038843   \n",
       "2019-01-28 -0.569067    0.066468     -0.531933  -1.268273  -1.121999   \n",
       "2019-01-29 -0.928190    0.072546     -0.095419  -1.296455  -1.101410   \n",
       "...              ...         ...           ...        ...        ...   \n",
       "2021-04-09 -0.617261   -0.208961     -1.489658   2.078112   2.567628   \n",
       "2021-04-12 -0.621355   -0.178297     -1.861021   2.053465   2.545661   \n",
       "2021-04-13 -0.277611   -0.060887     -0.681781   2.125210   2.518552   \n",
       "2021-04-14 -0.329436   -0.315597      0.236853   2.057315   2.539889   \n",
       "2021-04-15 -0.689698   -0.154815     -0.193146   2.146159   2.661292   \n",
       "\n",
       "               Close   nas_vol   dow_vol  \n",
       "date                                      \n",
       "2019-01-23 -0.380935 -0.737715 -0.275269  \n",
       "2019-01-24 -0.252455 -0.662000 -0.262992  \n",
       "2019-01-25 -0.123973 -0.637608  0.180554  \n",
       "2019-01-28 -0.222804 -0.640832 -0.051854  \n",
       "2019-01-29 -0.173389 -0.848835 -0.179319  \n",
       "...              ...       ...       ...  \n",
       "2021-04-09  2.202245  0.244007 -0.292395  \n",
       "2021-04-12  2.132575  0.438723 -0.206689  \n",
       "2021-04-13  2.036107  0.420755 -0.229288  \n",
       "2021-04-14  2.057544  0.361859 -0.300841  \n",
       "2021-04-15  2.057544  0.530432 -0.266824  \n",
       "\n",
       "[556 rows x 8 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "2a7667fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visual Distribution of the features\n",
    "ford_1_std = (Ford_1 - train_f1_mean) / train_f1_std\n",
    "ford_1_std = ford_1_std.melt(var_name='Column', value_name='Normalized')\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.violinplot(x='Column', y='Normalized', data=ford_1_std)\n",
    "_ = ax.set_xticklabels(Ford_1.keys(), rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "1c114caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Flow times series dataframe modifier\n",
    "\n",
    "\n",
    "# format\n",
    "# X                                             y\n",
    "# [[[V1_0, V2_0], [V1_1, V2_1], [V1_2, V2_2]]]  [target_3]\n",
    "# [[[V1_1, V2_1], [V1_2, V2_3], [V1_3, V2_3]]]  [target_4]\n",
    "# [[[V1_2, V2_2], [V1_3, V2_3], [V1_4, V2_4]]]  [target_5]\n",
    "\n",
    "def df_to_X_y2(df, target, window_size=5):\n",
    "  df_as_np = df.to_numpy() # converts to matrix of numpy arrays\n",
    "  X = []\n",
    "  y = []\n",
    "  for i in range(len(df_as_np)-window_size): # length of data frame - window_size so it does't take empty values at the end\n",
    "    row = [r for r in df_as_np[i:i+window_size]] # grabs row i and all rows above within the window size length\n",
    "    X.append(row) # creates 3 dimentional array, (# obseravtions, # rows in window, # features)\n",
    "    label = target[i+window_size][0:] # pulls the target variable after the window, target varible needs to be column zero in this \n",
    "    y.append(label) # returns (N,) martix of targets i+window_length time periods away\n",
    "  return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "9dd47617",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf1_train, yf1_train = df_to_X_y2(train_f1, train_f1t)\n",
    "Xf1_val, yf1_val = df_to_X_y2(val_f1, val_f1t)\n",
    "Xf1_test, yf1_test = df_to_X_y2(test_f1, test_f1t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e21b47a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, InputLayer\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "38a870aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_51 (Conv1D)          (None, 4, 5)              85        \n",
      "                                                                 \n",
      " max_pooling1d_35 (MaxPoolin  (None, 2, 5)             0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_28 (Flatten)        (None, 10)                0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 50)                550       \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 737\n",
      "Trainable params: 737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "n_steps = 5\n",
    "n_features = 8\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=5, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model.add(MaxPooling1D(pool_size=2)) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu')) \n",
    "model.add(Dense(2, activation='softmax')) # was getting lots of errors, apparently for binary classification needs just 1 in its shape???\n",
    "# this was the explination I got after typing in error;  \n",
    "# ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 1))\n",
    "# thought binary classification needed output of 2 though\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 13ms/step - loss: 0.7016 - accuracy: 0.5191 - val_loss: 0.6951 - val_accuracy: 0.5130\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6867 - accuracy: 0.5354 - val_loss: 0.6991 - val_accuracy: 0.5065\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.5644 - val_loss: 0.6970 - val_accuracy: 0.5195\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6792 - accuracy: 0.5626 - val_loss: 0.6952 - val_accuracy: 0.5260\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6776 - accuracy: 0.5753 - val_loss: 0.6941 - val_accuracy: 0.5260\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6754 - accuracy: 0.5699 - val_loss: 0.6950 - val_accuracy: 0.5260\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6735 - accuracy: 0.5826 - val_loss: 0.6947 - val_accuracy: 0.5325\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6721 - accuracy: 0.5844 - val_loss: 0.6951 - val_accuracy: 0.5195\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6718 - accuracy: 0.5862 - val_loss: 0.6944 - val_accuracy: 0.5260\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6692 - accuracy: 0.5898 - val_loss: 0.6944 - val_accuracy: 0.5260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x158b0bfa0>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xf1_train,yf1_train,epochs=10,  validation_data=(Xf1_val, yf1_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "426397d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hat = model.predict(Xf1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "5fe22aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat = (hat > 0.5) # for basic accuracy ratio\n",
    "metrics.accuracy_score(yf1_test,hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "4857c7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "6b854efa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"max_pooling1d_36\" (type MaxPooling1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling1d_36/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 1, 1], padding=\"VALID\", strides=[1, 2, 1, 1]](max_pooling1d_36/ExpandDims)' with input shapes: [?,1,1,5].\n\nCall arguments received:\n  â€¢ inputs=tf.Tensor(shape=(None, 1, 5), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jx/v484103954dd6vtd4swk8hd40000gn/T/ipykernel_26963/3474172746.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/backend.py\u001b[0m in \u001b[0;36mpool2d\u001b[0;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001b[0m\n\u001b[1;32m   6063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6064\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6065\u001b[0;31m     x = tf.compat.v1.nn.max_pool(\n\u001b[0m\u001b[1;32m   6066\u001b[0m         x, pool_size, strides, padding=padding, data_format=tf_data_format)\n\u001b[1;32m   6067\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'avg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"max_pooling1d_36\" (type MaxPooling1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling1d_36/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 1, 1], padding=\"VALID\", strides=[1, 2, 1, 1]](max_pooling1d_36/ExpandDims)' with input shapes: [?,1,1,5].\n\nCall arguments received:\n  â€¢ inputs=tf.Tensor(shape=(None, 1, 5), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# model repeated but with kernal size = window size, My understading may be wrong but kernal size should just be the size of the window no?\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=5, kernel_size=5, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model.add(MaxPooling1D()) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu')) \n",
    "model.add(Dense(2, activation='softmax')) \n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                   metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b97ae118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/18 [==============================] - 4s 172ms/step - loss: 0.6945 - accuracy: 0.5336 - val_loss: 0.7032 - val_accuracy: 0.5065\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6847 - accuracy: 0.5608 - val_loss: 0.7045 - val_accuracy: 0.5065\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6792 - accuracy: 0.5590 - val_loss: 0.7299 - val_accuracy: 0.5065\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6729 - accuracy: 0.5862 - val_loss: 0.7248 - val_accuracy: 0.5065\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6677 - accuracy: 0.6062 - val_loss: 0.7693 - val_accuracy: 0.5065\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6632 - accuracy: 0.6025 - val_loss: 0.7901 - val_accuracy: 0.5065\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6553 - accuracy: 0.6425 - val_loss: 0.8314 - val_accuracy: 0.5065\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6492 - accuracy: 0.6225 - val_loss: 0.8345 - val_accuracy: 0.5065\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6409 - accuracy: 0.6334 - val_loss: 0.8511 - val_accuracy: 0.5065\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6331 - accuracy: 0.6570 - val_loss: 0.9200 - val_accuracy: 0.5065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x158cb69d0>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model2.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model2.add(MaxPooling1D(pool_size=2)) \n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(50, activation='relu')) \n",
    "model2.add(Dense(2, activation='softmax')) \n",
    "\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                   metrics=[\"accuracy\"])\n",
    "model2.fit(Xf1_train,yf1_train,epochs=10,  validation_data=(Xf1_val, yf1_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "6b64c69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5866666666666667"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat2 = model2.predict(Xf1_test)\n",
    "hat2 = (hat2 > 0.5)\n",
    "metrics.accuracy_score(yf1_test, hat2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "d1c9c0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False]]),\n",
       " array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat2, yf1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae222ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"conv1d_24\" (type Conv1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node conv1d_24/Conv1D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d_24/Conv1D/ExpandDims, conv1d_24/Conv1D/ExpandDims_1)' with input shapes: [?,1,1,32], [1,2,32,32].\n\nCall arguments received:\n  â€¢ inputs=tf.Tensor(shape=(None, 1, 32), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jx/v484103954dd6vtd4swk8hd40000gn/T/ipykernel_26963/1013524856.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   2011\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2013\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"conv1d_24\" (type Conv1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node conv1d_24/Conv1D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d_24/Conv1D/ExpandDims, conv1d_24/Conv1D/ExpandDims_1)' with input shapes: [?,1,1,32], [1,2,32,32].\n\nCall arguments received:\n  â€¢ inputs=tf.Tensor(shape=(None, 1, 32), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# Model three failed, seems to be an issue with adding convoiltion layer again agter pooling\n",
    "model3 = Sequential()\n",
    "model3.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model3.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
    "model3.add(MaxPooling1D(pool_size=2)) \n",
    "model3.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model3.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model3.add(MaxPooling1D(pool_size=2)) \n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(25, activation='relu')) \n",
    "model3.add(Dense(2, activation='softmax')) \n",
    "\n",
    "model3.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                   metrics=[\"accuracy\"])\n",
    "model3.fit(Xf1_train,yf1_train,epochs=10,  validation_data=(Xf1_val, yf1_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "fd8b8779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 1s 16ms/step - loss: 0.6941 - accuracy: 0.4900 - val_loss: 0.7112 - val_accuracy: 0.5065\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.6889 - accuracy: 0.5499 - val_loss: 0.7134 - val_accuracy: 0.5065\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.6873 - accuracy: 0.5481 - val_loss: 0.7219 - val_accuracy: 0.5065\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6853 - accuracy: 0.5717 - val_loss: 0.7177 - val_accuracy: 0.5065\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6837 - accuracy: 0.5826 - val_loss: 0.7105 - val_accuracy: 0.5065\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6818 - accuracy: 0.5844 - val_loss: 0.7280 - val_accuracy: 0.5065\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6796 - accuracy: 0.5862 - val_loss: 0.7221 - val_accuracy: 0.5065\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6760 - accuracy: 0.5917 - val_loss: 0.7533 - val_accuracy: 0.5065\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6736 - accuracy: 0.5917 - val_loss: 0.7423 - val_accuracy: 0.5065\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.6685 - accuracy: 0.6025 - val_loss: 0.7477 - val_accuracy: 0.5065\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6660 - accuracy: 0.5953 - val_loss: 0.7451 - val_accuracy: 0.5195\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6637 - accuracy: 0.6025 - val_loss: 0.7814 - val_accuracy: 0.5065\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6582 - accuracy: 0.6025 - val_loss: 0.7898 - val_accuracy: 0.5065\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.6556 - accuracy: 0.5989 - val_loss: 0.7868 - val_accuracy: 0.5065\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6518 - accuracy: 0.6116 - val_loss: 0.8327 - val_accuracy: 0.5065\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6540 - accuracy: 0.6134 - val_loss: 0.8162 - val_accuracy: 0.5065\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.6427 - accuracy: 0.6171 - val_loss: 0.8607 - val_accuracy: 0.5065\n",
      "Epoch 18/30\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.6446 - accuracy: 0.6098 - val_loss: 0.8768 - val_accuracy: 0.5065\n",
      "Epoch 19/30\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.6404 - accuracy: 0.6261 - val_loss: 0.8756 - val_accuracy: 0.5065\n",
      "Epoch 20/30\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.6390 - accuracy: 0.6189 - val_loss: 0.8499 - val_accuracy: 0.5065\n",
      "Epoch 21/30\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6342 - accuracy: 0.6152 - val_loss: 0.8848 - val_accuracy: 0.5065\n",
      "Epoch 22/30\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6309 - accuracy: 0.6298 - val_loss: 0.8834 - val_accuracy: 0.5065\n",
      "Epoch 23/30\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6286 - accuracy: 0.6316 - val_loss: 0.9197 - val_accuracy: 0.5065\n",
      "Epoch 24/30\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6286 - accuracy: 0.6298 - val_loss: 0.9388 - val_accuracy: 0.5065\n",
      "Epoch 25/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6294 - accuracy: 0.6334 - val_loss: 0.9386 - val_accuracy: 0.5065\n",
      "Epoch 26/30\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6241 - accuracy: 0.6352 - val_loss: 0.9166 - val_accuracy: 0.5065\n",
      "Epoch 27/30\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6195 - accuracy: 0.6461 - val_loss: 0.9094 - val_accuracy: 0.5130\n",
      "Epoch 28/30\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6160 - accuracy: 0.6461 - val_loss: 0.9057 - val_accuracy: 0.5130\n",
      "Epoch 29/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6182 - accuracy: 0.6370 - val_loss: 0.9036 - val_accuracy: 0.5195\n",
      "Epoch 30/30\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6155 - accuracy: 0.6443 - val_loss: 0.9292 - val_accuracy: 0.5130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x158edfdc0>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Conv1D(filters=4, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model4.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
    "model4.add(MaxPooling1D(pool_size=2)) \n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(100, activation='relu')) \n",
    "model4.add(Dense(2, activation='softmax')) \n",
    "\n",
    "model4.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                   metrics=[\"accuracy\"])\n",
    "model4.fit(Xf1_train,yf1_train,epochs=30,  validation_data=(Xf1_val, yf1_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5bd43bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.87959027e-01, 1.20409699e-02],\n",
       "       [9.85336602e-01, 1.46633862e-02],\n",
       "       [9.89741087e-01, 1.02589587e-02],\n",
       "       [9.95198071e-01, 4.80197370e-03],\n",
       "       [9.94870067e-01, 5.12992870e-03],\n",
       "       [9.94799256e-01, 5.20075345e-03],\n",
       "       [9.89107072e-01, 1.08929323e-02],\n",
       "       [9.87193882e-01, 1.28061231e-02],\n",
       "       [9.90194976e-01, 9.80507582e-03],\n",
       "       [9.89267409e-01, 1.07325185e-02],\n",
       "       [9.74742532e-01, 2.52574235e-02],\n",
       "       [9.58638012e-01, 4.13619503e-02],\n",
       "       [9.65297520e-01, 3.47024798e-02],\n",
       "       [9.73175704e-01, 2.68242583e-02],\n",
       "       [9.75861192e-01, 2.41388865e-02],\n",
       "       [9.79127705e-01, 2.08722446e-02],\n",
       "       [9.62102830e-01, 3.78972106e-02],\n",
       "       [9.96372223e-01, 3.62781668e-03],\n",
       "       [9.99631166e-01, 3.68771522e-04],\n",
       "       [9.99789178e-01, 2.10787766e-04],\n",
       "       [9.99812424e-01, 1.87582496e-04],\n",
       "       [9.98481810e-01, 1.51816686e-03],\n",
       "       [9.96935129e-01, 3.06482962e-03],\n",
       "       [9.94232237e-01, 5.76768164e-03],\n",
       "       [9.95424449e-01, 4.57560830e-03],\n",
       "       [9.97594655e-01, 2.40533240e-03],\n",
       "       [9.97525752e-01, 2.47424678e-03],\n",
       "       [9.97354627e-01, 2.64535402e-03],\n",
       "       [9.98429716e-01, 1.57031219e-03],\n",
       "       [9.98390079e-01, 1.60995894e-03],\n",
       "       [9.97748911e-01, 2.25109747e-03],\n",
       "       [9.97690082e-01, 2.30997778e-03],\n",
       "       [9.95229363e-01, 4.77060163e-03],\n",
       "       [9.90441680e-01, 9.55836102e-03],\n",
       "       [9.89222169e-01, 1.07778087e-02],\n",
       "       [9.89572048e-01, 1.04280338e-02],\n",
       "       [9.89118695e-01, 1.08813429e-02],\n",
       "       [9.88035262e-01, 1.19647272e-02],\n",
       "       [9.84236121e-01, 1.57638323e-02],\n",
       "       [9.91829574e-01, 8.17041006e-03],\n",
       "       [9.95855868e-01, 4.14408604e-03],\n",
       "       [9.94664907e-01, 5.33505622e-03],\n",
       "       [9.92796838e-01, 7.20315939e-03],\n",
       "       [9.89280164e-01, 1.07198851e-02],\n",
       "       [9.82541144e-01, 1.74588766e-02],\n",
       "       [9.84350443e-01, 1.56495534e-02],\n",
       "       [9.85278189e-01, 1.47218211e-02],\n",
       "       [9.80112135e-01, 1.98879410e-02],\n",
       "       [9.73524570e-01, 2.64753904e-02],\n",
       "       [9.72885072e-01, 2.71149389e-02],\n",
       "       [9.82486248e-01, 1.75137669e-02],\n",
       "       [9.82934058e-01, 1.70659665e-02],\n",
       "       [9.79185522e-01, 2.08144933e-02],\n",
       "       [9.82219696e-01, 1.77802481e-02],\n",
       "       [9.86846209e-01, 1.31537775e-02],\n",
       "       [9.83394265e-01, 1.66057572e-02],\n",
       "       [9.72904563e-01, 2.70954426e-02],\n",
       "       [9.81271088e-01, 1.87289268e-02],\n",
       "       [9.79900181e-01, 2.00998504e-02],\n",
       "       [9.74274337e-01, 2.57256981e-02],\n",
       "       [9.49795783e-01, 5.02041616e-02],\n",
       "       [9.40686941e-01, 5.93130738e-02],\n",
       "       [9.51333404e-01, 4.86665927e-02],\n",
       "       [9.72199380e-01, 2.78005432e-02],\n",
       "       [9.62089539e-01, 3.79104838e-02],\n",
       "       [9.54647541e-01, 4.53524366e-02],\n",
       "       [9.63563800e-01, 3.64362188e-02],\n",
       "       [9.70844507e-01, 2.91555021e-02],\n",
       "       [9.74183440e-01, 2.58165896e-02],\n",
       "       [9.59848583e-01, 4.01513875e-02],\n",
       "       [9.34311450e-01, 6.56885430e-02],\n",
       "       [9.17036116e-01, 8.29638690e-02],\n",
       "       [9.54982579e-01, 4.50174622e-02],\n",
       "       [9.43419516e-01, 5.65805063e-02],\n",
       "       [9.37800229e-01, 6.21997491e-02]], dtype=float32)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat4 = model4.predict(Xf1_test)\n",
    "hat4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e42b0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "hat4 = (hat4 > 0.5)\n",
    "metrics.accuracy_score(yf1_test, hat4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "b27e500f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False]]),\n",
       " array([[ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False],\n",
       "        [ True, False]]))"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat4, hat2"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
