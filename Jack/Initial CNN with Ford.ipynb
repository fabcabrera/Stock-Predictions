{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a1a9e62",
   "metadata": {},
   "source": [
    "# Initial CNN Model Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be98f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense, Normalization\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "581b3306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, InputLayer\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f922ed4b",
   "metadata": {},
   "source": [
    "### Part 1 Figuuring out how to deal with NaNs\n",
    "Come to the coclusion just to use test data set for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b12719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ford = pd.read_csv(\"Ford_Cleaned_Date.csv\")\n",
    "Ford.date = pd.to_datetime(Ford.date)\n",
    "Ford = Ford.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "282fb5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(801, 169)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ford = Ford.iloc[14:, :]\n",
    "Ford.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba29efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "380faec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ford</th>\n",
       "      <th>F-150</th>\n",
       "      <th>Ford Bronco_x</th>\n",
       "      <th>Ford Mustang_x</th>\n",
       "      <th>Ford Stock</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Ford Motor Company</th>\n",
       "      <th>Ford Mustang_y</th>\n",
       "      <th>Ford F Series</th>\n",
       "      <th>Ford Bronco_y</th>\n",
       "      <th>Lincoln Navigator</th>\n",
       "      <th>Lincoln Aviator</th>\n",
       "      <th>Ford GT</th>\n",
       "      <th>dow_open</th>\n",
       "      <th>dow_high</th>\n",
       "      <th>dow_low</th>\n",
       "      <th>dow_close</th>\n",
       "      <th>dow_vol</th>\n",
       "      <th>nas_open</th>\n",
       "      <th>nas_high</th>\n",
       "      <th>nas_low</th>\n",
       "      <th>nas_close</th>\n",
       "      <th>nas_vol</th>\n",
       "      <th>Wiki_total</th>\n",
       "      <th>Google_total</th>\n",
       "      <th>Stock_total</th>\n",
       "      <th>Nas_total</th>\n",
       "      <th>Dow_total</th>\n",
       "      <th>Wiki_Moment_1</th>\n",
       "      <th>Wiki_Moment_2</th>\n",
       "      <th>Wiki_Moment_1_s</th>\n",
       "      <th>Wiki_Moment_2_s</th>\n",
       "      <th>Wiki_MAvg</th>\n",
       "      <th>Wiki_MAvg_s</th>\n",
       "      <th>Wiki_Disparity</th>\n",
       "      <th>Wiki_Disparity_s</th>\n",
       "      <th>Wiki_ROC</th>\n",
       "      <th>Wiki_ROC_s</th>\n",
       "      <th>Wiki_Rocp</th>\n",
       "      <th>Wiki_EMA</th>\n",
       "      <th>Wiki_diff</th>\n",
       "      <th>Wiki_gain</th>\n",
       "      <th>Wiki_loss</th>\n",
       "      <th>Wiki_avg_gain</th>\n",
       "      <th>Wiki_avg_loss</th>\n",
       "      <th>Wiki_rs</th>\n",
       "      <th>Wiki_RSI</th>\n",
       "      <th>Wiki_Move</th>\n",
       "      <th>Wiki_MAvg_Move</th>\n",
       "      <th>Wiki_MAvg_s_Move</th>\n",
       "      <th>Wiki_EMA_Move</th>\n",
       "      <th>Wiki_Disparity_Move</th>\n",
       "      <th>Wiki_Disparity_s_Move</th>\n",
       "      <th>Wiki_RSI_Move</th>\n",
       "      <th>Google_Moment_1</th>\n",
       "      <th>Google_Moment_2</th>\n",
       "      <th>Google_Moment_1_s</th>\n",
       "      <th>Google_Moment_2_s</th>\n",
       "      <th>Google_MAvg</th>\n",
       "      <th>Google_MAvg_s</th>\n",
       "      <th>Google_Disparity</th>\n",
       "      <th>Google_Disparity_s</th>\n",
       "      <th>Google_ROC</th>\n",
       "      <th>Google_ROC_s</th>\n",
       "      <th>Google_Rocp</th>\n",
       "      <th>Google_EMA</th>\n",
       "      <th>Google_diff</th>\n",
       "      <th>Google_gain</th>\n",
       "      <th>Google_loss</th>\n",
       "      <th>Google_avg_gain</th>\n",
       "      <th>Google_avg_loss</th>\n",
       "      <th>Google_rs</th>\n",
       "      <th>Google_RSI</th>\n",
       "      <th>Google_Move</th>\n",
       "      <th>Google_MAvg_Move</th>\n",
       "      <th>Google_MAvg_s_Move</th>\n",
       "      <th>Google_EMA_Move</th>\n",
       "      <th>Google_Disparity_Move</th>\n",
       "      <th>Google_Disparity_s_Move</th>\n",
       "      <th>Google_RSI_Move</th>\n",
       "      <th>Stock_Moment_1</th>\n",
       "      <th>Stock_Moment_2</th>\n",
       "      <th>Stock_Moment_1_s</th>\n",
       "      <th>Stock_Moment_2_s</th>\n",
       "      <th>Stock_MAvg</th>\n",
       "      <th>Stock_MAvg_s</th>\n",
       "      <th>Stock_Disparity</th>\n",
       "      <th>Stock_Disparity_s</th>\n",
       "      <th>Stock_ROC</th>\n",
       "      <th>Stock_ROC_s</th>\n",
       "      <th>Stock_Rocp</th>\n",
       "      <th>Stock_EMA</th>\n",
       "      <th>Stock_diff</th>\n",
       "      <th>Stock_gain</th>\n",
       "      <th>Stock_loss</th>\n",
       "      <th>Stock_avg_gain</th>\n",
       "      <th>Stock_avg_loss</th>\n",
       "      <th>Stock_rs</th>\n",
       "      <th>Stock_RSI</th>\n",
       "      <th>Stock_Move</th>\n",
       "      <th>Stock_MAvg_Move</th>\n",
       "      <th>Stock_MAvg_s_Move</th>\n",
       "      <th>Stock_EMA_Move</th>\n",
       "      <th>Stock_Disparity_Move</th>\n",
       "      <th>Stock_Disparity_s_Move</th>\n",
       "      <th>Stock_RSI_Move</th>\n",
       "      <th>Nas_Moment_1</th>\n",
       "      <th>Nas_Moment_2</th>\n",
       "      <th>Nas_Moment_1_s</th>\n",
       "      <th>Nas_Moment_2_s</th>\n",
       "      <th>Nas_MAvg</th>\n",
       "      <th>Nas_MAvg_s</th>\n",
       "      <th>Nas_Disparity</th>\n",
       "      <th>Nas_Disparity_s</th>\n",
       "      <th>Nas_ROC</th>\n",
       "      <th>Nas_ROC_s</th>\n",
       "      <th>Nas_Rocp</th>\n",
       "      <th>Nas_EMA</th>\n",
       "      <th>Nas_diff</th>\n",
       "      <th>Nas_gain</th>\n",
       "      <th>Nas_loss</th>\n",
       "      <th>Nas_avg_gain</th>\n",
       "      <th>Nas_avg_loss</th>\n",
       "      <th>Nas_rs</th>\n",
       "      <th>Nas_RSI</th>\n",
       "      <th>Nas_Move</th>\n",
       "      <th>Nas_MAvg_Move</th>\n",
       "      <th>Nas_MAvg_s_Move</th>\n",
       "      <th>Nas_EMA_Move</th>\n",
       "      <th>Nas_Disparity_Move</th>\n",
       "      <th>Nas_Disparity_s_Move</th>\n",
       "      <th>Nas_RSI_Move</th>\n",
       "      <th>Dow_Moment_1</th>\n",
       "      <th>Dow_Moment_2</th>\n",
       "      <th>Dow_Moment_1_s</th>\n",
       "      <th>Dow_Moment_2_s</th>\n",
       "      <th>Dow_MAvg</th>\n",
       "      <th>Dow_MAvg_s</th>\n",
       "      <th>Dow_Disparity</th>\n",
       "      <th>Dow_Disparity_s</th>\n",
       "      <th>Dow_ROC</th>\n",
       "      <th>Dow_ROC_s</th>\n",
       "      <th>Dow_Rocp</th>\n",
       "      <th>Dow_EMA</th>\n",
       "      <th>Dow_diff</th>\n",
       "      <th>Dow_gain</th>\n",
       "      <th>Dow_loss</th>\n",
       "      <th>Dow_avg_gain</th>\n",
       "      <th>Dow_avg_loss</th>\n",
       "      <th>Dow_rs</th>\n",
       "      <th>Dow_RSI</th>\n",
       "      <th>Dow_Move</th>\n",
       "      <th>Dow_MAvg_Move</th>\n",
       "      <th>Dow_MAvg_s_Move</th>\n",
       "      <th>Dow_EMA_Move</th>\n",
       "      <th>Dow_Disparity_Move</th>\n",
       "      <th>Dow_Disparity_s_Move</th>\n",
       "      <th>Dow_RSI_Move</th>\n",
       "      <th>target_1</th>\n",
       "      <th>target_2</th>\n",
       "      <th>target_3</th>\n",
       "      <th>target_4</th>\n",
       "      <th>target_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ford  F-150  Ford Bronco_x  Ford Mustang_x  Ford Stock  Open  High  Low  \\\n",
       "0     0      0              0               0           0     6     6    6   \n",
       "\n",
       "   Close  Volume  Dividends  Stock Splits  Ford Motor Company  Ford Mustang_y  \\\n",
       "0      6       6          6             6                   0               0   \n",
       "\n",
       "   Ford F Series  Ford Bronco_y  Lincoln Navigator  Lincoln Aviator  Ford GT  \\\n",
       "0              0              0                  0                0        0   \n",
       "\n",
       "   dow_open  dow_high  dow_low  dow_close  dow_vol  nas_open  nas_high  \\\n",
       "0         4         4        4          4        4         4         4   \n",
       "\n",
       "   nas_low  nas_close  nas_vol  Wiki_total  Google_total  Stock_total  \\\n",
       "0        4          4        4           0             0            6   \n",
       "\n",
       "   Nas_total  Dow_total  Wiki_Moment_1  Wiki_Moment_2  Wiki_Moment_1_s  \\\n",
       "0          4          4              0              0                0   \n",
       "\n",
       "   Wiki_Moment_2_s  Wiki_MAvg  Wiki_MAvg_s  Wiki_Disparity  Wiki_Disparity_s  \\\n",
       "0                0          0            0               0                 0   \n",
       "\n",
       "   Wiki_ROC  Wiki_ROC_s  Wiki_Rocp  Wiki_EMA  Wiki_diff  Wiki_gain  Wiki_loss  \\\n",
       "0         0           0          0         0          0          0          0   \n",
       "\n",
       "   Wiki_avg_gain  Wiki_avg_loss  Wiki_rs  Wiki_RSI  Wiki_Move  Wiki_MAvg_Move  \\\n",
       "0              0              0        0         0          0               0   \n",
       "\n",
       "   Wiki_MAvg_s_Move  Wiki_EMA_Move  Wiki_Disparity_Move  \\\n",
       "0                 0              0                    0   \n",
       "\n",
       "   Wiki_Disparity_s_Move  Wiki_RSI_Move  Google_Moment_1  Google_Moment_2  \\\n",
       "0                      0              0                0                0   \n",
       "\n",
       "   Google_Moment_1_s  Google_Moment_2_s  Google_MAvg  Google_MAvg_s  \\\n",
       "0                  0                  0            0              0   \n",
       "\n",
       "   Google_Disparity  Google_Disparity_s  Google_ROC  Google_ROC_s  \\\n",
       "0                 0                   0           0             0   \n",
       "\n",
       "   Google_Rocp  Google_EMA  Google_diff  Google_gain  Google_loss  \\\n",
       "0            0           0            0            0            0   \n",
       "\n",
       "   Google_avg_gain  Google_avg_loss  Google_rs  Google_RSI  Google_Move  \\\n",
       "0                0                0          0           0            0   \n",
       "\n",
       "   Google_MAvg_Move  Google_MAvg_s_Move  Google_EMA_Move  \\\n",
       "0                 0                   0                0   \n",
       "\n",
       "   Google_Disparity_Move  Google_Disparity_s_Move  Google_RSI_Move  \\\n",
       "0                      0                        0                0   \n",
       "\n",
       "   Stock_Moment_1  Stock_Moment_2  Stock_Moment_1_s  Stock_Moment_2_s  \\\n",
       "0              11              11                11                11   \n",
       "\n",
       "   Stock_MAvg  Stock_MAvg_s  Stock_Disparity  Stock_Disparity_s  Stock_ROC  \\\n",
       "0           0             0                6                  6         11   \n",
       "\n",
       "   Stock_ROC_s  Stock_Rocp  Stock_EMA  Stock_diff  Stock_gain  Stock_loss  \\\n",
       "0           11          11          6          11          11          11   \n",
       "\n",
       "   Stock_avg_gain  Stock_avg_loss  Stock_rs  Stock_RSI  Stock_Move  \\\n",
       "0              76              76        76         76           0   \n",
       "\n",
       "   Stock_MAvg_Move  Stock_MAvg_s_Move  Stock_EMA_Move  Stock_Disparity_Move  \\\n",
       "0                0                  0               0                     0   \n",
       "\n",
       "   Stock_Disparity_s_Move  Stock_RSI_Move  Nas_Moment_1  Nas_Moment_2  \\\n",
       "0                       0               0             7             7   \n",
       "\n",
       "   Nas_Moment_1_s  Nas_Moment_2_s  Nas_MAvg  Nas_MAvg_s  Nas_Disparity  \\\n",
       "0               7               7         0           0              4   \n",
       "\n",
       "   Nas_Disparity_s  Nas_ROC  Nas_ROC_s  Nas_Rocp  Nas_EMA  Nas_diff  Nas_gain  \\\n",
       "0                4        7          7         7        4         7         7   \n",
       "\n",
       "   Nas_loss  Nas_avg_gain  Nas_avg_loss  Nas_rs  Nas_RSI  Nas_Move  \\\n",
       "0         7            46            46      46       46         0   \n",
       "\n",
       "   Nas_MAvg_Move  Nas_MAvg_s_Move  Nas_EMA_Move  Nas_Disparity_Move  \\\n",
       "0              0                0             0                   0   \n",
       "\n",
       "   Nas_Disparity_s_Move  Nas_RSI_Move  Dow_Moment_1  Dow_Moment_2  \\\n",
       "0                     0             0             7             7   \n",
       "\n",
       "   Dow_Moment_1_s  Dow_Moment_2_s  Dow_MAvg  Dow_MAvg_s  Dow_Disparity  \\\n",
       "0               7               7         0           0              4   \n",
       "\n",
       "   Dow_Disparity_s  Dow_ROC  Dow_ROC_s  Dow_Rocp  Dow_EMA  Dow_diff  Dow_gain  \\\n",
       "0                4        7          7         7        4         7         7   \n",
       "\n",
       "   Dow_loss  Dow_avg_gain  Dow_avg_loss  Dow_rs  Dow_RSI  Dow_Move  \\\n",
       "0         7            46            46      46       46         0   \n",
       "\n",
       "   Dow_MAvg_Move  Dow_MAvg_s_Move  Dow_EMA_Move  Dow_Disparity_Move  \\\n",
       "0              0                0             0                   0   \n",
       "\n",
       "   Dow_Disparity_s_Move  Dow_RSI_Move  target_1  target_2  target_3  target_4  \\\n",
       "0                     0             0         0         0         0         0   \n",
       "\n",
       "   target_5  \n",
       "0         0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Ford.isna().sum()).T\n",
    "# we see that the gain, average gain, average loss and loss columns are causing large numbers of NA's\n",
    "# will need to come back and solve this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62aa2414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any infinitly large or small values\n",
    "# Ford.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Drop remanining NaN or null values\n",
    "#Ford = Ford.dropna()\n",
    "#Ford.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b9c763c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_1</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Wiki_total</th>\n",
       "      <th>Google_total</th>\n",
       "      <th>nas_close</th>\n",
       "      <th>dow_close</th>\n",
       "      <th>Close</th>\n",
       "      <th>nas_vol</th>\n",
       "      <th>dow_vol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-23</th>\n",
       "      <td>0</td>\n",
       "      <td>45196900.0</td>\n",
       "      <td>14836.0</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>7025.770020</td>\n",
       "      <td>24575.619141</td>\n",
       "      <td>7.562010</td>\n",
       "      <td>2.274420e+09</td>\n",
       "      <td>318600000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-24</th>\n",
       "      <td>1</td>\n",
       "      <td>79516400.0</td>\n",
       "      <td>15219.0</td>\n",
       "      <td>32.625000</td>\n",
       "      <td>7073.459961</td>\n",
       "      <td>24553.240234</td>\n",
       "      <td>7.797754</td>\n",
       "      <td>2.400290e+09</td>\n",
       "      <td>320170000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-25</th>\n",
       "      <td>0</td>\n",
       "      <td>53098800.0</td>\n",
       "      <td>14645.0</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>7164.859863</td>\n",
       "      <td>24737.199219</td>\n",
       "      <td>8.033502</td>\n",
       "      <td>2.440840e+09</td>\n",
       "      <td>376890000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-28</th>\n",
       "      <td>1</td>\n",
       "      <td>42116300.0</td>\n",
       "      <td>14390.0</td>\n",
       "      <td>21.958333</td>\n",
       "      <td>7085.680176</td>\n",
       "      <td>24528.220703</td>\n",
       "      <td>7.852159</td>\n",
       "      <td>2.435480e+09</td>\n",
       "      <td>347170000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-29</th>\n",
       "      <td>1</td>\n",
       "      <td>30485000.0</td>\n",
       "      <td>14412.0</td>\n",
       "      <td>24.750000</td>\n",
       "      <td>7028.290039</td>\n",
       "      <td>24579.960938</td>\n",
       "      <td>7.942830</td>\n",
       "      <td>2.089690e+09</td>\n",
       "      <td>330870000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target_1      Volume  Wiki_total  Google_total    nas_close  \\\n",
       "date                                                                      \n",
       "2019-01-23         0  45196900.0     14836.0     19.500000  7025.770020   \n",
       "2019-01-24         1  79516400.0     15219.0     32.625000  7073.459961   \n",
       "2019-01-25         0  53098800.0     14645.0     35.500000  7164.859863   \n",
       "2019-01-28         1  42116300.0     14390.0     21.958333  7085.680176   \n",
       "2019-01-29         1  30485000.0     14412.0     24.750000  7028.290039   \n",
       "\n",
       "               dow_close     Close       nas_vol      dow_vol  \n",
       "date                                                           \n",
       "2019-01-23  24575.619141  7.562010  2.274420e+09  318600000.0  \n",
       "2019-01-24  24553.240234  7.797754  2.400290e+09  320170000.0  \n",
       "2019-01-25  24737.199219  8.033502  2.440840e+09  376890000.0  \n",
       "2019-01-28  24528.220703  7.852159  2.435480e+09  347170000.0  \n",
       "2019-01-29  24579.960938  7.942830  2.089690e+09  330870000.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ford 1, Basic Varaibles,  \n",
    "Ford_1 = Ford[Ford.columns.drop(list(Ford.filter(regex='Move')))]\n",
    "Ford_1 = Ford_1[[\"target_1\", \"Volume\", \n",
    "                \"Wiki_total\", \"Google_total\", \n",
    "                \"nas_close\", \"dow_close\",\n",
    "                 \"Close\", \"nas_vol\", \n",
    "                 \"dow_vol\"\n",
    "                 ]]\n",
    "Ford_1.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48545017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for checking NaN values\n",
    "\n",
    "# Ford_1[Ford_1['Volume'].isnull()]\n",
    "# pd.DataFrame(Ford.loc[\"2019-12-31\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cf48137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(801, 9)\n",
      "(795, 9)\n"
     ]
    }
   ],
   "source": [
    "print(Ford_1.shape)\n",
    "print(Ford_1.dropna().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "319246d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_1          int64\n",
       "Volume          float64\n",
       "Wiki_total      float64\n",
       "Google_total    float64\n",
       "nas_close       float64\n",
       "dow_close       float64\n",
       "Close           float64\n",
       "nas_vol         float64\n",
       "dow_vol         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ford_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b154f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ford_1 = Ford_1.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2377d6ae",
   "metadata": {},
   "source": [
    "## Part 2, Setting up Data to be useable with tensor flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9628c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ford_1[\"target_1\"] = to_categorical(Ford_1['target_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccca909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into training sets \n",
    "column_indices = {name: i for i, name in enumerate(Ford_1.columns)}\n",
    "\n",
    "n = len(Ford_1)\n",
    "train_f1 = Ford_1[0:int(n*0.7)]\n",
    "val_f1 = Ford_1[int(n*0.7):int(n*0.9)]\n",
    "test_f1 = Ford_1[int(n*0.9):]\n",
    "\n",
    "num_features = Ford_1.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70f97d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seporating out all non binary varibles to be normalized\n",
    "f_list = [\"Volume\", \n",
    "            \"Wiki_total\", \"Google_total\", \n",
    "            \"nas_close\", \"dow_close\",\n",
    "            \"Close\", \"nas_vol\", \n",
    "            \"dow_vol\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "566204bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/frame.py:3641: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "#normalizing the data, may come back later to take normalization with moving averages to avoid allwoing\n",
    "# the training set to have access to futre traing data, makes model more realistic\n",
    "train_f1_mean = train_f1[f_list].mean()\n",
    "train_f1_std = train_f1[f_list].std()\n",
    "\n",
    "train_f1[f_list] = (train_f1[f_list] - train_f1_mean) / train_f1_std\n",
    "val_f1[f_list] = (val_f1[f_list] - train_f1_mean) / train_f1_std\n",
    "test_f1[f_list] = (test_f1[f_list] - train_f1_mean) / train_f1_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30570790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_1        float32\n",
      "Volume          float64\n",
      "Wiki_total      float64\n",
      "Google_total    float64\n",
      "nas_close       float64\n",
      "dow_close       float64\n",
      "Close           float64\n",
      "nas_vol         float64\n",
      "dow_vol         float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_1</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Wiki_total</th>\n",
       "      <th>Google_total</th>\n",
       "      <th>nas_close</th>\n",
       "      <th>dow_close</th>\n",
       "      <th>Close</th>\n",
       "      <th>nas_vol</th>\n",
       "      <th>dow_vol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.473952</td>\n",
       "      <td>0.189679</td>\n",
       "      <td>-0.916326</td>\n",
       "      <td>-1.297693</td>\n",
       "      <td>-1.103138</td>\n",
       "      <td>-0.380935</td>\n",
       "      <td>-0.737715</td>\n",
       "      <td>-0.275269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585682</td>\n",
       "      <td>0.295486</td>\n",
       "      <td>1.135943</td>\n",
       "      <td>-1.274274</td>\n",
       "      <td>-1.112043</td>\n",
       "      <td>-0.252455</td>\n",
       "      <td>-0.662000</td>\n",
       "      <td>-0.262992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.229977</td>\n",
       "      <td>0.136914</td>\n",
       "      <td>1.585487</td>\n",
       "      <td>-1.229390</td>\n",
       "      <td>-1.038843</td>\n",
       "      <td>-0.123973</td>\n",
       "      <td>-0.637608</td>\n",
       "      <td>0.180554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.569067</td>\n",
       "      <td>0.066468</td>\n",
       "      <td>-0.531933</td>\n",
       "      <td>-1.268273</td>\n",
       "      <td>-1.121999</td>\n",
       "      <td>-0.222804</td>\n",
       "      <td>-0.640832</td>\n",
       "      <td>-0.051854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.928190</td>\n",
       "      <td>0.072546</td>\n",
       "      <td>-0.095419</td>\n",
       "      <td>-1.296455</td>\n",
       "      <td>-1.101410</td>\n",
       "      <td>-0.173389</td>\n",
       "      <td>-0.848835</td>\n",
       "      <td>-0.179319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-09</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.617261</td>\n",
       "      <td>-0.208961</td>\n",
       "      <td>-1.489658</td>\n",
       "      <td>2.078112</td>\n",
       "      <td>2.567628</td>\n",
       "      <td>2.202245</td>\n",
       "      <td>0.244007</td>\n",
       "      <td>-0.292395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.621355</td>\n",
       "      <td>-0.178297</td>\n",
       "      <td>-1.861021</td>\n",
       "      <td>2.053465</td>\n",
       "      <td>2.545661</td>\n",
       "      <td>2.132575</td>\n",
       "      <td>0.438723</td>\n",
       "      <td>-0.206689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.277611</td>\n",
       "      <td>-0.060887</td>\n",
       "      <td>-0.681781</td>\n",
       "      <td>2.125210</td>\n",
       "      <td>2.518552</td>\n",
       "      <td>2.036107</td>\n",
       "      <td>0.420755</td>\n",
       "      <td>-0.229288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.329436</td>\n",
       "      <td>-0.315597</td>\n",
       "      <td>0.236853</td>\n",
       "      <td>2.057315</td>\n",
       "      <td>2.539889</td>\n",
       "      <td>2.057544</td>\n",
       "      <td>0.361859</td>\n",
       "      <td>-0.300841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.689698</td>\n",
       "      <td>-0.154815</td>\n",
       "      <td>-0.193146</td>\n",
       "      <td>2.146159</td>\n",
       "      <td>2.661292</td>\n",
       "      <td>2.057544</td>\n",
       "      <td>0.530432</td>\n",
       "      <td>-0.266824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>556 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            target_1    Volume  Wiki_total  Google_total  nas_close  \\\n",
       "date                                                                  \n",
       "2019-01-23       1.0 -0.473952    0.189679     -0.916326  -1.297693   \n",
       "2019-01-24       0.0  0.585682    0.295486      1.135943  -1.274274   \n",
       "2019-01-25       1.0 -0.229977    0.136914      1.585487  -1.229390   \n",
       "2019-01-28       0.0 -0.569067    0.066468     -0.531933  -1.268273   \n",
       "2019-01-29       0.0 -0.928190    0.072546     -0.095419  -1.296455   \n",
       "...              ...       ...         ...           ...        ...   \n",
       "2021-04-09       1.0 -0.617261   -0.208961     -1.489658   2.078112   \n",
       "2021-04-12       0.0 -0.621355   -0.178297     -1.861021   2.053465   \n",
       "2021-04-13       1.0 -0.277611   -0.060887     -0.681781   2.125210   \n",
       "2021-04-14       0.0 -0.329436   -0.315597      0.236853   2.057315   \n",
       "2021-04-15       0.0 -0.689698   -0.154815     -0.193146   2.146159   \n",
       "\n",
       "            dow_close     Close   nas_vol   dow_vol  \n",
       "date                                                 \n",
       "2019-01-23  -1.103138 -0.380935 -0.737715 -0.275269  \n",
       "2019-01-24  -1.112043 -0.252455 -0.662000 -0.262992  \n",
       "2019-01-25  -1.038843 -0.123973 -0.637608  0.180554  \n",
       "2019-01-28  -1.121999 -0.222804 -0.640832 -0.051854  \n",
       "2019-01-29  -1.101410 -0.173389 -0.848835 -0.179319  \n",
       "...               ...       ...       ...       ...  \n",
       "2021-04-09   2.567628  2.202245  0.244007 -0.292395  \n",
       "2021-04-12   2.545661  2.132575  0.438723 -0.206689  \n",
       "2021-04-13   2.518552  2.036107  0.420755 -0.229288  \n",
       "2021-04-14   2.539889  2.057544  0.361859 -0.300841  \n",
       "2021-04-15   2.661292  2.057544  0.530432 -0.266824  \n",
       "\n",
       "[556 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_f1.dtypes)\n",
    "train_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a7667fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visual Distribution of the features, this did not work as well once I included normailzed only data, don't know why\n",
    "ford_1_std = (Ford_1 - train_f1_mean) / train_f1_std\n",
    "ford_1_std = ford_1_std.melt(var_name='Column', value_name='Normalized')\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.violinplot(x='Column', y='Normalized', data=ford_1_std)\n",
    "_ = ax.set_xticklabels(Ford_1.keys(), rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c114caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Flow times series dataframe modifier\n",
    "#### for this function to work as written the target variable MUST be the first column in the Dataframe #####\n",
    "      # this can be modified you just need to know which column target gets put in in the numpy matrix\n",
    "\n",
    "\n",
    "# format\n",
    "# X                                             y\n",
    "# [[[V1_0, V2_0], [V1_1, V2_1], [V1_2, V2_2]]]  [target_3]\n",
    "# [[[V1_1, V2_1], [V1_2, V2_3], [V1_3, V2_3]]]  [target_4]\n",
    "# [[[V1_2, V2_2], [V1_3, V2_3], [V1_4, V2_4]]]  [target_5]\n",
    "\n",
    "def df_to_X_y2(df, window_size=5):\n",
    "  df_as_np = df.to_numpy() # converts to matrix of numpy arrays\n",
    "  X = []\n",
    "  y = []\n",
    "  for i in range(len(df_as_np)-window_size): # length of data frame - window_size so it does't take empty values at the end\n",
    "    row = [r for r in df_as_np[i:i+window_size]] # grabs row i and all rows above within the window size length\n",
    "    X.append(row) # creates 3 dimentional array, (# obseravtions, # rows in window, # features)\n",
    "    label = df_as_np[i+window_size][0] # pulls the target variable after the window, tagrget varible needs to be column zero in this \n",
    "    y.append(label) # returns (N,) martix of targets i+window_length time periods away\n",
    "  return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dd47617",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf1_train, yf1_train = df_to_X_y2(train_f1)\n",
    "Xf1_val, yf1_val = df_to_X_y2(val_f1)\n",
    "Xf1_test, yf1_test = df_to_X_y2(test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e21b47a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, InputLayer\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38a870aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 4, 2)              38        \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 2, 2)             0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 50)                250       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 339\n",
      "Trainable params: 339\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "n_steps = 5\n",
    "n_features = 9\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=2, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model.add(MaxPooling1D(pool_size=2)) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu')) \n",
    "model.add(Dense(1, activation='softmax')) # was getting lots of errors, apparently for binary classification needs just 1 in its shape???\n",
    "# this was the explination I got after typing in error;  \n",
    "# ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 1))\n",
    "# thought binary classification needed output of 2 though\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 23ms/step - loss: 0.6825 - accuracy: 0.4174 - val_loss: 0.6792 - val_accuracy: 0.4091\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6790 - accuracy: 0.4174 - val_loss: 0.6808 - val_accuracy: 0.4091\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6779 - accuracy: 0.4174 - val_loss: 0.6844 - val_accuracy: 0.4091\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6765 - accuracy: 0.4174 - val_loss: 0.6833 - val_accuracy: 0.4091\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6762 - accuracy: 0.4174 - val_loss: 0.6806 - val_accuracy: 0.4091\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6751 - accuracy: 0.4174 - val_loss: 0.6820 - val_accuracy: 0.4091\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6746 - accuracy: 0.4174 - val_loss: 0.6836 - val_accuracy: 0.4091\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6737 - accuracy: 0.4174 - val_loss: 0.6800 - val_accuracy: 0.4091\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6728 - accuracy: 0.4174 - val_loss: 0.6810 - val_accuracy: 0.4091\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6731 - accuracy: 0.4174 - val_loss: 0.6829 - val_accuracy: 0.4091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1538fcb50>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xf1_train,yf1_train,epochs=10,  validation_data=(Xf1_val, yf1_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "426397d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hat = model.predict(Xf1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "509f1d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fe22aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat = (hat > 0.5)\n",
    "metrics.accuracy_score(yf1_test,hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4857c7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
       "        0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
       "        1., 0., 1., 0., 0., 1., 1.]),\n",
       " array([[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yf1_test, hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b854efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "18/18 [==============================] - 1s 12ms/step - loss: 2.1448 - accuracy: 0.4646 - val_loss: 7.0442 - val_accuracy: 0.4091\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.7991 - accuracy: 0.4973 - val_loss: 4.9511 - val_accuracy: 0.4221\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.2663 - accuracy: 0.5227 - val_loss: 1.7874 - val_accuracy: 0.4545\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.0568 - accuracy: 0.5372 - val_loss: 1.2011 - val_accuracy: 0.6039\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.0085 - accuracy: 0.5045 - val_loss: 1.1996 - val_accuracy: 0.5519\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.5444 - accuracy: 0.5245 - val_loss: 2.8517 - val_accuracy: 0.4091\n",
      "Epoch 7/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.6836 - accuracy: 0.5191 - val_loss: 2.3730 - val_accuracy: 0.4351\n",
      "Epoch 8/20\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.6740 - accuracy: 0.5136 - val_loss: 1.8796 - val_accuracy: 0.4805\n",
      "Epoch 9/20\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.6159 - accuracy: 0.5064 - val_loss: 1.9033 - val_accuracy: 0.4870\n",
      "Epoch 10/20\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.5774 - accuracy: 0.5064 - val_loss: 1.8517 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.5243 - accuracy: 0.5064 - val_loss: 1.7966 - val_accuracy: 0.5065\n",
      "Epoch 12/20\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1.5226 - accuracy: 0.4973 - val_loss: 1.2497 - val_accuracy: 0.6039\n",
      "Epoch 13/20\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.4618 - accuracy: 0.5118 - val_loss: 1.4853 - val_accuracy: 0.6169\n",
      "Epoch 14/20\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.7729 - accuracy: 0.4991 - val_loss: 1.5975 - val_accuracy: 0.6364\n",
      "Epoch 15/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.7657 - accuracy: 0.4918 - val_loss: 1.6432 - val_accuracy: 0.5974\n",
      "Epoch 16/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.5119 - accuracy: 0.4936 - val_loss: 1.5784 - val_accuracy: 0.6234\n",
      "Epoch 17/20\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 1.4299 - accuracy: 0.4918 - val_loss: 1.4544 - val_accuracy: 0.6039\n",
      "Epoch 18/20\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.3301 - accuracy: 0.5064 - val_loss: 1.3915 - val_accuracy: 0.5195\n",
      "Epoch 19/20\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.2765 - accuracy: 0.5118 - val_loss: 1.5255 - val_accuracy: 0.4805\n",
      "Epoch 20/20\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.2558 - accuracy: 0.5172 - val_loss: 1.2302 - val_accuracy: 0.5130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x153ab28e0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(InputLayer((5, 9)))\n",
    "model2.add(Conv1D(64, kernel_size=2))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(8, 'relu'))\n",
    "model2.add(Dense(2))\n",
    "\n",
    "model2.compile(optimizer='adam', loss='BinaryCrossentropy',\n",
    "                   metrics=[\"accuracy\"], )\n",
    "\n",
    "model2.fit(Xf1_train, yf1_train, epochs=20,  validation_data=(Xf1_val, yf1_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b64c69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38090017,  0.25122583],\n",
       "       [ 0.9139482 ,  0.6362824 ],\n",
       "       [ 0.11184497, -0.00551247],\n",
       "       [ 0.22665195, -0.23130922],\n",
       "       [ 0.15720509, -0.39631793],\n",
       "       [ 0.27900946, -0.22819984],\n",
       "       [ 0.03397487, -0.28559068],\n",
       "       [ 0.22708605, -0.44348556],\n",
       "       [ 0.25453928, -0.11878382],\n",
       "       [ 0.48513952,  0.2319439 ],\n",
       "       [ 0.3667068 ,  0.51618457],\n",
       "       [ 0.66699344,  0.5345569 ],\n",
       "       [ 0.62033296,  0.26944223],\n",
       "       [ 0.6730507 ,  0.4681451 ],\n",
       "       [ 0.82915914,  0.5929318 ],\n",
       "       [ 0.9024698 ,  0.9453597 ],\n",
       "       [ 1.2160367 ,  1.2838428 ],\n",
       "       [ 0.25202796, -0.0819025 ],\n",
       "       [ 0.38402277, -0.8121875 ],\n",
       "       [ 0.05321532, -1.2633929 ],\n",
       "       [ 0.34237382, -0.45505488],\n",
       "       [ 0.3207265 , -0.40676862],\n",
       "       [ 0.6018281 ,  0.03138862],\n",
       "       [ 0.6381951 ,  0.05456395],\n",
       "       [ 0.34203202,  0.07160933],\n",
       "       [ 0.45966998, -0.07436352],\n",
       "       [ 0.61482567, -0.4957779 ],\n",
       "       [ 0.01929147, -0.76556486],\n",
       "       [-0.01821954, -0.8442772 ],\n",
       "       [ 0.03500925, -0.7481568 ],\n",
       "       [ 0.15998814, -0.6138787 ],\n",
       "       [ 0.22734572, -0.3418228 ],\n",
       "       [ 0.15636651, -0.47600555],\n",
       "       [ 0.22511011,  0.02418042],\n",
       "       [ 0.18409272, -0.40021372],\n",
       "       [ 0.22003064, -0.26463574],\n",
       "       [ 0.2512195 , -0.03915679],\n",
       "       [ 0.20662463,  0.16270736],\n",
       "       [ 0.4926316 ,  0.13637516],\n",
       "       [ 0.03804168, -0.38038215],\n",
       "       [ 0.26137185, -0.6391652 ],\n",
       "       [ 0.23979412, -0.27863657],\n",
       "       [ 0.22163504, -0.29519233],\n",
       "       [ 0.30922163, -0.00247448],\n",
       "       [ 0.22499514, -0.30672625],\n",
       "       [ 0.12157369, -0.28578874],\n",
       "       [ 0.29287723, -0.0723161 ],\n",
       "       [ 0.58006597,  0.44783777],\n",
       "       [ 0.6651414 ,  0.39591718],\n",
       "       [ 0.10753827, -0.1642029 ],\n",
       "       [ 0.22584367, -0.17262395],\n",
       "       [ 0.02504286, -0.5295879 ],\n",
       "       [ 0.04498601, -0.5904176 ],\n",
       "       [ 0.02500061, -0.5788294 ],\n",
       "       [ 0.39853472, -0.06250482],\n",
       "       [ 0.289315  , -0.01911499],\n",
       "       [ 0.02112946, -0.36204535],\n",
       "       [ 0.05278556, -0.12182482],\n",
       "       [ 0.01720361, -0.15458713],\n",
       "       [ 0.05441747, -0.28156742],\n",
       "       [ 0.04532973, -0.49902928],\n",
       "       [ 0.1456492 , -0.2989562 ],\n",
       "       [ 0.26403517, -0.15471071],\n",
       "       [ 0.13012429, -0.15395463],\n",
       "       [ 0.14492321, -0.04287567],\n",
       "       [ 0.12807745, -0.23207122],\n",
       "       [ 0.26235422, -0.178893  ],\n",
       "       [ 0.1828651 ,  0.06360216],\n",
       "       [ 0.12522209, -0.38967556],\n",
       "       [ 0.12375985, -0.1444467 ],\n",
       "       [ 0.32698858,  0.22566262],\n",
       "       [ 0.06798396,  0.17036518],\n",
       "       [ 0.0333205 , -0.00465839],\n",
       "       [ 0.4204346 ,  0.42371637],\n",
       "       [ 0.05916455,  0.05064873]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yf1_hat = model2.predict(Xf1_test)\n",
    "#metrics.accuracy_score(yf1_test, yf1_hat)\n",
    "yf1_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aae222ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "18/18 [==============================] - 1s 11ms/step - loss: 0.7114 - accuracy: 0.4374 - val_loss: 0.6844 - val_accuracy: 0.5909\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6834 - accuracy: 0.5808 - val_loss: 0.6876 - val_accuracy: 0.5909\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.5826 - val_loss: 0.6872 - val_accuracy: 0.5909\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6766 - accuracy: 0.5844 - val_loss: 0.6874 - val_accuracy: 0.5909\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6737 - accuracy: 0.5898 - val_loss: 0.6920 - val_accuracy: 0.5909\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6710 - accuracy: 0.5862 - val_loss: 0.6964 - val_accuracy: 0.5909\n",
      "Epoch 7/20\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6680 - accuracy: 0.5935 - val_loss: 0.6867 - val_accuracy: 0.5909\n",
      "Epoch 8/20\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6670 - accuracy: 0.5935 - val_loss: 0.6871 - val_accuracy: 0.5909\n",
      "Epoch 9/20\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6635 - accuracy: 0.6007 - val_loss: 0.6829 - val_accuracy: 0.5844\n",
      "Epoch 10/20\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6606 - accuracy: 0.6098 - val_loss: 0.6809 - val_accuracy: 0.5844\n",
      "Epoch 11/20\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6584 - accuracy: 0.6025 - val_loss: 0.6800 - val_accuracy: 0.5974\n",
      "Epoch 12/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6594 - accuracy: 0.6116 - val_loss: 0.6826 - val_accuracy: 0.5519\n",
      "Epoch 13/20\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6515 - accuracy: 0.6189 - val_loss: 0.6821 - val_accuracy: 0.5649\n",
      "Epoch 14/20\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6486 - accuracy: 0.6098 - val_loss: 0.6821 - val_accuracy: 0.5714\n",
      "Epoch 15/20\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.6388 - val_loss: 0.6831 - val_accuracy: 0.5714\n",
      "Epoch 16/20\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.6370 - val_loss: 0.6854 - val_accuracy: 0.5649\n",
      "Epoch 17/20\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6377 - accuracy: 0.6370 - val_loss: 0.6909 - val_accuracy: 0.5519\n",
      "Epoch 18/20\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.6243 - val_loss: 0.6954 - val_accuracy: 0.5260\n",
      "Epoch 19/20\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.6697 - val_loss: 0.7018 - val_accuracy: 0.5195\n",
      "Epoch 20/20\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6321 - accuracy: 0.6243 - val_loss: 0.6913 - val_accuracy: 0.5649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.52"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "n_steps = 5\n",
    "n_features = 9\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Conv1D(filters=16, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model3.add(Conv1D(filters=16, kernel_size=2, activation='relu')) \n",
    "model3.add(MaxPooling1D(pool_size=2)) \n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(50, activation='relu')) \n",
    "model3.add(Dense(1, activation='sigmoid')) # was getting lots of errors, apparently for binary classification needs just 1 in its shape???\n",
    "# this was the explination I got after typing in error;  \n",
    "# ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 1))\n",
    "# thought binary classification needed output of 2 though\n",
    "\n",
    "model3.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                   metrics=[\"accuracy\"])\n",
    "model3.fit(Xf1_train, yf1_train, epochs=20,  validation_data=(Xf1_val, yf1_val))\n",
    "hat2 = model.predict(Xf1_test)\n",
    "hat2 = (hat2 > 0.5)\n",
    "metrics.accuracy_score(yf1_test,hat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fd03e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat2"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
