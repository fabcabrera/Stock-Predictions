{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb8e4404-bf54-495d-8280-b26cee5c44bf",
   "metadata": {},
   "source": [
    "# Ford Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd00f305-04b1-4a86-b519-6a19d7cfbed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "#%pip install pytrends\n",
    "import pytrends\n",
    "from pytrends.request import TrendReq\n",
    "#pip install pageviewapi\n",
    "import pageviewapi\n",
    "#%pip install yfinance\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dd1cf71-d578-4098-a0a4-50a3faedfad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Big_scraper(kw_list_1, kw_list_2, ticker, start,end):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description:\n",
    "    ------------\n",
    "    \n",
    "    The function initially grabs historical, indexed, hourly data for when the keyword \n",
    "    was searched most as shown on Google Trends' Interest Over Time section.\n",
    "    It then cleans the data to show daily hits on the keyword in Google news.\n",
    "\n",
    "    \n",
    "    input:\n",
    "    -----\n",
    "    kw_list_1: List of up to 5 key words that will be scraped from google trends for the dates given.\n",
    "             Here, the scraping will pull the total posted items in google news that contains\n",
    "             one of the key words.\n",
    "    \n",
    "    kw_list_2: List of wikipedia article titles (unlimited length) that will pull the amount of\n",
    "            views the article recieved each day. \n",
    "\n",
    "    ticker: the ticker abriviation of the desired stock. Must be netered in as an all capitalized string \n",
    "    example Apple Inc. woud be \"AAPL\"\n",
    "             \n",
    "    start: the start of the desired timeline you want scrape. Date Must be entered in as \"YYYYMMDD\"\n",
    "    \n",
    "    end: the end of the desired timeline you want scrape. Date Must be entered in as \"YYYYMMDD\"\n",
    "             \n",
    "    return:\n",
    "    -------\n",
    "    \n",
    "    combined: a dataframe containing the sum of the daily keyword hits in google news (key words labeled _x),\n",
    "    \n",
    "    data frame cointaing stock info including open, close, high, low prices of the stock,\n",
    "    as well as the stocks daily trading volume and the amount if there was a split or dividend \n",
    "    preformed on the stock that day,\n",
    "    \n",
    "    and the sum of how many times key word wikipedia pages were viewed in a day (key words labeled _y)\n",
    "    \"\"\"\n",
    "    \n",
    "    year_s = int(start[0:4])\n",
    "    month_s = int(start[4:6])\n",
    "    day_s = int(start[6:8])\n",
    "    year_e = int(end[0:4])\n",
    "    month_e = int(end[4:6])\n",
    "    day_e = int(end[6:8])\n",
    "    \n",
    "    starter = pd.to_datetime(f\"'{year_s}-{month_s}-{day_s}'\")\n",
    "    ender = pd.to_datetime(f\"'{year_e}-{month_e}-{day_e}'\")\n",
    "    \n",
    "    \n",
    "    pytrends = TrendReq(hl='en-US', tz=360, retries=10)\n",
    "    jeff = pytrends.get_historical_interest(kw_list_1, \\\n",
    "                                 year_start = year_s, month_start = month_s, day_start = day_s, hour_start = 1, \\\n",
    "                                 year_end = year_e, month_end = month_e, day_end = day_e, hour_end = 23, \\\n",
    "                                 cat = 0, geo = '', gprop = 'news', sleep = 60)\n",
    "    \n",
    "    jeff = jeff.iloc[:, 0:-1] # eliminates the isPartial Column\n",
    "    jeff = jeff.reset_index().drop_duplicates(subset = \"date\") #removing duplicates from the index\n",
    "    jeff = jeff.groupby(pd.Grouper(key=\"date\", freq=\"D\")).sum() # coverts to the sum of daily posts\n",
    "    \n",
    "    tick = yf.Ticker(ticker)\n",
    "    hist = tick.history(start=starter, end=ender)\n",
    "    hist = pd.DataFrame(hist)\n",
    "    \n",
    "    combined = jeff.merge(hist, left_index=True, right_index=True, how=\"left\") \n",
    "    \n",
    "    d = pd.DataFrame()\n",
    "    for key_word in kw_list_2:\n",
    "        geoff = pageviewapi.per_article('en.wikipedia', key_word, start, end,\n",
    "                                    access='all-access', agent='all-agents', granularity='daily')\n",
    "        dicty = dict(geoff)\n",
    "        views = pd.DataFrame(dicty[\"items\"])\n",
    "        views[\"timestamp\"] = pd.to_datetime((views[\"timestamp\"]), format=\"%Y%m%d%H\")\n",
    "        views = views.set_index(\"timestamp\")\n",
    "        page = pd.Series(views[\"views\"])\n",
    "        d[key_word] = page\n",
    "        \n",
    "    combined = combined.merge(d, left_index=True, right_index=True, how=\"left\") \n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5ee1ce9-734a-48f2-b256-0d23f5110a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_list_1 = [\"Ford\", \"F-150\", \"Ford Bronco\", \"Ford Mustang\", \"Ford Stock\"]\n",
    "kw_list_2 = [\"Ford Motor Company\", \"Ford Mustang\", \"Ford F Series\", \"Ford Bronco\", \"Lincoln Navigator\", \"Lincoln Aviator\", \"Ford GT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e228238e-aa10-4d03-b68a-80b0ba8aafd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ford = Big_scraper(kw_list_1, kw_list_2,\"F\", \"20210101\", \"20210114\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb9a695a-249d-46e3-9386-14c25e5f92c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ford</th>\n",
       "      <th>F-150</th>\n",
       "      <th>Ford Bronco_x</th>\n",
       "      <th>Ford Mustang_x</th>\n",
       "      <th>Ford Stock</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Ford Motor Company</th>\n",
       "      <th>Ford Mustang_y</th>\n",
       "      <th>Ford F Series</th>\n",
       "      <th>Ford Bronco_y</th>\n",
       "      <th>Lincoln Navigator</th>\n",
       "      <th>Lincoln Aviator</th>\n",
       "      <th>Ford GT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>592</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4819</td>\n",
       "      <td>3186</td>\n",
       "      <td>6</td>\n",
       "      <td>1724</td>\n",
       "      <td>653</td>\n",
       "      <td>766</td>\n",
       "      <td>1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02</th>\n",
       "      <td>555</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5138</td>\n",
       "      <td>3312</td>\n",
       "      <td>4</td>\n",
       "      <td>1667</td>\n",
       "      <td>779</td>\n",
       "      <td>1209</td>\n",
       "      <td>1915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-03</th>\n",
       "      <td>384</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5356</td>\n",
       "      <td>3576</td>\n",
       "      <td>12</td>\n",
       "      <td>1774</td>\n",
       "      <td>746</td>\n",
       "      <td>1109</td>\n",
       "      <td>1842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>568</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>8.721023</td>\n",
       "      <td>8.750720</td>\n",
       "      <td>8.344861</td>\n",
       "      <td>8.433952</td>\n",
       "      <td>85043100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5467</td>\n",
       "      <td>3276</td>\n",
       "      <td>7</td>\n",
       "      <td>1574</td>\n",
       "      <td>728</td>\n",
       "      <td>734</td>\n",
       "      <td>1640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05</th>\n",
       "      <td>442</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>8.384458</td>\n",
       "      <td>8.631933</td>\n",
       "      <td>8.374559</td>\n",
       "      <td>8.562639</td>\n",
       "      <td>70127800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5402</td>\n",
       "      <td>3294</td>\n",
       "      <td>12</td>\n",
       "      <td>1613</td>\n",
       "      <td>676</td>\n",
       "      <td>704</td>\n",
       "      <td>1510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-06</th>\n",
       "      <td>753</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>8.701226</td>\n",
       "      <td>8.849710</td>\n",
       "      <td>8.592337</td>\n",
       "      <td>8.750721</td>\n",
       "      <td>72590200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5156</td>\n",
       "      <td>3110</td>\n",
       "      <td>16</td>\n",
       "      <td>1524</td>\n",
       "      <td>609</td>\n",
       "      <td>623</td>\n",
       "      <td>1414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-07</th>\n",
       "      <td>614</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>8.849710</td>\n",
       "      <td>8.988297</td>\n",
       "      <td>8.790317</td>\n",
       "      <td>8.968499</td>\n",
       "      <td>77117100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5001</td>\n",
       "      <td>2952</td>\n",
       "      <td>8</td>\n",
       "      <td>1450</td>\n",
       "      <td>603</td>\n",
       "      <td>551</td>\n",
       "      <td>1402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-08</th>\n",
       "      <td>331</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>9.008095</td>\n",
       "      <td>9.047691</td>\n",
       "      <td>8.800216</td>\n",
       "      <td>8.909104</td>\n",
       "      <td>59162200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5044</td>\n",
       "      <td>3024</td>\n",
       "      <td>7</td>\n",
       "      <td>1659</td>\n",
       "      <td>580</td>\n",
       "      <td>568</td>\n",
       "      <td>1443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-09</th>\n",
       "      <td>620</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5163</td>\n",
       "      <td>3548</td>\n",
       "      <td>5</td>\n",
       "      <td>2315</td>\n",
       "      <td>1181</td>\n",
       "      <td>737</td>\n",
       "      <td>1633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-10</th>\n",
       "      <td>477</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5364</td>\n",
       "      <td>3519</td>\n",
       "      <td>5</td>\n",
       "      <td>2176</td>\n",
       "      <td>1190</td>\n",
       "      <td>644</td>\n",
       "      <td>1525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-11</th>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>8.780418</td>\n",
       "      <td>9.225873</td>\n",
       "      <td>8.730923</td>\n",
       "      <td>9.206076</td>\n",
       "      <td>95968300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5419</td>\n",
       "      <td>3321</td>\n",
       "      <td>8</td>\n",
       "      <td>1964</td>\n",
       "      <td>866</td>\n",
       "      <td>797</td>\n",
       "      <td>1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-12</th>\n",
       "      <td>926</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>9.206075</td>\n",
       "      <td>9.720823</td>\n",
       "      <td>9.196176</td>\n",
       "      <td>9.681227</td>\n",
       "      <td>124808500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9893</td>\n",
       "      <td>3051</td>\n",
       "      <td>6</td>\n",
       "      <td>2540</td>\n",
       "      <td>789</td>\n",
       "      <td>643</td>\n",
       "      <td>1454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-13</th>\n",
       "      <td>793</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>9.809914</td>\n",
       "      <td>9.819813</td>\n",
       "      <td>9.542641</td>\n",
       "      <td>9.681227</td>\n",
       "      <td>89549300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5685</td>\n",
       "      <td>2998</td>\n",
       "      <td>4</td>\n",
       "      <td>1819</td>\n",
       "      <td>661</td>\n",
       "      <td>556</td>\n",
       "      <td>1355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-14</th>\n",
       "      <td>555</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5162</td>\n",
       "      <td>3001</td>\n",
       "      <td>3</td>\n",
       "      <td>1851</td>\n",
       "      <td>741</td>\n",
       "      <td>561</td>\n",
       "      <td>1365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Ford  F-150  Ford Bronco_x  Ford Mustang_x  Ford Stock      Open  \\\n",
       "date                                                                           \n",
       "2021-01-01   592      0              0              21          31       NaN   \n",
       "2021-01-02   555      0              0               0           0       NaN   \n",
       "2021-01-03   384      0             47               0           0       NaN   \n",
       "2021-01-04   568      0             67              46           0  8.721023   \n",
       "2021-01-05   442      0             40              15           0  8.384458   \n",
       "2021-01-06   753      0              0              20           0  8.701226   \n",
       "2021-01-07   614     18              0               0          14  8.849710   \n",
       "2021-01-08   331      0              0              14           0  9.008095   \n",
       "2021-01-09   620      0             12              11          14       NaN   \n",
       "2021-01-10   477      0             12               0           0       NaN   \n",
       "2021-01-11   510      0              0              27           0  8.780418   \n",
       "2021-01-12   926      0              9               0          20  9.206075   \n",
       "2021-01-13   793      0             38              18           0  9.809914   \n",
       "2021-01-14   555      0             25              21          29       NaN   \n",
       "\n",
       "                High       Low     Close       Volume  Dividends  \\\n",
       "date                                                               \n",
       "2021-01-01       NaN       NaN       NaN          NaN        NaN   \n",
       "2021-01-02       NaN       NaN       NaN          NaN        NaN   \n",
       "2021-01-03       NaN       NaN       NaN          NaN        NaN   \n",
       "2021-01-04  8.750720  8.344861  8.433952   85043100.0        0.0   \n",
       "2021-01-05  8.631933  8.374559  8.562639   70127800.0        0.0   \n",
       "2021-01-06  8.849710  8.592337  8.750721   72590200.0        0.0   \n",
       "2021-01-07  8.988297  8.790317  8.968499   77117100.0        0.0   \n",
       "2021-01-08  9.047691  8.800216  8.909104   59162200.0        0.0   \n",
       "2021-01-09       NaN       NaN       NaN          NaN        NaN   \n",
       "2021-01-10       NaN       NaN       NaN          NaN        NaN   \n",
       "2021-01-11  9.225873  8.730923  9.206076   95968300.0        0.0   \n",
       "2021-01-12  9.720823  9.196176  9.681227  124808500.0        0.0   \n",
       "2021-01-13  9.819813  9.542641  9.681227   89549300.0        0.0   \n",
       "2021-01-14       NaN       NaN       NaN          NaN        NaN   \n",
       "\n",
       "            Stock Splits  Ford Motor Company  Ford Mustang_y  Ford F Series  \\\n",
       "date                                                                          \n",
       "2021-01-01           NaN                4819            3186              6   \n",
       "2021-01-02           NaN                5138            3312              4   \n",
       "2021-01-03           NaN                5356            3576             12   \n",
       "2021-01-04           0.0                5467            3276              7   \n",
       "2021-01-05           0.0                5402            3294             12   \n",
       "2021-01-06           0.0                5156            3110             16   \n",
       "2021-01-07           0.0                5001            2952              8   \n",
       "2021-01-08           0.0                5044            3024              7   \n",
       "2021-01-09           NaN                5163            3548              5   \n",
       "2021-01-10           NaN                5364            3519              5   \n",
       "2021-01-11           0.0                5419            3321              8   \n",
       "2021-01-12           0.0                9893            3051              6   \n",
       "2021-01-13           0.0                5685            2998              4   \n",
       "2021-01-14           NaN                5162            3001              3   \n",
       "\n",
       "            Ford Bronco_y  Lincoln Navigator  Lincoln Aviator  Ford GT  \n",
       "date                                                                    \n",
       "2021-01-01           1724                653              766     1967  \n",
       "2021-01-02           1667                779             1209     1915  \n",
       "2021-01-03           1774                746             1109     1842  \n",
       "2021-01-04           1574                728              734     1640  \n",
       "2021-01-05           1613                676              704     1510  \n",
       "2021-01-06           1524                609              623     1414  \n",
       "2021-01-07           1450                603              551     1402  \n",
       "2021-01-08           1659                580              568     1443  \n",
       "2021-01-09           2315               1181              737     1633  \n",
       "2021-01-10           2176               1190              644     1525  \n",
       "2021-01-11           1964                866              797     1463  \n",
       "2021-01-12           2540                789              643     1454  \n",
       "2021-01-13           1819                661              556     1355  \n",
       "2021-01-14           1851                741              561     1365  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ford"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d311b9d1-f0d8-4614-97f7-6b5e7a34e5de",
   "metadata": {},
   "source": [
    "## individual functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "485838bc-a6dc-4ff5-8239-605387c181d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_trends(kw_list, year_start, month_start, year_end, month_end, day_end, day_start=1, hour_start=0, hour_end=23):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description:\n",
    "    ------------\n",
    "    \n",
    "    The function initially grabs historical, indexed, hourly data for when the keyword \n",
    "    was searched most as shown on Google Trends' Interest Over Time section.\n",
    "    It then cleans the data to show daily hits on the keyword in Google news.\n",
    "\n",
    "    \n",
    "    input:\n",
    "    -----\n",
    "    kw_list: List of up to 5 key words that will be scraped from the timeline given to the function.\n",
    "             Here, the scraping will pull the total posted items in google news. the contains\n",
    "             one of the key words.\n",
    "             \n",
    "    Rest of the varibles are self-explatory and used to set the timeline to scrape the key words. \n",
    "    \n",
    "    Plug in as decribed \n",
    "    year_start / end: YYYY int\n",
    "    month_start / end: M int\n",
    "    day_start /  end: D int\n",
    "    hour_start / end: H int\n",
    "    \n",
    "             \n",
    "    return:\n",
    "    -------\n",
    "    \n",
    "    jeff: a dataframe containing the sum of the daily keyword hits in google news\n",
    "    \"\"\"\n",
    "    \n",
    "    pytrends = TrendReq(hl='en-US', tz=360, retries=10)\n",
    "    jeff = pytrends.get_historical_interest(kw_list, \\\n",
    "                                 year_start = year_start, month_start = month_start, day_start = day_start, hour_start = hour_start, \\\n",
    "                                 year_end = year_end, month_end = month_end, day_end = day_end, hour_end = hour_end, \\\n",
    "                                 cat = 0, geo = '', gprop = 'news', sleep = 60)\n",
    "    \n",
    "    jeff = jeff.iloc[:, 0:-1] # eliminates the isPartial Column\n",
    "    jeff = jeff.reset_index().drop_duplicates(subset = \"date\") #removing duplicates from the index\n",
    "    jeff = jeff.groupby(pd.Grouper(key=\"date\", freq=\"D\")).sum() # coverts to the sum of daily posts\n",
    "    \n",
    "    return jeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "70727f7d-1905-4edc-ae9e-f2904cd3b7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_stats(ticker: str, start_date: str, end_date: str):\n",
    "    \"\"\"\n",
    "    Description: Scrapes historial daily stock data from the Yahoo Fince sight\n",
    "    and returns a dataframe containing daily open, close, high, low prices of the stock,\n",
    "    as well as the stocks daily trading volume and the amount if there was a split or dividend \n",
    "    preformed on the stock that day.\n",
    "    \n",
    "    inputs:\n",
    "    ------\n",
    "    ticker: the ticker abriviation of the desired stock. Must be netered in as an all capitalized string \n",
    "    example Apple Inc. woud be \"AAPL\"\n",
    "    \n",
    "    start_date: the start of the desired timeline you want scrape. Date Must be entered in as \"YYYY-MM-DD\"\n",
    "    \n",
    "    end_date: Self explanetory, Date Must be entered in as \"YYYY-MM-DD\"\n",
    "    \n",
    "    return:\n",
    "    ------\n",
    "    hist: dataframe containing open, close, high, low prices of the stock,\n",
    "    as well as the stocks daily trading volume and the amount if there was a split or dividend \n",
    "    preformed on the stock that day. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    tick = yf.Ticker(ticker)\n",
    "    hist = tick.history(start=start_date, end=end_date)\n",
    "    hist = pd.DataFrame(hist)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "a6bc9f7b-be9f-409f-abfe-46c351ea937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_scraper(kw_list: list, start_date: str, end_date: str):\n",
    "    '''\n",
    "    Description: Pulls the sum of how many times a wikipedia page was viewed that day\n",
    "    \n",
    "    inputs:\n",
    "    ------\n",
    "    \n",
    "    kw_list: list of wikipedia page names to be scrpapped, can be of unlimted length\n",
    "    \n",
    "    start_date: the start of the desired timeline you want scrape. Date Must be entered in as \"YYYYMMDD\"\n",
    "    \n",
    "    end_date: the end of the desired timeline you want scrape. Date Must be entered in as \"YYYYMMDD\"\n",
    "    \n",
    "    '''\n",
    "    d = pd.DataFrame()\n",
    "    for key_word in kw_list:\n",
    "        geoff = pageviewapi.per_article('en.wikipedia', key_word, start_date, end_date,\n",
    "                                    access='all-access', agent='all-agents', granularity='daily')\n",
    "        dicty = dict(geoff)\n",
    "        views = pd.DataFrame(dicty[\"items\"])\n",
    "        views[\"timestamp\"] = pd.to_datetime((views[\"timestamp\"]), format=\"%Y%m%d%H\")\n",
    "        views = views.set_index(\"timestamp\")\n",
    "        page = pd.Series(views[\"views\"])\n",
    "        d[key_word] = page\n",
    "        \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe19f57-1f95-459c-84b0-757d2caa417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_list_2 = [\"Ford Motor Company\", \"Ford Mustang\", \"Ford F Series\", \"Ford Bronco\", \"Lincoln Navigator\", \"Lincoln Aviator\", \"Ford GT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448f76a4-025d-47a5-b57c-b619b4950ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_trends(kw_list1, 2019,12,2019,12,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "9f172e03-f082-4749-885d-efcb8f996cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joiner(google_trends, yahoo_finace, wiki_pagecount):\n",
    "    \"\"\"\n",
    "    Description: joins all stock data sets into one dataframe\n",
    "    \n",
    "    input:\n",
    "    ------\n",
    "    google_trends: data frame counting daily hit counts for google news stories on specific key words\n",
    "    \n",
    "    yahoo_finace: data frame cointaing stock info including open, close, high, low prices of the stock,\n",
    "    as well as the stocks daily trading volume and the amount if there was a split or dividend \n",
    "    preformed on the stock that day.\n",
    "    \n",
    "    wiki_pagecount: the sum of how many times key wikipedia pages were viewed in a day\n",
    "    \"\"\"\n",
    "    \n",
    "    combined = google_trends.merge(yahoo_finace, left_index=True, right_index=True, how=\"left\")\n",
    "    combined = combined.merge(wiki_pagecount, left_index=True, right_index=True, how=\"left\")\n",
    "    return combined"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
