{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb8e4404-bf54-495d-8280-b26cee5c44bf",
   "metadata": {},
   "source": [
    "# Ford Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd00f305-04b1-4a86-b519-6a19d7cfbed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "#%pip install pytrends\n",
    "import pytrends\n",
    "from pytrends.request import TrendReq\n",
    "#pip install pageviewapi\n",
    "import pageviewapi\n",
    "#%pip install yfinance\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Big_scraper(kw_list_1, kw_list_2, ticker, start,end):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description:\n",
    "    ------------\n",
    "    \n",
    "    The function initially grabs historical, indexed, hourly data for when the keyword \n",
    "    was searched most as shown on Google Trends' Interest Over Time section.\n",
    "    It then cleans the data to show daily hits on the keyword in Google news.\n",
    "\n",
    "    \n",
    "    input:\n",
    "    -----\n",
    "    kw_list_1: List of up to 5 key words that will be scraped from google trends for the dates given.\n",
    "             Here, the scraping will pull the total posted items in google news that contains\n",
    "             one of the key words.\n",
    "    \n",
    "    kw_list_2: List of wikipedia article titles (unlimited length) that will pull the amount of\n",
    "            views the article recieved each day. \n",
    "\n",
    "    ticker: the ticker abriviation of the desired stock. Must be netered in as an all capitalized string \n",
    "    example Apple Inc. woud be \"AAPL\"\n",
    "             \n",
    "    start: the start of the desired timeline you want scrape. Date Must be entered in as \"YYYYMMDD\"\n",
    "    \n",
    "    end: the end of the desired timeline you want scrape. Date Must be entered in as \"YYYYMMDD\"\n",
    "             \n",
    "    return:\n",
    "    -------\n",
    "    \n",
    "    combined: a dataframe containing the sum of the daily keyword hits in google news (key words labeled _x),\n",
    "    \n",
    "    data frame cointaing stock info including open, close, high, low prices of the stock,\n",
    "    as well as the stocks daily trading volume and the amount if there was a split or dividend \n",
    "    preformed on the stock that day,\n",
    "    \n",
    "    and the sum of how many times key word wikipedia pages were viewed in a day (key words labeled _y)\n",
    "    \"\"\"\n",
    "    \n",
    "    year_s = int(start[0:4])\n",
    "    month_s = int(start[4:6])\n",
    "    day_s = int(start[6:8])\n",
    "    year_e = int(end[0:4])\n",
    "    month_e = int(end[4:6])\n",
    "    day_e = int(end[6:8])\n",
    "    \n",
    "    starter = pd.to_datetime(f\"'{year_s}-{month_s}-{day_s}'\")\n",
    "    ender = pd.to_datetime(f\"'{year_e}-{month_e}-{day_e}'\")\n",
    "    \n",
    "    \n",
    "    pytrends = TrendReq(hl='en-US', tz=360, retries=10)\n",
    "    jeff = pytrends.get_historical_interest(kw_list_1, \\\n",
    "                                 year_start = year_s, month_start = month_s, day_start = day_s, hour_start = 1, \\\n",
    "                                 year_end = year_e, month_end = month_e, day_end = day_e, hour_end = 23, \\\n",
    "                                 cat = 0, geo = '', gprop = 'news', sleep = 60)\n",
    "    \n",
    "    jeff = jeff.iloc[:, 0:-1] # eliminates the isPartial Column\n",
    "    jeff = jeff.reset_index().drop_duplicates(subset = \"date\") #removing duplicates from the index\n",
    "    jeff = jeff.groupby(pd.Grouper(key=\"date\", freq=\"D\")).mean() # coverts to the mean of daily scores\n",
    "\n",
    "    dow = yf.Ticker(\"^DJI\")\n",
    "    dow_h = dow.history(start=starter, end=ender)\n",
    "    dow_h = pd.DataFrame(dow_h)\n",
    "    dow_names = {\"Open\":\"dow_open\",\"Close\":\"dow_close\",\"Low\": \"dow_low\",\n",
    "    'High':'dow_high','Volume':'dow_vol'}\n",
    "    dow_h=dow_h.rename(dow_names, axis=1).drop([\"Dividends\",\"Stock Splits\"], axis=1)\n",
    "\n",
    "    nas = yf.Ticker(\"^IXIC\")\n",
    "    nas_h = nas.history(start=starter, end=ender)\n",
    "    nas_h = pd.DataFrame(nas_h)\n",
    "    nas_names = {\"Open\":\"nas_open\", \"Close\":\"nas_close\", \"Low\": \"nas_low\",\n",
    "    'High':'nas_high','Volume':'nas_vol'}\n",
    "    nas_h=nas_h.rename(nas_names, axis=1).drop([\"Dividends\",\"Stock Splits\"], axis=1)\n",
    "\n",
    "    market = dow_h.merge(nas_h,left_index=True, right_index=True, how=\"left\")\n",
    "    \n",
    "    tick = yf.Ticker(ticker)\n",
    "    hist = tick.history(start=starter, end=ender)\n",
    "    hist = pd.DataFrame(hist)\n",
    "    \n",
    "    combined = jeff.merge(hist, left_index=True, right_index=True, how=\"left\")\n",
    "    combined = combined.merge(market, left_index=True, right_index=True, how=\"left\")  \n",
    "    \n",
    "    d = pd.DataFrame()\n",
    "    for key_word in kw_list_2:\n",
    "        geoff = pageviewapi.per_article('en.wikipedia', key_word, start, end,\n",
    "                                    access='all-access', agent='all-agents', granularity='daily')\n",
    "        dicty = dict(geoff)\n",
    "        views = pd.DataFrame(dicty[\"items\"])\n",
    "        views[\"timestamp\"] = pd.to_datetime((views[\"timestamp\"]), format=\"%Y%m%d%H\")\n",
    "        views = views.set_index(\"timestamp\")\n",
    "        page = pd.Series(views[\"views\"])\n",
    "        d[key_word] = page\n",
    "        \n",
    "    combined = combined.merge(d, left_index=True, right_index=True, how=\"left\") \n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5ee1ce9-734a-48f2-b256-0d23f5110a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_list_1 = [\"Ford\", \"F-150\", \"Ford Bronco\", \"Ford Mustang\", \"Ford Stock\"]\n",
    "kw_list_2 = [\"Ford Motor Company\", \"Ford Mustang\", \"Ford F Series\", \"Ford Bronco\", \"Lincoln Navigator\", \"Lincoln Aviator\", \"Ford GT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ea88fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ford = Big_scraper(kw_list_1, kw_list_2,\"F\", \"20190101\", \"20191231\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe9bea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ford.to_csv(\"2019_Ford_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "829ebb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ford_20 = Big_scraper(kw_list_1, kw_list_2,\"F\", \"20200101\", \"20201231\")\n",
    "Ford_20.to_csv(\"2020_Ford_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2d1fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ford_21 = Big_scraper(kw_list_1, kw_list_2,\"F\", \"20210101\", \"20211231\")\n",
    "Ford_21.to_csv(\"2021_Ford_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56908410",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ford_22 = Big_scraper(kw_list_1, kw_list_2,\"F\", \"20220101\", \"20220331\")\n",
    "Ford_22.to_csv(\"2022_Ford_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bed317a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ford</th>\n",
       "      <th>F-150</th>\n",
       "      <th>Ford Bronco_x</th>\n",
       "      <th>Ford Mustang_x</th>\n",
       "      <th>Ford Stock</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Ford Motor Company</th>\n",
       "      <th>Ford Mustang_y</th>\n",
       "      <th>Ford F Series</th>\n",
       "      <th>Ford Bronco_y</th>\n",
       "      <th>Lincoln Navigator</th>\n",
       "      <th>Lincoln Aviator</th>\n",
       "      <th>Ford GT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>592</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4819</td>\n",
       "      <td>3186</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1724</td>\n",
       "      <td>653</td>\n",
       "      <td>766</td>\n",
       "      <td>1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02</th>\n",
       "      <td>555</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5138</td>\n",
       "      <td>3312</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1667</td>\n",
       "      <td>779</td>\n",
       "      <td>1209</td>\n",
       "      <td>1915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-03</th>\n",
       "      <td>384</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5356</td>\n",
       "      <td>3576</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1774</td>\n",
       "      <td>746</td>\n",
       "      <td>1109</td>\n",
       "      <td>1842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>568</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>8.721023</td>\n",
       "      <td>8.750720</td>\n",
       "      <td>8.344861</td>\n",
       "      <td>8.433952</td>\n",
       "      <td>85043100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5467</td>\n",
       "      <td>3276</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1574</td>\n",
       "      <td>728</td>\n",
       "      <td>734</td>\n",
       "      <td>1640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05</th>\n",
       "      <td>442</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>8.384458</td>\n",
       "      <td>8.631933</td>\n",
       "      <td>8.374559</td>\n",
       "      <td>8.562639</td>\n",
       "      <td>70127800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5402</td>\n",
       "      <td>3294</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1613</td>\n",
       "      <td>676</td>\n",
       "      <td>704</td>\n",
       "      <td>1510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Ford  F-150  Ford Bronco_x  Ford Mustang_x  Ford Stock      Open  \\\n",
       "date                                                                           \n",
       "2021-01-01   592      0              0              21          31       NaN   \n",
       "2021-01-02   555      0              0               0           0       NaN   \n",
       "2021-01-03   384      0             47               0           0       NaN   \n",
       "2021-01-04   568      0             67              46           0  8.721023   \n",
       "2021-01-05   442      0             40              15           0  8.384458   \n",
       "\n",
       "                High       Low     Close      Volume  Dividends  Stock Splits  \\\n",
       "date                                                                            \n",
       "2021-01-01       NaN       NaN       NaN         NaN        NaN           NaN   \n",
       "2021-01-02       NaN       NaN       NaN         NaN        NaN           NaN   \n",
       "2021-01-03       NaN       NaN       NaN         NaN        NaN           NaN   \n",
       "2021-01-04  8.750720  8.344861  8.433952  85043100.0        0.0           0.0   \n",
       "2021-01-05  8.631933  8.374559  8.562639  70127800.0        0.0           0.0   \n",
       "\n",
       "            Ford Motor Company  Ford Mustang_y  Ford F Series  Ford Bronco_y  \\\n",
       "date                                                                           \n",
       "2021-01-01                4819            3186            6.0           1724   \n",
       "2021-01-02                5138            3312            4.0           1667   \n",
       "2021-01-03                5356            3576           12.0           1774   \n",
       "2021-01-04                5467            3276            7.0           1574   \n",
       "2021-01-05                5402            3294           12.0           1613   \n",
       "\n",
       "            Lincoln Navigator  Lincoln Aviator  Ford GT  \n",
       "date                                                     \n",
       "2021-01-01                653              766     1967  \n",
       "2021-01-02                779             1209     1915  \n",
       "2021-01-03                746             1109     1842  \n",
       "2021-01-04                728              734     1640  \n",
       "2021-01-05                676              704     1510  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ford.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c9f6f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variables_creator(df, variable_list, w=7):\n",
    "    \n",
    "    '''\n",
    "    descrition:\n",
    "    -----------\n",
    "    takes dataframe and returns new varibles based on recommmended calcualtions, \n",
    "    it should be done seporately with internet based and stock based dataframes\n",
    "\n",
    "    Note: When using for aggreated varaibles, for example Wiki_total, the sum of all the wiki pages daily page view counts, \n",
    "    you MUST calculate Wiki_total in the dataframe seperately BEFORE this function can be used. \n",
    "\n",
    "    For example if you had wiki page counts for Ford Bronco and Ford Ranger, Wiki_total would equal Ford Bronco + Ford ranger counts, \n",
    "    AGAIN Wiki_total must be calculated in the desired dateframe before using this function \n",
    "\n",
    "    input:\n",
    "    ------\n",
    "    df: dataframe containing the google trends, yahoo finance, and or wikipedia page count data\n",
    "\n",
    "    variable_list: list of strings to be added to the equations to calculate the new varaibles. \n",
    "    ex. insertting the string \"Wiki\" will add to df[f\"{}_total\"] to become \"Wiki_total\"\n",
    "\n",
    "    w: the window length for one period shift. Default is 7 providing 7 day moving averages for wiki and google data, \n",
    "        FOR STOCK DATA THIS WILL NEED TO BE CHANGED TO 5.\n",
    "\n",
    "    output:\n",
    "    -------\n",
    "    df: the same dataframe as was inputted but now containing variables for \n",
    "    Momemtum, Disparity, Moving Average, Exponential Moving Aerage, Rator Change, and RSI index score.\n",
    "    Also containg are moving variables, which are boolean with 1 indicating an increase in the above variables\n",
    "    '''   \n",
    "    \n",
    "    for i in variable_list:\n",
    "        # Momentum_1\n",
    "        df[f\"{i}_Moment_1\"] =  (df[f\"{i}_total\"] / df[f\"{i}_total\"].shift(w)) * 100\n",
    "        # Momentum_2\n",
    "        df[f\"{i}_Moment_2\"] =  (df[f\"{i}_total\"] - df[f\"{i}_total\"].shift(w)) * 100\n",
    "        # Momentum_1_s three day shift (instead of w)\n",
    "        df[f\"{i}_Moment_1_s\"] =  (df[f\"{i}_total\"] / df[f\"{i}_total\"].shift(3)) * 100\n",
    "        # Momentum_2_s\n",
    "        df[f\"{i}_Moment_2_s\"] =  (df[f\"{i}_total\"] - df[f\"{i}_total\"].shift(3)) * 100\n",
    "        # Moving average\n",
    "        df[f\"{i}_MAvg\"] = df[f\"{i}_total\"].rolling(f\"{w}d\").mean()\n",
    "        # Moving average 3 day\n",
    "        df[f\"{i}_MAvg_s\"] = df[f\"{i}_total\"].rolling(\"3d\").mean()\n",
    "        # Disparity\n",
    "        df[f\"{i}_Disparity\"] = (df[f\"{i}_total\"]/df[f\"{i}_MAvg\"]) * 100\n",
    "        # Disparity 3 day\n",
    "        df[f\"{i}_Disparity_s\"] = (df[f\"{i}_total\"]/df[f\"{i}_MAvg_s\"]) * 100\n",
    "        # Rate of Change Normal Way\n",
    "        df[f\"{i}_ROC\"] = (df[f\"{i}_total\"]-df[f\"{i}_total\"].shift(w))/(df[f\"{i}_total\"].shift(w)) *100\n",
    "        df[f\"{i}_ROC_s\"] = (df[f\"{i}_total\"]-df[f\"{i}_total\"].shift(3))/(df[f\"{i}_total\"].shift(3)) *100\n",
    "        #Rate of Change Paper Way (doesn't make sense but just in case)\n",
    "        df[f'{i}_Rocp'] = (df[f\"{i}_total\"]/df[f\"{i}_Moment_2\"]) *100\n",
    "        # Exponential Moving Average\n",
    "        df[f\"{i}_EMA\"] = (df[f\"{i}_total\"]-df[f\"{i}_MAvg\"].shift(1))*(2/(w+1))+df[f\"{i}_MAvg\"].shift(1)\n",
    "\n",
    "        # calculating the Relative Strength Index, based on 14 day window\n",
    "        df[f\"{i}_diff\"] = df[f\"{i}_total\"].diff(1)\n",
    "        df[f\"{i}_gain\"] = df[f\"{i}_diff\"].clip(lower=0).round(2) #keeps all values above or below a given threshold, lower=lower bound\n",
    "        df[f\"{i}_loss\"] = df[f\"{i}_diff\"].clip(upper=0).round(2)\n",
    "        df[f'{i}_avg_gain'] = df[f'{i}_gain'].rolling(14).mean()\n",
    "        df[f'{i}_avg_loss'] = df[f'{i}_loss'].rolling(14).mean()\n",
    "        df[f'{i}_rs'] = df[f'{i}_avg_gain'] / df[f'{i}_avg_loss']\n",
    "        df[f'{i}_RSI'] = 100 - (100 / (1.0 + df[f'{i}_rs']))\n",
    "\n",
    "        # Calculatiing the Move Variables \n",
    "        df[f\"{i}_Move\"] = df[f\"{i}_total\"] > df[f\"{i}_total\"].shift(1) \n",
    "        df[f\"{i}_Move\"] = df[f\"{i}_Move\"].replace({True:1,False: 0})\n",
    "    \n",
    "      \n",
    "        df[f\"{i}_MAvg_Move\"] = df[f\"{i}_MAvg\"] > df[f\"{i}_MAvg\"].shift(1) \n",
    "        df[f\"{i}_MAvg_Move\"] = df[f\"{i}_MAvg_Move\"].replace({True:1,False: 0})\n",
    "        df[f\"{i}_MAvg_s_Move\"] = df[f\"{i}_MAvg_s\"] > df[f\"{i}_MAvg_s\"].shift(1) \n",
    "        df[f\"{i}_MAvg_s_Move\"] = df[f\"{i}_MAvg_s_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "        df[f\"{i}_EMA_Move\"] = df[f\"{i}_EMA\"] > df[f\"{i}_EMA\"].shift(1) \n",
    "        df[f\"{i}_EMA_Move\"] = df[f\"{i}_EMA_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "        df[f\"{i}_Disparity_Move\"] = df[f\"{i}_Disparity\"] > df[f\"{i}_Disparity\"].shift(1) \n",
    "        df[f\"{i}_Disparity_Move\"] = df[f\"{i}_Disparity_Move\"].replace({True:1,False: 0})\n",
    "        df[f\"{i}_Disparity_s_Move\"] = df[f\"{i}_Disparity_s\"] > df[f\"{i}_Disparity_s\"].shift(1) \n",
    "        df[f\"{i}_Disparity_s_Move\"] = df[f\"{i}_Disparity_s_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "        df[f\"{i}_RSI_Move\"] = df[f\"{i}_RSI\"] > df[f\"{i}_RSI\"].shift(1) \n",
    "        df[f\"{i}_RSI_Move\"] = df[f\"{i}_RSI_Move\"].replace({True:1,False: 0})\n",
    "        \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
