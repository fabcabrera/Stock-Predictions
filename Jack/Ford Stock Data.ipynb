{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb8e4404-bf54-495d-8280-b26cee5c44bf",
   "metadata": {},
   "source": [
    "# Ford Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dd00f305-04b1-4a86-b519-6a19d7cfbed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "#%pip install pytrends\n",
    "import pytrends\n",
    "from pytrends.request import TrendReq\n",
    "#pip install pageviewapi\n",
    "import pageviewapi\n",
    "#%pip install yfinance\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Big_scraper(kw_list_1, kw_list_2, ticker, start,end):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description:\n",
    "    ------------\n",
    "    \n",
    "    The function initially grabs historical, indexed, hourly data for when the keyword \n",
    "    was searched most as shown on Google Trends' Interest Over Time section.\n",
    "    It then cleans the data to show daily hits on the keyword in Google news.\n",
    "\n",
    "    \n",
    "    input:\n",
    "    -----\n",
    "    kw_list_1: List of up to 5 key words that will be scraped from google trends for the dates given.\n",
    "             Here, the scraping will pull the total posted items in google news that contains\n",
    "             one of the key words.\n",
    "    \n",
    "    kw_list_2: List of wikipedia article titles (unlimited length) that will pull the amount of\n",
    "            views the article recieved each day. \n",
    "\n",
    "    ticker: the ticker abriviation of the desired stock. Must be netered in as an all capitalized string \n",
    "    example Apple Inc. woud be \"AAPL\"\n",
    "             \n",
    "    start: the start of the desired timeline you want scrape. Date Must be entered in as \"YYYYMMDD\"\n",
    "    \n",
    "    end: the end of the desired timeline you want scrape. Date Must be entered in as \"YYYYMMDD\"\n",
    "             \n",
    "    return:\n",
    "    -------\n",
    "    \n",
    "    combined: a dataframe containing the sum of the daily keyword hits in google news (key words labeled _x),\n",
    "    \n",
    "    data frame cointaing stock info including open, close, high, low prices of the stock,\n",
    "    as well as the stocks daily trading volume and the amount if there was a split or dividend \n",
    "    preformed on the stock that day,\n",
    "    \n",
    "    and the sum of how many times key word wikipedia pages were viewed in a day (key words labeled _y)\n",
    "    \"\"\"\n",
    "    \n",
    "    year_s = int(start[0:4])\n",
    "    month_s = int(start[4:6])\n",
    "    day_s = int(start[6:8])\n",
    "    year_e = int(end[0:4])\n",
    "    month_e = int(end[4:6])\n",
    "    day_e = int(end[6:8])\n",
    "    \n",
    "    starter = pd.to_datetime(f\"'{year_s}-{month_s}-{day_s}'\")\n",
    "    ender = pd.to_datetime(f\"'{year_e}-{month_e}-{day_e}'\")\n",
    "    \n",
    "    \n",
    "    pytrends = TrendReq(hl='en-US', tz=360, retries=10)\n",
    "    jeff = pytrends.get_historical_interest(kw_list_1, \\\n",
    "                                 year_start = year_s, month_start = month_s, day_start = day_s, hour_start = 1, \\\n",
    "                                 year_end = year_e, month_end = month_e, day_end = day_e, hour_end = 23, \\\n",
    "                                 cat = 0, geo = '', gprop = 'news', sleep = 60)\n",
    "    \n",
    "    jeff = jeff.iloc[:, 0:-1] # eliminates the isPartial Column\n",
    "    jeff = jeff.reset_index().drop_duplicates(subset = \"date\") #removing duplicates from the index\n",
    "    jeff = jeff.groupby(pd.Grouper(key=\"date\", freq=\"D\")).mean() # coverts to the mean of daily scores\n",
    "\n",
    "    dow = yf.Ticker(\"^DJI\")\n",
    "    dow_h = dow.history(start=starter, end=ender)\n",
    "    dow_h = pd.DataFrame(dow_h)\n",
    "    dow_names = {\"Open\":\"dow_open\",\"Close\":\"dow_close\",\"Low\": \"dow_low\",\n",
    "    'High':'dow_high','Volume':'dow_vol'}\n",
    "    dow_h=dow_h.rename(dow_names, axis=1).drop([\"Dividends\",\"Stock Splits\"], axis=1)\n",
    "\n",
    "    nas = yf.Ticker(\"^IXIC\")\n",
    "    nas_h = nas.history(start=starter, end=ender)\n",
    "    nas_h = pd.DataFrame(nas_h)\n",
    "    nas_names = {\"Open\":\"nas_open\", \"Close\":\"nas_close\", \"Low\": \"nas_low\",\n",
    "    'High':'nas_high','Volume':'nas_vol'}\n",
    "    nas_h=nas_h.rename(nas_names, axis=1).drop([\"Dividends\",\"Stock Splits\"], axis=1)\n",
    "\n",
    "    market = dow_h.merge(nas_h,left_index=True, right_index=True, how=\"left\")\n",
    "    \n",
    "    tick = yf.Ticker(ticker)\n",
    "    hist = tick.history(start=starter, end=ender)\n",
    "    hist = pd.DataFrame(hist)\n",
    "    \n",
    "    combined = jeff.merge(hist, left_index=True, right_index=True, how=\"left\")\n",
    "    combined = combined.merge(market, left_index=True, right_index=True, how=\"left\")  \n",
    "    \n",
    "    d = pd.DataFrame()\n",
    "    for key_word in kw_list_2:\n",
    "        geoff = pageviewapi.per_article('en.wikipedia', key_word, start, end,\n",
    "                                    access='all-access', agent='all-agents', granularity='daily')\n",
    "        dicty = dict(geoff)\n",
    "        views = pd.DataFrame(dicty[\"items\"])\n",
    "        views[\"timestamp\"] = pd.to_datetime((views[\"timestamp\"]), format=\"%Y%m%d%H\")\n",
    "        views = views.set_index(\"timestamp\")\n",
    "        page = pd.Series(views[\"views\"])\n",
    "        d[key_word] = page\n",
    "        \n",
    "    combined = combined.merge(d, left_index=True, right_index=True, how=\"left\") \n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "30e94948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ford</th>\n",
       "      <th>F-150</th>\n",
       "      <th>Ford Bronco_x</th>\n",
       "      <th>Ford Mustang_x</th>\n",
       "      <th>Ford Stock</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>...</th>\n",
       "      <th>nas_low</th>\n",
       "      <th>nas_close</th>\n",
       "      <th>nas_vol</th>\n",
       "      <th>Ford Motor Company</th>\n",
       "      <th>Ford Mustang_y</th>\n",
       "      <th>Ford F Series</th>\n",
       "      <th>Ford Bronco_y</th>\n",
       "      <th>Lincoln Navigator</th>\n",
       "      <th>Lincoln Aviator</th>\n",
       "      <th>Ford GT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>13.565217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.173913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5163</td>\n",
       "      <td>3279</td>\n",
       "      <td>15</td>\n",
       "      <td>1372</td>\n",
       "      <td>668</td>\n",
       "      <td>329</td>\n",
       "      <td>1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02</th>\n",
       "      <td>18.791667</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.827570</td>\n",
       "      <td>7.271861</td>\n",
       "      <td>6.782234</td>\n",
       "      <td>7.163055</td>\n",
       "      <td>47494400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6506.879883</td>\n",
       "      <td>6665.939941</td>\n",
       "      <td>2.261800e+09</td>\n",
       "      <td>5648</td>\n",
       "      <td>3804</td>\n",
       "      <td>24</td>\n",
       "      <td>1597</td>\n",
       "      <td>710</td>\n",
       "      <td>341</td>\n",
       "      <td>1466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>22.166667</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>7.226524</td>\n",
       "      <td>7.244658</td>\n",
       "      <td>7.054248</td>\n",
       "      <td>7.054248</td>\n",
       "      <td>39172400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6457.129883</td>\n",
       "      <td>6463.500000</td>\n",
       "      <td>2.607290e+09</td>\n",
       "      <td>6290</td>\n",
       "      <td>3792</td>\n",
       "      <td>11</td>\n",
       "      <td>1549</td>\n",
       "      <td>678</td>\n",
       "      <td>334</td>\n",
       "      <td>1375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>18.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>7.172122</td>\n",
       "      <td>7.362532</td>\n",
       "      <td>7.117719</td>\n",
       "      <td>7.326263</td>\n",
       "      <td>43039800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6554.240234</td>\n",
       "      <td>6738.859863</td>\n",
       "      <td>2.579550e+09</td>\n",
       "      <td>6227</td>\n",
       "      <td>3800</td>\n",
       "      <td>15</td>\n",
       "      <td>1387</td>\n",
       "      <td>679</td>\n",
       "      <td>303</td>\n",
       "      <td>1390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-05</th>\n",
       "      <td>23.291667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6131</td>\n",
       "      <td>3872</td>\n",
       "      <td>22</td>\n",
       "      <td>3319</td>\n",
       "      <td>761</td>\n",
       "      <td>339</td>\n",
       "      <td>1490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-06</th>\n",
       "      <td>16.416667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6778</td>\n",
       "      <td>3910</td>\n",
       "      <td>15</td>\n",
       "      <td>1587</td>\n",
       "      <td>734</td>\n",
       "      <td>445</td>\n",
       "      <td>1470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-07</th>\n",
       "      <td>20.708333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.291667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6110</td>\n",
       "      <td>3760</td>\n",
       "      <td>25</td>\n",
       "      <td>1507</td>\n",
       "      <td>727</td>\n",
       "      <td>444</td>\n",
       "      <td>1277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Ford     F-150  Ford Bronco_x  Ford Mustang_x  Ford Stock  \\\n",
       "date                                                                         \n",
       "2019-01-01  13.565217  0.000000       0.000000        1.173913    0.000000   \n",
       "2019-01-02  18.791667  0.458333       0.000000        0.500000    0.000000   \n",
       "2019-01-03  22.166667  0.458333       1.000000        1.500000    0.416667   \n",
       "2019-01-04  18.333333  0.000000       0.458333        0.750000    1.125000   \n",
       "2019-01-05  23.291667  0.000000       0.625000        1.750000    0.000000   \n",
       "2019-01-06  16.416667  0.000000       0.000000        1.000000    0.000000   \n",
       "2019-01-07  20.708333  0.000000       1.291667        0.708333    0.000000   \n",
       "\n",
       "                Open      High       Low     Close      Volume  ...  \\\n",
       "date                                                            ...   \n",
       "2019-01-01       NaN       NaN       NaN       NaN         NaN  ...   \n",
       "2019-01-02  6.827570  7.271861  6.782234  7.163055  47494400.0  ...   \n",
       "2019-01-03  7.226524  7.244658  7.054248  7.054248  39172400.0  ...   \n",
       "2019-01-04  7.172122  7.362532  7.117719  7.326263  43039800.0  ...   \n",
       "2019-01-05       NaN       NaN       NaN       NaN         NaN  ...   \n",
       "2019-01-06       NaN       NaN       NaN       NaN         NaN  ...   \n",
       "2019-01-07       NaN       NaN       NaN       NaN         NaN  ...   \n",
       "\n",
       "                nas_low    nas_close       nas_vol  Ford Motor Company  \\\n",
       "date                                                                     \n",
       "2019-01-01          NaN          NaN           NaN                5163   \n",
       "2019-01-02  6506.879883  6665.939941  2.261800e+09                5648   \n",
       "2019-01-03  6457.129883  6463.500000  2.607290e+09                6290   \n",
       "2019-01-04  6554.240234  6738.859863  2.579550e+09                6227   \n",
       "2019-01-05          NaN          NaN           NaN                6131   \n",
       "2019-01-06          NaN          NaN           NaN                6778   \n",
       "2019-01-07          NaN          NaN           NaN                6110   \n",
       "\n",
       "            Ford Mustang_y  Ford F Series  Ford Bronco_y  Lincoln Navigator  \\\n",
       "date                                                                          \n",
       "2019-01-01            3279             15           1372                668   \n",
       "2019-01-02            3804             24           1597                710   \n",
       "2019-01-03            3792             11           1549                678   \n",
       "2019-01-04            3800             15           1387                679   \n",
       "2019-01-05            3872             22           3319                761   \n",
       "2019-01-06            3910             15           1587                734   \n",
       "2019-01-07            3760             25           1507                727   \n",
       "\n",
       "            Lincoln Aviator  Ford GT  \n",
       "date                                  \n",
       "2019-01-01              329     1290  \n",
       "2019-01-02              341     1466  \n",
       "2019-01-03              334     1375  \n",
       "2019-01-04              303     1390  \n",
       "2019-01-05              339     1490  \n",
       "2019-01-06              445     1470  \n",
       "2019-01-07              444     1277  \n",
       "\n",
       "[7 rows x 29 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Big_scraper(kw_list_1, kw_list_2,\"F\", \"20190101\", \"20190107\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e5ee1ce9-734a-48f2-b256-0d23f5110a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_list_1 = [\"Ford\", \"F-150\", \"Ford Bronco\", \"Ford Mustang\", \"Ford Stock\"]\n",
    "kw_list_2 = [\"Ford Motor Company\", \"Ford Mustang\", \"Ford F Series\", \"Ford Bronco\", \"Lincoln Navigator\", \"Lincoln Aviator\", \"Ford GT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6ea88fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ford = Big_scraper(kw_list_1, kw_list_2,\"F\", \"20190101\", \"20191231\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9bea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ford.to_csv(\"2019_Ford_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829ebb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ford_20 = Big_scraper(kw_list_1, kw_list_2,\"F\", \"20200101\", \"20201231\")\n",
    "Ford_20.to_csv(\"2020_Ford_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d1fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ford_21 = Big_scraper(kw_list_1, kw_list_2,\"F\", \"20210101\", \"20211231\")\n",
    "Ford_21.to_csv(\"2021_Ford_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56908410",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ford_22 = Big_scraper(kw_list_1, kw_list_2,\"F\", \"20220101\", \"20220331\")\n",
    "Ford_22.to_csv(\"2022_Ford_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49518538",
   "metadata": {},
   "outputs": [],
   "source": [
    "ford = pd.concat([Ford, Ford_20, Ford_21, Ford_22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "12e15378",
   "metadata": {},
   "outputs": [],
   "source": [
    "dow = yf.Ticker(\"^DJI\")\n",
    "dow_h = dow.history(start=\"2019-01-01\", end=\"2022-03-31\")\n",
    "dow_h = pd.DataFrame(dow_h)\n",
    "dow_names = {\"Open\":\"dow_open\",\"Close\":\"dow_close\",\"Low\": \"dow_low\",\n",
    "    'High':'dow_high','Volume':'dow_vol'}\n",
    "dow_h=dow_h.rename(dow_names, axis=1).drop([\"Dividends\",\"Stock Splits\"], axis=1)\n",
    "\n",
    "nas = yf.Ticker(\"^IXIC\")\n",
    "nas_h = nas.history(start=\"2019-01-01\", end=\"2022-03-31\")\n",
    "nas_h = pd.DataFrame(nas_h)\n",
    "nas_names = {\"Open\":\"nas_open\", \"Close\":\"nas_close\", \"Low\": \"nas_low\",\n",
    "    'High':'nas_high','Volume':'nas_vol'}\n",
    "nas_h=nas_h.rename(nas_names, axis=1).drop([\"Dividends\",\"Stock Splits\"], axis=1)\n",
    "\n",
    "market = dow_h.merge(nas_h,left_index=True, right_index=True, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "20b35f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ford = ford.merge(market,left_index=True, right_index=True, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aef4c9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ford</th>\n",
       "      <th>F-150</th>\n",
       "      <th>Ford Bronco_x</th>\n",
       "      <th>Ford Mustang_x</th>\n",
       "      <th>Ford Stock</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>...</th>\n",
       "      <th>dow_open</th>\n",
       "      <th>dow_high</th>\n",
       "      <th>dow_low</th>\n",
       "      <th>dow_close</th>\n",
       "      <th>dow_vol</th>\n",
       "      <th>nas_open</th>\n",
       "      <th>nas_high</th>\n",
       "      <th>nas_low</th>\n",
       "      <th>nas_close</th>\n",
       "      <th>nas_vol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>14.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.217391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02</th>\n",
       "      <td>19.416667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.827570</td>\n",
       "      <td>7.271861</td>\n",
       "      <td>6.782234</td>\n",
       "      <td>7.163055</td>\n",
       "      <td>47494400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23058.609375</td>\n",
       "      <td>23413.470703</td>\n",
       "      <td>22928.589844</td>\n",
       "      <td>23346.240234</td>\n",
       "      <td>321570000.0</td>\n",
       "      <td>6506.910156</td>\n",
       "      <td>6693.709961</td>\n",
       "      <td>6506.879883</td>\n",
       "      <td>6665.939941</td>\n",
       "      <td>2.261800e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>23.041667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>7.226524</td>\n",
       "      <td>7.244659</td>\n",
       "      <td>7.054249</td>\n",
       "      <td>7.054249</td>\n",
       "      <td>39172400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23176.390625</td>\n",
       "      <td>23176.390625</td>\n",
       "      <td>22638.410156</td>\n",
       "      <td>22686.220703</td>\n",
       "      <td>424240000.0</td>\n",
       "      <td>6584.770020</td>\n",
       "      <td>6600.209961</td>\n",
       "      <td>6457.129883</td>\n",
       "      <td>6463.500000</td>\n",
       "      <td>2.607290e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>19.208333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>1.208333</td>\n",
       "      <td>7.172122</td>\n",
       "      <td>7.362532</td>\n",
       "      <td>7.117719</td>\n",
       "      <td>7.326263</td>\n",
       "      <td>43039800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22894.919922</td>\n",
       "      <td>23518.640625</td>\n",
       "      <td>22894.919922</td>\n",
       "      <td>23433.160156</td>\n",
       "      <td>396020000.0</td>\n",
       "      <td>6567.140137</td>\n",
       "      <td>6760.689941</td>\n",
       "      <td>6554.240234</td>\n",
       "      <td>6738.859863</td>\n",
       "      <td>2.579550e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-05</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Ford  F-150  Ford Bronco_x  Ford Mustang_x  Ford Stock  \\\n",
       "date                                                                      \n",
       "2019-01-01  14.043478    0.0       0.000000        1.217391    0.000000   \n",
       "2019-01-02  19.416667    0.5       0.000000        0.541667    0.000000   \n",
       "2019-01-03  23.041667    0.5       1.083333        1.500000    0.458333   \n",
       "2019-01-04  19.208333    0.0       0.500000        0.791667    1.208333   \n",
       "2019-01-05  24.000000    0.0       0.666667        1.875000    0.000000   \n",
       "\n",
       "                Open      High       Low     Close      Volume  ...  \\\n",
       "date                                                            ...   \n",
       "2019-01-01       NaN       NaN       NaN       NaN         NaN  ...   \n",
       "2019-01-02  6.827570  7.271861  6.782234  7.163055  47494400.0  ...   \n",
       "2019-01-03  7.226524  7.244659  7.054249  7.054249  39172400.0  ...   \n",
       "2019-01-04  7.172122  7.362532  7.117719  7.326263  43039800.0  ...   \n",
       "2019-01-05       NaN       NaN       NaN       NaN         NaN  ...   \n",
       "\n",
       "                dow_open      dow_high       dow_low     dow_close  \\\n",
       "date                                                                 \n",
       "2019-01-01           NaN           NaN           NaN           NaN   \n",
       "2019-01-02  23058.609375  23413.470703  22928.589844  23346.240234   \n",
       "2019-01-03  23176.390625  23176.390625  22638.410156  22686.220703   \n",
       "2019-01-04  22894.919922  23518.640625  22894.919922  23433.160156   \n",
       "2019-01-05           NaN           NaN           NaN           NaN   \n",
       "\n",
       "                dow_vol     nas_open     nas_high      nas_low    nas_close  \\\n",
       "date                                                                          \n",
       "2019-01-01          NaN          NaN          NaN          NaN          NaN   \n",
       "2019-01-02  321570000.0  6506.910156  6693.709961  6506.879883  6665.939941   \n",
       "2019-01-03  424240000.0  6584.770020  6600.209961  6457.129883  6463.500000   \n",
       "2019-01-04  396020000.0  6567.140137  6760.689941  6554.240234  6738.859863   \n",
       "2019-01-05          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "                 nas_vol  \n",
       "date                      \n",
       "2019-01-01           NaN  \n",
       "2019-01-02  2.261800e+09  \n",
       "2019-01-03  2.607290e+09  \n",
       "2019-01-04  2.579550e+09  \n",
       "2019-01-05           NaN  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ford.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3022eab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ford', 'F-150', 'Ford Bronco_x', 'Ford Mustang_x', 'Ford Stock',\n",
       "       'Open', 'High', 'Low', 'Close', 'Volume',\n",
       "       ...\n",
       "       'dow_open', 'dow_high', 'dow_low', 'dow_close', 'dow_vol', 'nas_open',\n",
       "       'nas_high', 'nas_low', 'nas_close', 'nas_vol'],\n",
       "      dtype='object', length=110)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ford.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fc106274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating base varibles to be used in variable creator functions\n",
    "ford[\"Wiki_total\"] = (ford[\"Ford Motor Company\"] + \n",
    "    ford[\"Ford Mustang_y\"] + ford[\"Ford F Series\"] + \n",
    "    ford[\"Ford Bronco_y\"] + ford[\"Lincoln Navigator\"] + \n",
    "    ford[\"Lincoln Aviator\"] + ford[\"Ford GT\"])\n",
    "\n",
    "ford[\"Google_total\"] = (ford[\"Ford\"] +\n",
    "    ford[\"F-150\"] + ford[\"Ford Bronco_x\"] +\n",
    "    ford[\"Ford Mustang_x\"] + ford[\"Ford Stock\"])\n",
    "\n",
    "ford[\"Stock_total\"] = ford[\"Close\"]\n",
    "ford[\"Nas_total\"] = ford[\"nas_close\"]\n",
    "ford[\"Dow_total\"] = ford[\"dow_close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9c9f6f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variables_creator(df, variable_list, w=7):\n",
    "    \n",
    "    '''\n",
    "    descrition:\n",
    "    -----------\n",
    "    takes dataframe and returns new varibles based on recommmended calcualtions, \n",
    "    it should be done seporately with internet based and stock based dataframes\n",
    "\n",
    "    Note: When using for aggreated varaibles, for example Wiki_total, the sum of all the wiki pages daily page view counts, \n",
    "    you MUST calculate Wiki_total in the dataframe seperately BEFORE this function can be used. \n",
    "\n",
    "    For example if you had wiki page counts for Ford Bronco and Ford Ranger, Wiki_total would equal Ford Bronco + Ford ranger counts, \n",
    "    AGAIN Wiki_total must be calculated in the desired dateframe before using this function \n",
    "\n",
    "    input:\n",
    "    ------\n",
    "    df: dataframe containing the google trends, yahoo finance, and or wikipedia page count data\n",
    "\n",
    "    variable_list: list of strings to be added to the equations to calculate the new varaibles. \n",
    "    ex. insertting the string \"Wiki\" will add to df[f\"{}_total\"] to become \"Wiki_total\"\n",
    "\n",
    "    w: the window length for one period shift. Default is 7 providing 7 day moving averages for wiki and google data, \n",
    "        FOR STOCK DATA THIS WILL NEED TO BE CHANGED TO 5.\n",
    "\n",
    "    output:\n",
    "    -------\n",
    "    df: the same dataframe as was inputted but now containing variables for \n",
    "    Momemtum, Disparity, Moving Average, Exponential Moving Aerage, Rator Change, and RSI index score.\n",
    "    Also containg are moving variables, which are boolean with 1 indicating an increase in the above variables\n",
    "    '''   \n",
    "    \n",
    "    for i in variable_list:\n",
    "        # Momentum_1\n",
    "        df[f\"{i}_Moment_1\"] =  (df[f\"{i}_total\"] / df[f\"{i}_total\"].shift(w)) * 100\n",
    "        # Momentum_2\n",
    "        df[f\"{i}_Moment_2\"] =  (df[f\"{i}_total\"] - df[f\"{i}_total\"].shift(w)) * 100\n",
    "        # Momentum_1_s three day shift (instead of w)\n",
    "        df[f\"{i}_Moment_1_s\"] =  (df[f\"{i}_total\"] / df[f\"{i}_total\"].shift(3)) * 100\n",
    "        # Momentum_2_s\n",
    "        df[f\"{i}_Moment_2_s\"] =  (df[f\"{i}_total\"] - df[f\"{i}_total\"].shift(3)) * 100\n",
    "        # Moving average\n",
    "        df[f\"{i}_MAvg\"] = df[f\"{i}_total\"].rolling(f\"{w}d\").mean()\n",
    "        # Moving average 3 day\n",
    "        df[f\"{i}_MAvg_s\"] = df[f\"{i}_total\"].rolling(\"3d\").mean()\n",
    "        # Disparity\n",
    "        df[f\"{i}_Disparity\"] = (df[f\"{i}_total\"]/df[f\"{i}_MAvg\"]) * 100\n",
    "        # Disparity 3 day\n",
    "        df[f\"{i}_Disparity_s\"] = (df[f\"{i}_total\"]/df[f\"{i}_MAvg_s\"]) * 100\n",
    "        # Rate of Change Normal Way\n",
    "        df[f\"{i}_ROC\"] = (df[f\"{i}_total\"]-df[f\"{i}_total\"].shift(w))/(df[f\"{i}_total\"].shift(w)) *100\n",
    "        df[f\"{i}_ROC_s\"] = (df[f\"{i}_total\"]-df[f\"{i}_total\"].shift(3))/(df[f\"{i}_total\"].shift(3)) *100\n",
    "        #Rate of Change Paper Way (doesn't make sense but just in case)\n",
    "        df[f'{i}_Rocp'] = (df[f\"{i}_total\"]/df[f\"{i}_Moment_2\"]) *100\n",
    "        # Exponential Moving Average\n",
    "        df[f\"{i}_EMA\"] = (df[f\"{i}_total\"]-df[f\"{i}_MAvg\"].shift(1))*(2/(w+1))+df[f\"{i}_MAvg\"].shift(1)\n",
    "\n",
    "        # calculating the Relative Strength Index, based on 14 day window\n",
    "        df[f\"{i}_diff\"] = df[f\"{i}_total\"].diff(1)\n",
    "        df[f\"{i}_gain\"] = df[f\"{i}_diff\"].clip(lower=0).round(2) #keeps all values above or below a given threshold, lower=lower bound\n",
    "        df[f\"{i}_loss\"] = df[f\"{i}_diff\"].clip(upper=0).round(2)\n",
    "        df[f'{i}_avg_gain'] = df[f'{i}_gain'].rolling(14).mean()\n",
    "        df[f'{i}_avg_loss'] = df[f'{i}_loss'].rolling(14).mean()\n",
    "        df[f'{i}_rs'] = df[f'{i}_avg_gain'] / df[f'{i}_avg_loss']\n",
    "        df[f'{i}_RSI'] = 100 - (100 / (1.0 + df[f'{i}_rs']))\n",
    "\n",
    "        # Calculatiing the Move Variables \n",
    "        df[f\"{i}_Move\"] = df[f\"{i}_total\"] > df[f\"{i}_total\"].shift(1) \n",
    "        df[f\"{i}_Move\"] = df[f\"{i}_Move\"].replace({True:1,False: 0})\n",
    "    \n",
    "      \n",
    "        df[f\"{i}_MAvg_Move\"] = df[f\"{i}_MAvg\"] > df[f\"{i}_MAvg\"].shift(1) \n",
    "        df[f\"{i}_MAvg_Move\"] = df[f\"{i}_MAvg_Move\"].replace({True:1,False: 0})\n",
    "        df[f\"{i}_MAvg_s_Move\"] = df[f\"{i}_MAvg_s\"] > df[f\"{i}_MAvg_s\"].shift(1) \n",
    "        df[f\"{i}_MAvg_s_Move\"] = df[f\"{i}_MAvg_s_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "        df[f\"{i}_EMA_Move\"] = df[f\"{i}_EMA\"] > df[f\"{i}_EMA\"].shift(1) \n",
    "        df[f\"{i}_EMA_Move\"] = df[f\"{i}_EMA_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "        df[f\"{i}_Disparity_Move\"] = df[f\"{i}_Disparity\"] > df[f\"{i}_Disparity\"].shift(1) \n",
    "        df[f\"{i}_Disparity_Move\"] = df[f\"{i}_Disparity_Move\"].replace({True:1,False: 0})\n",
    "        df[f\"{i}_Disparity_s_Move\"] = df[f\"{i}_Disparity_s\"] > df[f\"{i}_Disparity_s\"].shift(1) \n",
    "        df[f\"{i}_Disparity_s_Move\"] = df[f\"{i}_Disparity_s_Move\"].replace({True:1,False: 0})\n",
    "\n",
    "        df[f\"{i}_RSI_Move\"] = df[f\"{i}_RSI\"] > df[f\"{i}_RSI\"].shift(1) \n",
    "        df[f\"{i}_RSI_Move\"] = df[f\"{i}_RSI_Move\"].replace({True:1,False: 0})\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8f696b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ford = variables_creator(ford, [\"Wiki\",\"Google\", \"Stock\", \"Nas\", \"Dow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bf6fd849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_creator(df):\n",
    "    '''\n",
    "    description: creates the differnt types of target variables based on tomorrow minus today,\n",
    "    '''\n",
    "        \n",
    "    # target 1, Open(t+1) - Close(t)\n",
    "    df[\"target_1\"] = (df[\"Open\"].shift(-1) - df[\"Close\"]) > 0\n",
    "    df[\"target_1\"] = df[\"target_1\"].replace({True:1,False: 0})\n",
    "    # target 2\n",
    "    df[\"target_2\"] = (df[\"Open\"].shift(-1) - df[\"Open\"]) > 0\n",
    "    df[\"target_2\"] = df[\"target_2\"].replace({True:1,False: 0})\n",
    "    # target 3\n",
    "    df[\"target_3\"] = (df[\"Close\"].shift(-1) - df[\"Close\"]) > 0\n",
    "    df[\"target_3\"] = df[\"target_3\"].replace({True:1,False: 0})\n",
    "    # target 4\n",
    "    df[\"target_4\"] = (df[\"Close\"].shift(-1) - df[\"Open\"]) > 0\n",
    "    df[\"target_4\"] = df[\"target_4\"].replace({True:1,False: 0})\n",
    "    # target 5\n",
    "    df[\"target_5\"] = (df[\"Volume\"].shift(-1) - df[\"Volume\"]) > 0\n",
    "    df[\"target_5\"] = df[\"target_5\"].replace({True:1,False: 0})\n",
    " \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c86b1a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "ford = target_creator(ford)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e73e76f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ford.to_csv(\"Ford_full_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
