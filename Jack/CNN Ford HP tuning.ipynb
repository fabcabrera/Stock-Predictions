{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9a1ccf7",
   "metadata": {},
   "source": [
    "# CNN Ford Hyperparemter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c680638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense, Normalization\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, InputLayer, SimpleRNN\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn import (\n",
    "    linear_model, metrics, neural_network, pipeline, model_selection\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3072e520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ford</th>\n",
       "      <th>F-150</th>\n",
       "      <th>Ford Bronco_x</th>\n",
       "      <th>Ford Mustang_x</th>\n",
       "      <th>Ford Stock</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>...</th>\n",
       "      <th>Dow_MAvg_s_Move</th>\n",
       "      <th>Dow_EMA_Move</th>\n",
       "      <th>Dow_Disparity_Move</th>\n",
       "      <th>Dow_Disparity_s_Move</th>\n",
       "      <th>Dow_RSI_Move</th>\n",
       "      <th>target_1</th>\n",
       "      <th>target_2</th>\n",
       "      <th>target_3</th>\n",
       "      <th>target_4</th>\n",
       "      <th>target_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ford  F-150  Ford Bronco_x  Ford Mustang_x  Ford Stock  Open  High  Low  \\\n",
       "0     0      0              0               0           0     6     6    6   \n",
       "\n",
       "   Close  Volume  ...  Dow_MAvg_s_Move  Dow_EMA_Move  Dow_Disparity_Move  \\\n",
       "0      6       6  ...                0             0                   0   \n",
       "\n",
       "   Dow_Disparity_s_Move  Dow_RSI_Move  target_1  target_2  target_3  target_4  \\\n",
       "0                     0             0         0         0         0         0   \n",
       "\n",
       "   target_5  \n",
       "0         0  \n",
       "\n",
       "[1 rows x 166 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ford = pd.read_csv(\"Ford_Cleaned_Date.csv\")\n",
    "Ford.date = pd.to_datetime(Ford.date)\n",
    "Ford = Ford.set_index(\"date\")\n",
    "Ford = Ford.iloc[14:, :] # to remove first 14 days that include NaNs due to some calculations\n",
    "Ford = Ford.drop([\"Nas_total\", 'Stock_total', 'Dow_total'],axis=1) # to remove duplicated columns\n",
    "pd.DataFrame(Ford.isna().sum()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c763aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ford = Ford.dropna()\n",
    "Ford = Ford[~(Ford.isin([np.inf, -np.inf]).any(axis=1))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c174a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ford = Ford.drop(['target_1', 'target_2', 'target_4', 'target_5'], axis=1)\n",
    "target_3 = Ford[\"target_3\"]\n",
    "\n",
    "#splitting into training sets \n",
    "column_indices = {name: i for i, name in enumerate(Ford.columns)}\n",
    "\n",
    "n = len(Ford)\n",
    "X_train = Ford[0:int(n*0.7)]\n",
    "X_val = Ford[int(n*0.7):int(n*0.9)]\n",
    "X_test = Ford[int(n*0.9):]\n",
    "\n",
    "y_train = target_3[0:int(n*0.7)]\n",
    "y_val = target_3[int(n*0.7):int(n*0.9)]\n",
    "y_test = target_3[int(n*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "234b2987",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mscaler = MinMaxScaler() # keeps binarys at zero and 1 :)\n",
    "\n",
    "X_train = pd.DataFrame(Mscaler.fit_transform(X_train), columns = Ford.columns)\n",
    "X_val = pd.DataFrame(Mscaler.fit_transform(X_val), columns = Ford.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d950dc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_X_y2(df, target, window_size=5):\n",
    "  df_as_np = df.to_numpy() # converts to matrix of numpy arrays\n",
    "  X = []\n",
    "  y = []\n",
    "  for i in range(len(df_as_np)-window_size): # length of data frame - window_size so it does't take empty values at the end, \n",
    "    # does force you to loose the last 5 values, could fix with padding\n",
    "    row = [r for r in df_as_np[i:i+window_size]] # grabs row i and all rows above within the window size length\n",
    "    X.append(row) # creates 3 dimentional array, (# obseravtions, # rows in window, # features)\n",
    "    label = target[i+window_size] # pulls the target variable after the window, target varible needs to be column zero in this \n",
    "    y.append(label) # returns (N,) martix of targets i+window_length time periods away\n",
    "  return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b87523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kbest_creator(k):\n",
    "    \"\"\"\n",
    "    returns list of k best features and the number of efficient principle compents to use with said k features\n",
    "    \"\"\"\n",
    "    # apply SelectKBest class to extract top 40 best features\n",
    "    bestfeatures = SelectKBest(score_func=f_regression, k=k)\n",
    "    best_fit = bestfeatures.fit(X_train, y_train)\n",
    "    best_scores = pd.DataFrame(best_fit.scores_)\n",
    "    best_columns = pd.DataFrame(Ford.columns)\n",
    "    \n",
    "    # concatenate the dataframes for better visualization\n",
    "    features_score = pd.concat([best_columns, best_scores], axis=1)\n",
    "    features_score.columns = ['Features', 'Score']  # naming the dataframe columns\n",
    "    feats = list(features_score.nlargest(k, 'Score')['Features'])\n",
    "\n",
    "    pca = PCA().fit(X_train[feats])\n",
    "    pca_scores = np.cumsum(pca.explained_variance_ratio_) * 100\n",
    "    res = next(x for x, val in enumerate(pca_scores) if val > 85)\n",
    "    res = res +1\n",
    "    res\n",
    "    \n",
    "    return feats, res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8f1bab",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb32886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b532ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "# Model1\n",
    "\n",
    "feats, comp = kbest_creator(5)\n",
    "\n",
    "sklearn_pca = PCA(n_components=comp)\n",
    "X_train_1 = pd.DataFrame(sklearn_pca.fit_transform(X_train[feats]))\n",
    "X_val_1 = pd.DataFrame(sklearn_pca.transform(X_val[feats]))\n",
    "X_test_1 = pd.DataFrame(sklearn_pca.transform(X_test[feats]))\n",
    "\n",
    "# converting to window format, in this case 5 periods\n",
    "X_train_1, train_5w = df_to_X_y2(X_train_1,y_train)\n",
    "X_val_1, val_5w = df_to_X_y2(X_val_1, y_val)\n",
    "X_test_1, test_5w = df_to_X_y2(X_test_1,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db90ed2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-13 15:56:04.064649: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 15ms/step - loss: 0.6977 - binary_accuracy: 0.4501 - val_loss: 0.6930 - val_binary_accuracy: 0.5182\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6890 - binary_accuracy: 0.5418 - val_loss: 0.6926 - val_binary_accuracy: 0.5182\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6865 - binary_accuracy: 0.5397 - val_loss: 0.6947 - val_binary_accuracy: 0.4526\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6823 - binary_accuracy: 0.5845 - val_loss: 0.6946 - val_binary_accuracy: 0.4526\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6810 - binary_accuracy: 0.5621 - val_loss: 0.6961 - val_binary_accuracy: 0.5036\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6773 - binary_accuracy: 0.5703 - val_loss: 0.6952 - val_binary_accuracy: 0.4818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x150cef3d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_1.shape[1]\n",
    "n_features = X_train_1.shape[2]\n",
    "\n",
    "model1_1 = Sequential()\n",
    "model1_1.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model1_1.add(Flatten())\n",
    "model1_1.add(Dense(25, activation='relu')) \n",
    "model1_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1_1.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model1_1.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1adbad04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 27ms/step - loss: 0.6947 - binary_accuracy: 0.4623 - val_loss: 0.6945 - val_binary_accuracy: 0.5182\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6922 - binary_accuracy: 0.5234 - val_loss: 0.6941 - val_binary_accuracy: 0.5182\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6906 - binary_accuracy: 0.5214 - val_loss: 0.6953 - val_binary_accuracy: 0.5182\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.6891 - binary_accuracy: 0.5336 - val_loss: 0.6949 - val_binary_accuracy: 0.5036\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6874 - binary_accuracy: 0.5316 - val_loss: 0.6967 - val_binary_accuracy: 0.5182\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6861 - binary_accuracy: 0.5377 - val_loss: 0.6993 - val_binary_accuracy: 0.5036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x151551cd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_2 = Sequential()\n",
    "model1_2.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model1_2.add(Conv1D(filters=15, kernel_size=2, activation='relu'))\n",
    "# better without pooling layer\n",
    "model1_2.add(Flatten())\n",
    "model1_2.add(Dense(30, activation='relu')) \n",
    "model1_2.add(Dense(30, activation='relu')) \n",
    "model1_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model1_2.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9ad1069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "# Model2\n",
    "\n",
    "feats, comp = kbest_creator(10)\n",
    "\n",
    "sklearn_pca = PCA(n_components=comp)\n",
    "X_train_1 = pd.DataFrame(sklearn_pca.fit_transform(X_train[feats]))\n",
    "X_val_1 = pd.DataFrame(sklearn_pca.transform(X_val[feats]))\n",
    "X_test_1 = pd.DataFrame(sklearn_pca.transform(X_test[feats]))\n",
    "\n",
    "# converting to window format, in this case 5 periods\n",
    "X_train_1, train_5w = df_to_X_y2(X_train_1,y_train)\n",
    "X_val_1, val_5w = df_to_X_y2(X_val_1, y_val)\n",
    "X_test_1, test_5w = df_to_X_y2(X_test_1,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77b199fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 19ms/step - loss: 0.6980 - binary_accuracy: 0.4745 - val_loss: 0.7005 - val_binary_accuracy: 0.4818\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6978 - binary_accuracy: 0.4745 - val_loss: 0.7003 - val_binary_accuracy: 0.4964\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6976 - binary_accuracy: 0.4745 - val_loss: 0.7002 - val_binary_accuracy: 0.4964\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6975 - binary_accuracy: 0.4745 - val_loss: 0.7000 - val_binary_accuracy: 0.5036\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6973 - binary_accuracy: 0.4766 - val_loss: 0.6999 - val_binary_accuracy: 0.5036\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6972 - binary_accuracy: 0.4766 - val_loss: 0.6998 - val_binary_accuracy: 0.5036\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6970 - binary_accuracy: 0.4745 - val_loss: 0.6997 - val_binary_accuracy: 0.5036\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6969 - binary_accuracy: 0.4766 - val_loss: 0.6996 - val_binary_accuracy: 0.4891\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6968 - binary_accuracy: 0.4766 - val_loss: 0.6995 - val_binary_accuracy: 0.4891\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6967 - binary_accuracy: 0.4807 - val_loss: 0.6994 - val_binary_accuracy: 0.4891\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6965 - binary_accuracy: 0.4766 - val_loss: 0.6993 - val_binary_accuracy: 0.4891\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6964 - binary_accuracy: 0.4786 - val_loss: 0.6992 - val_binary_accuracy: 0.4891\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6963 - binary_accuracy: 0.4725 - val_loss: 0.6992 - val_binary_accuracy: 0.5036\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6962 - binary_accuracy: 0.4745 - val_loss: 0.6991 - val_binary_accuracy: 0.5036\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6961 - binary_accuracy: 0.4725 - val_loss: 0.6991 - val_binary_accuracy: 0.5036\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6960 - binary_accuracy: 0.4725 - val_loss: 0.6990 - val_binary_accuracy: 0.4964\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6958 - binary_accuracy: 0.4705 - val_loss: 0.6989 - val_binary_accuracy: 0.4964\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6958 - binary_accuracy: 0.4705 - val_loss: 0.6989 - val_binary_accuracy: 0.4891\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6956 - binary_accuracy: 0.4684 - val_loss: 0.6988 - val_binary_accuracy: 0.4891\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.6955 - binary_accuracy: 0.4705 - val_loss: 0.6988 - val_binary_accuracy: 0.4891\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6955 - binary_accuracy: 0.4705 - val_loss: 0.6987 - val_binary_accuracy: 0.5036\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6954 - binary_accuracy: 0.4705 - val_loss: 0.6987 - val_binary_accuracy: 0.5036\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6953 - binary_accuracy: 0.4684 - val_loss: 0.6986 - val_binary_accuracy: 0.4964\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6951 - binary_accuracy: 0.4705 - val_loss: 0.6985 - val_binary_accuracy: 0.5109\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6951 - binary_accuracy: 0.4725 - val_loss: 0.6985 - val_binary_accuracy: 0.5036\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6949 - binary_accuracy: 0.4766 - val_loss: 0.6985 - val_binary_accuracy: 0.5036\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6949 - binary_accuracy: 0.4807 - val_loss: 0.6984 - val_binary_accuracy: 0.4964\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6948 - binary_accuracy: 0.4847 - val_loss: 0.6984 - val_binary_accuracy: 0.5036\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6947 - binary_accuracy: 0.4786 - val_loss: 0.6983 - val_binary_accuracy: 0.4964\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6946 - binary_accuracy: 0.4786 - val_loss: 0.6982 - val_binary_accuracy: 0.4964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1516e6820>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_1.shape[1]\n",
    "n_features = X_train_1.shape[2]\n",
    "\n",
    "model2_1 = Sequential()\n",
    "model2_1.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model2_1.add(Flatten())\n",
    "model2_1.add(Dense(25, activation='relu')) \n",
    "model2_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2_1.compile(optimizer='adagrad', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model2_1.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dec7b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 2s 14ms/step - loss: 0.7000 - binary_accuracy: 0.4949 - val_loss: 0.6906 - val_binary_accuracy: 0.5036\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6909 - binary_accuracy: 0.5112 - val_loss: 0.6903 - val_binary_accuracy: 0.4818\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6873 - binary_accuracy: 0.5275 - val_loss: 0.6918 - val_binary_accuracy: 0.4964\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6836 - binary_accuracy: 0.5642 - val_loss: 0.6944 - val_binary_accuracy: 0.5255\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6816 - binary_accuracy: 0.5356 - val_loss: 0.6951 - val_binary_accuracy: 0.5255\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6785 - binary_accuracy: 0.5682 - val_loss: 0.6973 - val_binary_accuracy: 0.5182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1517e05b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_2 = Sequential()\n",
    "model2_2.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model2_2.add(Flatten())\n",
    "model2_2.add(Dense(25, activation='relu')) \n",
    "model2_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2_2.compile(optimizer='RMSProp', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model2_2.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa1feb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 14ms/step - loss: 0.6920 - binary_accuracy: 0.5214 - val_loss: 0.6953 - val_binary_accuracy: 0.5182\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6877 - binary_accuracy: 0.5295 - val_loss: 0.6959 - val_binary_accuracy: 0.4891\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6864 - binary_accuracy: 0.5479 - val_loss: 0.6976 - val_binary_accuracy: 0.5255\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6848 - binary_accuracy: 0.5519 - val_loss: 0.6985 - val_binary_accuracy: 0.5182\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6844 - binary_accuracy: 0.5560 - val_loss: 0.7006 - val_binary_accuracy: 0.5182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1516e6af0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_3 = Sequential()\n",
    "model2_3.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model2_3.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
    "model2_3.add(MaxPooling1D(pool_size=2)) \n",
    "# better without pooling layer\n",
    "model2_3.add(Flatten())\n",
    "model2_3.add(Dense(30, activation='relu')) \n",
    "model2_3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2_3.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model2_3.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "368645cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 2s 22ms/step - loss: 0.6947 - binary_accuracy: 0.5173 - val_loss: 0.6936 - val_binary_accuracy: 0.5182\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6905 - binary_accuracy: 0.5336 - val_loss: 0.6939 - val_binary_accuracy: 0.5182\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6886 - binary_accuracy: 0.5377 - val_loss: 0.6952 - val_binary_accuracy: 0.4891\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6869 - binary_accuracy: 0.5397 - val_loss: 0.6974 - val_binary_accuracy: 0.4818\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6842 - binary_accuracy: 0.5397 - val_loss: 0.7022 - val_binary_accuracy: 0.4599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x151b0bfd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_4 = Sequential()\n",
    "model2_4.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model2_4.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model2_4.add(MaxPooling1D(pool_size=2)) \n",
    "model2_4.add(Conv1D(filters=32, kernel_size=1, activation='relu')) \n",
    "model2_4.add(Flatten())\n",
    "model2_4.add(Flatten())\n",
    "model2_4.add(Dense(25, activation='relu')) \n",
    "model2_4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2_4.compile(optimizer='RMSProp', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model2_4.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ffbbfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "# Model3\n",
    "\n",
    "feats, comp = kbest_creator(25)\n",
    "\n",
    "sklearn_pca = PCA(n_components=comp)\n",
    "X_train_1 = pd.DataFrame(sklearn_pca.fit_transform(X_train[feats]))\n",
    "X_val_1 = pd.DataFrame(sklearn_pca.transform(X_val[feats]))\n",
    "X_test_1 = pd.DataFrame(sklearn_pca.transform(X_test[feats]))\n",
    "\n",
    "# converting to window format, in this case 5 periods\n",
    "X_train_1, train_5w = df_to_X_y2(X_train_1,y_train)\n",
    "X_val_1, val_5w = df_to_X_y2(X_val_1, y_val)\n",
    "X_test_1, test_5w = df_to_X_y2(X_test_1,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d66c72ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 36ms/step - loss: 0.6963 - binary_accuracy: 0.5071 - val_loss: 0.6958 - val_binary_accuracy: 0.5182\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6873 - binary_accuracy: 0.5377 - val_loss: 0.6950 - val_binary_accuracy: 0.5036\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6829 - binary_accuracy: 0.5764 - val_loss: 0.6955 - val_binary_accuracy: 0.5109\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6782 - binary_accuracy: 0.5825 - val_loss: 0.6976 - val_binary_accuracy: 0.4964\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6746 - binary_accuracy: 0.5927 - val_loss: 0.6977 - val_binary_accuracy: 0.5328\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6710 - binary_accuracy: 0.6334 - val_loss: 0.7007 - val_binary_accuracy: 0.4818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x151d19fa0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_1.shape[1]\n",
    "n_features = X_train_1.shape[2]\n",
    "\n",
    "model3_1 = Sequential()\n",
    "model3_1.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model3_1.add(Flatten())\n",
    "model3_1.add(Dense(25, activation='relu')) \n",
    "model3_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3_1.compile(optimizer='RMSProp', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model3_1.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c67da6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 14ms/step - loss: 0.6985 - binary_accuracy: 0.4603 - val_loss: 0.6939 - val_binary_accuracy: 0.4745\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6902 - binary_accuracy: 0.5621 - val_loss: 0.6938 - val_binary_accuracy: 0.4891\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6861 - binary_accuracy: 0.6008 - val_loss: 0.6938 - val_binary_accuracy: 0.5109\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6827 - binary_accuracy: 0.6029 - val_loss: 0.6940 - val_binary_accuracy: 0.4745\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6780 - binary_accuracy: 0.6375 - val_loss: 0.6949 - val_binary_accuracy: 0.4891\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.6738 - binary_accuracy: 0.6293 - val_loss: 0.6945 - val_binary_accuracy: 0.5620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x151e64ee0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3_2 = Sequential()\n",
    "model3_2.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model3_2.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
    "model3_2.add(MaxPooling1D(pool_size=2)) \n",
    "# better without pooling layer\n",
    "model3_2.add(Flatten())\n",
    "model3_2.add(Dense(30, activation='relu')) \n",
    "model3_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model3_2.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "723ca40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "# Model4\n",
    "\n",
    "feats, comp = kbest_creator(50)\n",
    "\n",
    "sklearn_pca = PCA(n_components=comp)\n",
    "X_train_1 = pd.DataFrame(sklearn_pca.fit_transform(X_train[feats]))\n",
    "X_val_1 = pd.DataFrame(sklearn_pca.transform(X_val[feats]))\n",
    "X_test_1 = pd.DataFrame(sklearn_pca.transform(X_test[feats]))\n",
    "\n",
    "# converting to window format, in this case 5 periods\n",
    "X_train_1, train_5w = df_to_X_y2(X_train_1,y_train)\n",
    "X_val_1, val_5w = df_to_X_y2(X_val_1, y_val)\n",
    "X_test_1, test_5w = df_to_X_y2(X_test_1,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef3e4e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 12ms/step - loss: 0.7213 - binary_accuracy: 0.4623 - val_loss: 0.6950 - val_binary_accuracy: 0.5182\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6949 - binary_accuracy: 0.5214 - val_loss: 0.6907 - val_binary_accuracy: 0.5328\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6823 - binary_accuracy: 0.5866 - val_loss: 0.6895 - val_binary_accuracy: 0.5401\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6724 - binary_accuracy: 0.6130 - val_loss: 0.6901 - val_binary_accuracy: 0.5474\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6626 - binary_accuracy: 0.6395 - val_loss: 0.6912 - val_binary_accuracy: 0.5474\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6547 - binary_accuracy: 0.6538 - val_loss: 0.6914 - val_binary_accuracy: 0.5328\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6468 - binary_accuracy: 0.6599 - val_loss: 0.6933 - val_binary_accuracy: 0.5474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15204efd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_1.shape[1]\n",
    "n_features = X_train_1.shape[2]\n",
    "\n",
    "model4_1 = Sequential()\n",
    "model4_1.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model4_1.add(Flatten())\n",
    "model4_1.add(Dense(25, activation='relu')) \n",
    "model4_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model4_1.compile(optimizer='RMSProp', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model4_1.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a916bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 13ms/step - loss: 0.7035 - binary_accuracy: 0.4705 - val_loss: 0.7010 - val_binary_accuracy: 0.4526\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6879 - binary_accuracy: 0.5214 - val_loss: 0.6999 - val_binary_accuracy: 0.4818\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6825 - binary_accuracy: 0.5784 - val_loss: 0.6993 - val_binary_accuracy: 0.4818\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6752 - binary_accuracy: 0.6212 - val_loss: 0.6985 - val_binary_accuracy: 0.4964\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6693 - binary_accuracy: 0.6334 - val_loss: 0.6992 - val_binary_accuracy: 0.5036\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6631 - binary_accuracy: 0.6456 - val_loss: 0.6999 - val_binary_accuracy: 0.5036\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6553 - binary_accuracy: 0.6538 - val_loss: 0.7003 - val_binary_accuracy: 0.4745\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6459 - binary_accuracy: 0.7026 - val_loss: 0.7005 - val_binary_accuracy: 0.4891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1521ef820>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_2 = Sequential()\n",
    "model4_2.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model4_2.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
    "model4_2.add(MaxPooling1D(pool_size=2)) \n",
    "# better without pooling layer\n",
    "model4_2.add(Flatten())\n",
    "model4_2.add(Dense(30, activation='relu')) \n",
    "model4_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model4_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model4_2.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86f2643b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "# Model5\n",
    "\n",
    "feats, comp = kbest_creator(100)\n",
    "\n",
    "sklearn_pca = PCA(n_components=comp)\n",
    "X_train_1 = pd.DataFrame(sklearn_pca.fit_transform(X_train[feats]))\n",
    "X_val_1 = pd.DataFrame(sklearn_pca.transform(X_val[feats]))\n",
    "X_test_1 = pd.DataFrame(sklearn_pca.transform(X_test[feats]))\n",
    "\n",
    "# converting to window format, in this case 5 periods\n",
    "X_train_1, train_5w = df_to_X_y2(X_train_1,y_train)\n",
    "X_val_1, val_5w = df_to_X_y2(X_val_1, y_val)\n",
    "X_test_1, test_5w = df_to_X_y2(X_test_1,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acd90c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 14ms/step - loss: 0.7091 - binary_accuracy: 0.5499 - val_loss: 0.7003 - val_binary_accuracy: 0.5328\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6811 - binary_accuracy: 0.5703 - val_loss: 0.6986 - val_binary_accuracy: 0.5401\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6666 - binary_accuracy: 0.6232 - val_loss: 0.6995 - val_binary_accuracy: 0.5401\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6524 - binary_accuracy: 0.6436 - val_loss: 0.7001 - val_binary_accuracy: 0.5255\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6420 - binary_accuracy: 0.6823 - val_loss: 0.7045 - val_binary_accuracy: 0.4891\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6295 - binary_accuracy: 0.6762 - val_loss: 0.7067 - val_binary_accuracy: 0.4964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1523c0eb0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_1.shape[1]\n",
    "n_features = X_train_1.shape[2]\n",
    "\n",
    "model5_1 = Sequential()\n",
    "model5_1.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model5_1.add(Flatten())\n",
    "model5_1.add(Dense(25, activation='relu')) \n",
    "model5_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model5_1.compile(optimizer='RMSProp', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model5_1.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "423afe89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 14ms/step - loss: 0.7050 - binary_accuracy: 0.5071 - val_loss: 0.7002 - val_binary_accuracy: 0.5328\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6843 - binary_accuracy: 0.5418 - val_loss: 0.7016 - val_binary_accuracy: 0.4818\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6761 - binary_accuracy: 0.5825 - val_loss: 0.7034 - val_binary_accuracy: 0.4672\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6681 - binary_accuracy: 0.6151 - val_loss: 0.7049 - val_binary_accuracy: 0.5036\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6608 - binary_accuracy: 0.6090 - val_loss: 0.7097 - val_binary_accuracy: 0.5182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15251f5b0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5_2 = Sequential()\n",
    "model5_2.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model5_2.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
    "model5_2.add(MaxPooling1D(pool_size=2)) \n",
    "# better without pooling layer\n",
    "model5_2.add(Flatten())\n",
    "model5_2.add(Dense(30, activation='relu')) \n",
    "model5_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model5_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model5_2.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6cf808aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 15ms/step - loss: 0.6971 - binary_accuracy: 0.5275 - val_loss: 0.6904 - val_binary_accuracy: 0.5693\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6837 - binary_accuracy: 0.5397 - val_loss: 0.6920 - val_binary_accuracy: 0.5474\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6756 - binary_accuracy: 0.5723 - val_loss: 0.6928 - val_binary_accuracy: 0.5109\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6667 - binary_accuracy: 0.5927 - val_loss: 0.6918 - val_binary_accuracy: 0.5255\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6578 - binary_accuracy: 0.6090 - val_loss: 0.6922 - val_binary_accuracy: 0.5474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1519dbd90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5_3 = Sequential()\n",
    "model5_3.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model5_3.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
    "model5_3.add(MaxPooling1D(pool_size=2)) \n",
    "model5_3.add(Conv1D(filters=16, kernel_size=1, activation='relu'))\n",
    "# better without pooling layer\n",
    "model5_3.add(Flatten())\n",
    "model5_3.add(Dense(30, activation='relu')) \n",
    "model5_3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model5_3.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model5_3.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "784d96db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "#Model6 Starting to Adjust Window Size\n",
    "feats, comp = kbest_creator(40)\n",
    "\n",
    "sklearn_pca = PCA(n_components=comp)\n",
    "X_train_1 = pd.DataFrame(sklearn_pca.fit_transform(X_train[feats]))\n",
    "X_val_1 = pd.DataFrame(sklearn_pca.transform(X_val[feats]))\n",
    "X_test_1 = pd.DataFrame(sklearn_pca.transform(X_test[feats]))\n",
    "\n",
    "# converting to window format, in this case 3 periods\n",
    "X_train_1, train_3w = df_to_X_y2(X_train_1,y_train,3)\n",
    "X_val_1, val_3w = df_to_X_y2(X_val_1, y_val, 3)\n",
    "X_test_1, test_3w = df_to_X_y2(X_test_1,y_test, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c1245d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 12ms/step - loss: 0.7063 - binary_accuracy: 0.4888 - val_loss: 0.6956 - val_binary_accuracy: 0.5683\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6920 - binary_accuracy: 0.5355 - val_loss: 0.6938 - val_binary_accuracy: 0.5612\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6859 - binary_accuracy: 0.5436 - val_loss: 0.6935 - val_binary_accuracy: 0.5396\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6805 - binary_accuracy: 0.5619 - val_loss: 0.6937 - val_binary_accuracy: 0.5108\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6761 - binary_accuracy: 0.5842 - val_loss: 0.6954 - val_binary_accuracy: 0.5180\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6724 - binary_accuracy: 0.6146 - val_loss: 0.6963 - val_binary_accuracy: 0.5180\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6683 - binary_accuracy: 0.6166 - val_loss: 0.6977 - val_binary_accuracy: 0.5396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15204efa0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_1.shape[1]\n",
    "n_features = X_train_1.shape[2]\n",
    "\n",
    "model6_1 = Sequential()\n",
    "model6_1.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model6_1.add(Flatten())\n",
    "model6_1.add(Dense(25, activation='relu')) \n",
    "model6_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model6_1.compile(optimizer='RMSProp', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model6_1.fit(X_train_1, train_3w,epochs=30,  validation_data=(X_val_1, val_3w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05707607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 14ms/step - loss: 0.6981 - binary_accuracy: 0.4767 - val_loss: 0.6951 - val_binary_accuracy: 0.4748\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6892 - binary_accuracy: 0.5619 - val_loss: 0.6950 - val_binary_accuracy: 0.5108\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6845 - binary_accuracy: 0.5963 - val_loss: 0.6944 - val_binary_accuracy: 0.5036\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6799 - binary_accuracy: 0.6146 - val_loss: 0.6953 - val_binary_accuracy: 0.5108\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6750 - binary_accuracy: 0.6450 - val_loss: 0.6951 - val_binary_accuracy: 0.4820\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6696 - binary_accuracy: 0.6673 - val_loss: 0.6953 - val_binary_accuracy: 0.5108\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6642 - binary_accuracy: 0.6714 - val_loss: 0.6939 - val_binary_accuracy: 0.4892\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6567 - binary_accuracy: 0.6856 - val_loss: 0.6916 - val_binary_accuracy: 0.5252\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6499 - binary_accuracy: 0.6856 - val_loss: 0.6933 - val_binary_accuracy: 0.5180\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6403 - binary_accuracy: 0.6937 - val_loss: 0.6899 - val_binary_accuracy: 0.5468\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6296 - binary_accuracy: 0.7120 - val_loss: 0.6936 - val_binary_accuracy: 0.5468\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6166 - binary_accuracy: 0.7241 - val_loss: 0.6911 - val_binary_accuracy: 0.5396\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6034 - binary_accuracy: 0.7383 - val_loss: 0.6891 - val_binary_accuracy: 0.5468\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5868 - binary_accuracy: 0.7323 - val_loss: 0.6993 - val_binary_accuracy: 0.5396\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5688 - binary_accuracy: 0.7525 - val_loss: 0.7022 - val_binary_accuracy: 0.5324\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5482 - binary_accuracy: 0.7627 - val_loss: 0.7087 - val_binary_accuracy: 0.5396\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5296 - binary_accuracy: 0.7789 - val_loss: 0.7250 - val_binary_accuracy: 0.5108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x152875e50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6_2 = Sequential()\n",
    "model6_2.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model6_2.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
    "model6_2.add(MaxPooling1D(pool_size=1)) #has to be one, I'm guessing becuase of decrease in window size\n",
    "# better without pooling layer\n",
    "model6_2.add(Flatten())\n",
    "model6_2.add(Dense(30, activation='relu')) \n",
    "model6_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model6_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model6_2.fit(X_train_1, train_3w,epochs=30,  validation_data=(X_val_1, val_3w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bced0840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "#Model7 Starting to Adjust Window Size\n",
    "feats, comp = kbest_creator(40)\n",
    "\n",
    "sklearn_pca = PCA(n_components=comp)\n",
    "X_train_1 = pd.DataFrame(sklearn_pca.fit_transform(X_train[feats]))\n",
    "X_val_1 = pd.DataFrame(sklearn_pca.transform(X_val[feats]))\n",
    "X_test_1 = pd.DataFrame(sklearn_pca.transform(X_test[feats]))\n",
    "\n",
    "# converting to window format, in this case 7 periods\n",
    "X_train_1, train_7w = df_to_X_y2(X_train_1,y_train,7)\n",
    "X_val_1, val_7w = df_to_X_y2(X_val_1, y_val, 7)\n",
    "X_test_1, test_7w = df_to_X_y2(X_test_1,y_test, 7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "398cb8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 16ms/step - loss: 0.7014 - binary_accuracy: 0.4847 - val_loss: 0.7001 - val_binary_accuracy: 0.5111\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6826 - binary_accuracy: 0.5685 - val_loss: 0.6992 - val_binary_accuracy: 0.5111\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6709 - binary_accuracy: 0.5971 - val_loss: 0.7004 - val_binary_accuracy: 0.5185\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6632 - binary_accuracy: 0.6176 - val_loss: 0.6964 - val_binary_accuracy: 0.4741\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6524 - binary_accuracy: 0.6585 - val_loss: 0.7001 - val_binary_accuracy: 0.4667\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6435 - binary_accuracy: 0.6503 - val_loss: 0.6963 - val_binary_accuracy: 0.4593\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6329 - binary_accuracy: 0.6892 - val_loss: 0.6978 - val_binary_accuracy: 0.4667\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6231 - binary_accuracy: 0.7035 - val_loss: 0.6980 - val_binary_accuracy: 0.4815\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6112 - binary_accuracy: 0.7280 - val_loss: 0.7008 - val_binary_accuracy: 0.4889\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6009 - binary_accuracy: 0.7239 - val_loss: 0.7014 - val_binary_accuracy: 0.4741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x152a297c0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_1.shape[1]\n",
    "n_features = X_train_1.shape[2]\n",
    "\n",
    "model7_1 = Sequential()\n",
    "model7_1.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model7_1.add(Flatten())\n",
    "model7_1.add(Dense(25, activation='relu')) \n",
    "model7_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model7_1.compile(optimizer='RMSProp', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model7_1.fit(X_train_1, train_7w,epochs=30,  validation_data=(X_val_1, val_7w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9332cbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 14ms/step - loss: 0.6981 - binary_accuracy: 0.4806 - val_loss: 0.6957 - val_binary_accuracy: 0.5185\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6804 - binary_accuracy: 0.5542 - val_loss: 0.6956 - val_binary_accuracy: 0.5407\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6698 - binary_accuracy: 0.6217 - val_loss: 0.6940 - val_binary_accuracy: 0.4889\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6585 - binary_accuracy: 0.6524 - val_loss: 0.6931 - val_binary_accuracy: 0.5037\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6468 - binary_accuracy: 0.6810 - val_loss: 0.6952 - val_binary_accuracy: 0.4667\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6331 - binary_accuracy: 0.7055 - val_loss: 0.6948 - val_binary_accuracy: 0.4741\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6171 - binary_accuracy: 0.7260 - val_loss: 0.7003 - val_binary_accuracy: 0.4741\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5984 - binary_accuracy: 0.7219 - val_loss: 0.7142 - val_binary_accuracy: 0.4667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x152ba4d00>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7_2 = Sequential()\n",
    "model7_2.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model7_2.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
    "model7_2.add(MaxPooling1D(pool_size=1)) #has to be one, I'm guessing becuase of decrease in window size\n",
    "# better without pooling layer\n",
    "model7_2.add(Flatten())\n",
    "model7_2.add(Dense(30, activation='relu')) \n",
    "model7_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model7_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model7_2.fit(X_train_1, train_7w,epochs=30,  validation_data=(X_val_1, val_7w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26132306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "#Model8 Starting to Adjust Window Size\n",
    "feats, comp = kbest_creator(40)\n",
    "\n",
    "sklearn_pca = PCA(n_components=comp)\n",
    "X_train_1 = pd.DataFrame(sklearn_pca.fit_transform(X_train[feats]))\n",
    "X_val_1 = pd.DataFrame(sklearn_pca.transform(X_val[feats]))\n",
    "X_test_1 = pd.DataFrame(sklearn_pca.transform(X_test[feats]))\n",
    "\n",
    "# converting to window format, in this case 14 periods\n",
    "X_train_1, train_14w = df_to_X_y2(X_train_1,y_train,14)\n",
    "X_val_1, val_14w = df_to_X_y2(X_val_1, y_val, 14)\n",
    "X_test_1, test_14w = df_to_X_y2(X_test_1,y_test, 14) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee0fada0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 13ms/step - loss: 0.7032 - binary_accuracy: 0.5207 - val_loss: 0.6985 - val_binary_accuracy: 0.4531\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6699 - binary_accuracy: 0.6162 - val_loss: 0.7009 - val_binary_accuracy: 0.5391\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6506 - binary_accuracy: 0.6639 - val_loss: 0.7121 - val_binary_accuracy: 0.5156\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6372 - binary_accuracy: 0.6722 - val_loss: 0.7127 - val_binary_accuracy: 0.4531\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6208 - binary_accuracy: 0.7324 - val_loss: 0.7009 - val_binary_accuracy: 0.5469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x152d1db50>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_1.shape[1]\n",
    "n_features = X_train_1.shape[2]\n",
    "\n",
    "model8_1 = Sequential()\n",
    "model8_1.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model8_1.add(Flatten())\n",
    "model8_1.add(Dense(25, activation='relu')) \n",
    "model8_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model8_1.compile(optimizer='RMSProp', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model8_1.fit(X_train_1, train_14w,epochs=30,  validation_data=(X_val_1, val_14w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1312eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 14ms/step - loss: 0.7008 - binary_accuracy: 0.4979 - val_loss: 0.7131 - val_binary_accuracy: 0.5078\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6714 - binary_accuracy: 0.6266 - val_loss: 0.7125 - val_binary_accuracy: 0.4062\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6570 - binary_accuracy: 0.6805 - val_loss: 0.7161 - val_binary_accuracy: 0.4141\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6423 - binary_accuracy: 0.6784 - val_loss: 0.7209 - val_binary_accuracy: 0.4219\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6204 - binary_accuracy: 0.6909 - val_loss: 0.7233 - val_binary_accuracy: 0.3750\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6069 - binary_accuracy: 0.7220 - val_loss: 0.7257 - val_binary_accuracy: 0.4062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x152d06f10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8_2 = Sequential()\n",
    "model8_2.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model8_2.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
    "model8_2.add(MaxPooling1D(pool_size=1)) #has to be one, I'm guessing becuase of decrease in window size\n",
    "# better without pooling layer\n",
    "model8_2.add(Flatten())\n",
    "model8_2.add(Dense(30, activation='relu')) \n",
    "model8_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model8_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model8_2.fit(X_train_1, train_14w,epochs=30,  validation_data=(X_val_1, val_14w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c511df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "#Model9 Early RNN\n",
    "feats, comp = kbest_creator(40)\n",
    "\n",
    "sklearn_pca = PCA(n_components=comp)\n",
    "X_train_1 = pd.DataFrame(sklearn_pca.fit_transform(X_train[feats]))\n",
    "X_val_1 = pd.DataFrame(sklearn_pca.transform(X_val[feats]))\n",
    "X_test_1 = pd.DataFrame(sklearn_pca.transform(X_test[feats]))\n",
    "\n",
    "# converting to window format, in this case 14 periods\n",
    "X_train_1, train_5w = df_to_X_y2(X_train_1,y_train,5)\n",
    "X_val_1, val_5w = df_to_X_y2(X_val_1, y_val, 5)\n",
    "X_test_1, test_5w = df_to_X_y2(X_test_1,y_test, 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a5d502d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 19ms/step - loss: 0.7014 - binary_accuracy: 0.4847 - val_loss: 0.6984 - val_binary_accuracy: 0.4672\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6963 - binary_accuracy: 0.5153 - val_loss: 0.6961 - val_binary_accuracy: 0.4964\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6938 - binary_accuracy: 0.5295 - val_loss: 0.6943 - val_binary_accuracy: 0.5109\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6915 - binary_accuracy: 0.5418 - val_loss: 0.6925 - val_binary_accuracy: 0.5036\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6894 - binary_accuracy: 0.5438 - val_loss: 0.6917 - val_binary_accuracy: 0.4964\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6875 - binary_accuracy: 0.5418 - val_loss: 0.6902 - val_binary_accuracy: 0.4891\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6857 - binary_accuracy: 0.5458 - val_loss: 0.6898 - val_binary_accuracy: 0.4891\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6841 - binary_accuracy: 0.5458 - val_loss: 0.6891 - val_binary_accuracy: 0.5036\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6824 - binary_accuracy: 0.5662 - val_loss: 0.6889 - val_binary_accuracy: 0.4964\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6807 - binary_accuracy: 0.5682 - val_loss: 0.6880 - val_binary_accuracy: 0.4745\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6794 - binary_accuracy: 0.5601 - val_loss: 0.6876 - val_binary_accuracy: 0.4818\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6776 - binary_accuracy: 0.5743 - val_loss: 0.6875 - val_binary_accuracy: 0.4964\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6759 - binary_accuracy: 0.5784 - val_loss: 0.6871 - val_binary_accuracy: 0.5109\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6743 - binary_accuracy: 0.5743 - val_loss: 0.6871 - val_binary_accuracy: 0.5109\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6727 - binary_accuracy: 0.5845 - val_loss: 0.6863 - val_binary_accuracy: 0.5036\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6713 - binary_accuracy: 0.5825 - val_loss: 0.6862 - val_binary_accuracy: 0.5255\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6696 - binary_accuracy: 0.5886 - val_loss: 0.6873 - val_binary_accuracy: 0.5182\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6682 - binary_accuracy: 0.5886 - val_loss: 0.6873 - val_binary_accuracy: 0.5328\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6666 - binary_accuracy: 0.5906 - val_loss: 0.6878 - val_binary_accuracy: 0.5328\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6652 - binary_accuracy: 0.5927 - val_loss: 0.6877 - val_binary_accuracy: 0.5255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1530774c0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_1.shape[1]\n",
    "n_features = X_train_1.shape[2]\n",
    "\n",
    "model_9 = Sequential()\n",
    "model_9.add(SimpleRNN(8,activation=\"relu\", return_sequences=False, input_shape=(n_steps,n_features)))\n",
    "model_9.add(Dense(30, activation='relu')) \n",
    "model_9.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_9.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model_9.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8f7cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
