{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9a1ccf7",
   "metadata": {},
   "source": [
    "# CNN Ford Hyperparemter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c680638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense, Normalization\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, InputLayer, SimpleRNN\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn import (\n",
    "    linear_model, metrics, neural_network, pipeline, model_selection\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3072e520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ford</th>\n",
       "      <th>F-150</th>\n",
       "      <th>Ford Bronco_x</th>\n",
       "      <th>Ford Mustang_x</th>\n",
       "      <th>Ford Stock</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>...</th>\n",
       "      <th>Dow_MAvg_s_Move</th>\n",
       "      <th>Dow_EMA_Move</th>\n",
       "      <th>Dow_Disparity_Move</th>\n",
       "      <th>Dow_Disparity_s_Move</th>\n",
       "      <th>Dow_RSI_Move</th>\n",
       "      <th>target_1</th>\n",
       "      <th>target_2</th>\n",
       "      <th>target_3</th>\n",
       "      <th>target_4</th>\n",
       "      <th>target_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ford  F-150  Ford Bronco_x  Ford Mustang_x  Ford Stock  Open  High  Low  \\\n",
       "0     0      0              0               0           0     6     6    6   \n",
       "\n",
       "   Close  Volume  ...  Dow_MAvg_s_Move  Dow_EMA_Move  Dow_Disparity_Move  \\\n",
       "0      6       6  ...                0             0                   0   \n",
       "\n",
       "   Dow_Disparity_s_Move  Dow_RSI_Move  target_1  target_2  target_3  target_4  \\\n",
       "0                     0             0         0         0         0         0   \n",
       "\n",
       "   target_5  \n",
       "0         0  \n",
       "\n",
       "[1 rows x 169 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ford = pd.read_csv(\"Ford_Cleaned_Date.csv\")\n",
    "Ford.date = pd.to_datetime(Ford.date)\n",
    "Ford = Ford.set_index(\"date\")\n",
    "Ford = Ford.iloc[14:, :] # to remove first 14 days that include NaNs due to some calculations\n",
    "pd.DataFrame(Ford.isna().sum()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c763aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ford = Ford.dropna()\n",
    "Ford = Ford[~(Ford.isin([np.inf, -np.inf]).any(axis=1))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c174a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ford = Ford.drop(['target_1', 'target_2', 'target_4', 'target_5'], axis=1)\n",
    "target_3 = Ford[\"target_3\"]\n",
    "\n",
    "#splitting into training sets \n",
    "column_indices = {name: i for i, name in enumerate(Ford.columns)}\n",
    "\n",
    "n = len(Ford)\n",
    "X_train = Ford[0:int(n*0.7)]\n",
    "X_val = Ford[int(n*0.7):int(n*0.9)]\n",
    "X_test = Ford[int(n*0.9):]\n",
    "\n",
    "y_train = target_3[0:int(n*0.7)]\n",
    "y_val = target_3[int(n*0.7):int(n*0.9)]\n",
    "y_test = target_3[int(n*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "234b2987",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mscaler = MinMaxScaler() # keeps binarys at zero and 1 :)\n",
    "\n",
    "X_train = pd.DataFrame(Mscaler.fit_transform(X_train), columns = Ford.columns)\n",
    "X_val = pd.DataFrame(Mscaler.fit_transform(X_val), columns = Ford.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d950dc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_X_y2(df, target, window_size=5):\n",
    "  df_as_np = df.to_numpy() # converts to matrix of numpy arrays\n",
    "  X = []\n",
    "  y = []\n",
    "  for i in range(len(df_as_np)-window_size): # length of data frame - window_size so it does't take empty values at the end, \n",
    "    # does force you to loose the last 5 values, could fix with padding\n",
    "    row = [r for r in df_as_np[i:i+window_size]] # grabs row i and all rows above within the window size length\n",
    "    X.append(row) # creates 3 dimentional array, (# obseravtions, # rows in window, # features)\n",
    "    label = target[i+window_size] # pulls the target variable after the window, target varible needs to be column zero in this \n",
    "    y.append(label) # returns (N,) martix of targets i+window_length time periods away\n",
    "  return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b87523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kbest_creator(k):\n",
    "    \"\"\"\n",
    "    returns list of k best features and the number of efficient principle compents to use with said k features\n",
    "    \"\"\"\n",
    "    # apply SelectKBest class to extract top 40 best features\n",
    "    bestfeatures = SelectKBest(score_func=f_regression, k=k)\n",
    "    best_fit = bestfeatures.fit(X_train, y_train)\n",
    "    best_scores = pd.DataFrame(best_fit.scores_)\n",
    "    best_columns = pd.DataFrame(Ford.columns)\n",
    "    \n",
    "    # concatenate the dataframes for better visualization\n",
    "    features_score = pd.concat([best_columns, best_scores], axis=1)\n",
    "    features_score.columns = ['Features', 'Score']  # naming the dataframe columns\n",
    "    feats = list(features_score.nlargest(k, 'Score')['Features'])\n",
    "\n",
    "    pca = PCA().fit(X_train[feats])\n",
    "    pca_scores = np.cumsum(pca.explained_variance_ratio_) * 100\n",
    "    res = next(x for x, val in enumerate(pca_scores) if val > 85)\n",
    "    res = res +1\n",
    "    res\n",
    "    \n",
    "    return feats, res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8f1bab",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb32886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b532ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "# Model1\n",
    "\n",
    "feats, comp = kbest_creator(5)\n",
    "\n",
    "sklearn_pca = PCA(n_components=comp)\n",
    "X_train_1 = pd.DataFrame(sklearn_pca.fit_transform(X_train[feats]))\n",
    "X_val_1 = pd.DataFrame(sklearn_pca.transform(X_val[feats]))\n",
    "X_test_1 = pd.DataFrame(sklearn_pca.transform(X_test[feats]))\n",
    "\n",
    "# converting to window format, in this case 5 periods\n",
    "X_train_1, train_5w = df_to_X_y2(X_train_1,y_train)\n",
    "X_val_1, val_5w = df_to_X_y2(X_val_1, y_val)\n",
    "X_test_1, test_5w = df_to_X_y2(X_test_1,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db90ed2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-13 14:07:23.123134: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 42ms/step - loss: 0.6941 - binary_accuracy: 0.4969 - val_loss: 0.6877 - val_binary_accuracy: 0.5547\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6845 - binary_accuracy: 0.5703 - val_loss: 0.6875 - val_binary_accuracy: 0.5620\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6812 - binary_accuracy: 0.5642 - val_loss: 0.6862 - val_binary_accuracy: 0.5328\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6782 - binary_accuracy: 0.5845 - val_loss: 0.6850 - val_binary_accuracy: 0.5474\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6746 - binary_accuracy: 0.5866 - val_loss: 0.6849 - val_binary_accuracy: 0.5620\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6729 - binary_accuracy: 0.6029 - val_loss: 0.6874 - val_binary_accuracy: 0.5328\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6697 - binary_accuracy: 0.5988 - val_loss: 0.6872 - val_binary_accuracy: 0.5547\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6667 - binary_accuracy: 0.5927 - val_loss: 0.6863 - val_binary_accuracy: 0.5474\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6638 - binary_accuracy: 0.6253 - val_loss: 0.6889 - val_binary_accuracy: 0.5328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1550e0f10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_1.shape[1]\n",
    "n_features = X_train_1.shape[2]\n",
    "\n",
    "model1_1 = Sequential()\n",
    "model1_1.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model1_1.add(Flatten())\n",
    "model1_1.add(Dense(25, activation='relu')) \n",
    "model1_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1_1.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model1_1.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1adbad04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 2s 34ms/step - loss: 0.6933 - binary_accuracy: 0.5010 - val_loss: 0.6900 - val_binary_accuracy: 0.5328\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.6900 - binary_accuracy: 0.5479 - val_loss: 0.6877 - val_binary_accuracy: 0.5693\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6884 - binary_accuracy: 0.5540 - val_loss: 0.6862 - val_binary_accuracy: 0.5839\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6862 - binary_accuracy: 0.5601 - val_loss: 0.6858 - val_binary_accuracy: 0.5620\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6844 - binary_accuracy: 0.5519 - val_loss: 0.6867 - val_binary_accuracy: 0.5401\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.6813 - binary_accuracy: 0.5580 - val_loss: 0.6852 - val_binary_accuracy: 0.5474\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6786 - binary_accuracy: 0.5825 - val_loss: 0.6860 - val_binary_accuracy: 0.5328\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6754 - binary_accuracy: 0.5906 - val_loss: 0.6877 - val_binary_accuracy: 0.5182\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6721 - binary_accuracy: 0.6110 - val_loss: 0.6905 - val_binary_accuracy: 0.5109\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6675 - binary_accuracy: 0.6069 - val_loss: 0.6936 - val_binary_accuracy: 0.5109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x155942040>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_2 = Sequential()\n",
    "model1_2.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model1_2.add(Conv1D(filters=15, kernel_size=2, activation='relu'))\n",
    "# better without pooling layer\n",
    "model1_2.add(Flatten())\n",
    "model1_2.add(Dense(30, activation='relu')) \n",
    "model1_2.add(Dense(30, activation='relu')) \n",
    "model1_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model1_2.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9ad1069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "# Model2\n",
    "\n",
    "feats, comp = kbest_creator(10)\n",
    "\n",
    "sklearn_pca = PCA(n_components=comp)\n",
    "X_train_1 = pd.DataFrame(sklearn_pca.fit_transform(X_train[feats]))\n",
    "X_val_1 = pd.DataFrame(sklearn_pca.transform(X_val[feats]))\n",
    "X_test_1 = pd.DataFrame(sklearn_pca.transform(X_test[feats]))\n",
    "\n",
    "# converting to window format, in this case 5 periods\n",
    "X_train_1, train_5w = df_to_X_y2(X_train_1,y_train)\n",
    "X_val_1, val_5w = df_to_X_y2(X_val_1, y_val)\n",
    "X_test_1, test_5w = df_to_X_y2(X_test_1,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77b199fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 24ms/step - loss: 0.7002 - binary_accuracy: 0.4908 - val_loss: 0.6889 - val_binary_accuracy: 0.5036\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6998 - binary_accuracy: 0.4929 - val_loss: 0.6886 - val_binary_accuracy: 0.5036\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6994 - binary_accuracy: 0.4990 - val_loss: 0.6884 - val_binary_accuracy: 0.5182\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6990 - binary_accuracy: 0.4929 - val_loss: 0.6881 - val_binary_accuracy: 0.5182\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6987 - binary_accuracy: 0.4969 - val_loss: 0.6879 - val_binary_accuracy: 0.5255\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6983 - binary_accuracy: 0.5010 - val_loss: 0.6876 - val_binary_accuracy: 0.5328\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6980 - binary_accuracy: 0.5010 - val_loss: 0.6874 - val_binary_accuracy: 0.5328\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.6978 - binary_accuracy: 0.5051 - val_loss: 0.6873 - val_binary_accuracy: 0.5401\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6975 - binary_accuracy: 0.5031 - val_loss: 0.6871 - val_binary_accuracy: 0.5328\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6972 - binary_accuracy: 0.5031 - val_loss: 0.6869 - val_binary_accuracy: 0.5255\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6970 - binary_accuracy: 0.5051 - val_loss: 0.6868 - val_binary_accuracy: 0.5255\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6968 - binary_accuracy: 0.5071 - val_loss: 0.6867 - val_binary_accuracy: 0.5328\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6966 - binary_accuracy: 0.5071 - val_loss: 0.6865 - val_binary_accuracy: 0.5328\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6963 - binary_accuracy: 0.5112 - val_loss: 0.6863 - val_binary_accuracy: 0.5547\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6961 - binary_accuracy: 0.5092 - val_loss: 0.6862 - val_binary_accuracy: 0.5547\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6959 - binary_accuracy: 0.5112 - val_loss: 0.6861 - val_binary_accuracy: 0.5547\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6957 - binary_accuracy: 0.5173 - val_loss: 0.6860 - val_binary_accuracy: 0.5547\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6955 - binary_accuracy: 0.5193 - val_loss: 0.6859 - val_binary_accuracy: 0.5620\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6953 - binary_accuracy: 0.5234 - val_loss: 0.6858 - val_binary_accuracy: 0.5620\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6951 - binary_accuracy: 0.5275 - val_loss: 0.6858 - val_binary_accuracy: 0.5547\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6950 - binary_accuracy: 0.5275 - val_loss: 0.6857 - val_binary_accuracy: 0.5474\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6948 - binary_accuracy: 0.5255 - val_loss: 0.6856 - val_binary_accuracy: 0.5401\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6946 - binary_accuracy: 0.5234 - val_loss: 0.6855 - val_binary_accuracy: 0.5620\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6945 - binary_accuracy: 0.5173 - val_loss: 0.6855 - val_binary_accuracy: 0.5620\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6943 - binary_accuracy: 0.5193 - val_loss: 0.6854 - val_binary_accuracy: 0.5547\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6942 - binary_accuracy: 0.5153 - val_loss: 0.6854 - val_binary_accuracy: 0.5620\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6941 - binary_accuracy: 0.5092 - val_loss: 0.6853 - val_binary_accuracy: 0.5474\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6940 - binary_accuracy: 0.5051 - val_loss: 0.6853 - val_binary_accuracy: 0.5547\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6939 - binary_accuracy: 0.5051 - val_loss: 0.6853 - val_binary_accuracy: 0.5547\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6938 - binary_accuracy: 0.5071 - val_loss: 0.6852 - val_binary_accuracy: 0.5547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x155ad1e80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_1.shape[1]\n",
    "n_features = X_train_1.shape[2]\n",
    "\n",
    "model2_1 = Sequential()\n",
    "model2_1.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model2_1.add(Flatten())\n",
    "model2_1.add(Dense(25, activation='relu')) \n",
    "model2_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2_1.compile(optimizer='adagrad', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model2_1.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dec7b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 2s 14ms/step - loss: 0.6991 - binary_accuracy: 0.5132 - val_loss: 0.6913 - val_binary_accuracy: 0.4818\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6892 - binary_accuracy: 0.5560 - val_loss: 0.6906 - val_binary_accuracy: 0.4964\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6852 - binary_accuracy: 0.5601 - val_loss: 0.6879 - val_binary_accuracy: 0.5109\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6810 - binary_accuracy: 0.6008 - val_loss: 0.6868 - val_binary_accuracy: 0.5109\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6771 - binary_accuracy: 0.5967 - val_loss: 0.6864 - val_binary_accuracy: 0.5182\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6741 - binary_accuracy: 0.6151 - val_loss: 0.6860 - val_binary_accuracy: 0.5474\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6705 - binary_accuracy: 0.6354 - val_loss: 0.6868 - val_binary_accuracy: 0.5620\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6681 - binary_accuracy: 0.6069 - val_loss: 0.6873 - val_binary_accuracy: 0.5328\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6645 - binary_accuracy: 0.6436 - val_loss: 0.6877 - val_binary_accuracy: 0.5401\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6614 - binary_accuracy: 0.6477 - val_loss: 0.6884 - val_binary_accuracy: 0.5474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x155ba3580>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_2 = Sequential()\n",
    "model2_2.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model2_2.add(Flatten())\n",
    "model2_2.add(Dense(25, activation='relu')) \n",
    "model2_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2_2.compile(optimizer='RMSProp', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model2_2.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa1feb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 19ms/step - loss: 0.6933 - binary_accuracy: 0.4949 - val_loss: 0.6895 - val_binary_accuracy: 0.5547\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.6863 - binary_accuracy: 0.5601 - val_loss: 0.6909 - val_binary_accuracy: 0.5328\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6831 - binary_accuracy: 0.5703 - val_loss: 0.6922 - val_binary_accuracy: 0.4964\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6803 - binary_accuracy: 0.5886 - val_loss: 0.6928 - val_binary_accuracy: 0.4745\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6789 - binary_accuracy: 0.6069 - val_loss: 0.6930 - val_binary_accuracy: 0.5109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x155929ee0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_3 = Sequential()\n",
    "model2_3.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model2_3.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
    "model2_3.add(MaxPooling1D(pool_size=2)) \n",
    "# better without pooling layer\n",
    "model2_3.add(Flatten())\n",
    "model2_3.add(Dense(30, activation='relu')) \n",
    "model2_3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2_3.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model2_3.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "368645cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 20ms/step - loss: 0.6928 - binary_accuracy: 0.5010 - val_loss: 0.6917 - val_binary_accuracy: 0.4964\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6880 - binary_accuracy: 0.5336 - val_loss: 0.6908 - val_binary_accuracy: 0.4891\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.6857 - binary_accuracy: 0.5479 - val_loss: 0.6911 - val_binary_accuracy: 0.4964\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6828 - binary_accuracy: 0.5804 - val_loss: 0.6936 - val_binary_accuracy: 0.4891\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6802 - binary_accuracy: 0.5845 - val_loss: 0.6929 - val_binary_accuracy: 0.4891\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6778 - binary_accuracy: 0.5764 - val_loss: 0.6956 - val_binary_accuracy: 0.4818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x155efb0d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_4 = Sequential()\n",
    "model2_4.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model2_4.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model2_4.add(MaxPooling1D(pool_size=2)) \n",
    "model2_4.add(Conv1D(filters=32, kernel_size=1, activation='relu')) \n",
    "model2_4.add(Flatten())\n",
    "model2_4.add(Flatten())\n",
    "model2_4.add(Dense(25, activation='relu')) \n",
    "model2_4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2_4.compile(optimizer='RMSProp', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model2_4.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ffbbfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "# Model3\n",
    "\n",
    "feats, comp = kbest_creator(25)\n",
    "\n",
    "sklearn_pca = PCA(n_components=comp)\n",
    "X_train_1 = pd.DataFrame(sklearn_pca.fit_transform(X_train[feats]))\n",
    "X_val_1 = pd.DataFrame(sklearn_pca.transform(X_val[feats]))\n",
    "X_test_1 = pd.DataFrame(sklearn_pca.transform(X_test[feats]))\n",
    "\n",
    "# converting to window format, in this case 5 periods\n",
    "X_train_1, train_5w = df_to_X_y2(X_train_1,y_train)\n",
    "X_val_1, val_5w = df_to_X_y2(X_val_1, y_val)\n",
    "X_test_1, test_5w = df_to_X_y2(X_test_1,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d66c72ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 27ms/step - loss: 0.6967 - binary_accuracy: 0.4908 - val_loss: 0.6897 - val_binary_accuracy: 0.4964\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6851 - binary_accuracy: 0.5662 - val_loss: 0.6902 - val_binary_accuracy: 0.5328\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6791 - binary_accuracy: 0.5845 - val_loss: 0.6912 - val_binary_accuracy: 0.5036\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6738 - binary_accuracy: 0.6029 - val_loss: 0.6924 - val_binary_accuracy: 0.4964\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6680 - binary_accuracy: 0.6375 - val_loss: 0.6947 - val_binary_accuracy: 0.5036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x156110820>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_1.shape[1]\n",
    "n_features = X_train_1.shape[2]\n",
    "\n",
    "model3_1 = Sequential()\n",
    "model3_1.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model3_1.add(Flatten())\n",
    "model3_1.add(Dense(25, activation='relu')) \n",
    "model3_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3_1.compile(optimizer='RMSProp', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model3_1.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c67da6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 19ms/step - loss: 0.6972 - binary_accuracy: 0.4664 - val_loss: 0.6909 - val_binary_accuracy: 0.5255\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6901 - binary_accuracy: 0.5092 - val_loss: 0.6917 - val_binary_accuracy: 0.4964\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6853 - binary_accuracy: 0.5316 - val_loss: 0.6917 - val_binary_accuracy: 0.5255\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6808 - binary_accuracy: 0.5540 - val_loss: 0.6946 - val_binary_accuracy: 0.5036\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6759 - binary_accuracy: 0.5886 - val_loss: 0.6942 - val_binary_accuracy: 0.5255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1562a8880>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3_2 = Sequential()\n",
    "model3_2.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model3_2.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
    "model3_2.add(MaxPooling1D(pool_size=2)) \n",
    "# better without pooling layer\n",
    "model3_2.add(Flatten())\n",
    "model3_2.add(Dense(30, activation='relu')) \n",
    "model3_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model3_2.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "723ca40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "# Model4\n",
    "\n",
    "feats, comp = kbest_creator(50)\n",
    "\n",
    "sklearn_pca = PCA(n_components=comp)\n",
    "X_train_1 = pd.DataFrame(sklearn_pca.fit_transform(X_train[feats]))\n",
    "X_val_1 = pd.DataFrame(sklearn_pca.transform(X_val[feats]))\n",
    "X_test_1 = pd.DataFrame(sklearn_pca.transform(X_test[feats]))\n",
    "\n",
    "# converting to window format, in this case 5 periods\n",
    "X_train_1, train_5w = df_to_X_y2(X_train_1,y_train)\n",
    "X_val_1, val_5w = df_to_X_y2(X_val_1, y_val)\n",
    "X_test_1, test_5w = df_to_X_y2(X_test_1,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef3e4e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 14ms/step - loss: 0.6977 - binary_accuracy: 0.5010 - val_loss: 0.6888 - val_binary_accuracy: 0.4964\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6780 - binary_accuracy: 0.5743 - val_loss: 0.6870 - val_binary_accuracy: 0.5036\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6669 - binary_accuracy: 0.6171 - val_loss: 0.6859 - val_binary_accuracy: 0.5036\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6575 - binary_accuracy: 0.6538 - val_loss: 0.6851 - val_binary_accuracy: 0.5182\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6481 - binary_accuracy: 0.6599 - val_loss: 0.6835 - val_binary_accuracy: 0.5620\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6388 - binary_accuracy: 0.6741 - val_loss: 0.6832 - val_binary_accuracy: 0.5693\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.6290 - binary_accuracy: 0.6884 - val_loss: 0.6847 - val_binary_accuracy: 0.5620\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6187 - binary_accuracy: 0.7189 - val_loss: 0.6853 - val_binary_accuracy: 0.5620\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6095 - binary_accuracy: 0.7230 - val_loss: 0.6859 - val_binary_accuracy: 0.5766\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5987 - binary_accuracy: 0.7373 - val_loss: 0.6846 - val_binary_accuracy: 0.5693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15643ff40>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_1.shape[1]\n",
    "n_features = X_train_1.shape[2]\n",
    "\n",
    "model4_1 = Sequential()\n",
    "model4_1.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model4_1.add(Flatten())\n",
    "model4_1.add(Dense(25, activation='relu')) \n",
    "model4_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model4_1.compile(optimizer='RMSProp', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model4_1.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a916bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 2s 16ms/step - loss: 0.6991 - binary_accuracy: 0.5092 - val_loss: 0.6965 - val_binary_accuracy: 0.5328\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6872 - binary_accuracy: 0.5438 - val_loss: 0.6958 - val_binary_accuracy: 0.4672\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6793 - binary_accuracy: 0.5967 - val_loss: 0.6968 - val_binary_accuracy: 0.4453\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6722 - binary_accuracy: 0.6110 - val_loss: 0.6989 - val_binary_accuracy: 0.4526\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6650 - binary_accuracy: 0.6151 - val_loss: 0.7013 - val_binary_accuracy: 0.4818\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6567 - binary_accuracy: 0.6477 - val_loss: 0.7024 - val_binary_accuracy: 0.4745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1565dfe50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_2 = Sequential()\n",
    "model4_2.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model4_2.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
    "model4_2.add(MaxPooling1D(pool_size=2)) \n",
    "# better without pooling layer\n",
    "model4_2.add(Flatten())\n",
    "model4_2.add(Dense(30, activation='relu')) \n",
    "model4_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model4_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model4_2.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86f2643b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "# Model5\n",
    "\n",
    "feats, comp = kbest_creator(100)\n",
    "\n",
    "sklearn_pca = PCA(n_components=comp)\n",
    "X_train_1 = pd.DataFrame(sklearn_pca.fit_transform(X_train[feats]))\n",
    "X_val_1 = pd.DataFrame(sklearn_pca.transform(X_val[feats]))\n",
    "X_test_1 = pd.DataFrame(sklearn_pca.transform(X_test[feats]))\n",
    "\n",
    "# converting to window format, in this case 5 periods\n",
    "X_train_1, train_5w = df_to_X_y2(X_train_1,y_train)\n",
    "X_val_1, val_5w = df_to_X_y2(X_val_1, y_val)\n",
    "X_test_1, test_5w = df_to_X_y2(X_test_1,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acd90c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 14ms/step - loss: 0.7258 - binary_accuracy: 0.4888 - val_loss: 0.7220 - val_binary_accuracy: 0.4599\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6896 - binary_accuracy: 0.5397 - val_loss: 0.7225 - val_binary_accuracy: 0.4672\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6751 - binary_accuracy: 0.5967 - val_loss: 0.7166 - val_binary_accuracy: 0.4307\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6600 - binary_accuracy: 0.6130 - val_loss: 0.7245 - val_binary_accuracy: 0.4453\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6475 - binary_accuracy: 0.6477 - val_loss: 0.7204 - val_binary_accuracy: 0.4234\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6343 - binary_accuracy: 0.6843 - val_loss: 0.7195 - val_binary_accuracy: 0.4526\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6225 - binary_accuracy: 0.7149 - val_loss: 0.7225 - val_binary_accuracy: 0.4526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x156701af0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_1.shape[1]\n",
    "n_features = X_train_1.shape[2]\n",
    "\n",
    "model5_1 = Sequential()\n",
    "model5_1.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model5_1.add(Flatten())\n",
    "model5_1.add(Dense(25, activation='relu')) \n",
    "model5_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model5_1.compile(optimizer='RMSProp', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model5_1.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "423afe89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 28ms/step - loss: 0.7017 - binary_accuracy: 0.5275 - val_loss: 0.7063 - val_binary_accuracy: 0.4088\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6845 - binary_accuracy: 0.5662 - val_loss: 0.7029 - val_binary_accuracy: 0.4380\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6735 - binary_accuracy: 0.6293 - val_loss: 0.7034 - val_binary_accuracy: 0.4672\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6633 - binary_accuracy: 0.6395 - val_loss: 0.7054 - val_binary_accuracy: 0.4818\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6517 - binary_accuracy: 0.6599 - val_loss: 0.7079 - val_binary_accuracy: 0.4964\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6407 - binary_accuracy: 0.7006 - val_loss: 0.7098 - val_binary_accuracy: 0.4964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x156913bb0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5_2 = Sequential()\n",
    "model5_2.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model5_2.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
    "model5_2.add(MaxPooling1D(pool_size=2)) \n",
    "# better without pooling layer\n",
    "model5_2.add(Flatten())\n",
    "model5_2.add(Dense(30, activation='relu')) \n",
    "model5_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model5_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model5_2.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cf808aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 2s 27ms/step - loss: 0.6913 - binary_accuracy: 0.5234 - val_loss: 0.6881 - val_binary_accuracy: 0.5328\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6826 - binary_accuracy: 0.5886 - val_loss: 0.6890 - val_binary_accuracy: 0.5547\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6762 - binary_accuracy: 0.6232 - val_loss: 0.6886 - val_binary_accuracy: 0.5693\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6685 - binary_accuracy: 0.6599 - val_loss: 0.6885 - val_binary_accuracy: 0.5839\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.6596 - binary_accuracy: 0.6477 - val_loss: 0.6909 - val_binary_accuracy: 0.5766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15666b610>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5_3 = Sequential()\n",
    "model5_3.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model5_3.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
    "model5_3.add(MaxPooling1D(pool_size=2)) \n",
    "model5_3.add(Conv1D(filters=16, kernel_size=1, activation='relu'))\n",
    "# better without pooling layer\n",
    "model5_3.add(Flatten())\n",
    "model5_3.add(Dense(30, activation='relu')) \n",
    "model5_3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model5_3.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model5_3.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "784d96db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "#Model6 Starting to Adjust Window Size\n",
    "feats, comp = kbest_creator(40)\n",
    "\n",
    "sklearn_pca = PCA(n_components=comp)\n",
    "X_train_1 = pd.DataFrame(sklearn_pca.fit_transform(X_train[feats]))\n",
    "X_val_1 = pd.DataFrame(sklearn_pca.transform(X_val[feats]))\n",
    "X_test_1 = pd.DataFrame(sklearn_pca.transform(X_test[feats]))\n",
    "\n",
    "# converting to window format, in this case 3 periods\n",
    "X_train_1, train_3w = df_to_X_y2(X_train_1,y_train,3)\n",
    "X_val_1, val_3w = df_to_X_y2(X_val_1, y_val, 3)\n",
    "X_test_1, test_3w = df_to_X_y2(X_test_1,y_test, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c1245d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 14ms/step - loss: 0.7146 - binary_accuracy: 0.4929 - val_loss: 0.6964 - val_binary_accuracy: 0.5612\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6935 - binary_accuracy: 0.5213 - val_loss: 0.6956 - val_binary_accuracy: 0.5540\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6855 - binary_accuracy: 0.5416 - val_loss: 0.6953 - val_binary_accuracy: 0.5180\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6793 - binary_accuracy: 0.5659 - val_loss: 0.6949 - val_binary_accuracy: 0.5324\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6737 - binary_accuracy: 0.5903 - val_loss: 0.6941 - val_binary_accuracy: 0.5683\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6689 - binary_accuracy: 0.6065 - val_loss: 0.6938 - val_binary_accuracy: 0.5612\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6635 - binary_accuracy: 0.6166 - val_loss: 0.6949 - val_binary_accuracy: 0.5683\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6580 - binary_accuracy: 0.6349 - val_loss: 0.6953 - val_binary_accuracy: 0.5396\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6534 - binary_accuracy: 0.6450 - val_loss: 0.6943 - val_binary_accuracy: 0.5468\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6488 - binary_accuracy: 0.6633 - val_loss: 0.6954 - val_binary_accuracy: 0.5252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15670d100>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_1.shape[1]\n",
    "n_features = X_train_1.shape[2]\n",
    "\n",
    "model6_1 = Sequential()\n",
    "model6_1.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model6_1.add(Flatten())\n",
    "model6_1.add(Dense(25, activation='relu')) \n",
    "model6_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model6_1.compile(optimizer='RMSProp', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model6_1.fit(X_train_1, train_3w,epochs=30,  validation_data=(X_val_1, val_3w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05707607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 22ms/step - loss: 0.7033 - binary_accuracy: 0.4828 - val_loss: 0.6933 - val_binary_accuracy: 0.5540\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6919 - binary_accuracy: 0.5436 - val_loss: 0.6912 - val_binary_accuracy: 0.5683\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6846 - binary_accuracy: 0.5740 - val_loss: 0.6898 - val_binary_accuracy: 0.5612\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6786 - binary_accuracy: 0.5943 - val_loss: 0.6889 - val_binary_accuracy: 0.5468\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6730 - binary_accuracy: 0.6166 - val_loss: 0.6884 - val_binary_accuracy: 0.5612\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6665 - binary_accuracy: 0.6450 - val_loss: 0.6879 - val_binary_accuracy: 0.5683\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6600 - binary_accuracy: 0.6592 - val_loss: 0.6863 - val_binary_accuracy: 0.5683\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.6517 - binary_accuracy: 0.6775 - val_loss: 0.6877 - val_binary_accuracy: 0.5396\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6430 - binary_accuracy: 0.6897 - val_loss: 0.6854 - val_binary_accuracy: 0.5180\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6335 - binary_accuracy: 0.6815 - val_loss: 0.6859 - val_binary_accuracy: 0.5180\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6209 - binary_accuracy: 0.7099 - val_loss: 0.6891 - val_binary_accuracy: 0.4964\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6083 - binary_accuracy: 0.7120 - val_loss: 0.6921 - val_binary_accuracy: 0.4748\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5906 - binary_accuracy: 0.7404 - val_loss: 0.6947 - val_binary_accuracy: 0.4892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x156db5c40>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6_2 = Sequential()\n",
    "model6_2.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model6_2.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
    "model6_2.add(MaxPooling1D(pool_size=1)) #has to be one, I'm guessing becuase of decrease in window size\n",
    "# better without pooling layer\n",
    "model6_2.add(Flatten())\n",
    "model6_2.add(Dense(30, activation='relu')) \n",
    "model6_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model6_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model6_2.fit(X_train_1, train_3w,epochs=30,  validation_data=(X_val_1, val_3w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bced0840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "#Model7 Starting to Adjust Window Size\n",
    "feats, comp = kbest_creator(40)\n",
    "\n",
    "sklearn_pca = PCA(n_components=comp)\n",
    "X_train_1 = pd.DataFrame(sklearn_pca.fit_transform(X_train[feats]))\n",
    "X_val_1 = pd.DataFrame(sklearn_pca.transform(X_val[feats]))\n",
    "X_test_1 = pd.DataFrame(sklearn_pca.transform(X_test[feats]))\n",
    "\n",
    "# converting to window format, in this case 7 periods\n",
    "X_train_1, train_7w = df_to_X_y2(X_train_1,y_train,7)\n",
    "X_val_1, val_7w = df_to_X_y2(X_val_1, y_val, 7)\n",
    "X_test_1, test_7w = df_to_X_y2(X_test_1,y_test, 7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "398cb8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 17ms/step - loss: 0.6966 - binary_accuracy: 0.5072 - val_loss: 0.6913 - val_binary_accuracy: 0.4963\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6784 - binary_accuracy: 0.5726 - val_loss: 0.6897 - val_binary_accuracy: 0.4963\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6661 - binary_accuracy: 0.6135 - val_loss: 0.6886 - val_binary_accuracy: 0.5556\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6568 - binary_accuracy: 0.6135 - val_loss: 0.6870 - val_binary_accuracy: 0.5333\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.6474 - binary_accuracy: 0.6483 - val_loss: 0.6878 - val_binary_accuracy: 0.5333\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6391 - binary_accuracy: 0.6728 - val_loss: 0.6865 - val_binary_accuracy: 0.5259\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6272 - binary_accuracy: 0.6953 - val_loss: 0.6882 - val_binary_accuracy: 0.4889\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.6178 - binary_accuracy: 0.7280 - val_loss: 0.6875 - val_binary_accuracy: 0.5111\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6088 - binary_accuracy: 0.7117 - val_loss: 0.6868 - val_binary_accuracy: 0.5111\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5998 - binary_accuracy: 0.7464 - val_loss: 0.6899 - val_binary_accuracy: 0.5407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x156f61b80>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_1.shape[1]\n",
    "n_features = X_train_1.shape[2]\n",
    "\n",
    "model7_1 = Sequential()\n",
    "model7_1.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model7_1.add(Flatten())\n",
    "model7_1.add(Dense(25, activation='relu')) \n",
    "model7_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model7_1.compile(optimizer='RMSProp', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model7_1.fit(X_train_1, train_7w,epochs=30,  validation_data=(X_val_1, val_7w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9332cbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 25ms/step - loss: 0.7001 - binary_accuracy: 0.5072 - val_loss: 0.6919 - val_binary_accuracy: 0.5333\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6816 - binary_accuracy: 0.5971 - val_loss: 0.6923 - val_binary_accuracy: 0.5333\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6712 - binary_accuracy: 0.5971 - val_loss: 0.6916 - val_binary_accuracy: 0.5185\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6592 - binary_accuracy: 0.6074 - val_loss: 0.6867 - val_binary_accuracy: 0.5259\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6502 - binary_accuracy: 0.6728 - val_loss: 0.6860 - val_binary_accuracy: 0.5852\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6345 - binary_accuracy: 0.7117 - val_loss: 0.6828 - val_binary_accuracy: 0.5407\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6208 - binary_accuracy: 0.7137 - val_loss: 0.6826 - val_binary_accuracy: 0.5481\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6078 - binary_accuracy: 0.6994 - val_loss: 0.6865 - val_binary_accuracy: 0.5704\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5932 - binary_accuracy: 0.7280 - val_loss: 0.6865 - val_binary_accuracy: 0.5778\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5735 - binary_accuracy: 0.7117 - val_loss: 0.6920 - val_binary_accuracy: 0.5481\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5524 - binary_accuracy: 0.7689 - val_loss: 0.6899 - val_binary_accuracy: 0.5630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1570bffd0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7_2 = Sequential()\n",
    "model7_2.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model7_2.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
    "model7_2.add(MaxPooling1D(pool_size=1)) #has to be one, I'm guessing becuase of decrease in window size\n",
    "# better without pooling layer\n",
    "model7_2.add(Flatten())\n",
    "model7_2.add(Dense(30, activation='relu')) \n",
    "model7_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model7_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model7_2.fit(X_train_1, train_7w,epochs=30,  validation_data=(X_val_1, val_7w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26132306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "#Model8 Starting to Adjust Window Size\n",
    "feats, comp = kbest_creator(40)\n",
    "\n",
    "sklearn_pca = PCA(n_components=comp)\n",
    "X_train_1 = pd.DataFrame(sklearn_pca.fit_transform(X_train[feats]))\n",
    "X_val_1 = pd.DataFrame(sklearn_pca.transform(X_val[feats]))\n",
    "X_test_1 = pd.DataFrame(sklearn_pca.transform(X_test[feats]))\n",
    "\n",
    "# converting to window format, in this case 14 periods\n",
    "X_train_1, train_14w = df_to_X_y2(X_train_1,y_train,14)\n",
    "X_val_1, val_14w = df_to_X_y2(X_val_1, y_val, 14)\n",
    "X_test_1, test_14w = df_to_X_y2(X_test_1,y_test, 14) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee0fada0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 36ms/step - loss: 0.7046 - binary_accuracy: 0.4917 - val_loss: 0.6915 - val_binary_accuracy: 0.5625\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6626 - binary_accuracy: 0.6266 - val_loss: 0.6888 - val_binary_accuracy: 0.5703\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6449 - binary_accuracy: 0.6805 - val_loss: 0.6989 - val_binary_accuracy: 0.5234\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6241 - binary_accuracy: 0.7033 - val_loss: 0.7010 - val_binary_accuracy: 0.5469\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6075 - binary_accuracy: 0.7261 - val_loss: 0.7031 - val_binary_accuracy: 0.5156\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5891 - binary_accuracy: 0.7510 - val_loss: 0.7069 - val_binary_accuracy: 0.5547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1572dbf40>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_1.shape[1]\n",
    "n_features = X_train_1.shape[2]\n",
    "\n",
    "model8_1 = Sequential()\n",
    "model8_1.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model8_1.add(Flatten())\n",
    "model8_1.add(Dense(25, activation='relu')) \n",
    "model8_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model8_1.compile(optimizer='RMSProp', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model8_1.fit(X_train_1, train_14w,epochs=30,  validation_data=(X_val_1, val_14w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1312eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 30ms/step - loss: 0.6993 - binary_accuracy: 0.4813 - val_loss: 0.6975 - val_binary_accuracy: 0.4766\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6774 - binary_accuracy: 0.5685 - val_loss: 0.7028 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6635 - binary_accuracy: 0.6473 - val_loss: 0.6999 - val_binary_accuracy: 0.4844\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6464 - binary_accuracy: 0.7012 - val_loss: 0.7055 - val_binary_accuracy: 0.4375\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6262 - binary_accuracy: 0.7427 - val_loss: 0.7075 - val_binary_accuracy: 0.4766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1573f9f40>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8_2 = Sequential()\n",
    "model8_2.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model8_2.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
    "model8_2.add(MaxPooling1D(pool_size=1)) #has to be one, I'm guessing becuase of decrease in window size\n",
    "# better without pooling layer\n",
    "model8_2.add(Flatten())\n",
    "model8_2.add(Dense(30, activation='relu')) \n",
    "model8_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model8_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model8_2.fit(X_train_1, train_14w,epochs=30,  validation_data=(X_val_1, val_14w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c511df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "#Model9 Early RNN\n",
    "feats, comp = kbest_creator(40)\n",
    "\n",
    "sklearn_pca = PCA(n_components=comp)\n",
    "X_train_1 = pd.DataFrame(sklearn_pca.fit_transform(X_train[feats]))\n",
    "X_val_1 = pd.DataFrame(sklearn_pca.transform(X_val[feats]))\n",
    "X_test_1 = pd.DataFrame(sklearn_pca.transform(X_test[feats]))\n",
    "\n",
    "# converting to window format, in this case 14 periods\n",
    "X_train_1, train_5w = df_to_X_y2(X_train_1,y_train,5)\n",
    "X_val_1, val_5w = df_to_X_y2(X_val_1, y_val, 5)\n",
    "X_test_1, test_5w = df_to_X_y2(X_test_1,y_test, 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a5d502d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 21ms/step - loss: 0.6935 - binary_accuracy: 0.4929 - val_loss: 0.6820 - val_binary_accuracy: 0.5839\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6859 - binary_accuracy: 0.5336 - val_loss: 0.6812 - val_binary_accuracy: 0.5766\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6838 - binary_accuracy: 0.5621 - val_loss: 0.6810 - val_binary_accuracy: 0.5839\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6826 - binary_accuracy: 0.5560 - val_loss: 0.6816 - val_binary_accuracy: 0.5839\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6814 - binary_accuracy: 0.5866 - val_loss: 0.6818 - val_binary_accuracy: 0.5620\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6798 - binary_accuracy: 0.5804 - val_loss: 0.6810 - val_binary_accuracy: 0.6058\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6783 - binary_accuracy: 0.5784 - val_loss: 0.6810 - val_binary_accuracy: 0.5985\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6772 - binary_accuracy: 0.5804 - val_loss: 0.6809 - val_binary_accuracy: 0.6204\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6762 - binary_accuracy: 0.5845 - val_loss: 0.6812 - val_binary_accuracy: 0.5912\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.6744 - binary_accuracy: 0.5906 - val_loss: 0.6818 - val_binary_accuracy: 0.6058\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6732 - binary_accuracy: 0.5927 - val_loss: 0.6826 - val_binary_accuracy: 0.5985\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6722 - binary_accuracy: 0.5988 - val_loss: 0.6823 - val_binary_accuracy: 0.5912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15751b190>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_1.shape[1]\n",
    "n_features = X_train_1.shape[2]\n",
    "\n",
    "model_9 = Sequential()\n",
    "model_9.add(SimpleRNN(8,activation=\"relu\", return_sequences=False, input_shape=(n_steps,n_features)))\n",
    "model_9.add(Dense(30, activation='relu')) \n",
    "model_9.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_9.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model_9.fit(X_train_1, train_5w,epochs=30,  validation_data=(X_val_1, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8f7cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
