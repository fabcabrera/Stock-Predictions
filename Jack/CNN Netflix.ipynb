{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dba26a6-1827-4e08-ba17-ddefa8156a12",
   "metadata": {},
   "source": [
    "# CNN Netflix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5000c067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense, Normalization\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, InputLayer, SimpleRNN\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn import (\n",
    "    linear_model, metrics, neural_network, pipeline, model_selection\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f13dc36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Netflix. Inc</th>\n",
       "      <th>Netflix_x</th>\n",
       "      <th>Netflix Stock</th>\n",
       "      <th>Streaming media</th>\n",
       "      <th>Reed Hastings_x</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>...</th>\n",
       "      <th>Dow_MAvg_s_Move</th>\n",
       "      <th>Dow_EMA_Move</th>\n",
       "      <th>Dow_Disparity_Move</th>\n",
       "      <th>Dow_Disparity_s_Move</th>\n",
       "      <th>Dow_RSI_Move</th>\n",
       "      <th>target_1</th>\n",
       "      <th>target_2</th>\n",
       "      <th>target_3</th>\n",
       "      <th>target_4</th>\n",
       "      <th>target_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Netflix. Inc  Netflix_x  Netflix Stock  Streaming media  Reed Hastings_x  \\\n",
       "0             0          0              0                0                0   \n",
       "\n",
       "   Open  High  Low  Close  Volume  ...  Dow_MAvg_s_Move  Dow_EMA_Move  \\\n",
       "0     0     0    0      0       0  ...                0             0   \n",
       "\n",
       "   Dow_Disparity_Move  Dow_Disparity_s_Move  Dow_RSI_Move  target_1  target_2  \\\n",
       "0                   0                     0             0         0         0   \n",
       "\n",
       "   target_3  target_4  target_5  \n",
       "0         0         0         0  \n",
       "\n",
       "[1 rows x 161 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Netflix = pd.read_csv(\"/Users/jackbrennan/Documents/GitHub/Stock-Predictions/Alex/Netflix_model_ready.csv\")\n",
    "Netflix.date = pd.to_datetime(Netflix.date)\n",
    "Netflix = Netflix.set_index(\"date\")\n",
    "Netflix = Netflix.drop([\"Nas_total\", 'Stock_total', 'Dow_total'],axis=1) # to remove duplicated columns\n",
    "pd.DataFrame(Netflix.isna().sum()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01c88f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "Netflix = Netflix.dropna()\n",
    "Netflix = Netflix[~(Netflix.isin([np.inf, -np.inf]).any(axis=1))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23c9fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Netflix = Netflix.drop(['target_1', 'target_2', 'target_4', 'target_5'], axis=1)\n",
    "target_3 = Netflix[\"target_3\"]\n",
    "\n",
    "#splitting into training sets \n",
    "column_indices = {name: i for i, name in enumerate(Netflix.columns)}\n",
    "\n",
    "n = len(Netflix)\n",
    "X_train = Netflix[0:int(n*0.7)]\n",
    "X_val = Netflix[int(n*0.7):int(n*0.9)]\n",
    "X_test = Netflix[int(n*0.9):]\n",
    "\n",
    "y_train = target_3[0:int(n*0.7)]\n",
    "y_val = target_3[int(n*0.7):int(n*0.9)]\n",
    "y_test = target_3[int(n*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37634713",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mscaler = MinMaxScaler() # keeps binarys at zero and 1 :)\n",
    "\n",
    "X_train = pd.DataFrame(Mscaler.fit_transform(X_train), columns = Netflix.columns)\n",
    "X_val = pd.DataFrame(Mscaler.fit_transform(X_val), columns = Netflix.columns)\n",
    "X_test = pd.DataFrame(Mscaler.fit_transform(X_test), columns = Netflix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f734d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kbest_creator(k, df, df_val, df_test):\n",
    "    \"\"\"\n",
    "    returns data frame of principle componets of # of k best features \n",
    "    \"\"\"\n",
    "    # apply SelectKBest class to extract top 40 best features\n",
    "    bestfeatures = SelectKBest(score_func=f_regression, k=k)\n",
    "    best_fit = bestfeatures.fit(df, y_train)\n",
    "    best_scores = pd.DataFrame(best_fit.scores_)\n",
    "    best_columns = pd.DataFrame(Netflix.columns)\n",
    "    \n",
    "    # concatenate the dataframes for better visualization\n",
    "    features_score = pd.concat([best_columns, best_scores], axis=1)\n",
    "    features_score.columns = ['Features', 'Score']  # naming the dataframe columns\n",
    "    feats_kb = list(features_score.nlargest(k, 'Score').iloc[1:k]['Features'])\n",
    "\n",
    "    pca = PCA().fit(df[feats_kb])\n",
    "    pca_scores = np.cumsum(pca.explained_variance_ratio_) * 100\n",
    "    res = next(x for x, val in enumerate(pca_scores) if val > 85)\n",
    "    res = res + 1\n",
    "    res\n",
    "    \n",
    "    pca_kb_1 = PCA(n_components = res).fit(df[feats_kb].to_numpy())\n",
    "    df = pca_kb_1.transform(df[feats_kb].to_numpy())\n",
    "    df_val = pca_kb_1.transform(df_val[feats_kb].to_numpy())\n",
    "    df_test = pca_kb_1.transform(df_test[feats_kb].to_numpy())\n",
    "    return df, df_val, df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0df7665c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "X_train_kb_10, X_val_kb_10, X_test_kb_10 = kbest_creator(10, X_train, X_val, X_test) \n",
    "X_train_kb_25, X_val_kb_25, X_test_kb_25 = kbest_creator(25, X_train, X_val, X_test) \n",
    "X_train_kb_40, X_val_kb_40, X_test_kb_40 = kbest_creator(40, X_train, X_val, X_test) \n",
    "X_train_kb_55, X_val_kb_55, X_test_kb_55 = kbest_creator(55, X_train, X_val, X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce1f947",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "802d7e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f0c8d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_X_y2(df, target, window_size=5):\n",
    "  # converts to matrix of numpy arrays\n",
    "  X = []\n",
    "  y = []\n",
    "  for i in range(len(df)-window_size): # length of data frame - window_size so it does't take empty values at the end, \n",
    "    # does force you to loose the last 5 values, could fix with padding\n",
    "    row = [r for r in df[i:i+window_size]] # grabs row i and all rows above within the window size length\n",
    "    X.append(row) # creates 3 dimentional array, (# obseravtions, # rows in window, # features)\n",
    "    label = target[i+window_size] # pulls the target variable after the window, target varible needs to be column zero in this \n",
    "    y.append(label) # returns (N,) martix of targets i+window_length time periods away\n",
    "  return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e9a67462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to window format, in this case 5 periods\n",
    "X_train_kb_40, train_5w = df_to_X_y2(X_train_kb_40,y_train)\n",
    "X_val_kb_40, val_5w = df_to_X_y2(X_val_kb_40, y_val)\n",
    "X_test_kb_40, test_5w = df_to_X_y2(X_test_kb_40,y_test) \n",
    "\n",
    "X_train_kb_10, _ = df_to_X_y2(X_train_kb_10,y_train)\n",
    "X_val_kb_10, _ = df_to_X_y2(X_val_kb_10, y_val)\n",
    "X_test_kb_10, _ = df_to_X_y2(X_test_kb_10,y_test) \n",
    "\n",
    "X_train_kb_25, _ = df_to_X_y2(X_train_kb_25,y_train)\n",
    "X_val_kb_25, _ = df_to_X_y2(X_val_kb_25, y_val)\n",
    "X_test_kb_25, _ = df_to_X_y2(X_test_kb_25,y_test) \n",
    "\n",
    "X_train_kb_55, _ = df_to_X_y2(X_train_kb_55,y_train)\n",
    "X_val_kb_55, _ = df_to_X_y2(X_val_kb_55, y_val)\n",
    "X_test_kb_55, _ = df_to_X_y2(X_test_kb_55,y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa349c0e",
   "metadata": {},
   "source": [
    "### Model Format 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2a6a4c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 13ms/step - loss: 0.6942 - binary_accuracy: 0.4850 - val_loss: 0.6992 - val_binary_accuracy: 0.4460\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6872 - binary_accuracy: 0.5711 - val_loss: 0.6913 - val_binary_accuracy: 0.5612\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6845 - binary_accuracy: 0.5812 - val_loss: 0.6936 - val_binary_accuracy: 0.5180\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6826 - binary_accuracy: 0.5611 - val_loss: 0.6955 - val_binary_accuracy: 0.5036\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6806 - binary_accuracy: 0.5852 - val_loss: 0.6977 - val_binary_accuracy: 0.5108\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6794 - binary_accuracy: 0.5711 - val_loss: 0.7031 - val_binary_accuracy: 0.5036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x155f14310>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 1_1 - 1_4, using differnt k best pca variables\n",
    "n_steps = X_train_kb_10.shape[1]\n",
    "n_features = X_train_kb_10.shape[2]\n",
    "\n",
    "model1_1 = Sequential()\n",
    "model1_1.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model1_1.add(Flatten())\n",
    "model1_1.add(Dense(25, activation='relu')) \n",
    "model1_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1_1.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model1_1.fit(X_train_kb_10, train_5w,epochs=30,  validation_data=(X_val_kb_10, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "540bf1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4411764705882353"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat1_1 = model1_1.predict(X_test_kb_10)\n",
    "y_hat1_1 = y_hat1_1 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6c962f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 12ms/step - loss: 0.6940 - binary_accuracy: 0.5010 - val_loss: 0.6966 - val_binary_accuracy: 0.4892\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6813 - binary_accuracy: 0.5832 - val_loss: 0.7033 - val_binary_accuracy: 0.4532\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6660 - binary_accuracy: 0.6253 - val_loss: 0.6989 - val_binary_accuracy: 0.4892\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6577 - binary_accuracy: 0.6293 - val_loss: 0.7042 - val_binary_accuracy: 0.5108\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6497 - binary_accuracy: 0.6513 - val_loss: 0.7076 - val_binary_accuracy: 0.5180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x156433d90>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_25.shape[1]\n",
    "n_features = X_train_kb_25.shape[2]\n",
    "\n",
    "model1_2 = Sequential()\n",
    "model1_2.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model1_2.add(Flatten())\n",
    "model1_2.add(Dense(25, activation='relu')) \n",
    "model1_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model1_2.fit(X_train_kb_25, train_5w,epochs=30,  validation_data=(X_val_kb_25, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aa3d1fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4264705882352941"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat1_2 = model1_2.predict(X_test_kb_25)\n",
    "y_hat1_2 = y_hat1_2 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "24e0ad96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 14ms/step - loss: 0.6966 - binary_accuracy: 0.5070 - val_loss: 0.6929 - val_binary_accuracy: 0.4892\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6776 - binary_accuracy: 0.6253 - val_loss: 0.6946 - val_binary_accuracy: 0.4892\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6658 - binary_accuracy: 0.6313 - val_loss: 0.7003 - val_binary_accuracy: 0.4892\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6551 - binary_accuracy: 0.6573 - val_loss: 0.7032 - val_binary_accuracy: 0.4676\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6450 - binary_accuracy: 0.6633 - val_loss: 0.7090 - val_binary_accuracy: 0.4676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1565297f0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_40.shape[1]\n",
    "n_features = X_train_kb_40.shape[2]\n",
    "\n",
    "model1_3 = Sequential()\n",
    "model1_3.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model1_3.add(Flatten())\n",
    "model1_3.add(Dense(25, activation='relu')) \n",
    "model1_3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1_3.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model1_3.fit(X_train_kb_40, train_5w,epochs=30,  validation_data=(X_val_kb_40, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cd22db0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39705882352941174"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat1_3 = model1_3.predict(X_test_kb_40)\n",
    "y_hat1_3 = y_hat1_3 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat1_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "26ddd69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 12ms/step - loss: 0.7046 - binary_accuracy: 0.4709 - val_loss: 0.6900 - val_binary_accuracy: 0.5108\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6801 - binary_accuracy: 0.6132 - val_loss: 0.7016 - val_binary_accuracy: 0.4820\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6674 - binary_accuracy: 0.6613 - val_loss: 0.7029 - val_binary_accuracy: 0.5036\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6552 - binary_accuracy: 0.6653 - val_loss: 0.7046 - val_binary_accuracy: 0.5036\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6425 - binary_accuracy: 0.6914 - val_loss: 0.7117 - val_binary_accuracy: 0.4820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1566dfc40>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_55.shape[1]\n",
    "n_features = X_train_kb_55.shape[2]\n",
    "\n",
    "model1_4 = Sequential()\n",
    "model1_4.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model1_4.add(Flatten())\n",
    "model1_4.add(Dense(25, activation='relu')) \n",
    "model1_4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1_4.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model1_4.fit(X_train_kb_55, train_5w,epochs=30,  validation_data=(X_val_kb_55, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4c8dd064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45588235294117646"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat1_4 = model1_4.predict(X_test_kb_55)\n",
    "y_hat1_4 = y_hat1_4 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat1_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80642814",
   "metadata": {},
   "source": [
    "### Model 2, Less Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2a6a4c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 15ms/step - loss: 0.6946 - binary_accuracy: 0.4890 - val_loss: 0.6909 - val_binary_accuracy: 0.4964\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6926 - binary_accuracy: 0.5190 - val_loss: 0.6891 - val_binary_accuracy: 0.4892\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.6914 - binary_accuracy: 0.5331 - val_loss: 0.6889 - val_binary_accuracy: 0.5036\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6904 - binary_accuracy: 0.5411 - val_loss: 0.6894 - val_binary_accuracy: 0.4964\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6896 - binary_accuracy: 0.5551 - val_loss: 0.6889 - val_binary_accuracy: 0.5036\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6886 - binary_accuracy: 0.5631 - val_loss: 0.6888 - val_binary_accuracy: 0.4892\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6876 - binary_accuracy: 0.5671 - val_loss: 0.6890 - val_binary_accuracy: 0.4892\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6870 - binary_accuracy: 0.5691 - val_loss: 0.6886 - val_binary_accuracy: 0.4964\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6859 - binary_accuracy: 0.5731 - val_loss: 0.6893 - val_binary_accuracy: 0.5036\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6851 - binary_accuracy: 0.5711 - val_loss: 0.6899 - val_binary_accuracy: 0.5180\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6849 - binary_accuracy: 0.5711 - val_loss: 0.6918 - val_binary_accuracy: 0.5036\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6839 - binary_accuracy: 0.5752 - val_loss: 0.6911 - val_binary_accuracy: 0.5036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x156f05d90>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 2_1 - 2_4, using differnt k best pca variables. reduced filters\n",
    "n_steps = X_train_kb_10.shape[1]\n",
    "n_features = X_train_kb_10.shape[2]\n",
    "\n",
    "model2_1 = Sequential()\n",
    "model2_1.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model2_1.add(Flatten())\n",
    "model2_1.add(Dense(25, activation='relu')) \n",
    "model2_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2_1.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model2_1.fit(X_train_kb_10, train_5w,epochs=30,  validation_data=(X_val_kb_10, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "929becef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x157911310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4264705882352941"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat2_1 = model2_1.predict(X_test_kb_10)\n",
    "y_hat2_1 = y_hat2_1 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat2_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6c962f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.7065 - binary_accuracy: 0.4709 - val_loss: 0.6994 - val_binary_accuracy: 0.5540\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7004 - binary_accuracy: 0.4950 - val_loss: 0.6966 - val_binary_accuracy: 0.5683\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6959 - binary_accuracy: 0.5050 - val_loss: 0.6978 - val_binary_accuracy: 0.5683\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6920 - binary_accuracy: 0.5331 - val_loss: 0.6974 - val_binary_accuracy: 0.5755\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6888 - binary_accuracy: 0.5371 - val_loss: 0.6980 - val_binary_accuracy: 0.5612\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6858 - binary_accuracy: 0.5591 - val_loss: 0.6993 - val_binary_accuracy: 0.5180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x156dc2d00>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_25.shape[1]\n",
    "n_features = X_train_kb_25.shape[2]\n",
    "\n",
    "model2_2 = Sequential()\n",
    "model2_2.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model2_2.add(Flatten())\n",
    "model2_2.add(Dense(25, activation='relu')) \n",
    "model2_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model2_2.fit(X_train_kb_25, train_5w,epochs=30,  validation_data=(X_val_kb_25, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4021da90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1578343a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat2_2 = model2_2.predict(X_test_kb_25)\n",
    "y_hat2_2 = y_hat2_2 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "24e0ad96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 20ms/step - loss: 0.6984 - binary_accuracy: 0.4790 - val_loss: 0.7075 - val_binary_accuracy: 0.4964\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.6898 - binary_accuracy: 0.5090 - val_loss: 0.7044 - val_binary_accuracy: 0.4892\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6841 - binary_accuracy: 0.5411 - val_loss: 0.7023 - val_binary_accuracy: 0.4820\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6794 - binary_accuracy: 0.5551 - val_loss: 0.7044 - val_binary_accuracy: 0.4460\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6758 - binary_accuracy: 0.5671 - val_loss: 0.7037 - val_binary_accuracy: 0.4604\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6725 - binary_accuracy: 0.5852 - val_loss: 0.7070 - val_binary_accuracy: 0.4604\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6689 - binary_accuracy: 0.6012 - val_loss: 0.7065 - val_binary_accuracy: 0.4820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x156db5a60>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_40.shape[1]\n",
    "n_features = X_train_kb_40.shape[2]\n",
    "\n",
    "model2_3 = Sequential()\n",
    "model2_3.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model2_3.add(Flatten())\n",
    "model2_3.add(Dense(25, activation='relu')) \n",
    "model2_3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2_3.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model2_3.fit(X_train_kb_40, train_5w,epochs=30,  validation_data=(X_val_kb_40, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e994ea9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat2_3 = model2_3.predict(X_test_kb_40)\n",
    "y_hat2_3 = y_hat2_3 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat2_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "26ddd69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 12ms/step - loss: 0.6980 - binary_accuracy: 0.4950 - val_loss: 0.6924 - val_binary_accuracy: 0.5180\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6924 - binary_accuracy: 0.5150 - val_loss: 0.6876 - val_binary_accuracy: 0.5108\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6867 - binary_accuracy: 0.5411 - val_loss: 0.6885 - val_binary_accuracy: 0.4964\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6837 - binary_accuracy: 0.5691 - val_loss: 0.6916 - val_binary_accuracy: 0.5252\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6798 - binary_accuracy: 0.5752 - val_loss: 0.6931 - val_binary_accuracy: 0.5324\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6765 - binary_accuracy: 0.5872 - val_loss: 0.6907 - val_binary_accuracy: 0.5180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x156bfd190>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_55.shape[1]\n",
    "n_features = X_train_kb_55.shape[2]\n",
    "\n",
    "model2_4 = Sequential()\n",
    "model2_4.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model2_4.add(Flatten())\n",
    "model2_4.add(Dense(25, activation='relu')) \n",
    "model2_4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2_4.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model2_4.fit(X_train_kb_55, train_5w,epochs=30,  validation_data=(X_val_kb_55, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "68c28a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39705882352941174"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat2_4 = model2_4.predict(X_test_kb_55)\n",
    "y_hat2_4 = y_hat2_4 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat2_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a946d9",
   "metadata": {},
   "source": [
    "### Model 3, Adding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2a6a4c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 28ms/step - loss: 0.6942 - binary_accuracy: 0.4930 - val_loss: 0.6946 - val_binary_accuracy: 0.4532\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6934 - binary_accuracy: 0.5090 - val_loss: 0.6936 - val_binary_accuracy: 0.4604\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6928 - binary_accuracy: 0.5170 - val_loss: 0.6928 - val_binary_accuracy: 0.4892\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6923 - binary_accuracy: 0.5251 - val_loss: 0.6924 - val_binary_accuracy: 0.4676\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6920 - binary_accuracy: 0.5271 - val_loss: 0.6918 - val_binary_accuracy: 0.5252\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6918 - binary_accuracy: 0.5331 - val_loss: 0.6916 - val_binary_accuracy: 0.5540\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6916 - binary_accuracy: 0.5371 - val_loss: 0.6911 - val_binary_accuracy: 0.5683\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6914 - binary_accuracy: 0.5591 - val_loss: 0.6912 - val_binary_accuracy: 0.5396\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6912 - binary_accuracy: 0.5631 - val_loss: 0.6908 - val_binary_accuracy: 0.5612\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6909 - binary_accuracy: 0.5711 - val_loss: 0.6906 - val_binary_accuracy: 0.5971\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6906 - binary_accuracy: 0.5872 - val_loss: 0.6908 - val_binary_accuracy: 0.5899\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6904 - binary_accuracy: 0.5832 - val_loss: 0.6902 - val_binary_accuracy: 0.5612\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6901 - binary_accuracy: 0.5731 - val_loss: 0.6903 - val_binary_accuracy: 0.5540\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6898 - binary_accuracy: 0.5832 - val_loss: 0.6904 - val_binary_accuracy: 0.5540\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6896 - binary_accuracy: 0.5711 - val_loss: 0.6899 - val_binary_accuracy: 0.5540\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6893 - binary_accuracy: 0.5812 - val_loss: 0.6895 - val_binary_accuracy: 0.5540\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6889 - binary_accuracy: 0.5792 - val_loss: 0.6897 - val_binary_accuracy: 0.5683\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6884 - binary_accuracy: 0.5611 - val_loss: 0.6889 - val_binary_accuracy: 0.5827\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6878 - binary_accuracy: 0.5671 - val_loss: 0.6901 - val_binary_accuracy: 0.5396\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6873 - binary_accuracy: 0.5711 - val_loss: 0.6898 - val_binary_accuracy: 0.5324\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6868 - binary_accuracy: 0.5651 - val_loss: 0.6902 - val_binary_accuracy: 0.5252\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6865 - binary_accuracy: 0.5691 - val_loss: 0.6911 - val_binary_accuracy: 0.5252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1568525e0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 3_1 - 3_4, adding layers\n",
    "n_steps = X_train_kb_10.shape[1]\n",
    "n_features = X_train_kb_10.shape[2]\n",
    "\n",
    "model3_1 = Sequential()\n",
    "model3_1.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model3_1.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model3_1.add(MaxPooling1D(pool_size=2))\n",
    "model3_1.add(Flatten())\n",
    "model3_1.add(Dense(8, activation='relu')) \n",
    "model3_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3_1.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model3_1.fit(X_train_kb_10, train_5w,epochs=30,  validation_data=(X_val_kb_10, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a9c077a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4117647058823529"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat3_1 = model3_1.predict(X_test_kb_10)\n",
    "y_hat3_1 = y_hat3_1 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat3_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6c962f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 16ms/step - loss: 0.6935 - binary_accuracy: 0.5150 - val_loss: 0.6878 - val_binary_accuracy: 0.5827\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6905 - binary_accuracy: 0.5150 - val_loss: 0.6875 - val_binary_accuracy: 0.5827\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6886 - binary_accuracy: 0.5251 - val_loss: 0.6881 - val_binary_accuracy: 0.6043\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6866 - binary_accuracy: 0.5351 - val_loss: 0.6880 - val_binary_accuracy: 0.5827\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6842 - binary_accuracy: 0.5471 - val_loss: 0.6882 - val_binary_accuracy: 0.5612\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6820 - binary_accuracy: 0.5471 - val_loss: 0.6886 - val_binary_accuracy: 0.5324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15721adc0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_25.shape[1]\n",
    "n_features = X_train_kb_25.shape[2]\n",
    "\n",
    "model3_2 = Sequential()\n",
    "model3_2.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model3_2.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model3_2.add(MaxPooling1D(pool_size=2))\n",
    "model3_2.add(Flatten())\n",
    "model3_2.add(Dense(25, activation='relu')) \n",
    "model3_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model3_2.fit(X_train_kb_25, train_5w,epochs=30,  validation_data=(X_val_kb_25, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "94fe03bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3235294117647059"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat3_2 = model3_2.predict(X_test_kb_25)\n",
    "y_hat3_2 = y_hat3_2 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat3_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "24e0ad96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.6924 - binary_accuracy: 0.5110 - val_loss: 0.6911 - val_binary_accuracy: 0.5540\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6902 - binary_accuracy: 0.5451 - val_loss: 0.6909 - val_binary_accuracy: 0.5612\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6888 - binary_accuracy: 0.5291 - val_loss: 0.6899 - val_binary_accuracy: 0.5683\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6866 - binary_accuracy: 0.5631 - val_loss: 0.6905 - val_binary_accuracy: 0.5324\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6848 - binary_accuracy: 0.5511 - val_loss: 0.6892 - val_binary_accuracy: 0.5396\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6821 - binary_accuracy: 0.5752 - val_loss: 0.6898 - val_binary_accuracy: 0.5180\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6790 - binary_accuracy: 0.5992 - val_loss: 0.6905 - val_binary_accuracy: 0.4964\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6759 - binary_accuracy: 0.6012 - val_loss: 0.6904 - val_binary_accuracy: 0.5252\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6709 - binary_accuracy: 0.6373 - val_loss: 0.6933 - val_binary_accuracy: 0.5180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x157348d90>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_40.shape[1]\n",
    "n_features = X_train_kb_40.shape[2]\n",
    "\n",
    "model3_3 = Sequential()\n",
    "model3_3.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model3_3.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model3_3.add(MaxPooling1D(pool_size=2))\n",
    "model3_3.add(Flatten())\n",
    "model3_3.add(Dense(25, activation='relu')) \n",
    "model3_3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3_3.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model3_3.fit(X_train_kb_40, train_5w,epochs=30,  validation_data=(X_val_kb_40, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f8a26636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39705882352941174"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat3_3 = model3_3.predict(X_test_kb_40)\n",
    "y_hat3_3 = y_hat3_3 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat3_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "26ddd69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 14ms/step - loss: 0.6965 - binary_accuracy: 0.5030 - val_loss: 0.6925 - val_binary_accuracy: 0.5324\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6927 - binary_accuracy: 0.5311 - val_loss: 0.6922 - val_binary_accuracy: 0.5755\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6916 - binary_accuracy: 0.5431 - val_loss: 0.6900 - val_binary_accuracy: 0.6043\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6899 - binary_accuracy: 0.5531 - val_loss: 0.6898 - val_binary_accuracy: 0.6259\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6889 - binary_accuracy: 0.5551 - val_loss: 0.6901 - val_binary_accuracy: 0.6043\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6876 - binary_accuracy: 0.5431 - val_loss: 0.6894 - val_binary_accuracy: 0.5971\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6864 - binary_accuracy: 0.5551 - val_loss: 0.6876 - val_binary_accuracy: 0.6115\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6853 - binary_accuracy: 0.5691 - val_loss: 0.6876 - val_binary_accuracy: 0.6115\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6835 - binary_accuracy: 0.5651 - val_loss: 0.6870 - val_binary_accuracy: 0.6115\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6823 - binary_accuracy: 0.5711 - val_loss: 0.6872 - val_binary_accuracy: 0.5755\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6806 - binary_accuracy: 0.5872 - val_loss: 0.6854 - val_binary_accuracy: 0.5971\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6789 - binary_accuracy: 0.5711 - val_loss: 0.6861 - val_binary_accuracy: 0.5971\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6764 - binary_accuracy: 0.5772 - val_loss: 0.6859 - val_binary_accuracy: 0.5827\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6742 - binary_accuracy: 0.5912 - val_loss: 0.6857 - val_binary_accuracy: 0.5755\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6717 - binary_accuracy: 0.5972 - val_loss: 0.6845 - val_binary_accuracy: 0.5612\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6691 - binary_accuracy: 0.5972 - val_loss: 0.6850 - val_binary_accuracy: 0.5683\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6658 - binary_accuracy: 0.6072 - val_loss: 0.6853 - val_binary_accuracy: 0.5683\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6626 - binary_accuracy: 0.6212 - val_loss: 0.6861 - val_binary_accuracy: 0.5540\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6602 - binary_accuracy: 0.6172 - val_loss: 0.6869 - val_binary_accuracy: 0.5683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x157545cd0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_55.shape[1]\n",
    "n_features = X_train_kb_55.shape[2]\n",
    "\n",
    "model3_4 = Sequential()\n",
    "model3_4.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model3_4.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model3_4.add(MaxPooling1D(pool_size=2))\n",
    "model3_4.add(Flatten())\n",
    "model3_4.add(Dense(25, activation='relu')) \n",
    "model3_4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3_4.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model3_4.fit(X_train_kb_55, train_5w,epochs=30,  validation_data=(X_val_kb_55, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a7941f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5588235294117647"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat3_4 = model3_4.predict(X_test_kb_55)\n",
    "y_hat3_4 = y_hat3_4 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat3_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a38693",
   "metadata": {},
   "source": [
    "### Model 4, adding conv layer after pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2a6a4c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 30ms/step - loss: 0.6949 - binary_accuracy: 0.5130 - val_loss: 0.6943 - val_binary_accuracy: 0.5252\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6910 - binary_accuracy: 0.5170 - val_loss: 0.6874 - val_binary_accuracy: 0.5971\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6904 - binary_accuracy: 0.5331 - val_loss: 0.6857 - val_binary_accuracy: 0.5971\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6885 - binary_accuracy: 0.5291 - val_loss: 0.6855 - val_binary_accuracy: 0.5827\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6882 - binary_accuracy: 0.5271 - val_loss: 0.6879 - val_binary_accuracy: 0.5612\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6863 - binary_accuracy: 0.5611 - val_loss: 0.6847 - val_binary_accuracy: 0.5971\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6855 - binary_accuracy: 0.5531 - val_loss: 0.6850 - val_binary_accuracy: 0.5827\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6851 - binary_accuracy: 0.5651 - val_loss: 0.6858 - val_binary_accuracy: 0.5612\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6845 - binary_accuracy: 0.5892 - val_loss: 0.6865 - val_binary_accuracy: 0.5612\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6836 - binary_accuracy: 0.5711 - val_loss: 0.6873 - val_binary_accuracy: 0.5468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x157a38c40>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 4_1 - 4_4, adding conv layer after pooling\n",
    "n_steps = X_train_kb_10.shape[1]\n",
    "n_features = X_train_kb_10.shape[2]\n",
    "\n",
    "model4_1 = Sequential()\n",
    "model4_1.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model4_1.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model4_1.add(MaxPooling1D(pool_size=2))\n",
    "model4_1.add(Conv1D(filters=16, kernel_size=1, activation='relu'))\n",
    "model4_1.add(Flatten())\n",
    "model4_1.add(Dense(8, activation='relu')) \n",
    "model4_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model4_1.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model4_1.fit(X_train_kb_10, train_5w,epochs=30,  validation_data=(X_val_kb_10, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0ea7e586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45588235294117646"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat4_1 = model4_1.predict(X_test_kb_10)\n",
    "y_hat4_1 = y_hat4_1 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat4_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6c962f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 17ms/step - loss: 0.6938 - binary_accuracy: 0.4830 - val_loss: 0.6926 - val_binary_accuracy: 0.5252\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6915 - binary_accuracy: 0.5190 - val_loss: 0.6924 - val_binary_accuracy: 0.5324\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6901 - binary_accuracy: 0.5431 - val_loss: 0.6922 - val_binary_accuracy: 0.5324\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6880 - binary_accuracy: 0.5511 - val_loss: 0.6911 - val_binary_accuracy: 0.5755\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6867 - binary_accuracy: 0.5291 - val_loss: 0.6902 - val_binary_accuracy: 0.5827\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6830 - binary_accuracy: 0.5351 - val_loss: 0.6922 - val_binary_accuracy: 0.5396\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6791 - binary_accuracy: 0.5611 - val_loss: 0.6936 - val_binary_accuracy: 0.5252\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6752 - binary_accuracy: 0.6072 - val_loss: 0.6940 - val_binary_accuracy: 0.5108\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6693 - binary_accuracy: 0.6172 - val_loss: 0.6974 - val_binary_accuracy: 0.5036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x157c07df0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_25.shape[1]\n",
    "n_features = X_train_kb_25.shape[2]\n",
    "\n",
    "model4_2 = Sequential()\n",
    "model4_2.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model4_2.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model4_2.add(MaxPooling1D(pool_size=2))\n",
    "model4_2.add(Conv1D(filters=16, kernel_size=1, activation='relu'))\n",
    "model4_2.add(Flatten())\n",
    "model4_2.add(Dense(25, activation='relu')) \n",
    "model4_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model4_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model4_2.fit(X_train_kb_25, train_5w,epochs=30,  validation_data=(X_val_kb_25, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7443231d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4117647058823529"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat4_2 = model4_2.predict(X_test_kb_25)\n",
    "y_hat4_2 = y_hat4_2 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat4_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "24e0ad96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 20ms/step - loss: 0.6938 - binary_accuracy: 0.5150 - val_loss: 0.6894 - val_binary_accuracy: 0.5827\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6913 - binary_accuracy: 0.5170 - val_loss: 0.6903 - val_binary_accuracy: 0.5827\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6898 - binary_accuracy: 0.5170 - val_loss: 0.6895 - val_binary_accuracy: 0.5827\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6880 - binary_accuracy: 0.5251 - val_loss: 0.6884 - val_binary_accuracy: 0.5827\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6857 - binary_accuracy: 0.5331 - val_loss: 0.6875 - val_binary_accuracy: 0.5899\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6830 - binary_accuracy: 0.5651 - val_loss: 0.6881 - val_binary_accuracy: 0.5683\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6785 - binary_accuracy: 0.5772 - val_loss: 0.6879 - val_binary_accuracy: 0.5683\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6732 - binary_accuracy: 0.5812 - val_loss: 0.6911 - val_binary_accuracy: 0.5396\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6674 - binary_accuracy: 0.6273 - val_loss: 0.6906 - val_binary_accuracy: 0.5108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x157db4dc0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_40.shape[1]\n",
    "n_features = X_train_kb_40.shape[2]\n",
    "\n",
    "model4_3 = Sequential()\n",
    "model4_3.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model4_3.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model4_3.add(MaxPooling1D(pool_size=2))\n",
    "model4_3.add(Conv1D(filters=16, kernel_size=1, activation='relu'))\n",
    "model4_3.add(Flatten())\n",
    "model4_3.add(Dense(25, activation='relu')) \n",
    "model4_3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model4_3.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model4_3.fit(X_train_kb_40, train_5w,epochs=30,  validation_data=(X_val_kb_40, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4a97295e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4411764705882353"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat4_3 = model4_3.predict(X_test_kb_40)\n",
    "y_hat4_3 = y_hat4_3 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat4_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "26ddd69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 18ms/step - loss: 0.6979 - binary_accuracy: 0.4770 - val_loss: 0.6931 - val_binary_accuracy: 0.5540\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6920 - binary_accuracy: 0.5471 - val_loss: 0.6874 - val_binary_accuracy: 0.5971\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6901 - binary_accuracy: 0.5391 - val_loss: 0.6856 - val_binary_accuracy: 0.5755\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6887 - binary_accuracy: 0.5451 - val_loss: 0.6839 - val_binary_accuracy: 0.5971\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6875 - binary_accuracy: 0.5491 - val_loss: 0.6832 - val_binary_accuracy: 0.6187\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6859 - binary_accuracy: 0.5371 - val_loss: 0.6851 - val_binary_accuracy: 0.5683\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6835 - binary_accuracy: 0.5671 - val_loss: 0.6839 - val_binary_accuracy: 0.5612\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6815 - binary_accuracy: 0.5731 - val_loss: 0.6837 - val_binary_accuracy: 0.5612\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6786 - binary_accuracy: 0.5832 - val_loss: 0.6848 - val_binary_accuracy: 0.5755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1566dd5b0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_55.shape[1]\n",
    "n_features = X_train_kb_55.shape[2]\n",
    "\n",
    "model4_4 = Sequential()\n",
    "model4_4.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model4_4.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model4_4.add(MaxPooling1D(pool_size=2))\n",
    "model4_4.add(Conv1D(filters=16, kernel_size=1, activation='relu'))\n",
    "model4_4.add(Flatten())\n",
    "model4_4.add(Dense(25, activation='relu')) \n",
    "model4_4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model4_4.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model4_4.fit(X_train_kb_55, train_5w,epochs=30,  validation_data=(X_val_kb_55, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "263a0ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45588235294117646"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat4_4 = model4_4.predict(X_test_kb_55)\n",
    "y_hat4_4 = y_hat4_4 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat4_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c637d4e3",
   "metadata": {},
   "source": [
    "# Trying the Correlation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "76a38693",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = X_train.corr()\n",
    "corr_matrix\n",
    "\n",
    "feats_corr_10 = list(pd.DataFrame(corr_matrix['target_3'].sort_values(ascending=False).iloc[1:11]).reset_index()['index'])\n",
    "feats_corr_25 = list(pd.DataFrame(corr_matrix['target_3'].sort_values(ascending=False).iloc[1:26]).reset_index()['index'])\n",
    "feats_corr_40 = list(pd.DataFrame(corr_matrix['target_3'].sort_values(ascending=False).iloc[1:41]).reset_index()['index'])\n",
    "feats_corr_55 = list(pd.DataFrame(corr_matrix['target_3'].sort_values(ascending=False).iloc[1:56]).reset_index()['index'])\n",
    "\n",
    "X_train_cr_10 = X_train[feats_corr_10]\n",
    "X_test_cr_10 = X_test[feats_corr_10]\n",
    "X_val_cr_10 = X_val[feats_corr_10]\n",
    "X_train_cr_25 = X_train[feats_corr_25]\n",
    "X_test_cr_25 = X_test[feats_corr_25]\n",
    "X_val_cr_25 = X_val[feats_corr_25]\n",
    "X_train_cr_40 = X_train[feats_corr_40]\n",
    "X_test_cr_40 = X_test[feats_corr_40]\n",
    "X_val_cr_40 = X_val[feats_corr_40]\n",
    "X_train_cr_55 = X_train[feats_corr_55]\n",
    "X_test_cr_55 = X_test[feats_corr_55]\n",
    "X_val_cr_55 = X_val[feats_corr_55]\n",
    "\n",
    "def pca_finder(df, df_val, df_test):\n",
    "    \n",
    "    pca = PCA().fit(df)\n",
    "    pca_scores = np.cumsum(pca.explained_variance_ratio_) * 100\n",
    "    res = next(x for x, val in enumerate(pca_scores) if val > 85)\n",
    "    res = res + 1\n",
    "    res\n",
    "    \n",
    "    pca_cr_1 = PCA(n_components = res).fit(df.to_numpy())\n",
    "    df = pca_cr_1.transform(df.to_numpy())\n",
    "    df_val = pca_cr_1.transform(df_val.to_numpy())\n",
    "    df_test = pca_cr_1.transform(df_test.to_numpy())\n",
    "    return df, df_val, df_test\n",
    "\n",
    "X_train_cr_10, X_val_cr_10, X_test_cr_10 = pca_finder(X_train_cr_10, X_val_cr_10, X_test_cr_10)\n",
    "X_train_cr_25, X_val_cr_25, X_test_cr_25 = pca_finder(X_train_cr_25, X_val_cr_25, X_test_cr_25)\n",
    "X_train_cr_40, X_val_cr_40, X_test_cr_40 = pca_finder(X_train_cr_40, X_val_cr_40, X_test_cr_40)\n",
    "X_train_cr_55, X_val_cr_55, X_test_cr_55 = pca_finder(X_train_cr_55, X_val_cr_55, X_test_cr_55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "06fc0d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cr_40, train_5w = df_to_X_y2(X_train_cr_40,y_train)\n",
    "X_val_cr_40, val_5w = df_to_X_y2(X_val_cr_40, y_val)\n",
    "X_test_cr_40, test_5w = df_to_X_y2(X_test_cr_40,y_test) \n",
    "\n",
    "X_train_cr_10, _ = df_to_X_y2(X_train_cr_10,y_train)\n",
    "X_val_cr_10, _ = df_to_X_y2(X_val_cr_10, y_val)\n",
    "X_test_cr_10, _ = df_to_X_y2(X_test_cr_10,y_test) \n",
    "\n",
    "X_train_cr_25, _ = df_to_X_y2(X_train_cr_25,y_train)\n",
    "X_val_cr_25, _ = df_to_X_y2(X_val_cr_25, y_val)\n",
    "X_test_cr_25, _ = df_to_X_y2(X_test_cr_25,y_test) \n",
    "\n",
    "X_train_cr_55, _ = df_to_X_y2(X_train_cr_55,y_train)\n",
    "X_val_cr_55, _ = df_to_X_y2(X_val_cr_55, y_val)\n",
    "X_test_cr_55, _ = df_to_X_y2(X_test_cr_55,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2a6a4c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 17ms/step - loss: 0.6953 - binary_accuracy: 0.5210 - val_loss: 0.6815 - val_binary_accuracy: 0.5755\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6916 - binary_accuracy: 0.5331 - val_loss: 0.6812 - val_binary_accuracy: 0.5827\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6884 - binary_accuracy: 0.5451 - val_loss: 0.6802 - val_binary_accuracy: 0.5899\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6858 - binary_accuracy: 0.5551 - val_loss: 0.6815 - val_binary_accuracy: 0.5252\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6838 - binary_accuracy: 0.5671 - val_loss: 0.6811 - val_binary_accuracy: 0.5324\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6816 - binary_accuracy: 0.5671 - val_loss: 0.6818 - val_binary_accuracy: 0.5540\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6800 - binary_accuracy: 0.5611 - val_loss: 0.6828 - val_binary_accuracy: 0.5540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1581b1a90>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 2_1 - 2_4, using differnt k best pca variables. reduced filters\n",
    "n_steps = X_train_cr_10.shape[1]\n",
    "n_features = X_train_cr_10.shape[2]\n",
    "\n",
    "model2_1_cr = Sequential()\n",
    "model2_1_cr.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model2_1_cr.add(Flatten())\n",
    "model2_1_cr.add(Dense(25, activation='relu')) \n",
    "model2_1_cr.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2_1_cr.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model2_1_cr.fit(X_train_cr_10, train_5w,epochs=30,  validation_data=(X_val_cr_10, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "929becef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5147058823529411"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat2_1_cr = model2_1_cr.predict(X_test_cr_10)\n",
    "y_hat2_1_cr = y_hat2_1_cr > .5\n",
    "metrics.accuracy_score(test_5w,y_hat2_1_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6c962f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 33ms/step - loss: 0.7028 - binary_accuracy: 0.4749 - val_loss: 0.7118 - val_binary_accuracy: 0.4245\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.6932 - binary_accuracy: 0.5251 - val_loss: 0.7049 - val_binary_accuracy: 0.4748\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6889 - binary_accuracy: 0.5371 - val_loss: 0.7019 - val_binary_accuracy: 0.4964\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6850 - binary_accuracy: 0.5471 - val_loss: 0.6984 - val_binary_accuracy: 0.4892\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6816 - binary_accuracy: 0.5511 - val_loss: 0.7001 - val_binary_accuracy: 0.4676\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6789 - binary_accuracy: 0.5571 - val_loss: 0.6990 - val_binary_accuracy: 0.4820\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6760 - binary_accuracy: 0.5691 - val_loss: 0.7017 - val_binary_accuracy: 0.4748\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6728 - binary_accuracy: 0.5731 - val_loss: 0.6998 - val_binary_accuracy: 0.4964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15832bd60>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_cr_25.shape[1]\n",
    "n_features = X_train_cr_25.shape[2]\n",
    "\n",
    "model2_2_cr = Sequential()\n",
    "model2_2_cr.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model2_2_cr.add(Flatten())\n",
    "model2_2_cr.add(Dense(25, activation='relu')) \n",
    "model2_2_cr.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2_2_cr.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model2_2_cr.fit(X_train_cr_25, train_5w,epochs=30,  validation_data=(X_val_cr_25, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4021da90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47058823529411764"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat2_2_cr = model2_2_cr.predict(X_test_cr_25)\n",
    "y_hat2_2_cr = y_hat2_2_cr > .5\n",
    "metrics.accuracy_score(test_5w,y_hat2_2_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "24e0ad96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 26ms/step - loss: 0.7049 - binary_accuracy: 0.4990 - val_loss: 0.7029 - val_binary_accuracy: 0.4820\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6964 - binary_accuracy: 0.5110 - val_loss: 0.6968 - val_binary_accuracy: 0.4892\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6921 - binary_accuracy: 0.5431 - val_loss: 0.6936 - val_binary_accuracy: 0.5108\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6887 - binary_accuracy: 0.5671 - val_loss: 0.6931 - val_binary_accuracy: 0.5396\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6854 - binary_accuracy: 0.5792 - val_loss: 0.6941 - val_binary_accuracy: 0.5324\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6818 - binary_accuracy: 0.5912 - val_loss: 0.6922 - val_binary_accuracy: 0.5540\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6784 - binary_accuracy: 0.5892 - val_loss: 0.6914 - val_binary_accuracy: 0.5468\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6753 - binary_accuracy: 0.6032 - val_loss: 0.6901 - val_binary_accuracy: 0.5683\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6733 - binary_accuracy: 0.6112 - val_loss: 0.6935 - val_binary_accuracy: 0.5180\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6696 - binary_accuracy: 0.6192 - val_loss: 0.6910 - val_binary_accuracy: 0.5180\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6669 - binary_accuracy: 0.6192 - val_loss: 0.6876 - val_binary_accuracy: 0.5540\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6644 - binary_accuracy: 0.6273 - val_loss: 0.6896 - val_binary_accuracy: 0.5540\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6617 - binary_accuracy: 0.6273 - val_loss: 0.6899 - val_binary_accuracy: 0.5540\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6592 - binary_accuracy: 0.6253 - val_loss: 0.6869 - val_binary_accuracy: 0.5755\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6562 - binary_accuracy: 0.6393 - val_loss: 0.6887 - val_binary_accuracy: 0.5540\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6535 - binary_accuracy: 0.6353 - val_loss: 0.6899 - val_binary_accuracy: 0.5540\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6514 - binary_accuracy: 0.6433 - val_loss: 0.6908 - val_binary_accuracy: 0.5540\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6490 - binary_accuracy: 0.6713 - val_loss: 0.6947 - val_binary_accuracy: 0.5396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15848beb0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_cr_40.shape[1]\n",
    "n_features = X_train_cr_40.shape[2]\n",
    "\n",
    "model2_3_cr = Sequential()\n",
    "model2_3_cr.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model2_3_cr.add(Flatten())\n",
    "model2_3_cr.add(Dense(25, activation='relu')) \n",
    "model2_3_cr.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2_3_cr.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model2_3_cr.fit(X_train_cr_40, train_5w,epochs=30,  validation_data=(X_val_cr_40, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e994ea9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat2_3_cr = model2_3_cr.predict(X_test_cr_40)\n",
    "y_hat2_3_cr = y_hat2_3_cr > .5\n",
    "metrics.accuracy_score(test_5w,y_hat2_3_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "26ddd69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 31ms/step - loss: 0.7283 - binary_accuracy: 0.4830 - val_loss: 0.7159 - val_binary_accuracy: 0.4604\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.7066 - binary_accuracy: 0.5210 - val_loss: 0.7024 - val_binary_accuracy: 0.4964\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6998 - binary_accuracy: 0.5090 - val_loss: 0.6958 - val_binary_accuracy: 0.5180\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6936 - binary_accuracy: 0.5170 - val_loss: 0.6936 - val_binary_accuracy: 0.5180\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6885 - binary_accuracy: 0.5271 - val_loss: 0.6925 - val_binary_accuracy: 0.5180\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6835 - binary_accuracy: 0.5411 - val_loss: 0.6917 - val_binary_accuracy: 0.5108\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6798 - binary_accuracy: 0.5591 - val_loss: 0.6902 - val_binary_accuracy: 0.5108\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6758 - binary_accuracy: 0.5752 - val_loss: 0.6891 - val_binary_accuracy: 0.5108\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6725 - binary_accuracy: 0.5872 - val_loss: 0.6885 - val_binary_accuracy: 0.4964\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6698 - binary_accuracy: 0.5952 - val_loss: 0.6869 - val_binary_accuracy: 0.4964\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6669 - binary_accuracy: 0.6052 - val_loss: 0.6919 - val_binary_accuracy: 0.5180\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6630 - binary_accuracy: 0.6072 - val_loss: 0.6877 - val_binary_accuracy: 0.4820\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6595 - binary_accuracy: 0.6172 - val_loss: 0.6875 - val_binary_accuracy: 0.4964\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6564 - binary_accuracy: 0.6212 - val_loss: 0.6892 - val_binary_accuracy: 0.5252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x158783640>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_cr_55.shape[1]\n",
    "n_features = X_train_cr_55.shape[2]\n",
    "\n",
    "model2_4_cr = Sequential()\n",
    "model2_4_cr.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model2_4_cr.add(Flatten())\n",
    "model2_4_cr.add(Dense(25, activation='relu')) \n",
    "model2_4_cr.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2_4_cr.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model2_4_cr.fit(X_train_cr_55, train_5w,epochs=30,  validation_data=(X_val_cr_55, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "68c28a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat2_4_cr = model2_4_cr.predict(X_test_cr_55)\n",
    "y_hat2_4_cr = y_hat2_4_cr > .5\n",
    "metrics.accuracy_score(test_5w,y_hat2_4_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "84c605eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 25ms/step - loss: 0.7186 - binary_accuracy: 0.4850 - val_loss: 0.7379 - val_binary_accuracy: 0.4173\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7041 - binary_accuracy: 0.4850 - val_loss: 0.7220 - val_binary_accuracy: 0.4173\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6972 - binary_accuracy: 0.4850 - val_loss: 0.7125 - val_binary_accuracy: 0.4173\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6933 - binary_accuracy: 0.4830 - val_loss: 0.7074 - val_binary_accuracy: 0.4173\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6909 - binary_accuracy: 0.4810 - val_loss: 0.7023 - val_binary_accuracy: 0.4029\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6895 - binary_accuracy: 0.5030 - val_loss: 0.6999 - val_binary_accuracy: 0.4245\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6887 - binary_accuracy: 0.5210 - val_loss: 0.6970 - val_binary_accuracy: 0.4460\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6876 - binary_accuracy: 0.5611 - val_loss: 0.6966 - val_binary_accuracy: 0.4317\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6870 - binary_accuracy: 0.5531 - val_loss: 0.6960 - val_binary_accuracy: 0.4317\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6866 - binary_accuracy: 0.5731 - val_loss: 0.6948 - val_binary_accuracy: 0.4748\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6857 - binary_accuracy: 0.5792 - val_loss: 0.6955 - val_binary_accuracy: 0.4676\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6851 - binary_accuracy: 0.5892 - val_loss: 0.6949 - val_binary_accuracy: 0.4748\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6847 - binary_accuracy: 0.5852 - val_loss: 0.6965 - val_binary_accuracy: 0.4820\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6835 - binary_accuracy: 0.5912 - val_loss: 0.6957 - val_binary_accuracy: 0.4964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5147058823529411"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 3_1 - 3_4, adding layers\n",
    "n_steps = X_train_cr_10.shape[1]\n",
    "n_features = X_train_cr_10.shape[2]\n",
    "\n",
    "model3_1_cr = Sequential()\n",
    "model3_1_cr.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model3_1_cr.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model3_1_cr.add(MaxPooling1D(pool_size=2))\n",
    "model3_1_cr.add(Flatten())\n",
    "model3_1_cr.add(Dense(8, activation='relu')) \n",
    "model3_1_cr.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3_1_cr.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model3_1_cr.fit(X_train_cr_10, train_5w,epochs=30,  validation_data=(X_val_cr_10, val_5w), callbacks = [early_stopping_monitor])\n",
    "y_hat3_1_cr = model3_1_cr.predict(X_test_cr_10)\n",
    "y_hat3_1_cr = y_hat3_1_cr > .5\n",
    "metrics.accuracy_score(test_5w,y_hat3_1_cr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d4e97456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 19ms/step - loss: 0.6936 - binary_accuracy: 0.5070 - val_loss: 0.6914 - val_binary_accuracy: 0.5036\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6915 - binary_accuracy: 0.5291 - val_loss: 0.6909 - val_binary_accuracy: 0.5683\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6898 - binary_accuracy: 0.5631 - val_loss: 0.6890 - val_binary_accuracy: 0.5612\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6876 - binary_accuracy: 0.5852 - val_loss: 0.6900 - val_binary_accuracy: 0.5468\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6853 - binary_accuracy: 0.5952 - val_loss: 0.6886 - val_binary_accuracy: 0.5468\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6827 - binary_accuracy: 0.5952 - val_loss: 0.6891 - val_binary_accuracy: 0.5468\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.6795 - binary_accuracy: 0.6112 - val_loss: 0.6874 - val_binary_accuracy: 0.5396\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6766 - binary_accuracy: 0.6072 - val_loss: 0.6889 - val_binary_accuracy: 0.5324\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6735 - binary_accuracy: 0.6152 - val_loss: 0.6858 - val_binary_accuracy: 0.5468\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6689 - binary_accuracy: 0.6192 - val_loss: 0.6867 - val_binary_accuracy: 0.5468\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6657 - binary_accuracy: 0.6313 - val_loss: 0.6858 - val_binary_accuracy: 0.5683\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6598 - binary_accuracy: 0.6293 - val_loss: 0.6845 - val_binary_accuracy: 0.5540\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6548 - binary_accuracy: 0.6453 - val_loss: 0.6843 - val_binary_accuracy: 0.5683\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6490 - binary_accuracy: 0.6613 - val_loss: 0.6869 - val_binary_accuracy: 0.5540\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6428 - binary_accuracy: 0.6573 - val_loss: 0.6832 - val_binary_accuracy: 0.5540\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6361 - binary_accuracy: 0.6453 - val_loss: 0.6858 - val_binary_accuracy: 0.5540\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6287 - binary_accuracy: 0.6794 - val_loss: 0.6856 - val_binary_accuracy: 0.5396\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6218 - binary_accuracy: 0.6874 - val_loss: 0.6916 - val_binary_accuracy: 0.5468\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6145 - binary_accuracy: 0.6874 - val_loss: 0.6927 - val_binary_accuracy: 0.5252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4264705882352941"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_cr_25.shape[1]\n",
    "n_features = X_train_cr_25.shape[2]\n",
    "\n",
    "model3_2_cr = Sequential()\n",
    "model3_2_cr.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model3_2_cr.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model3_2_cr.add(MaxPooling1D(pool_size=2))\n",
    "model3_2_cr.add(Flatten())\n",
    "model3_2_cr.add(Dense(25, activation='relu')) \n",
    "model3_2_cr.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3_2_cr.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model3_2_cr.fit(X_train_cr_25, train_5w,epochs=30,  validation_data=(X_val_cr_25, val_5w), callbacks = [early_stopping_monitor])\n",
    "y_hat3_2_cr = model3_2_cr.predict(X_test_cr_25)\n",
    "y_hat3_2_cr = y_hat3_2_cr > .5\n",
    "metrics.accuracy_score(test_5w,y_hat3_2_cr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d2679fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 18ms/step - loss: 0.6957 - binary_accuracy: 0.4890 - val_loss: 0.6913 - val_binary_accuracy: 0.5036\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6876 - binary_accuracy: 0.5651 - val_loss: 0.6930 - val_binary_accuracy: 0.4964\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6831 - binary_accuracy: 0.5691 - val_loss: 0.6919 - val_binary_accuracy: 0.5324\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6795 - binary_accuracy: 0.5772 - val_loss: 0.6902 - val_binary_accuracy: 0.5324\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6747 - binary_accuracy: 0.6132 - val_loss: 0.6935 - val_binary_accuracy: 0.4892\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6700 - binary_accuracy: 0.6333 - val_loss: 0.6930 - val_binary_accuracy: 0.5036\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6641 - binary_accuracy: 0.6373 - val_loss: 0.6906 - val_binary_accuracy: 0.5324\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6579 - binary_accuracy: 0.6633 - val_loss: 0.6941 - val_binary_accuracy: 0.5036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4852941176470588"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "n_steps = X_train_cr_40.shape[1]\n",
    "n_features = X_train_cr_40.shape[2]\n",
    "\n",
    "model3_3_cr = Sequential()\n",
    "model3_3_cr.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model3_3_cr.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model3_3_cr.add(MaxPooling1D(pool_size=2))\n",
    "model3_3_cr.add(Flatten())\n",
    "model3_3_cr.add(Dense(25, activation='relu')) \n",
    "model3_3_cr.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3_3_cr.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model3_3_cr.fit(X_train_cr_40, train_5w,epochs=30,  validation_data=(X_val_cr_40, val_5w), callbacks = [early_stopping_monitor])\n",
    "y_hat3_3_cr = model3_3_cr.predict(X_test_cr_40)\n",
    "y_hat3_3_cr = y_hat3_3_cr > .5\n",
    "metrics.accuracy_score(test_5w,y_hat3_3_cr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "839a97bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 17ms/step - loss: 0.6983 - binary_accuracy: 0.5090 - val_loss: 0.6894 - val_binary_accuracy: 0.5899\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6943 - binary_accuracy: 0.5271 - val_loss: 0.6895 - val_binary_accuracy: 0.6043\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6929 - binary_accuracy: 0.5291 - val_loss: 0.6910 - val_binary_accuracy: 0.5683\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6914 - binary_accuracy: 0.5451 - val_loss: 0.6920 - val_binary_accuracy: 0.5396\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6904 - binary_accuracy: 0.5511 - val_loss: 0.6934 - val_binary_accuracy: 0.5108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5147058823529411"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_cr_55.shape[1]\n",
    "n_features = X_train_cr_55.shape[2]\n",
    "\n",
    "model3_4_cr = Sequential()\n",
    "model3_4_cr.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model3_4_cr.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model3_4_cr.add(MaxPooling1D(pool_size=2))\n",
    "model3_4_cr.add(Flatten())\n",
    "model3_4_cr.add(Dense(25, activation='relu')) \n",
    "model3_4_cr.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3_4_cr.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model3_4_cr.fit(X_train_cr_55, train_5w,epochs=30,  validation_data=(X_val_cr_55, val_5w), callbacks = [early_stopping_monitor])\n",
    "y_hat3_4_cr = model3_4_cr.predict(X_test_cr_55)\n",
    "y_hat3_4_cr = y_hat3_4_cr > .5\n",
    "metrics.accuracy_score(test_5w,y_hat3_4_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478f9482",
   "metadata": {},
   "source": [
    "# Changes to the Target Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ae54949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "X_train_kb_10, X_val_kb_10, X_test_kb_10 = kbest_creator(10, X_train.drop('target_3', axis=1), X_val.drop('target_3', axis=1), X_test.drop('target_3', axis=1)) \n",
    "X_train_kb_25, X_val_kb_25, X_test_kb_25 = kbest_creator(25, X_train.drop('target_3', axis=1), X_val.drop('target_3', axis=1), X_test.drop('target_3', axis=1)) \n",
    "X_train_kb_40, X_val_kb_40, X_test_kb_40 = kbest_creator(40, X_train.drop('target_3', axis=1), X_val.drop('target_3', axis=1), X_test.drop('target_3', axis=1)) \n",
    "X_train_kb_55, X_val_kb_55, X_test_kb_55 = kbest_creator(55, X_train.drop('target_3', axis=1), X_val.drop('target_3', axis=1), X_test.drop('target_3', axis=1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d12e59da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_X_y_mod(df, target, window_size=5):\n",
    "  # converts to matrix of numpy arrays\n",
    "  X = []\n",
    "  y = []\n",
    "  for i in range(len(df)-window_size): # length of data frame - window_size so it does't take empty values at the end, \n",
    "    # does force you to loose the last 5 values, could fix with padding\n",
    "    row = [r for r in df[i:i+window_size]] # grabs row i and all rows above within the window size length\n",
    "    X.append(row) # creates 3 dimentional array, (# obseravtions, # rows in window, # features)\n",
    "    label = target[i+window_size-1] # pulls the target variable after the window, target varible needs to be column zero in this \n",
    "    y.append(label) # returns (N,) martix of targets i+window_length time periods away\n",
    "  return np.array(X), np.array(y)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "72d79d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to window format, in this case 5 periods\n",
    "X_train_kb_40, train_5w = df_to_X_y2(X_train_kb_40,y_train)\n",
    "X_val_kb_40, val_5w = df_to_X_y2(X_val_kb_40, y_val)\n",
    "X_test_kb_40, test_5w = df_to_X_y2(X_test_kb_40,y_test) \n",
    "\n",
    "X_train_kb_10, _ = df_to_X_y2(X_train_kb_10,y_train)\n",
    "X_val_kb_10, _ = df_to_X_y2(X_val_kb_10, y_val)\n",
    "X_test_kb_10, _ = df_to_X_y2(X_test_kb_10,y_test) \n",
    "\n",
    "X_train_kb_25, _ = df_to_X_y2(X_train_kb_25,y_train)\n",
    "X_val_kb_25, _ = df_to_X_y2(X_val_kb_25, y_val)\n",
    "X_test_kb_25, _ = df_to_X_y2(X_test_kb_25,y_test) \n",
    "\n",
    "X_train_kb_55, _ = df_to_X_y2(X_train_kb_55,y_train)\n",
    "X_val_kb_55, _ = df_to_X_y2(X_val_kb_55, y_val)\n",
    "X_test_kb_55, _ = df_to_X_y2(X_test_kb_55,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "10acaa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 21ms/step - loss: 0.6954 - binary_accuracy: 0.4830 - val_loss: 0.6984 - val_binary_accuracy: 0.4173\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6933 - binary_accuracy: 0.4930 - val_loss: 0.6945 - val_binary_accuracy: 0.4604\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6923 - binary_accuracy: 0.5170 - val_loss: 0.6937 - val_binary_accuracy: 0.5108\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6915 - binary_accuracy: 0.5431 - val_loss: 0.6934 - val_binary_accuracy: 0.5252\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6911 - binary_accuracy: 0.5752 - val_loss: 0.6940 - val_binary_accuracy: 0.5036\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6903 - binary_accuracy: 0.5772 - val_loss: 0.6915 - val_binary_accuracy: 0.5324\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6895 - binary_accuracy: 0.5832 - val_loss: 0.6942 - val_binary_accuracy: 0.5036\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6880 - binary_accuracy: 0.5912 - val_loss: 0.6944 - val_binary_accuracy: 0.5252\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6864 - binary_accuracy: 0.5912 - val_loss: 0.6953 - val_binary_accuracy: 0.5180\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6851 - binary_accuracy: 0.5852 - val_loss: 0.6947 - val_binary_accuracy: 0.5252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x158ff5ee0>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_25.shape[1]\n",
    "n_features = X_train_kb_25.shape[2]\n",
    "\n",
    "model_mod4 = Sequential()\n",
    "model_mod4.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model_mod4.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model_mod4.add(MaxPooling1D(pool_size=2))\n",
    "model_mod4.add(Conv1D(filters=16, kernel_size=1, activation='relu'))\n",
    "model_mod4.add(Flatten())\n",
    "model_mod4.add(Dense(25, activation='relu')) \n",
    "model_mod4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_mod4.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model_mod4.fit(X_train_kb_25, train_5w,epochs=30,  validation_data=(X_val_kb_25, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c39a79c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38235294117647056"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_mod4_kb = model_mod4.predict(X_test_kb_25)\n",
    "y_hat_mod4_kb = y_hat_mod4_kb > .5\n",
    "metrics.accuracy_score(test_5w,y_hat_mod4_kb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d3b1741a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 37ms/step - loss: 0.6943 - binary_accuracy: 0.4910 - val_loss: 0.7065 - val_binary_accuracy: 0.4460\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6899 - binary_accuracy: 0.5491 - val_loss: 0.6984 - val_binary_accuracy: 0.4388\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6872 - binary_accuracy: 0.5852 - val_loss: 0.6969 - val_binary_accuracy: 0.4532\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6856 - binary_accuracy: 0.5992 - val_loss: 0.6956 - val_binary_accuracy: 0.4676\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6842 - binary_accuracy: 0.5852 - val_loss: 0.6929 - val_binary_accuracy: 0.4748\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6831 - binary_accuracy: 0.5912 - val_loss: 0.6943 - val_binary_accuracy: 0.4820\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6812 - binary_accuracy: 0.5992 - val_loss: 0.6948 - val_binary_accuracy: 0.4748\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6797 - binary_accuracy: 0.6012 - val_loss: 0.6959 - val_binary_accuracy: 0.4748\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6780 - binary_accuracy: 0.6172 - val_loss: 0.6954 - val_binary_accuracy: 0.4820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x157d40c40>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mod3 = Sequential()\n",
    "model_mod3.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model_mod3.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model_mod3.add(MaxPooling1D(pool_size=2))\n",
    "model_mod3.add(Flatten())\n",
    "model_mod3.add(Dense(25, activation='relu')) \n",
    "model_mod3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_mod3.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model_mod3.fit(X_train_kb_25, train_5w,epochs=30,  validation_data=(X_val_kb_25, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d3532b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47058823529411764"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_mod3_kb = model_mod3.predict(X_test_kb_25)\n",
    "y_hat_mod3_kb = y_hat_mod3_kb > .5\n",
    "metrics.accuracy_score(test_5w,y_hat_mod3_kb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "09950897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 19ms/step - loss: 0.6991 - binary_accuracy: 0.4509 - val_loss: 0.7007 - val_binary_accuracy: 0.4245\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6945 - binary_accuracy: 0.4749 - val_loss: 0.6964 - val_binary_accuracy: 0.4748\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6916 - binary_accuracy: 0.5391 - val_loss: 0.6939 - val_binary_accuracy: 0.5108\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6897 - binary_accuracy: 0.5591 - val_loss: 0.6911 - val_binary_accuracy: 0.5324\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6876 - binary_accuracy: 0.5611 - val_loss: 0.6909 - val_binary_accuracy: 0.5540\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6857 - binary_accuracy: 0.5651 - val_loss: 0.6905 - val_binary_accuracy: 0.5468\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6837 - binary_accuracy: 0.5752 - val_loss: 0.6916 - val_binary_accuracy: 0.5468\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6816 - binary_accuracy: 0.5892 - val_loss: 0.6897 - val_binary_accuracy: 0.5683\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6790 - binary_accuracy: 0.5952 - val_loss: 0.6907 - val_binary_accuracy: 0.5396\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6773 - binary_accuracy: 0.5872 - val_loss: 0.6931 - val_binary_accuracy: 0.5468\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6750 - binary_accuracy: 0.5972 - val_loss: 0.6902 - val_binary_accuracy: 0.5612\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6719 - binary_accuracy: 0.5992 - val_loss: 0.6915 - val_binary_accuracy: 0.5468\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6694 - binary_accuracy: 0.5992 - val_loss: 0.6917 - val_binary_accuracy: 0.5683\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6668 - binary_accuracy: 0.5992 - val_loss: 0.6980 - val_binary_accuracy: 0.5324\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6629 - binary_accuracy: 0.6172 - val_loss: 0.6953 - val_binary_accuracy: 0.5755\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6600 - binary_accuracy: 0.6132 - val_loss: 0.6935 - val_binary_accuracy: 0.5612\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6565 - binary_accuracy: 0.6253 - val_loss: 0.6943 - val_binary_accuracy: 0.5612\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6534 - binary_accuracy: 0.6273 - val_loss: 0.6984 - val_binary_accuracy: 0.5612\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6511 - binary_accuracy: 0.6353 - val_loss: 0.7031 - val_binary_accuracy: 0.5540\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6475 - binary_accuracy: 0.6232 - val_loss: 0.7047 - val_binary_accuracy: 0.5540\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6451 - binary_accuracy: 0.6253 - val_loss: 0.7051 - val_binary_accuracy: 0.5612\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6417 - binary_accuracy: 0.6313 - val_loss: 0.7065 - val_binary_accuracy: 0.5540\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6395 - binary_accuracy: 0.6333 - val_loss: 0.7089 - val_binary_accuracy: 0.5540\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6374 - binary_accuracy: 0.6373 - val_loss: 0.7102 - val_binary_accuracy: 0.5612\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6348 - binary_accuracy: 0.6493 - val_loss: 0.7078 - val_binary_accuracy: 0.5540\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6312 - binary_accuracy: 0.6473 - val_loss: 0.7180 - val_binary_accuracy: 0.5683\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6285 - binary_accuracy: 0.6493 - val_loss: 0.7161 - val_binary_accuracy: 0.5612\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6251 - binary_accuracy: 0.6473 - val_loss: 0.7243 - val_binary_accuracy: 0.5612\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6231 - binary_accuracy: 0.6453 - val_loss: 0.7262 - val_binary_accuracy: 0.5540\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6203 - binary_accuracy: 0.6473 - val_loss: 0.7281 - val_binary_accuracy: 0.5612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x159508e20>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mod2 = Sequential()\n",
    "model_mod2.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model_mod2.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model_mod2.add(Flatten())\n",
    "model_mod2.add(Dense(25, activation='relu')) \n",
    "model_mod2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_mod2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model_mod2.fit(X_train_kb_25, train_5w,epochs=30,  validation_data=(X_val_kb_25, val_5w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "88ba84ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47058823529411764"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_mod2_kb = model_mod2.predict(X_test_kb_25)\n",
    "y_hat_mod2_kb = y_hat_mod2_kb > .5\n",
    "metrics.accuracy_score(test_5w,y_hat_mod2_kb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ba039765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 22ms/step - loss: 0.7098 - binary_accuracy: 0.5030 - val_loss: 0.7170 - val_binary_accuracy: 0.3957\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6922 - binary_accuracy: 0.5150 - val_loss: 0.7008 - val_binary_accuracy: 0.4604\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6856 - binary_accuracy: 0.5351 - val_loss: 0.6925 - val_binary_accuracy: 0.4964\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6808 - binary_accuracy: 0.5591 - val_loss: 0.6899 - val_binary_accuracy: 0.5755\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6769 - binary_accuracy: 0.5792 - val_loss: 0.6925 - val_binary_accuracy: 0.5540\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6726 - binary_accuracy: 0.5852 - val_loss: 0.6908 - val_binary_accuracy: 0.5612\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6699 - binary_accuracy: 0.6012 - val_loss: 0.6930 - val_binary_accuracy: 0.5396\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6663 - binary_accuracy: 0.6072 - val_loss: 0.6906 - val_binary_accuracy: 0.5612\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6626 - binary_accuracy: 0.6152 - val_loss: 0.6930 - val_binary_accuracy: 0.5540\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6600 - binary_accuracy: 0.6253 - val_loss: 0.6953 - val_binary_accuracy: 0.5468\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6574 - binary_accuracy: 0.6353 - val_loss: 0.6934 - val_binary_accuracy: 0.5468\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6542 - binary_accuracy: 0.6513 - val_loss: 0.6967 - val_binary_accuracy: 0.5683\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6517 - binary_accuracy: 0.6513 - val_loss: 0.7008 - val_binary_accuracy: 0.5755\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6485 - binary_accuracy: 0.6613 - val_loss: 0.6994 - val_binary_accuracy: 0.5899\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6455 - binary_accuracy: 0.6633 - val_loss: 0.7036 - val_binary_accuracy: 0.5612\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6435 - binary_accuracy: 0.6633 - val_loss: 0.7016 - val_binary_accuracy: 0.5755\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6401 - binary_accuracy: 0.6733 - val_loss: 0.7119 - val_binary_accuracy: 0.5683\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6381 - binary_accuracy: 0.6774 - val_loss: 0.7090 - val_binary_accuracy: 0.5468\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6344 - binary_accuracy: 0.6814 - val_loss: 0.7122 - val_binary_accuracy: 0.5468\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6319 - binary_accuracy: 0.6754 - val_loss: 0.7138 - val_binary_accuracy: 0.5468\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.6288 - binary_accuracy: 0.6834 - val_loss: 0.7147 - val_binary_accuracy: 0.5540\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6268 - binary_accuracy: 0.6794 - val_loss: 0.7170 - val_binary_accuracy: 0.5396\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6238 - binary_accuracy: 0.6814 - val_loss: 0.7241 - val_binary_accuracy: 0.5180\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6210 - binary_accuracy: 0.6854 - val_loss: 0.7232 - val_binary_accuracy: 0.5252\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6181 - binary_accuracy: 0.6834 - val_loss: 0.7256 - val_binary_accuracy: 0.5324\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6154 - binary_accuracy: 0.6874 - val_loss: 0.7254 - val_binary_accuracy: 0.5180\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6131 - binary_accuracy: 0.6814 - val_loss: 0.7309 - val_binary_accuracy: 0.5324\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6102 - binary_accuracy: 0.6834 - val_loss: 0.7314 - val_binary_accuracy: 0.5324\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6086 - binary_accuracy: 0.6934 - val_loss: 0.7291 - val_binary_accuracy: 0.5396\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6053 - binary_accuracy: 0.6934 - val_loss: 0.7359 - val_binary_accuracy: 0.5324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1596a0d30>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mod1 = Sequential()\n",
    "model_mod1.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model_mod1.add(Flatten())\n",
    "model_mod1.add(Dense(25, activation='relu')) \n",
    "model_mod1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_mod1.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model_mod1.fit(X_train_kb_25, train_5w,epochs=30,  validation_data=(X_val_kb_25, val_5w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "89178642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_mod1_kb = model_mod1.predict(X_test_kb_25)\n",
    "y_hat_mod1_kb = y_hat_mod1_kb > .5\n",
    "metrics.accuracy_score(test_5w,y_hat_mod1_kb)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
