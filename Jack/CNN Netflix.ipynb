{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dba26a6-1827-4e08-ba17-ddefa8156a12",
   "metadata": {},
   "source": [
    "# CNN Netflix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5000c067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense, Normalization\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, InputLayer, SimpleRNN\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn import (\n",
    "    linear_model, metrics, neural_network, pipeline, model_selection\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "# %pip install -q -U keras-tuner\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f13dc36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Netflix. Inc</th>\n",
       "      <th>Netflix_x</th>\n",
       "      <th>Netflix Stock</th>\n",
       "      <th>Streaming media</th>\n",
       "      <th>Reed Hastings_x</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>...</th>\n",
       "      <th>Dow_MAvg_s_Move</th>\n",
       "      <th>Dow_EMA_Move</th>\n",
       "      <th>Dow_Disparity_Move</th>\n",
       "      <th>Dow_Disparity_s_Move</th>\n",
       "      <th>Dow_RSI_Move</th>\n",
       "      <th>target_1</th>\n",
       "      <th>target_2</th>\n",
       "      <th>target_3</th>\n",
       "      <th>target_4</th>\n",
       "      <th>target_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Netflix. Inc  Netflix_x  Netflix Stock  Streaming media  Reed Hastings_x  \\\n",
       "0             0          0              0                0                0   \n",
       "\n",
       "   Open  High  Low  Close  Volume  ...  Dow_MAvg_s_Move  Dow_EMA_Move  \\\n",
       "0     0     0    0      0       0  ...                0             0   \n",
       "\n",
       "   Dow_Disparity_Move  Dow_Disparity_s_Move  Dow_RSI_Move  target_1  target_2  \\\n",
       "0                   0                     0             0         0         0   \n",
       "\n",
       "   target_3  target_4  target_5  \n",
       "0         0         0         0  \n",
       "\n",
       "[1 rows x 161 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Netflix = pd.read_csv(\"/Users/jackbrennan/Documents/GitHub/Stock-Predictions/Alex/Netflix_model_ready.csv\")\n",
    "Netflix.date = pd.to_datetime(Netflix.date)\n",
    "Netflix = Netflix.set_index(\"date\")\n",
    "Netflix = Netflix.drop([\"Nas_total\", 'Stock_total', 'Dow_total'],axis=1) # to remove duplicated columns\n",
    "pd.DataFrame(Netflix.isna().sum()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01c88f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "Netflix = Netflix.dropna()\n",
    "Netflix = Netflix[~(Netflix.isin([np.inf, -np.inf]).any(axis=1))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23c9fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Netflix = Netflix.drop(['target_1', 'target_2', 'target_4', 'target_5'], axis=1)\n",
    "target_3 = Netflix[\"target_3\"]\n",
    "\n",
    "#splitting into training sets \n",
    "column_indices = {name: i for i, name in enumerate(Netflix.columns)}\n",
    "\n",
    "n = len(Netflix)\n",
    "X_train = Netflix[0:int(n*0.7)]\n",
    "X_val = Netflix[int(n*0.7):int(n*0.9)]\n",
    "X_test = Netflix[int(n*0.9):]\n",
    "\n",
    "y_train = target_3[0:int(n*0.7)]\n",
    "y_val = target_3[int(n*0.7):int(n*0.9)]\n",
    "y_test = target_3[int(n*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37634713",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mscaler = MinMaxScaler() # keeps binarys at zero and 1 :)\n",
    "\n",
    "X_train = pd.DataFrame(Mscaler.fit_transform(X_train), columns = Netflix.columns)\n",
    "X_val = pd.DataFrame(Mscaler.fit_transform(X_val), columns = Netflix.columns)\n",
    "X_test = pd.DataFrame(Mscaler.fit_transform(X_test), columns = Netflix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f734d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kbest_creator(k, df, df_val, df_test):\n",
    "    \"\"\"\n",
    "    returns data frame of principle componets of # of k best features \n",
    "    \"\"\"\n",
    "    # apply SelectKBest class to extract top 40 best features\n",
    "    bestfeatures = SelectKBest(score_func=f_regression, k=k)\n",
    "    best_fit = bestfeatures.fit(df, y_train)\n",
    "    best_scores = pd.DataFrame(best_fit.scores_)\n",
    "    best_columns = pd.DataFrame(Netflix.columns)\n",
    "    \n",
    "    # concatenate the dataframes for better visualization\n",
    "    features_score = pd.concat([best_columns, best_scores], axis=1)\n",
    "    features_score.columns = ['Features', 'Score']  # naming the dataframe columns\n",
    "    feats_kb = list(features_score.nlargest(k, 'Score').iloc[1:k]['Features'])\n",
    "\n",
    "    pca = PCA().fit(df[feats_kb])\n",
    "    pca_scores = np.cumsum(pca.explained_variance_ratio_) * 100\n",
    "    res = next(x for x, val in enumerate(pca_scores) if val > 85)\n",
    "    res = res + 1\n",
    "    res\n",
    "    \n",
    "    pca_kb_1 = PCA(n_components = res).fit(df[feats_kb].to_numpy())\n",
    "    df = pca_kb_1.transform(df[feats_kb].to_numpy())\n",
    "    df_val = pca_kb_1.transform(df_val[feats_kb].to_numpy())\n",
    "    df_test = pca_kb_1.transform(df_test[feats_kb].to_numpy())\n",
    "    return df, df_val, df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0df7665c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "X_train_kb_10, X_val_kb_10, X_test_kb_10 = kbest_creator(10, X_train, X_val, X_test) \n",
    "X_train_kb_25, X_val_kb_25, X_test_kb_25 = kbest_creator(25, X_train, X_val, X_test) \n",
    "X_train_kb_40, X_val_kb_40, X_test_kb_40 = kbest_creator(40, X_train, X_val, X_test) \n",
    "X_train_kb_55, X_val_kb_55, X_test_kb_55 = kbest_creator(55, X_train, X_val, X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce1f947",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "802d7e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0c8d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_X_y2(df, target, window_size=5):\n",
    "  # converts to matrix of numpy arrays\n",
    "  X = []\n",
    "  y = []\n",
    "  for i in range(len(df)-window_size): # length of data frame - window_size so it does't take empty values at the end, \n",
    "    # does force you to loose the last 5 values, could fix with padding\n",
    "    row = [r for r in df[i:i+window_size]] # grabs row i and all rows above within the window size length\n",
    "    X.append(row) # creates 3 dimentional array, (# obseravtions, # rows in window, # features)\n",
    "    label = target[i+window_size] # pulls the target variable after the window, target varible needs to be column zero in this \n",
    "    y.append(label) # returns (N,) martix of targets i+window_length time periods away\n",
    "  return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9a67462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to window format, in this case 5 periods\n",
    "X_train_kb_40, train_5w = df_to_X_y2(X_train_kb_40,y_train)\n",
    "X_val_kb_40, val_5w = df_to_X_y2(X_val_kb_40, y_val)\n",
    "X_test_kb_40, test_5w = df_to_X_y2(X_test_kb_40,y_test) \n",
    "\n",
    "X_train_kb_10, _ = df_to_X_y2(X_train_kb_10,y_train)\n",
    "X_val_kb_10, _ = df_to_X_y2(X_val_kb_10, y_val)\n",
    "X_test_kb_10, _ = df_to_X_y2(X_test_kb_10,y_test) \n",
    "\n",
    "X_train_kb_25, _ = df_to_X_y2(X_train_kb_25,y_train)\n",
    "X_val_kb_25, _ = df_to_X_y2(X_val_kb_25, y_val)\n",
    "X_test_kb_25, _ = df_to_X_y2(X_test_kb_25,y_test) \n",
    "\n",
    "X_train_kb_55, _ = df_to_X_y2(X_train_kb_55,y_train)\n",
    "X_val_kb_55, _ = df_to_X_y2(X_val_kb_55, y_val)\n",
    "X_test_kb_55, _ = df_to_X_y2(X_test_kb_55,y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa349c0e",
   "metadata": {},
   "source": [
    "### Model Format 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a7206c",
   "metadata": {},
   "source": [
    "## Hyper Parameter tuned Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2a6a4c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project ./untitled_project/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from ./untitled_project/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Model 1_1 - 1_4, using differnt k best pca variables\n",
    "\n",
    "def model_builder_1_1(hp):\n",
    "    n_steps = X_train_kb_10.shape[1]\n",
    "    n_features = X_train_kb_10.shape[2]\n",
    "\n",
    "    model1_1 = Sequential()\n",
    "\n",
    "    hp_filters = hp.Int('units', min_value=4, max_value=128, step=4)\n",
    "    hp_units = hp.Int('units', min_value=5, max_value=100, step=10)\n",
    "    model1_1.add(Conv1D(filters=hp_filters, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "    model1_1.add(Flatten())\n",
    "    model1_1.add(Dense(units = hp_units, activation='relu')) \n",
    "    model1_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model1_1.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "    return model1_1\n",
    "\n",
    "tuner = kt.Hyperband(model_builder_1_1,\n",
    "                     objective='val_binary_accuracy',\n",
    "                     max_epochs=30,\n",
    "                     factor=3,\n",
    "                     # directory='my_dir',    don't know what to do with this for now\n",
    "                     # project_name='intro_to_kt' # sasme with this\n",
    "                     )\n",
    "\n",
    "tuner.search(X_train_kb_10, train_5w, epochs=50, validation_data=(X_val_kb_10, val_5w), callbacks = [early_stopping_monitor])\n",
    "\n",
    "#model1_1.fit(X_train_kb_10, train_5w,epochs=30,  validation_data=(X_val_kb_10, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eb7daaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_tuner.engine.hyperparameters.HyperParameters at 0x15b2622e0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2e006937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 17ms/step - loss: 0.6945 - binary_accuracy: 0.5170 - val_loss: 0.6958 - val_binary_accuracy: 0.4964\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6854 - binary_accuracy: 0.5731 - val_loss: 0.6912 - val_binary_accuracy: 0.5324\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6800 - binary_accuracy: 0.5812 - val_loss: 0.6964 - val_binary_accuracy: 0.4964\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6762 - binary_accuracy: 0.5671 - val_loss: 0.6950 - val_binary_accuracy: 0.5180\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6728 - binary_accuracy: 0.5852 - val_loss: 0.6975 - val_binary_accuracy: 0.4820\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6691 - binary_accuracy: 0.5912 - val_loss: 0.6964 - val_binary_accuracy: 0.5396\n"
     ]
    }
   ],
   "source": [
    "model_1_1 = tuner.hypermodel.build(best_hps)\n",
    "history = model_1_1.fit(X_train_kb_10, train_5w, epochs=30, validation_data=(X_val_kb_10, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7994a832",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat1_1 = model_1_1.predict(X_test_kb_10)\n",
    "y_hat1_1 = y_hat1_1 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e3ae82",
   "metadata": {},
   "source": [
    "## Normal Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9fc525f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 37ms/step - loss: 0.6976 - binary_accuracy: 0.4950 - val_loss: 0.7011 - val_binary_accuracy: 0.4532\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6889 - binary_accuracy: 0.5150 - val_loss: 0.6971 - val_binary_accuracy: 0.4676\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6860 - binary_accuracy: 0.5972 - val_loss: 0.6936 - val_binary_accuracy: 0.5540\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6826 - binary_accuracy: 0.5892 - val_loss: 0.6997 - val_binary_accuracy: 0.4676\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6792 - binary_accuracy: 0.6012 - val_loss: 0.6988 - val_binary_accuracy: 0.4820\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6774 - binary_accuracy: 0.6253 - val_loss: 0.6955 - val_binary_accuracy: 0.5396\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6742 - binary_accuracy: 0.6132 - val_loss: 0.7002 - val_binary_accuracy: 0.5036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15d8cc7f0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_10.shape[1]\n",
    "n_features = X_train_kb_10.shape[2]\n",
    "\n",
    "model1_1 = Sequential()\n",
    "\n",
    "\n",
    "model1_1.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model1_1.add(Flatten())\n",
    "model1_1.add(Dense(units = 15, activation='relu')) \n",
    "model1_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1_1.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model1_1.fit(X_train_kb_10, train_5w,epochs=30,  validation_data=(X_val_kb_10, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "540bf1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4117647058823529"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat1_1 = model1_1.predict(X_test_kb_10)\n",
    "y_hat1_1 = y_hat1_1 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c962f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 21ms/step - loss: 0.6915 - binary_accuracy: 0.5210 - val_loss: 0.6943 - val_binary_accuracy: 0.4892\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6767 - binary_accuracy: 0.6072 - val_loss: 0.7018 - val_binary_accuracy: 0.4532\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6657 - binary_accuracy: 0.6232 - val_loss: 0.6993 - val_binary_accuracy: 0.5252\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6563 - binary_accuracy: 0.6513 - val_loss: 0.7036 - val_binary_accuracy: 0.5180\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6471 - binary_accuracy: 0.6553 - val_loss: 0.7116 - val_binary_accuracy: 0.4964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15923d2b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_25.shape[1]\n",
    "n_features = X_train_kb_25.shape[2]\n",
    "\n",
    "model1_2 = Sequential()\n",
    "model1_2.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model1_2.add(Flatten())\n",
    "model1_2.add(Dense(25, activation='relu')) \n",
    "model1_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model1_2.fit(X_train_kb_25, train_5w,epochs=30,  validation_data=(X_val_kb_25, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa3d1fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat1_2 = model1_2.predict(X_test_kb_25)\n",
    "y_hat1_2 = y_hat1_2 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24e0ad96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 15ms/step - loss: 0.6985 - binary_accuracy: 0.4830 - val_loss: 0.6870 - val_binary_accuracy: 0.5396\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6827 - binary_accuracy: 0.5531 - val_loss: 0.6939 - val_binary_accuracy: 0.4964\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6721 - binary_accuracy: 0.5872 - val_loss: 0.6981 - val_binary_accuracy: 0.4964\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6621 - binary_accuracy: 0.6273 - val_loss: 0.7025 - val_binary_accuracy: 0.4604\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6544 - binary_accuracy: 0.6573 - val_loss: 0.7095 - val_binary_accuracy: 0.4245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1593f2f40>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_40.shape[1]\n",
    "n_features = X_train_kb_40.shape[2]\n",
    "\n",
    "model1_3 = Sequential()\n",
    "model1_3.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model1_3.add(Flatten())\n",
    "model1_3.add(Dense(25, activation='relu')) \n",
    "model1_3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1_3.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model1_3.fit(X_train_kb_40, train_5w,epochs=30,  validation_data=(X_val_kb_40, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd22db0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45588235294117646"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat1_3 = model1_3.predict(X_test_kb_40)\n",
    "y_hat1_3 = y_hat1_3 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat1_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26ddd69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 14ms/step - loss: 0.6960 - binary_accuracy: 0.4910 - val_loss: 0.6812 - val_binary_accuracy: 0.5971\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6797 - binary_accuracy: 0.5892 - val_loss: 0.6823 - val_binary_accuracy: 0.5396\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6707 - binary_accuracy: 0.6212 - val_loss: 0.6810 - val_binary_accuracy: 0.5540\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6589 - binary_accuracy: 0.6733 - val_loss: 0.6908 - val_binary_accuracy: 0.5612\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6488 - binary_accuracy: 0.6994 - val_loss: 0.6868 - val_binary_accuracy: 0.5180\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6372 - binary_accuracy: 0.7134 - val_loss: 0.6897 - val_binary_accuracy: 0.5036\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6292 - binary_accuracy: 0.7134 - val_loss: 0.6896 - val_binary_accuracy: 0.5180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x159547cd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_55.shape[1]\n",
    "n_features = X_train_kb_55.shape[2]\n",
    "\n",
    "model1_4 = Sequential()\n",
    "model1_4.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model1_4.add(Flatten())\n",
    "model1_4.add(Dense(25, activation='relu')) \n",
    "model1_4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1_4.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model1_4.fit(X_train_kb_55, train_5w,epochs=30,  validation_data=(X_val_kb_55, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c8dd064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4264705882352941"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat1_4 = model1_4.predict(X_test_kb_55)\n",
    "y_hat1_4 = y_hat1_4 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat1_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80642814",
   "metadata": {},
   "source": [
    "### Model 2, Less Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a6a4c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 15ms/step - loss: 0.7050 - binary_accuracy: 0.4790 - val_loss: 0.7037 - val_binary_accuracy: 0.4388\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6982 - binary_accuracy: 0.4609 - val_loss: 0.6931 - val_binary_accuracy: 0.5324\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6940 - binary_accuracy: 0.4629 - val_loss: 0.6897 - val_binary_accuracy: 0.5540\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6918 - binary_accuracy: 0.5050 - val_loss: 0.6886 - val_binary_accuracy: 0.5683\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6906 - binary_accuracy: 0.5230 - val_loss: 0.6873 - val_binary_accuracy: 0.6115\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6895 - binary_accuracy: 0.5511 - val_loss: 0.6883 - val_binary_accuracy: 0.5899\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6882 - binary_accuracy: 0.5651 - val_loss: 0.6878 - val_binary_accuracy: 0.5683\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6877 - binary_accuracy: 0.5832 - val_loss: 0.6881 - val_binary_accuracy: 0.5755\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6862 - binary_accuracy: 0.5992 - val_loss: 0.6883 - val_binary_accuracy: 0.5683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x159667cd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 2_1 - 2_4, using differnt k best pca variables. reduced filters\n",
    "n_steps = X_train_kb_10.shape[1]\n",
    "n_features = X_train_kb_10.shape[2]\n",
    "\n",
    "model2_1 = Sequential()\n",
    "model2_1.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model2_1.add(Flatten())\n",
    "model2_1.add(Dense(25, activation='relu')) \n",
    "model2_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2_1.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model2_1.fit(X_train_kb_10, train_5w,epochs=30,  validation_data=(X_val_kb_10, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "929becef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1596474c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.39705882352941174"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat2_1 = model2_1.predict(X_test_kb_10)\n",
    "y_hat2_1 = y_hat2_1 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat2_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c962f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 18ms/step - loss: 0.7033 - binary_accuracy: 0.5010 - val_loss: 0.6965 - val_binary_accuracy: 0.5324\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6971 - binary_accuracy: 0.5130 - val_loss: 0.6989 - val_binary_accuracy: 0.4892\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6922 - binary_accuracy: 0.5371 - val_loss: 0.7018 - val_binary_accuracy: 0.4820\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6891 - binary_accuracy: 0.5391 - val_loss: 0.7021 - val_binary_accuracy: 0.4964\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.6854 - binary_accuracy: 0.5531 - val_loss: 0.7048 - val_binary_accuracy: 0.4820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1597dac70>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_25.shape[1]\n",
    "n_features = X_train_kb_25.shape[2]\n",
    "\n",
    "model2_2 = Sequential()\n",
    "model2_2.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model2_2.add(Flatten())\n",
    "model2_2.add(Dense(25, activation='relu')) \n",
    "model2_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model2_2.fit(X_train_kb_25, train_5w,epochs=30,  validation_data=(X_val_kb_25, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4021da90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x15990f280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4852941176470588"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat2_2 = model2_2.predict(X_test_kb_25)\n",
    "y_hat2_2 = y_hat2_2 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24e0ad96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 28ms/step - loss: 0.7029 - binary_accuracy: 0.5391 - val_loss: 0.6812 - val_binary_accuracy: 0.5252\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6959 - binary_accuracy: 0.5271 - val_loss: 0.6854 - val_binary_accuracy: 0.5324\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6901 - binary_accuracy: 0.5451 - val_loss: 0.6873 - val_binary_accuracy: 0.5612\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6872 - binary_accuracy: 0.5531 - val_loss: 0.6895 - val_binary_accuracy: 0.5252\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6841 - binary_accuracy: 0.5752 - val_loss: 0.6913 - val_binary_accuracy: 0.5540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1598ca0d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_40.shape[1]\n",
    "n_features = X_train_kb_40.shape[2]\n",
    "\n",
    "model2_3 = Sequential()\n",
    "model2_3.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model2_3.add(Flatten())\n",
    "model2_3.add(Dense(25, activation='relu')) \n",
    "model2_3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2_3.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model2_3.fit(X_train_kb_40, train_5w,epochs=30,  validation_data=(X_val_kb_40, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e994ea9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45588235294117646"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat2_3 = model2_3.predict(X_test_kb_40)\n",
    "y_hat2_3 = y_hat2_3 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat2_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26ddd69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 13ms/step - loss: 0.6982 - binary_accuracy: 0.4990 - val_loss: 0.6861 - val_binary_accuracy: 0.5396\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6910 - binary_accuracy: 0.5411 - val_loss: 0.6917 - val_binary_accuracy: 0.5108\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6874 - binary_accuracy: 0.5371 - val_loss: 0.6952 - val_binary_accuracy: 0.5252\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6842 - binary_accuracy: 0.5451 - val_loss: 0.6944 - val_binary_accuracy: 0.5540\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6813 - binary_accuracy: 0.5671 - val_loss: 0.6932 - val_binary_accuracy: 0.5612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x159ad2f70>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_55.shape[1]\n",
    "n_features = X_train_kb_55.shape[2]\n",
    "\n",
    "model2_4 = Sequential()\n",
    "model2_4.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model2_4.add(Flatten())\n",
    "model2_4.add(Dense(25, activation='relu')) \n",
    "model2_4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2_4.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model2_4.fit(X_train_kb_55, train_5w,epochs=30,  validation_data=(X_val_kb_55, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68c28a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4411764705882353"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat2_4 = model2_4.predict(X_test_kb_55)\n",
    "y_hat2_4 = y_hat2_4 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat2_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a946d9",
   "metadata": {},
   "source": [
    "### Model 3, Adding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a6a4c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 13ms/step - loss: 0.7017 - binary_accuracy: 0.4689 - val_loss: 0.6898 - val_binary_accuracy: 0.5108\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6993 - binary_accuracy: 0.4669 - val_loss: 0.6918 - val_binary_accuracy: 0.4964\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6974 - binary_accuracy: 0.4729 - val_loss: 0.6926 - val_binary_accuracy: 0.4964\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6960 - binary_accuracy: 0.4649 - val_loss: 0.6911 - val_binary_accuracy: 0.5036\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6952 - binary_accuracy: 0.4729 - val_loss: 0.6903 - val_binary_accuracy: 0.5180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x159c3dfa0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 3_1 - 3_4, adding layers\n",
    "n_steps = X_train_kb_10.shape[1]\n",
    "n_features = X_train_kb_10.shape[2]\n",
    "\n",
    "model3_1 = Sequential()\n",
    "model3_1.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model3_1.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model3_1.add(MaxPooling1D(pool_size=2))\n",
    "model3_1.add(Flatten())\n",
    "model3_1.add(Dense(8, activation='relu')) \n",
    "model3_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3_1.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model3_1.fit(X_train_kb_10, train_5w,epochs=30,  validation_data=(X_val_kb_10, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9c077a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47058823529411764"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat3_1 = model3_1.predict(X_test_kb_10)\n",
    "y_hat3_1 = y_hat3_1 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat3_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c962f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 15ms/step - loss: 0.6934 - binary_accuracy: 0.4950 - val_loss: 0.6923 - val_binary_accuracy: 0.5396\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6903 - binary_accuracy: 0.5471 - val_loss: 0.6909 - val_binary_accuracy: 0.5540\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6876 - binary_accuracy: 0.5671 - val_loss: 0.6894 - val_binary_accuracy: 0.5396\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6851 - binary_accuracy: 0.5792 - val_loss: 0.6902 - val_binary_accuracy: 0.5540\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6808 - binary_accuracy: 0.5892 - val_loss: 0.6925 - val_binary_accuracy: 0.5108\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6770 - binary_accuracy: 0.6092 - val_loss: 0.6958 - val_binary_accuracy: 0.4820\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6717 - binary_accuracy: 0.6253 - val_loss: 0.6983 - val_binary_accuracy: 0.4748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x159dfee50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_25.shape[1]\n",
    "n_features = X_train_kb_25.shape[2]\n",
    "\n",
    "model3_2 = Sequential()\n",
    "model3_2.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model3_2.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model3_2.add(MaxPooling1D(pool_size=2))\n",
    "model3_2.add(Flatten())\n",
    "model3_2.add(Dense(25, activation='relu')) \n",
    "model3_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model3_2.fit(X_train_kb_25, train_5w,epochs=30,  validation_data=(X_val_kb_25, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94fe03bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4852941176470588"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat3_2 = model3_2.predict(X_test_kb_25)\n",
    "y_hat3_2 = y_hat3_2 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat3_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24e0ad96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 17ms/step - loss: 0.6950 - binary_accuracy: 0.5110 - val_loss: 0.6816 - val_binary_accuracy: 0.5971\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6889 - binary_accuracy: 0.5311 - val_loss: 0.6824 - val_binary_accuracy: 0.5899\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6862 - binary_accuracy: 0.5451 - val_loss: 0.6831 - val_binary_accuracy: 0.5971\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6839 - binary_accuracy: 0.5451 - val_loss: 0.6827 - val_binary_accuracy: 0.6043\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6807 - binary_accuracy: 0.5912 - val_loss: 0.6830 - val_binary_accuracy: 0.5683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x159dd7820>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_40.shape[1]\n",
    "n_features = X_train_kb_40.shape[2]\n",
    "\n",
    "model3_3 = Sequential()\n",
    "model3_3.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model3_3.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model3_3.add(MaxPooling1D(pool_size=2))\n",
    "model3_3.add(Flatten())\n",
    "model3_3.add(Dense(25, activation='relu')) \n",
    "model3_3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3_3.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model3_3.fit(X_train_kb_40, train_5w,epochs=30,  validation_data=(X_val_kb_40, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8a26636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35294117647058826"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat3_3 = model3_3.predict(X_test_kb_40)\n",
    "y_hat3_3 = y_hat3_3 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat3_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26ddd69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 32ms/step - loss: 0.6972 - binary_accuracy: 0.4870 - val_loss: 0.7029 - val_binary_accuracy: 0.4820\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6928 - binary_accuracy: 0.5110 - val_loss: 0.6989 - val_binary_accuracy: 0.4748\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6914 - binary_accuracy: 0.5210 - val_loss: 0.6977 - val_binary_accuracy: 0.4892\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6901 - binary_accuracy: 0.5291 - val_loss: 0.6990 - val_binary_accuracy: 0.4676\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6891 - binary_accuracy: 0.5271 - val_loss: 0.6977 - val_binary_accuracy: 0.4748\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6879 - binary_accuracy: 0.5411 - val_loss: 0.6981 - val_binary_accuracy: 0.4676\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6875 - binary_accuracy: 0.5491 - val_loss: 0.7003 - val_binary_accuracy: 0.4604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x159dcf130>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_55.shape[1]\n",
    "n_features = X_train_kb_55.shape[2]\n",
    "\n",
    "model3_4 = Sequential()\n",
    "model3_4.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model3_4.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model3_4.add(MaxPooling1D(pool_size=2))\n",
    "model3_4.add(Flatten())\n",
    "model3_4.add(Dense(25, activation='relu')) \n",
    "model3_4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3_4.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model3_4.fit(X_train_kb_55, train_5w,epochs=30,  validation_data=(X_val_kb_55, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7941f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4117647058823529"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat3_4 = model3_4.predict(X_test_kb_55)\n",
    "y_hat3_4 = y_hat3_4 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat3_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a38693",
   "metadata": {},
   "source": [
    "### Model 4, adding conv layer after pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a6a4c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 38ms/step - loss: 0.6933 - binary_accuracy: 0.4629 - val_loss: 0.6926 - val_binary_accuracy: 0.5252\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6926 - binary_accuracy: 0.5150 - val_loss: 0.6922 - val_binary_accuracy: 0.5324\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6923 - binary_accuracy: 0.5471 - val_loss: 0.6922 - val_binary_accuracy: 0.5612\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6921 - binary_accuracy: 0.5351 - val_loss: 0.6916 - val_binary_accuracy: 0.5827\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6921 - binary_accuracy: 0.5291 - val_loss: 0.6917 - val_binary_accuracy: 0.5899\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6918 - binary_accuracy: 0.5210 - val_loss: 0.6911 - val_binary_accuracy: 0.5612\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6916 - binary_accuracy: 0.5130 - val_loss: 0.6913 - val_binary_accuracy: 0.5755\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6913 - binary_accuracy: 0.5291 - val_loss: 0.6910 - val_binary_accuracy: 0.5827\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6911 - binary_accuracy: 0.5150 - val_loss: 0.6906 - val_binary_accuracy: 0.5827\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6909 - binary_accuracy: 0.5190 - val_loss: 0.6905 - val_binary_accuracy: 0.5827\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6905 - binary_accuracy: 0.5311 - val_loss: 0.6911 - val_binary_accuracy: 0.5683\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6904 - binary_accuracy: 0.5291 - val_loss: 0.6907 - val_binary_accuracy: 0.5612\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6900 - binary_accuracy: 0.5371 - val_loss: 0.6905 - val_binary_accuracy: 0.5683\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6896 - binary_accuracy: 0.5411 - val_loss: 0.6916 - val_binary_accuracy: 0.5324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15a326fa0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 4_1 - 4_4, adding conv layer after pooling\n",
    "n_steps = X_train_kb_10.shape[1]\n",
    "n_features = X_train_kb_10.shape[2]\n",
    "\n",
    "model4_1 = Sequential()\n",
    "model4_1.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model4_1.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model4_1.add(MaxPooling1D(pool_size=2))\n",
    "model4_1.add(Conv1D(filters=16, kernel_size=1, activation='relu'))\n",
    "model4_1.add(Flatten())\n",
    "model4_1.add(Dense(8, activation='relu')) \n",
    "model4_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model4_1.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model4_1.fit(X_train_kb_10, train_5w,epochs=30,  validation_data=(X_val_kb_10, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ea7e586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36764705882352944"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat4_1 = model4_1.predict(X_test_kb_10)\n",
    "y_hat4_1 = y_hat4_1 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat4_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c962f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 15ms/step - loss: 0.6918 - binary_accuracy: 0.5170 - val_loss: 0.6875 - val_binary_accuracy: 0.5540\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6893 - binary_accuracy: 0.5531 - val_loss: 0.6876 - val_binary_accuracy: 0.5324\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6862 - binary_accuracy: 0.5491 - val_loss: 0.6857 - val_binary_accuracy: 0.5252\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6831 - binary_accuracy: 0.5852 - val_loss: 0.6840 - val_binary_accuracy: 0.5396\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6786 - binary_accuracy: 0.5972 - val_loss: 0.6849 - val_binary_accuracy: 0.5324\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6741 - binary_accuracy: 0.5852 - val_loss: 0.6853 - val_binary_accuracy: 0.5180\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6678 - binary_accuracy: 0.6393 - val_loss: 0.6866 - val_binary_accuracy: 0.5252\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6622 - binary_accuracy: 0.6172 - val_loss: 0.6872 - val_binary_accuracy: 0.5252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1597e7250>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_25.shape[1]\n",
    "n_features = X_train_kb_25.shape[2]\n",
    "\n",
    "model4_2 = Sequential()\n",
    "model4_2.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model4_2.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model4_2.add(MaxPooling1D(pool_size=2))\n",
    "model4_2.add(Conv1D(filters=16, kernel_size=1, activation='relu'))\n",
    "model4_2.add(Flatten())\n",
    "model4_2.add(Dense(25, activation='relu')) \n",
    "model4_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model4_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model4_2.fit(X_train_kb_25, train_5w,epochs=30,  validation_data=(X_val_kb_25, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7443231d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4852941176470588"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat4_2 = model4_2.predict(X_test_kb_25)\n",
    "y_hat4_2 = y_hat4_2 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat4_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24e0ad96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 14ms/step - loss: 0.6952 - binary_accuracy: 0.4429 - val_loss: 0.6902 - val_binary_accuracy: 0.5971\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6921 - binary_accuracy: 0.5190 - val_loss: 0.6892 - val_binary_accuracy: 0.5971\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6910 - binary_accuracy: 0.5451 - val_loss: 0.6899 - val_binary_accuracy: 0.5827\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6891 - binary_accuracy: 0.5772 - val_loss: 0.6890 - val_binary_accuracy: 0.5540\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6865 - binary_accuracy: 0.6092 - val_loss: 0.6900 - val_binary_accuracy: 0.5180\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6830 - binary_accuracy: 0.6192 - val_loss: 0.6921 - val_binary_accuracy: 0.5396\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6770 - binary_accuracy: 0.6333 - val_loss: 0.6951 - val_binary_accuracy: 0.5252\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6699 - binary_accuracy: 0.6373 - val_loss: 0.6999 - val_binary_accuracy: 0.5036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15a574df0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_40.shape[1]\n",
    "n_features = X_train_kb_40.shape[2]\n",
    "\n",
    "model4_3 = Sequential()\n",
    "model4_3.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model4_3.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model4_3.add(MaxPooling1D(pool_size=2))\n",
    "model4_3.add(Conv1D(filters=16, kernel_size=1, activation='relu'))\n",
    "model4_3.add(Flatten())\n",
    "model4_3.add(Dense(25, activation='relu')) \n",
    "model4_3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model4_3.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model4_3.fit(X_train_kb_40, train_5w,epochs=30,  validation_data=(X_val_kb_40, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a97295e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5147058823529411"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat4_3 = model4_3.predict(X_test_kb_40)\n",
    "y_hat4_3 = y_hat4_3 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat4_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26ddd69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 14ms/step - loss: 0.6933 - binary_accuracy: 0.5291 - val_loss: 0.6878 - val_binary_accuracy: 0.5468\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6913 - binary_accuracy: 0.5391 - val_loss: 0.6896 - val_binary_accuracy: 0.5396\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6900 - binary_accuracy: 0.5291 - val_loss: 0.6907 - val_binary_accuracy: 0.5324\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6891 - binary_accuracy: 0.5391 - val_loss: 0.6895 - val_binary_accuracy: 0.5252\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6883 - binary_accuracy: 0.5411 - val_loss: 0.6913 - val_binary_accuracy: 0.5036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15a74dbe0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_55.shape[1]\n",
    "n_features = X_train_kb_55.shape[2]\n",
    "\n",
    "model4_4 = Sequential()\n",
    "model4_4.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model4_4.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model4_4.add(MaxPooling1D(pool_size=2))\n",
    "model4_4.add(Conv1D(filters=16, kernel_size=1, activation='relu'))\n",
    "model4_4.add(Flatten())\n",
    "model4_4.add(Dense(25, activation='relu')) \n",
    "model4_4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model4_4.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model4_4.fit(X_train_kb_55, train_5w,epochs=30,  validation_data=(X_val_kb_55, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "263a0ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4852941176470588"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat4_4 = model4_4.predict(X_test_kb_55)\n",
    "y_hat4_4 = y_hat4_4 > .5\n",
    "metrics.accuracy_score(test_5w,y_hat4_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c637d4e3",
   "metadata": {},
   "source": [
    "# Trying the Correlation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76a38693",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = X_train.corr()\n",
    "corr_matrix\n",
    "\n",
    "feats_corr_10 = list(pd.DataFrame(corr_matrix['target_3'].sort_values(ascending=False).iloc[1:11]).reset_index()['index'])\n",
    "feats_corr_25 = list(pd.DataFrame(corr_matrix['target_3'].sort_values(ascending=False).iloc[1:26]).reset_index()['index'])\n",
    "feats_corr_40 = list(pd.DataFrame(corr_matrix['target_3'].sort_values(ascending=False).iloc[1:41]).reset_index()['index'])\n",
    "feats_corr_55 = list(pd.DataFrame(corr_matrix['target_3'].sort_values(ascending=False).iloc[1:56]).reset_index()['index'])\n",
    "\n",
    "X_train_cr_10 = X_train[feats_corr_10]\n",
    "X_test_cr_10 = X_test[feats_corr_10]\n",
    "X_val_cr_10 = X_val[feats_corr_10]\n",
    "X_train_cr_25 = X_train[feats_corr_25]\n",
    "X_test_cr_25 = X_test[feats_corr_25]\n",
    "X_val_cr_25 = X_val[feats_corr_25]\n",
    "X_train_cr_40 = X_train[feats_corr_40]\n",
    "X_test_cr_40 = X_test[feats_corr_40]\n",
    "X_val_cr_40 = X_val[feats_corr_40]\n",
    "X_train_cr_55 = X_train[feats_corr_55]\n",
    "X_test_cr_55 = X_test[feats_corr_55]\n",
    "X_val_cr_55 = X_val[feats_corr_55]\n",
    "\n",
    "def pca_finder(df, df_val, df_test):\n",
    "    \n",
    "    pca = PCA().fit(df)\n",
    "    pca_scores = np.cumsum(pca.explained_variance_ratio_) * 100\n",
    "    res = next(x for x, val in enumerate(pca_scores) if val > 85)\n",
    "    res = res + 1\n",
    "    res\n",
    "    \n",
    "    pca_cr_1 = PCA(n_components = res).fit(df.to_numpy())\n",
    "    df = pca_cr_1.transform(df.to_numpy())\n",
    "    df_val = pca_cr_1.transform(df_val.to_numpy())\n",
    "    df_test = pca_cr_1.transform(df_test.to_numpy())\n",
    "    return df, df_val, df_test\n",
    "\n",
    "X_train_cr_10, X_val_cr_10, X_test_cr_10 = pca_finder(X_train_cr_10, X_val_cr_10, X_test_cr_10)\n",
    "X_train_cr_25, X_val_cr_25, X_test_cr_25 = pca_finder(X_train_cr_25, X_val_cr_25, X_test_cr_25)\n",
    "X_train_cr_40, X_val_cr_40, X_test_cr_40 = pca_finder(X_train_cr_40, X_val_cr_40, X_test_cr_40)\n",
    "X_train_cr_55, X_val_cr_55, X_test_cr_55 = pca_finder(X_train_cr_55, X_val_cr_55, X_test_cr_55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06fc0d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cr_40, train_5w = df_to_X_y2(X_train_cr_40,y_train)\n",
    "X_val_cr_40, val_5w = df_to_X_y2(X_val_cr_40, y_val)\n",
    "X_test_cr_40, test_5w = df_to_X_y2(X_test_cr_40,y_test) \n",
    "\n",
    "X_train_cr_10, _ = df_to_X_y2(X_train_cr_10,y_train)\n",
    "X_val_cr_10, _ = df_to_X_y2(X_val_cr_10, y_val)\n",
    "X_test_cr_10, _ = df_to_X_y2(X_test_cr_10,y_test) \n",
    "\n",
    "X_train_cr_25, _ = df_to_X_y2(X_train_cr_25,y_train)\n",
    "X_val_cr_25, _ = df_to_X_y2(X_val_cr_25, y_val)\n",
    "X_test_cr_25, _ = df_to_X_y2(X_test_cr_25,y_test) \n",
    "\n",
    "X_train_cr_55, _ = df_to_X_y2(X_train_cr_55,y_train)\n",
    "X_val_cr_55, _ = df_to_X_y2(X_val_cr_55, y_val)\n",
    "X_test_cr_55, _ = df_to_X_y2(X_test_cr_55,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a6a4c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 12ms/step - loss: 0.6956 - binary_accuracy: 0.4850 - val_loss: 0.7023 - val_binary_accuracy: 0.4604\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6910 - binary_accuracy: 0.5391 - val_loss: 0.6985 - val_binary_accuracy: 0.5108\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6882 - binary_accuracy: 0.5471 - val_loss: 0.6979 - val_binary_accuracy: 0.4892\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6855 - binary_accuracy: 0.5611 - val_loss: 0.6959 - val_binary_accuracy: 0.4820\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6831 - binary_accuracy: 0.5731 - val_loss: 0.6954 - val_binary_accuracy: 0.4820\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6808 - binary_accuracy: 0.5812 - val_loss: 0.6962 - val_binary_accuracy: 0.5036\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6791 - binary_accuracy: 0.5772 - val_loss: 0.6978 - val_binary_accuracy: 0.5036\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6769 - binary_accuracy: 0.5812 - val_loss: 0.6984 - val_binary_accuracy: 0.5036\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6742 - binary_accuracy: 0.5912 - val_loss: 0.6979 - val_binary_accuracy: 0.5108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x159c45b20>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 2_1 - 2_4, using differnt k best pca variables. reduced filters\n",
    "n_steps = X_train_cr_10.shape[1]\n",
    "n_features = X_train_cr_10.shape[2]\n",
    "\n",
    "model2_1_cr = Sequential()\n",
    "model2_1_cr.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model2_1_cr.add(Flatten())\n",
    "model2_1_cr.add(Dense(25, activation='relu')) \n",
    "model2_1_cr.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2_1_cr.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model2_1_cr.fit(X_train_cr_10, train_5w,epochs=30,  validation_data=(X_val_cr_10, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "929becef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5147058823529411"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat2_1_cr = model2_1_cr.predict(X_test_cr_10)\n",
    "y_hat2_1_cr = y_hat2_1_cr > .5\n",
    "metrics.accuracy_score(test_5w,y_hat2_1_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c962f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 13ms/step - loss: 0.6977 - binary_accuracy: 0.5110 - val_loss: 0.6902 - val_binary_accuracy: 0.5683\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6915 - binary_accuracy: 0.5230 - val_loss: 0.6907 - val_binary_accuracy: 0.5755\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6872 - binary_accuracy: 0.5351 - val_loss: 0.6891 - val_binary_accuracy: 0.5899\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6842 - binary_accuracy: 0.5611 - val_loss: 0.6891 - val_binary_accuracy: 0.5827\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6806 - binary_accuracy: 0.5691 - val_loss: 0.6885 - val_binary_accuracy: 0.5683\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6777 - binary_accuracy: 0.5731 - val_loss: 0.6880 - val_binary_accuracy: 0.5683\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6747 - binary_accuracy: 0.5852 - val_loss: 0.6871 - val_binary_accuracy: 0.5540\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6719 - binary_accuracy: 0.6032 - val_loss: 0.6885 - val_binary_accuracy: 0.5683\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6693 - binary_accuracy: 0.6212 - val_loss: 0.6887 - val_binary_accuracy: 0.5683\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6669 - binary_accuracy: 0.6052 - val_loss: 0.6871 - val_binary_accuracy: 0.5540\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6637 - binary_accuracy: 0.6152 - val_loss: 0.6884 - val_binary_accuracy: 0.5755\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6616 - binary_accuracy: 0.6192 - val_loss: 0.6885 - val_binary_accuracy: 0.5683\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6593 - binary_accuracy: 0.6273 - val_loss: 0.6906 - val_binary_accuracy: 0.5612\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6568 - binary_accuracy: 0.6373 - val_loss: 0.6897 - val_binary_accuracy: 0.5468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15aa84ca0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_cr_25.shape[1]\n",
    "n_features = X_train_cr_25.shape[2]\n",
    "\n",
    "model2_2_cr = Sequential()\n",
    "model2_2_cr.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model2_2_cr.add(Flatten())\n",
    "model2_2_cr.add(Dense(25, activation='relu')) \n",
    "model2_2_cr.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2_2_cr.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model2_2_cr.fit(X_train_cr_25, train_5w,epochs=30,  validation_data=(X_val_cr_25, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4021da90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5294117647058824"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat2_2_cr = model2_2_cr.predict(X_test_cr_25)\n",
    "y_hat2_2_cr = y_hat2_2_cr > .5\n",
    "metrics.accuracy_score(test_5w,y_hat2_2_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24e0ad96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 13ms/step - loss: 0.7011 - binary_accuracy: 0.5130 - val_loss: 0.6991 - val_binary_accuracy: 0.4604\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6938 - binary_accuracy: 0.4930 - val_loss: 0.6925 - val_binary_accuracy: 0.4676\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6877 - binary_accuracy: 0.5050 - val_loss: 0.6934 - val_binary_accuracy: 0.4820\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6839 - binary_accuracy: 0.5170 - val_loss: 0.6928 - val_binary_accuracy: 0.4892\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6807 - binary_accuracy: 0.5190 - val_loss: 0.6922 - val_binary_accuracy: 0.5396\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6775 - binary_accuracy: 0.5431 - val_loss: 0.6921 - val_binary_accuracy: 0.5396\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6744 - binary_accuracy: 0.5511 - val_loss: 0.6918 - val_binary_accuracy: 0.5396\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6715 - binary_accuracy: 0.5591 - val_loss: 0.6921 - val_binary_accuracy: 0.5324\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6688 - binary_accuracy: 0.5832 - val_loss: 0.6943 - val_binary_accuracy: 0.5252\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6656 - binary_accuracy: 0.5772 - val_loss: 0.6927 - val_binary_accuracy: 0.5324\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6631 - binary_accuracy: 0.5912 - val_loss: 0.6921 - val_binary_accuracy: 0.5252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15abf25b0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_cr_40.shape[1]\n",
    "n_features = X_train_cr_40.shape[2]\n",
    "\n",
    "model2_3_cr = Sequential()\n",
    "model2_3_cr.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model2_3_cr.add(Flatten())\n",
    "model2_3_cr.add(Dense(25, activation='relu')) \n",
    "model2_3_cr.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2_3_cr.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model2_3_cr.fit(X_train_cr_40, train_5w,epochs=30,  validation_data=(X_val_cr_40, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e994ea9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4264705882352941"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat2_3_cr = model2_3_cr.predict(X_test_cr_40)\n",
    "y_hat2_3_cr = y_hat2_3_cr > .5\n",
    "metrics.accuracy_score(test_5w,y_hat2_3_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "26ddd69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 13ms/step - loss: 0.7225 - binary_accuracy: 0.5050 - val_loss: 0.6712 - val_binary_accuracy: 0.5755\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7037 - binary_accuracy: 0.5371 - val_loss: 0.6751 - val_binary_accuracy: 0.5899\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6964 - binary_accuracy: 0.5230 - val_loss: 0.6785 - val_binary_accuracy: 0.5899\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6921 - binary_accuracy: 0.5431 - val_loss: 0.6789 - val_binary_accuracy: 0.5827\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6883 - binary_accuracy: 0.5551 - val_loss: 0.6787 - val_binary_accuracy: 0.5827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15ad8ce50>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_cr_55.shape[1]\n",
    "n_features = X_train_cr_55.shape[2]\n",
    "\n",
    "model2_4_cr = Sequential()\n",
    "model2_4_cr.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "\n",
    "model2_4_cr.add(Flatten())\n",
    "model2_4_cr.add(Dense(25, activation='relu')) \n",
    "model2_4_cr.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2_4_cr.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model2_4_cr.fit(X_train_cr_55, train_5w,epochs=30,  validation_data=(X_val_cr_55, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68c28a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45588235294117646"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat2_4_cr = model2_4_cr.predict(X_test_cr_55)\n",
    "y_hat2_4_cr = y_hat2_4_cr > .5\n",
    "metrics.accuracy_score(test_5w,y_hat2_4_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "84c605eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 14ms/step - loss: 0.6940 - binary_accuracy: 0.4729 - val_loss: 0.6958 - val_binary_accuracy: 0.5036\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6926 - binary_accuracy: 0.5291 - val_loss: 0.6962 - val_binary_accuracy: 0.4604\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6913 - binary_accuracy: 0.5451 - val_loss: 0.6956 - val_binary_accuracy: 0.4892\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6905 - binary_accuracy: 0.5451 - val_loss: 0.6960 - val_binary_accuracy: 0.5036\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6899 - binary_accuracy: 0.5431 - val_loss: 0.6957 - val_binary_accuracy: 0.5036\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6890 - binary_accuracy: 0.5471 - val_loss: 0.6956 - val_binary_accuracy: 0.5108\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6883 - binary_accuracy: 0.5591 - val_loss: 0.6950 - val_binary_accuracy: 0.5396\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6876 - binary_accuracy: 0.5531 - val_loss: 0.6963 - val_binary_accuracy: 0.5252\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6871 - binary_accuracy: 0.5451 - val_loss: 0.6953 - val_binary_accuracy: 0.5396\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6863 - binary_accuracy: 0.5651 - val_loss: 0.6944 - val_binary_accuracy: 0.5468\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6857 - binary_accuracy: 0.5591 - val_loss: 0.6944 - val_binary_accuracy: 0.5468\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6852 - binary_accuracy: 0.5551 - val_loss: 0.6951 - val_binary_accuracy: 0.5108\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6843 - binary_accuracy: 0.5812 - val_loss: 0.6938 - val_binary_accuracy: 0.5540\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6837 - binary_accuracy: 0.5832 - val_loss: 0.6927 - val_binary_accuracy: 0.5540\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6829 - binary_accuracy: 0.5852 - val_loss: 0.6943 - val_binary_accuracy: 0.5468\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6822 - binary_accuracy: 0.5852 - val_loss: 0.6932 - val_binary_accuracy: 0.5755\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6813 - binary_accuracy: 0.5872 - val_loss: 0.6949 - val_binary_accuracy: 0.5468\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6808 - binary_accuracy: 0.5832 - val_loss: 0.6944 - val_binary_accuracy: 0.5683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5294117647058824"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 3_1 - 3_4, adding layers\n",
    "n_steps = X_train_cr_10.shape[1]\n",
    "n_features = X_train_cr_10.shape[2]\n",
    "\n",
    "model3_1_cr = Sequential()\n",
    "model3_1_cr.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model3_1_cr.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model3_1_cr.add(MaxPooling1D(pool_size=2))\n",
    "model3_1_cr.add(Flatten())\n",
    "model3_1_cr.add(Dense(8, activation='relu')) \n",
    "model3_1_cr.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3_1_cr.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model3_1_cr.fit(X_train_cr_10, train_5w,epochs=30,  validation_data=(X_val_cr_10, val_5w), callbacks = [early_stopping_monitor])\n",
    "y_hat3_1_cr = model3_1_cr.predict(X_test_cr_10)\n",
    "y_hat3_1_cr = y_hat3_1_cr > .5\n",
    "metrics.accuracy_score(test_5w,y_hat3_1_cr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d4e97456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 14ms/step - loss: 0.6932 - binary_accuracy: 0.4910 - val_loss: 0.6878 - val_binary_accuracy: 0.5899\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6900 - binary_accuracy: 0.5331 - val_loss: 0.6870 - val_binary_accuracy: 0.5899\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6881 - binary_accuracy: 0.5471 - val_loss: 0.6869 - val_binary_accuracy: 0.6115\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6865 - binary_accuracy: 0.5651 - val_loss: 0.6868 - val_binary_accuracy: 0.5683\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6839 - binary_accuracy: 0.5731 - val_loss: 0.6851 - val_binary_accuracy: 0.5899\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6809 - binary_accuracy: 0.5812 - val_loss: 0.6861 - val_binary_accuracy: 0.5324\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6780 - binary_accuracy: 0.6032 - val_loss: 0.6867 - val_binary_accuracy: 0.5252\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6741 - binary_accuracy: 0.6152 - val_loss: 0.6842 - val_binary_accuracy: 0.5324\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6704 - binary_accuracy: 0.6112 - val_loss: 0.6850 - val_binary_accuracy: 0.5540\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6661 - binary_accuracy: 0.6333 - val_loss: 0.6841 - val_binary_accuracy: 0.5612\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6631 - binary_accuracy: 0.6293 - val_loss: 0.6854 - val_binary_accuracy: 0.5612\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6568 - binary_accuracy: 0.6353 - val_loss: 0.6818 - val_binary_accuracy: 0.5612\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6487 - binary_accuracy: 0.6593 - val_loss: 0.6827 - val_binary_accuracy: 0.5755\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6431 - binary_accuracy: 0.6653 - val_loss: 0.6854 - val_binary_accuracy: 0.5683\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6354 - binary_accuracy: 0.6733 - val_loss: 0.6840 - val_binary_accuracy: 0.5683\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6294 - binary_accuracy: 0.6874 - val_loss: 0.6809 - val_binary_accuracy: 0.5683\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6186 - binary_accuracy: 0.7014 - val_loss: 0.6859 - val_binary_accuracy: 0.5468\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6095 - binary_accuracy: 0.7154 - val_loss: 0.6834 - val_binary_accuracy: 0.5683\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6000 - binary_accuracy: 0.6994 - val_loss: 0.6883 - val_binary_accuracy: 0.5540\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5894 - binary_accuracy: 0.7234 - val_loss: 0.6870 - val_binary_accuracy: 0.5755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6176470588235294"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_cr_25.shape[1]\n",
    "n_features = X_train_cr_25.shape[2]\n",
    "\n",
    "model3_2_cr = Sequential()\n",
    "model3_2_cr.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model3_2_cr.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model3_2_cr.add(MaxPooling1D(pool_size=2))\n",
    "model3_2_cr.add(Flatten())\n",
    "model3_2_cr.add(Dense(25, activation='relu')) \n",
    "model3_2_cr.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3_2_cr.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model3_2_cr.fit(X_train_cr_25, train_5w,epochs=30,  validation_data=(X_val_cr_25, val_5w), callbacks = [early_stopping_monitor])\n",
    "y_hat3_2_cr = model3_2_cr.predict(X_test_cr_25)\n",
    "y_hat3_2_cr = y_hat3_2_cr > .5\n",
    "metrics.accuracy_score(test_5w,y_hat3_2_cr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d2679fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 14ms/step - loss: 0.6976 - binary_accuracy: 0.5331 - val_loss: 0.6885 - val_binary_accuracy: 0.5540\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6869 - binary_accuracy: 0.5591 - val_loss: 0.6886 - val_binary_accuracy: 0.5612\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6839 - binary_accuracy: 0.5611 - val_loss: 0.6883 - val_binary_accuracy: 0.5683\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6793 - binary_accuracy: 0.5832 - val_loss: 0.6920 - val_binary_accuracy: 0.5252\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6752 - binary_accuracy: 0.6012 - val_loss: 0.6905 - val_binary_accuracy: 0.5468\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6687 - binary_accuracy: 0.6072 - val_loss: 0.6939 - val_binary_accuracy: 0.5108\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6631 - binary_accuracy: 0.6413 - val_loss: 0.6980 - val_binary_accuracy: 0.5180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4852941176470588"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "n_steps = X_train_cr_40.shape[1]\n",
    "n_features = X_train_cr_40.shape[2]\n",
    "\n",
    "model3_3_cr = Sequential()\n",
    "model3_3_cr.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model3_3_cr.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model3_3_cr.add(MaxPooling1D(pool_size=2))\n",
    "model3_3_cr.add(Flatten())\n",
    "model3_3_cr.add(Dense(25, activation='relu')) \n",
    "model3_3_cr.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3_3_cr.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model3_3_cr.fit(X_train_cr_40, train_5w,epochs=30,  validation_data=(X_val_cr_40, val_5w), callbacks = [early_stopping_monitor])\n",
    "y_hat3_3_cr = model3_3_cr.predict(X_test_cr_40)\n",
    "y_hat3_3_cr = y_hat3_3_cr > .5\n",
    "metrics.accuracy_score(test_5w,y_hat3_3_cr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "839a97bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 14ms/step - loss: 0.7169 - binary_accuracy: 0.4589 - val_loss: 0.7020 - val_binary_accuracy: 0.5396\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7041 - binary_accuracy: 0.4689 - val_loss: 0.6934 - val_binary_accuracy: 0.5540\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6984 - binary_accuracy: 0.4629 - val_loss: 0.6901 - val_binary_accuracy: 0.5971\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6959 - binary_accuracy: 0.4850 - val_loss: 0.6875 - val_binary_accuracy: 0.5612\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6939 - binary_accuracy: 0.4850 - val_loss: 0.6887 - val_binary_accuracy: 0.5683\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6921 - binary_accuracy: 0.5030 - val_loss: 0.6883 - val_binary_accuracy: 0.5683\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6908 - binary_accuracy: 0.5251 - val_loss: 0.6889 - val_binary_accuracy: 0.5899\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6894 - binary_accuracy: 0.5411 - val_loss: 0.6883 - val_binary_accuracy: 0.5755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38235294117647056"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_cr_55.shape[1]\n",
    "n_features = X_train_cr_55.shape[2]\n",
    "\n",
    "model3_4_cr = Sequential()\n",
    "model3_4_cr.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model3_4_cr.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model3_4_cr.add(MaxPooling1D(pool_size=2))\n",
    "model3_4_cr.add(Flatten())\n",
    "model3_4_cr.add(Dense(25, activation='relu')) \n",
    "model3_4_cr.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3_4_cr.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model3_4_cr.fit(X_train_cr_55, train_5w,epochs=30,  validation_data=(X_val_cr_55, val_5w), callbacks = [early_stopping_monitor])\n",
    "y_hat3_4_cr = model3_4_cr.predict(X_test_cr_55)\n",
    "y_hat3_4_cr = y_hat3_4_cr > .5\n",
    "metrics.accuracy_score(test_5w,y_hat3_4_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478f9482",
   "metadata": {},
   "source": [
    "# Changes to the Target Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ae54949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "X_train_kb_10, X_val_kb_10, X_test_kb_10 = kbest_creator(10, X_train.drop('target_3', axis=1), X_val.drop('target_3', axis=1), X_test.drop('target_3', axis=1)) \n",
    "X_train_kb_25, X_val_kb_25, X_test_kb_25 = kbest_creator(25, X_train.drop('target_3', axis=1), X_val.drop('target_3', axis=1), X_test.drop('target_3', axis=1)) \n",
    "X_train_kb_40, X_val_kb_40, X_test_kb_40 = kbest_creator(40, X_train.drop('target_3', axis=1), X_val.drop('target_3', axis=1), X_test.drop('target_3', axis=1)) \n",
    "X_train_kb_55, X_val_kb_55, X_test_kb_55 = kbest_creator(55, X_train.drop('target_3', axis=1), X_val.drop('target_3', axis=1), X_test.drop('target_3', axis=1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d12e59da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_X_y_mod(df, target, window_size=5):\n",
    "  # converts to matrix of numpy arrays\n",
    "  X = []\n",
    "  y = []\n",
    "  for i in range(len(df)-window_size): # length of data frame - window_size so it does't take empty values at the end, \n",
    "    # does force you to loose the last 5 values, could fix with padding\n",
    "    row = [r for r in df[i:i+window_size]] # grabs row i and all rows above within the window size length\n",
    "    X.append(row) # creates 3 dimentional array, (# obseravtions, # rows in window, # features)\n",
    "    label = target[i+window_size-1] # pulls the target variable after the window, target varible needs to be column zero in this \n",
    "    y.append(label) # returns (N,) martix of targets i+window_length time periods away\n",
    "  return np.array(X), np.array(y)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "72d79d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to window format, in this case 5 periods\n",
    "X_train_kb_40, train_5w = df_to_X_y2(X_train_kb_40,y_train)\n",
    "X_val_kb_40, val_5w = df_to_X_y2(X_val_kb_40, y_val)\n",
    "X_test_kb_40, test_5w = df_to_X_y2(X_test_kb_40,y_test) \n",
    "\n",
    "X_train_kb_10, _ = df_to_X_y2(X_train_kb_10,y_train)\n",
    "X_val_kb_10, _ = df_to_X_y2(X_val_kb_10, y_val)\n",
    "X_test_kb_10, _ = df_to_X_y2(X_test_kb_10,y_test) \n",
    "\n",
    "X_train_kb_25, _ = df_to_X_y2(X_train_kb_25,y_train)\n",
    "X_val_kb_25, _ = df_to_X_y2(X_val_kb_25, y_val)\n",
    "X_test_kb_25, _ = df_to_X_y2(X_test_kb_25,y_test) \n",
    "\n",
    "X_train_kb_55, _ = df_to_X_y2(X_train_kb_55,y_train)\n",
    "X_val_kb_55, _ = df_to_X_y2(X_val_kb_55, y_val)\n",
    "X_test_kb_55, _ = df_to_X_y2(X_test_kb_55,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "10acaa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 15ms/step - loss: 0.6971 - binary_accuracy: 0.4870 - val_loss: 0.7001 - val_binary_accuracy: 0.3813\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6934 - binary_accuracy: 0.4870 - val_loss: 0.6931 - val_binary_accuracy: 0.5108\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6928 - binary_accuracy: 0.5110 - val_loss: 0.6895 - val_binary_accuracy: 0.5683\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6918 - binary_accuracy: 0.5331 - val_loss: 0.6903 - val_binary_accuracy: 0.5612\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6911 - binary_accuracy: 0.5271 - val_loss: 0.6901 - val_binary_accuracy: 0.5683\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6906 - binary_accuracy: 0.5351 - val_loss: 0.6912 - val_binary_accuracy: 0.5468\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6900 - binary_accuracy: 0.5371 - val_loss: 0.6931 - val_binary_accuracy: 0.5036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15b40ac70>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = X_train_kb_25.shape[1]\n",
    "n_features = X_train_kb_25.shape[2]\n",
    "\n",
    "model_mod4 = Sequential()\n",
    "model_mod4.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model_mod4.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model_mod4.add(MaxPooling1D(pool_size=2))\n",
    "model_mod4.add(Conv1D(filters=16, kernel_size=1, activation='relu'))\n",
    "model_mod4.add(Flatten())\n",
    "model_mod4.add(Dense(25, activation='relu')) \n",
    "model_mod4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_mod4.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model_mod4.fit(X_train_kb_25, train_5w,epochs=30,  validation_data=(X_val_kb_25, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c39a79c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4264705882352941"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_mod4_kb = model_mod4.predict(X_test_kb_25)\n",
    "y_hat_mod4_kb = y_hat_mod4_kb > .5\n",
    "metrics.accuracy_score(test_5w,y_hat_mod4_kb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d3b1741a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 16ms/step - loss: 0.6964 - binary_accuracy: 0.4850 - val_loss: 0.6932 - val_binary_accuracy: 0.5108\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6938 - binary_accuracy: 0.5130 - val_loss: 0.6899 - val_binary_accuracy: 0.5396\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6922 - binary_accuracy: 0.5251 - val_loss: 0.6886 - val_binary_accuracy: 0.5612\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6908 - binary_accuracy: 0.5371 - val_loss: 0.6883 - val_binary_accuracy: 0.5755\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6900 - binary_accuracy: 0.5351 - val_loss: 0.6882 - val_binary_accuracy: 0.5827\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6887 - binary_accuracy: 0.5711 - val_loss: 0.6871 - val_binary_accuracy: 0.5612\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6877 - binary_accuracy: 0.5691 - val_loss: 0.6857 - val_binary_accuracy: 0.5755\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6868 - binary_accuracy: 0.5752 - val_loss: 0.6860 - val_binary_accuracy: 0.5827\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6859 - binary_accuracy: 0.5792 - val_loss: 0.6859 - val_binary_accuracy: 0.5827\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6850 - binary_accuracy: 0.5711 - val_loss: 0.6861 - val_binary_accuracy: 0.5755\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6838 - binary_accuracy: 0.5852 - val_loss: 0.6861 - val_binary_accuracy: 0.5683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15b5efeb0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mod3 = Sequential()\n",
    "model_mod3.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model_mod3.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model_mod3.add(MaxPooling1D(pool_size=2))\n",
    "model_mod3.add(Flatten())\n",
    "model_mod3.add(Dense(25, activation='relu')) \n",
    "model_mod3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_mod3.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model_mod3.fit(X_train_kb_25, train_5w,epochs=30,  validation_data=(X_val_kb_25, val_5w), callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d3532b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_mod3_kb = model_mod3.predict(X_test_kb_25)\n",
    "y_hat_mod3_kb = y_hat_mod3_kb > .5\n",
    "metrics.accuracy_score(test_5w,y_hat_mod3_kb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "09950897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 14ms/step - loss: 0.6921 - binary_accuracy: 0.5090 - val_loss: 0.6860 - val_binary_accuracy: 0.5324\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6876 - binary_accuracy: 0.5471 - val_loss: 0.6879 - val_binary_accuracy: 0.4892\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6842 - binary_accuracy: 0.5772 - val_loss: 0.6871 - val_binary_accuracy: 0.5036\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6815 - binary_accuracy: 0.5992 - val_loss: 0.6898 - val_binary_accuracy: 0.5108\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6785 - binary_accuracy: 0.6032 - val_loss: 0.6900 - val_binary_accuracy: 0.4964\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6759 - binary_accuracy: 0.5952 - val_loss: 0.6936 - val_binary_accuracy: 0.4964\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6729 - binary_accuracy: 0.5972 - val_loss: 0.6930 - val_binary_accuracy: 0.5180\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6702 - binary_accuracy: 0.6072 - val_loss: 0.6915 - val_binary_accuracy: 0.5180\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6676 - binary_accuracy: 0.6232 - val_loss: 0.6967 - val_binary_accuracy: 0.5324\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6644 - binary_accuracy: 0.6232 - val_loss: 0.6969 - val_binary_accuracy: 0.5324\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6617 - binary_accuracy: 0.6333 - val_loss: 0.6981 - val_binary_accuracy: 0.5324\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6585 - binary_accuracy: 0.6333 - val_loss: 0.7020 - val_binary_accuracy: 0.5252\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6556 - binary_accuracy: 0.6313 - val_loss: 0.7036 - val_binary_accuracy: 0.5252\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6534 - binary_accuracy: 0.6413 - val_loss: 0.7105 - val_binary_accuracy: 0.5396\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6497 - binary_accuracy: 0.6373 - val_loss: 0.7094 - val_binary_accuracy: 0.5324\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6470 - binary_accuracy: 0.6433 - val_loss: 0.7099 - val_binary_accuracy: 0.5252\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6447 - binary_accuracy: 0.6493 - val_loss: 0.7190 - val_binary_accuracy: 0.5252\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6414 - binary_accuracy: 0.6453 - val_loss: 0.7150 - val_binary_accuracy: 0.5396\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6393 - binary_accuracy: 0.6493 - val_loss: 0.7195 - val_binary_accuracy: 0.5324\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6357 - binary_accuracy: 0.6573 - val_loss: 0.7208 - val_binary_accuracy: 0.5180\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6342 - binary_accuracy: 0.6553 - val_loss: 0.7308 - val_binary_accuracy: 0.5396\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6296 - binary_accuracy: 0.6533 - val_loss: 0.7229 - val_binary_accuracy: 0.5324\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6283 - binary_accuracy: 0.6533 - val_loss: 0.7302 - val_binary_accuracy: 0.5252\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6254 - binary_accuracy: 0.6593 - val_loss: 0.7275 - val_binary_accuracy: 0.5396\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6214 - binary_accuracy: 0.6613 - val_loss: 0.7367 - val_binary_accuracy: 0.5180\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6193 - binary_accuracy: 0.6533 - val_loss: 0.7404 - val_binary_accuracy: 0.5180\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6161 - binary_accuracy: 0.6513 - val_loss: 0.7405 - val_binary_accuracy: 0.5252\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6135 - binary_accuracy: 0.6593 - val_loss: 0.7429 - val_binary_accuracy: 0.5180\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6111 - binary_accuracy: 0.6593 - val_loss: 0.7490 - val_binary_accuracy: 0.4964\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6073 - binary_accuracy: 0.6633 - val_loss: 0.7518 - val_binary_accuracy: 0.4820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15b7acfa0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mod2 = Sequential()\n",
    "model_mod2.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model_mod2.add(Conv1D(filters=8, kernel_size=2, activation='relu')) \n",
    "model_mod2.add(Flatten())\n",
    "model_mod2.add(Dense(25, activation='relu')) \n",
    "model_mod2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_mod2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model_mod2.fit(X_train_kb_25, train_5w,epochs=30,  validation_data=(X_val_kb_25, val_5w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "88ba84ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4852941176470588"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_mod2_kb = model_mod2.predict(X_test_kb_25)\n",
    "y_hat_mod2_kb = y_hat_mod2_kb > .5\n",
    "metrics.accuracy_score(test_5w,y_hat_mod2_kb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ba039765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 13ms/step - loss: 0.6927 - binary_accuracy: 0.5411 - val_loss: 0.7011 - val_binary_accuracy: 0.5108\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6872 - binary_accuracy: 0.5611 - val_loss: 0.7029 - val_binary_accuracy: 0.4532\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6838 - binary_accuracy: 0.5551 - val_loss: 0.7036 - val_binary_accuracy: 0.4604\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6812 - binary_accuracy: 0.5651 - val_loss: 0.7040 - val_binary_accuracy: 0.4676\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6786 - binary_accuracy: 0.5752 - val_loss: 0.7037 - val_binary_accuracy: 0.4748\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6766 - binary_accuracy: 0.5852 - val_loss: 0.7039 - val_binary_accuracy: 0.4676\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6744 - binary_accuracy: 0.5912 - val_loss: 0.7057 - val_binary_accuracy: 0.4604\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6723 - binary_accuracy: 0.5992 - val_loss: 0.7051 - val_binary_accuracy: 0.4604\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6702 - binary_accuracy: 0.6132 - val_loss: 0.7054 - val_binary_accuracy: 0.4532\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6680 - binary_accuracy: 0.6072 - val_loss: 0.7075 - val_binary_accuracy: 0.4676\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6657 - binary_accuracy: 0.6052 - val_loss: 0.7079 - val_binary_accuracy: 0.4604\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6639 - binary_accuracy: 0.6132 - val_loss: 0.7092 - val_binary_accuracy: 0.4676\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6612 - binary_accuracy: 0.6232 - val_loss: 0.7083 - val_binary_accuracy: 0.4460\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6590 - binary_accuracy: 0.6313 - val_loss: 0.7098 - val_binary_accuracy: 0.4676\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6567 - binary_accuracy: 0.6353 - val_loss: 0.7108 - val_binary_accuracy: 0.4604\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6547 - binary_accuracy: 0.6413 - val_loss: 0.7105 - val_binary_accuracy: 0.4820\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6521 - binary_accuracy: 0.6453 - val_loss: 0.7120 - val_binary_accuracy: 0.4532\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6494 - binary_accuracy: 0.6553 - val_loss: 0.7133 - val_binary_accuracy: 0.4892\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6473 - binary_accuracy: 0.6493 - val_loss: 0.7169 - val_binary_accuracy: 0.4892\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6447 - binary_accuracy: 0.6553 - val_loss: 0.7168 - val_binary_accuracy: 0.4820\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6432 - binary_accuracy: 0.6633 - val_loss: 0.7163 - val_binary_accuracy: 0.4964\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6393 - binary_accuracy: 0.6673 - val_loss: 0.7196 - val_binary_accuracy: 0.4892\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6374 - binary_accuracy: 0.6493 - val_loss: 0.7233 - val_binary_accuracy: 0.4964\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6346 - binary_accuracy: 0.6513 - val_loss: 0.7231 - val_binary_accuracy: 0.4892\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6314 - binary_accuracy: 0.6573 - val_loss: 0.7277 - val_binary_accuracy: 0.4892\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6287 - binary_accuracy: 0.6573 - val_loss: 0.7274 - val_binary_accuracy: 0.4892\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6262 - binary_accuracy: 0.6573 - val_loss: 0.7295 - val_binary_accuracy: 0.4892\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6239 - binary_accuracy: 0.6553 - val_loss: 0.7329 - val_binary_accuracy: 0.4892\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6205 - binary_accuracy: 0.6553 - val_loss: 0.7318 - val_binary_accuracy: 0.5036\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6183 - binary_accuracy: 0.6653 - val_loss: 0.7348 - val_binary_accuracy: 0.5036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15b942d30>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mod1 = Sequential()\n",
    "model_mod1.add(Conv1D(filters=8, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model_mod1.add(Flatten())\n",
    "model_mod1.add(Dense(25, activation='relu')) \n",
    "model_mod1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_mod1.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"BinaryAccuracy\"])\n",
    "\n",
    "model_mod1.fit(X_train_kb_25, train_5w,epochs=30,  validation_data=(X_val_kb_25, val_5w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "89178642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5441176470588235"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_mod1_kb = model_mod1.predict(X_test_kb_25)\n",
    "y_hat_mod1_kb = y_hat_mod1_kb > .5\n",
    "metrics.accuracy_score(test_5w,y_hat_mod1_kb)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
