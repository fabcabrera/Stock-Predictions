{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "515730c1-45ed-49e9-86b8-dbd07f2dbd0e",
   "metadata": {},
   "source": [
    "# CNN Model using full Ford data now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "23263a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense, Normalization\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, InputLayer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn import (\n",
    "    linear_model, metrics, neural_network, pipeline, model_selection\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb74ca8-4ea0-46a4-afa0-b61173feef12",
   "metadata": {},
   "source": [
    "## Part 1: Clean and Select Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "3e760be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9fb5de0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ford</th>\n",
       "      <th>F-150</th>\n",
       "      <th>Ford Bronco_x</th>\n",
       "      <th>Ford Mustang_x</th>\n",
       "      <th>Ford Stock</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Ford Motor Company</th>\n",
       "      <th>Ford Mustang_y</th>\n",
       "      <th>Ford F Series</th>\n",
       "      <th>Ford Bronco_y</th>\n",
       "      <th>Lincoln Navigator</th>\n",
       "      <th>Lincoln Aviator</th>\n",
       "      <th>Ford GT</th>\n",
       "      <th>dow_open</th>\n",
       "      <th>dow_high</th>\n",
       "      <th>dow_low</th>\n",
       "      <th>dow_close</th>\n",
       "      <th>dow_vol</th>\n",
       "      <th>nas_open</th>\n",
       "      <th>nas_high</th>\n",
       "      <th>nas_low</th>\n",
       "      <th>nas_close</th>\n",
       "      <th>nas_vol</th>\n",
       "      <th>Wiki_total</th>\n",
       "      <th>Google_total</th>\n",
       "      <th>Stock_total</th>\n",
       "      <th>Nas_total</th>\n",
       "      <th>Dow_total</th>\n",
       "      <th>Wiki_Moment_1</th>\n",
       "      <th>Wiki_Moment_2</th>\n",
       "      <th>Wiki_Moment_1_s</th>\n",
       "      <th>Wiki_Moment_2_s</th>\n",
       "      <th>Wiki_MAvg</th>\n",
       "      <th>Wiki_MAvg_s</th>\n",
       "      <th>Wiki_Disparity</th>\n",
       "      <th>Wiki_Disparity_s</th>\n",
       "      <th>Wiki_ROC</th>\n",
       "      <th>Wiki_ROC_s</th>\n",
       "      <th>Wiki_Rocp</th>\n",
       "      <th>Wiki_EMA</th>\n",
       "      <th>Wiki_diff</th>\n",
       "      <th>Wiki_gain</th>\n",
       "      <th>Wiki_loss</th>\n",
       "      <th>Wiki_avg_gain</th>\n",
       "      <th>Wiki_avg_loss</th>\n",
       "      <th>Wiki_rs</th>\n",
       "      <th>Wiki_RSI</th>\n",
       "      <th>Wiki_Move</th>\n",
       "      <th>Wiki_MAvg_Move</th>\n",
       "      <th>Wiki_MAvg_s_Move</th>\n",
       "      <th>Wiki_EMA_Move</th>\n",
       "      <th>Wiki_Disparity_Move</th>\n",
       "      <th>Wiki_Disparity_s_Move</th>\n",
       "      <th>Wiki_RSI_Move</th>\n",
       "      <th>Google_Moment_1</th>\n",
       "      <th>Google_Moment_2</th>\n",
       "      <th>Google_Moment_1_s</th>\n",
       "      <th>Google_Moment_2_s</th>\n",
       "      <th>Google_MAvg</th>\n",
       "      <th>Google_MAvg_s</th>\n",
       "      <th>Google_Disparity</th>\n",
       "      <th>Google_Disparity_s</th>\n",
       "      <th>Google_ROC</th>\n",
       "      <th>Google_ROC_s</th>\n",
       "      <th>Google_Rocp</th>\n",
       "      <th>Google_EMA</th>\n",
       "      <th>Google_diff</th>\n",
       "      <th>Google_gain</th>\n",
       "      <th>Google_loss</th>\n",
       "      <th>Google_avg_gain</th>\n",
       "      <th>Google_avg_loss</th>\n",
       "      <th>Google_rs</th>\n",
       "      <th>Google_RSI</th>\n",
       "      <th>Google_Move</th>\n",
       "      <th>Google_MAvg_Move</th>\n",
       "      <th>Google_MAvg_s_Move</th>\n",
       "      <th>Google_EMA_Move</th>\n",
       "      <th>Google_Disparity_Move</th>\n",
       "      <th>Google_Disparity_s_Move</th>\n",
       "      <th>Google_RSI_Move</th>\n",
       "      <th>Stock_Moment_1</th>\n",
       "      <th>Stock_Moment_2</th>\n",
       "      <th>Stock_Moment_1_s</th>\n",
       "      <th>Stock_Moment_2_s</th>\n",
       "      <th>Stock_MAvg</th>\n",
       "      <th>Stock_MAvg_s</th>\n",
       "      <th>Stock_Disparity</th>\n",
       "      <th>Stock_Disparity_s</th>\n",
       "      <th>Stock_ROC</th>\n",
       "      <th>Stock_ROC_s</th>\n",
       "      <th>Stock_Rocp</th>\n",
       "      <th>Stock_EMA</th>\n",
       "      <th>Stock_diff</th>\n",
       "      <th>Stock_gain</th>\n",
       "      <th>Stock_loss</th>\n",
       "      <th>Stock_avg_gain</th>\n",
       "      <th>Stock_avg_loss</th>\n",
       "      <th>Stock_rs</th>\n",
       "      <th>Stock_RSI</th>\n",
       "      <th>Stock_Move</th>\n",
       "      <th>Stock_MAvg_Move</th>\n",
       "      <th>Stock_MAvg_s_Move</th>\n",
       "      <th>Stock_EMA_Move</th>\n",
       "      <th>Stock_Disparity_Move</th>\n",
       "      <th>Stock_Disparity_s_Move</th>\n",
       "      <th>Stock_RSI_Move</th>\n",
       "      <th>Nas_Moment_1</th>\n",
       "      <th>Nas_Moment_2</th>\n",
       "      <th>Nas_Moment_1_s</th>\n",
       "      <th>Nas_Moment_2_s</th>\n",
       "      <th>Nas_MAvg</th>\n",
       "      <th>Nas_MAvg_s</th>\n",
       "      <th>Nas_Disparity</th>\n",
       "      <th>Nas_Disparity_s</th>\n",
       "      <th>Nas_ROC</th>\n",
       "      <th>Nas_ROC_s</th>\n",
       "      <th>Nas_Rocp</th>\n",
       "      <th>Nas_EMA</th>\n",
       "      <th>Nas_diff</th>\n",
       "      <th>Nas_gain</th>\n",
       "      <th>Nas_loss</th>\n",
       "      <th>Nas_avg_gain</th>\n",
       "      <th>Nas_avg_loss</th>\n",
       "      <th>Nas_rs</th>\n",
       "      <th>Nas_RSI</th>\n",
       "      <th>Nas_Move</th>\n",
       "      <th>Nas_MAvg_Move</th>\n",
       "      <th>Nas_MAvg_s_Move</th>\n",
       "      <th>Nas_EMA_Move</th>\n",
       "      <th>Nas_Disparity_Move</th>\n",
       "      <th>Nas_Disparity_s_Move</th>\n",
       "      <th>Nas_RSI_Move</th>\n",
       "      <th>Dow_Moment_1</th>\n",
       "      <th>Dow_Moment_2</th>\n",
       "      <th>Dow_Moment_1_s</th>\n",
       "      <th>Dow_Moment_2_s</th>\n",
       "      <th>Dow_MAvg</th>\n",
       "      <th>Dow_MAvg_s</th>\n",
       "      <th>Dow_Disparity</th>\n",
       "      <th>Dow_Disparity_s</th>\n",
       "      <th>Dow_ROC</th>\n",
       "      <th>Dow_ROC_s</th>\n",
       "      <th>Dow_Rocp</th>\n",
       "      <th>Dow_EMA</th>\n",
       "      <th>Dow_diff</th>\n",
       "      <th>Dow_gain</th>\n",
       "      <th>Dow_loss</th>\n",
       "      <th>Dow_avg_gain</th>\n",
       "      <th>Dow_avg_loss</th>\n",
       "      <th>Dow_rs</th>\n",
       "      <th>Dow_RSI</th>\n",
       "      <th>Dow_Move</th>\n",
       "      <th>Dow_MAvg_Move</th>\n",
       "      <th>Dow_MAvg_s_Move</th>\n",
       "      <th>Dow_EMA_Move</th>\n",
       "      <th>Dow_Disparity_Move</th>\n",
       "      <th>Dow_Disparity_s_Move</th>\n",
       "      <th>Dow_RSI_Move</th>\n",
       "      <th>target_1</th>\n",
       "      <th>target_2</th>\n",
       "      <th>target_3</th>\n",
       "      <th>target_4</th>\n",
       "      <th>target_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ford  F-150  Ford Bronco_x  Ford Mustang_x  Ford Stock  Open  High  Low  \\\n",
       "0     0      0              0               0           0     6     6    6   \n",
       "\n",
       "   Close  Volume  Dividends  Stock Splits  Ford Motor Company  Ford Mustang_y  \\\n",
       "0      6       6          6             6                   0               0   \n",
       "\n",
       "   Ford F Series  Ford Bronco_y  Lincoln Navigator  Lincoln Aviator  Ford GT  \\\n",
       "0              0              0                  0                0        0   \n",
       "\n",
       "   dow_open  dow_high  dow_low  dow_close  dow_vol  nas_open  nas_high  \\\n",
       "0         4         4        4          4        4         4         4   \n",
       "\n",
       "   nas_low  nas_close  nas_vol  Wiki_total  Google_total  Stock_total  \\\n",
       "0        4          4        4           0             0            6   \n",
       "\n",
       "   Nas_total  Dow_total  Wiki_Moment_1  Wiki_Moment_2  Wiki_Moment_1_s  \\\n",
       "0          4          4              0              0                0   \n",
       "\n",
       "   Wiki_Moment_2_s  Wiki_MAvg  Wiki_MAvg_s  Wiki_Disparity  Wiki_Disparity_s  \\\n",
       "0                0          0            0               0                 0   \n",
       "\n",
       "   Wiki_ROC  Wiki_ROC_s  Wiki_Rocp  Wiki_EMA  Wiki_diff  Wiki_gain  Wiki_loss  \\\n",
       "0         0           0          0         0          0          0          0   \n",
       "\n",
       "   Wiki_avg_gain  Wiki_avg_loss  Wiki_rs  Wiki_RSI  Wiki_Move  Wiki_MAvg_Move  \\\n",
       "0              0              0        0         0          0               0   \n",
       "\n",
       "   Wiki_MAvg_s_Move  Wiki_EMA_Move  Wiki_Disparity_Move  \\\n",
       "0                 0              0                    0   \n",
       "\n",
       "   Wiki_Disparity_s_Move  Wiki_RSI_Move  Google_Moment_1  Google_Moment_2  \\\n",
       "0                      0              0                0                0   \n",
       "\n",
       "   Google_Moment_1_s  Google_Moment_2_s  Google_MAvg  Google_MAvg_s  \\\n",
       "0                  0                  0            0              0   \n",
       "\n",
       "   Google_Disparity  Google_Disparity_s  Google_ROC  Google_ROC_s  \\\n",
       "0                 0                   0           0             0   \n",
       "\n",
       "   Google_Rocp  Google_EMA  Google_diff  Google_gain  Google_loss  \\\n",
       "0            0           0            0            0            0   \n",
       "\n",
       "   Google_avg_gain  Google_avg_loss  Google_rs  Google_RSI  Google_Move  \\\n",
       "0                0                0          0           0            0   \n",
       "\n",
       "   Google_MAvg_Move  Google_MAvg_s_Move  Google_EMA_Move  \\\n",
       "0                 0                   0                0   \n",
       "\n",
       "   Google_Disparity_Move  Google_Disparity_s_Move  Google_RSI_Move  \\\n",
       "0                      0                        0                0   \n",
       "\n",
       "   Stock_Moment_1  Stock_Moment_2  Stock_Moment_1_s  Stock_Moment_2_s  \\\n",
       "0              11              11                11                11   \n",
       "\n",
       "   Stock_MAvg  Stock_MAvg_s  Stock_Disparity  Stock_Disparity_s  Stock_ROC  \\\n",
       "0           0             0                6                  6         11   \n",
       "\n",
       "   Stock_ROC_s  Stock_Rocp  Stock_EMA  Stock_diff  Stock_gain  Stock_loss  \\\n",
       "0           11          11          6          11          11          11   \n",
       "\n",
       "   Stock_avg_gain  Stock_avg_loss  Stock_rs  Stock_RSI  Stock_Move  \\\n",
       "0              76              76        76         76           0   \n",
       "\n",
       "   Stock_MAvg_Move  Stock_MAvg_s_Move  Stock_EMA_Move  Stock_Disparity_Move  \\\n",
       "0                0                  0               0                     0   \n",
       "\n",
       "   Stock_Disparity_s_Move  Stock_RSI_Move  Nas_Moment_1  Nas_Moment_2  \\\n",
       "0                       0               0             7             7   \n",
       "\n",
       "   Nas_Moment_1_s  Nas_Moment_2_s  Nas_MAvg  Nas_MAvg_s  Nas_Disparity  \\\n",
       "0               7               7         0           0              4   \n",
       "\n",
       "   Nas_Disparity_s  Nas_ROC  Nas_ROC_s  Nas_Rocp  Nas_EMA  Nas_diff  Nas_gain  \\\n",
       "0                4        7          7         7        4         7         7   \n",
       "\n",
       "   Nas_loss  Nas_avg_gain  Nas_avg_loss  Nas_rs  Nas_RSI  Nas_Move  \\\n",
       "0         7            46            46      46       46         0   \n",
       "\n",
       "   Nas_MAvg_Move  Nas_MAvg_s_Move  Nas_EMA_Move  Nas_Disparity_Move  \\\n",
       "0              0                0             0                   0   \n",
       "\n",
       "   Nas_Disparity_s_Move  Nas_RSI_Move  Dow_Moment_1  Dow_Moment_2  \\\n",
       "0                     0             0             7             7   \n",
       "\n",
       "   Dow_Moment_1_s  Dow_Moment_2_s  Dow_MAvg  Dow_MAvg_s  Dow_Disparity  \\\n",
       "0               7               7         0           0              4   \n",
       "\n",
       "   Dow_Disparity_s  Dow_ROC  Dow_ROC_s  Dow_Rocp  Dow_EMA  Dow_diff  Dow_gain  \\\n",
       "0                4        7          7         7        4         7         7   \n",
       "\n",
       "   Dow_loss  Dow_avg_gain  Dow_avg_loss  Dow_rs  Dow_RSI  Dow_Move  \\\n",
       "0         7            46            46      46       46         0   \n",
       "\n",
       "   Dow_MAvg_Move  Dow_MAvg_s_Move  Dow_EMA_Move  Dow_Disparity_Move  \\\n",
       "0              0                0             0                   0   \n",
       "\n",
       "   Dow_Disparity_s_Move  Dow_RSI_Move  target_1  target_2  target_3  target_4  \\\n",
       "0                     0             0         0         0         0         0   \n",
       "\n",
       "   target_5  \n",
       "0         0  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ford = pd.read_csv(\"Ford_Cleaned_Date.csv\")\n",
    "Ford.date = pd.to_datetime(Ford.date)\n",
    "Ford = Ford.set_index(\"date\")\n",
    "Ford = Ford.iloc[14:, :] # to remove first 14 days that include NaNs due to some calculations\n",
    "Ford = Ford.drop([\"Nas_total\", 'Stock_total', 'Dow_total'],axis=1) # to remove duplicated columns\n",
    "pd.DataFrame(Ford.isna().sum()).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8736c8",
   "metadata": {},
   "source": [
    "We see from above that some varaibles contain a lot of NaN's so they either might not be useful, or they're going to lead us into eliminating a lot of data points.\n",
    "\n",
    "To Solve NaN problem we will create two initial data sets, one removing high NaN values, one not, and see which produced better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "997c5464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ford = Ford.drop([['Ford', 'Ford_Bronco_x', 'Ford_Stock', 'F-150', 'Ford_Bronco_y', 'Ford Motor Company', 'Ford F Series', 'Lincoln Navigator', 'Lincoln Aviator']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "74c58691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((709, 169), (768, 134))"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# High NaN varaibles included will be Ford_0\n",
    "Ford_0 = Ford.dropna()\n",
    "Ford_0 = Ford_0[~(Ford_0.isin([np.inf, -np.inf]).any(axis=1))] # to remove inf\n",
    "\n",
    "# Ford_1 will remove the high NaN columns\n",
    "Ford_1 = Ford[Ford.columns.drop(list(Ford.filter(regex='gain')))]\n",
    "Ford_1 = Ford_1[Ford_1.columns.drop(list(Ford_1.filter(regex='loss')))]\n",
    "Ford_1 = Ford_1[Ford_1.columns.drop(list(Ford_1.filter(regex='RSI')))]\n",
    "Ford_1 = Ford_1[Ford_1.columns.drop(list(Ford_1.filter(regex='_rs')))]\n",
    "Ford_1 = Ford_1.dropna()\n",
    "Ford_1 = Ford_1[~(Ford_1.isin([np.inf, -np.inf]).any(axis=1))]\n",
    "\n",
    "Ford_0.shape,Ford_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "8a68ca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Chosen is target_3\n",
    "Ford_0 = Ford_0.drop(['target_1', 'target_2', 'target_4', 'target_5'], axis=1)\n",
    "Ford_1 = Ford_1.drop(['target_1', 'target_2', 'target_4', 'target_5'], axis=1)\n",
    "\n",
    "target_3_0 = Ford_0[\"target_3\"]\n",
    "target_3_1 = Ford_1[\"target_3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c11fe5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((768,), (768, 130))"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_3_1.shape, Ford_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "262d44bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into training sets \n",
    "column_indices = {name: i for i, name in enumerate(Ford_1.columns)}\n",
    "\n",
    "n = len(Ford_0)\n",
    "train_f0 = Ford_0[0:int(n*0.7)]\n",
    "val_f0 = Ford_0[int(n*0.7):int(n*0.9)]\n",
    "test_f0 = Ford_0[int(n*0.9):]\n",
    "\n",
    "train_f0t = target_3_0[0:int(n*0.7)]\n",
    "val_f0t = target_3_0[int(n*0.7):int(n*0.9)]\n",
    "test_f0t = target_3_0[int(n*0.9):]\n",
    "\n",
    "# now with Ford_1\n",
    "n = len(Ford_1)\n",
    "train_f1 = Ford_1[0:int(n*0.7)]\n",
    "val_f1 = Ford_1[int(n*0.7):int(n*0.9)]\n",
    "test_f1 = Ford_1[int(n*0.9):]\n",
    "\n",
    "train_f1t = target_3_1[0:int(n*0.7)]\n",
    "val_f1t = target_3_1[int(n*0.7):int(n*0.9)]\n",
    "test_f1t = target_3_1[int(n*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e5e31954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preporocessing and standardizing the data\n",
    "Mscaler = MinMaxScaler() # keeps binarys at zero and 1 :)\n",
    "\n",
    "train_f0 = pd.DataFrame(Mscaler.fit_transform(train_f0), columns = Ford_0.columns)\n",
    "val_f0 = pd.DataFrame(Mscaler.fit_transform(val_f0), columns = Ford_0.columns)\n",
    "test_f0 = pd.DataFrame(Mscaler.fit_transform(test_f0), columns = Ford_0.columns)\n",
    "\n",
    "train_f1 = pd.DataFrame(Mscaler.fit_transform(train_f1), columns = Ford_1.columns)\n",
    "val_f1 = pd.DataFrame(Mscaler.fit_transform(val_f1), columns = Ford_1.columns)\n",
    "test_f1 = pd.DataFrame(Mscaler.fit_transform(test_f1), columns = Ford_1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2159c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series data modifier, will be used later\n",
    "\n",
    "def df_to_X_y2(df, target, window_size=5):\n",
    "  df_as_np = df.to_numpy() # converts to matrix of numpy arrays\n",
    "  X = []\n",
    "  y = []\n",
    "  for i in range(len(df_as_np)-window_size): # length of data frame - window_size so it does't take empty values at the end, \n",
    "    # does force you to loose the last 5 values, could fix with padding\n",
    "    row = [r for r in df_as_np[i:i+window_size]] # grabs row i and all rows above within the window size length\n",
    "    X.append(row) # creates 3 dimentional array, (# obseravtions, # rows in window, # features)\n",
    "    label = target[i+window_size] # pulls the target variable after the window, target varible needs to be column zero in this \n",
    "    y.append(label) # returns (N,) martix of targets i+window_length time periods away\n",
    "  return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b42ae",
   "metadata": {},
   "source": [
    "## Switching Focus to Just Ford_0, High NaN Varibles included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "eedd7227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Features         Score\n",
      "164                target_3  1.853982e+17\n",
      "57      Wiki_Disparity_Move  5.048879e+00\n",
      "155                  Dow_rs  3.490399e+00\n",
      "58    Wiki_Disparity_s_Move  3.014178e+00\n",
      "3            Ford Mustang_x  2.128389e+00\n",
      "53                Wiki_Move  2.075053e+00\n",
      "52                 Wiki_RSI  2.059093e+00\n",
      "154            Dow_avg_loss  2.040229e+00\n",
      "75          Google_avg_gain  1.990507e+00\n",
      "41         Wiki_Disparity_s  1.941543e+00\n",
      "128            Nas_avg_loss  1.866438e+00\n",
      "87           Stock_Moment_2  1.839803e+00\n",
      "110  Stock_Disparity_s_Move  1.623449e+00\n",
      "4                Ford Stock  1.510923e+00\n",
      "136    Nas_Disparity_s_Move  1.426169e+00\n",
      "148                Dow_Rocp  1.350381e+00\n",
      "82          Google_EMA_Move  1.347818e+00\n",
      "153            Dow_avg_gain  1.339265e+00\n",
      "76          Google_avg_loss  1.188484e+00\n",
      "10                Dividends  1.159343e+00\n",
      "15            Ford Bronco_y  1.009442e+00\n",
      "70              Google_Rocp  9.298293e-01\n",
      "104               Stock_RSI  9.298293e-01\n",
      "13           Ford Mustang_y  9.202174e-01\n",
      "18                  Ford GT  8.989922e-01\n",
      "94                Stock_ROC  8.890224e-01\n",
      "86           Stock_Moment_1  8.890224e-01\n",
      "12       Ford Motor Company  8.557236e-01\n",
      "119         Nas_Disparity_s  8.274363e-01\n",
      "118           Nas_Disparity  8.230253e-01\n",
      "85          Google_RSI_Move  7.997378e-01\n",
      "35            Wiki_Moment_2  7.776846e-01\n",
      "162    Dow_Disparity_s_Move  7.768721e-01\n",
      "131                Nas_Move  7.590650e-01\n",
      "108          Stock_EMA_Move  7.547244e-01\n",
      "47                Wiki_gain  7.470438e-01\n",
      "54           Wiki_MAvg_Move  7.190388e-01\n",
      "46                Wiki_diff  6.987742e-01\n",
      "89         Stock_Moment_2_s  6.953927e-01\n",
      "129                  Nas_rs  6.324531e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "# apply SelectKBest class to extract top 40 best features\n",
    "bestfeatures = SelectKBest(score_func=f_regression, k=40)\n",
    "best_fit = bestfeatures.fit(train_f0, train_f0t)\n",
    "best_scores = pd.DataFrame(best_fit.scores_)\n",
    "best_columns = pd.DataFrame(Ford_0.columns)\n",
    "\n",
    "# concatenate the dataframes for better visualization\n",
    "features_score = pd.concat([best_columns, best_scores], axis=1)\n",
    "features_score.columns = ['Features', 'Score']  # naming the dataframe columns\n",
    "print(features_score.nlargest(40, 'Score'))  # print the top 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "683d2281",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = list(features_score.nlargest(40, 'Score')['Features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "048d7967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 15.68433691,  24.74667373,  33.10378249,  40.54965109,\n",
       "        47.39486325,  52.10029515,  55.50687153,  58.50470073,\n",
       "        61.42530001,  64.16698358,  66.53422149,  68.88994394,\n",
       "        71.02367211,  73.08023374,  75.02227321,  76.60158477,\n",
       "        78.0620214 ,  79.39525157,  80.67360492,  81.84725939,\n",
       "        83.00384916,  84.08061599,  85.07367374,  86.01668656,\n",
       "        86.88167021,  87.66126402,  88.38898007,  89.07250363,\n",
       "        89.72934819,  90.35721032,  90.96092432,  91.51678808,\n",
       "        92.05310805,  92.55542469,  93.03539412,  93.48671903,\n",
       "        93.90272285,  94.30439446,  94.68386345,  95.03240113,\n",
       "        95.3773965 ,  95.69977774,  96.00449478,  96.27854221,\n",
       "        96.53127052,  96.77177334,  96.99681187,  97.20554906,\n",
       "        97.39294777,  97.57709392,  97.74530298,  97.90443261,\n",
       "        98.05346752,  98.18960852,  98.31107071,  98.42348617,\n",
       "        98.52366819,  98.62112629,  98.70982943,  98.7923154 ,\n",
       "        98.86712008,  98.9372757 ,  99.00342101,  99.06554473,\n",
       "        99.12432462,  99.17917825,  99.23162819,  99.28083157,\n",
       "        99.32823752,  99.37265359,  99.41454389,  99.45282069,\n",
       "        99.48730254,  99.51861474,  99.5471169 ,  99.57270153,\n",
       "        99.59784448,  99.62100526,  99.64350963,  99.66522011,\n",
       "        99.6856891 ,  99.70476123,  99.72290744,  99.74025873,\n",
       "        99.75691696,  99.77298203,  99.78846039,  99.80342555,\n",
       "        99.81769669,  99.83084151,  99.84374413,  99.85580942,\n",
       "        99.86764828,  99.87914171,  99.89013066,  99.90069459,\n",
       "        99.91091898,  99.92031976,  99.92834919,  99.93602977,\n",
       "        99.94327895,  99.94966882,  99.9551483 ,  99.96013141,\n",
       "        99.96492254,  99.96896246,  99.97267246,  99.97624287,\n",
       "        99.97936168,  99.98222935,  99.9848438 ,  99.98683568,\n",
       "        99.98857062,  99.99008194,  99.9915254 ,  99.99276596,\n",
       "        99.99397484,  99.99503114,  99.99569156,  99.99629903,\n",
       "        99.99677637,  99.99724637,  99.99763481,  99.99800224,\n",
       "        99.99833522,  99.99865038,  99.998931  ,  99.99913134,\n",
       "        99.99928818,  99.99942647,  99.99954131,  99.99963876,\n",
       "        99.99971003,  99.99977048,  99.99982408,  99.99986711,\n",
       "        99.99990905,  99.99993972,  99.99995556,  99.99997032,\n",
       "        99.99998449,  99.99999052,  99.99999561,  99.99999892,\n",
       "        99.99999999, 100.        , 100.        , 100.        ,\n",
       "       100.        , 100.        , 100.        , 100.        ,\n",
       "       100.        , 100.        , 100.        , 100.        ,\n",
       "       100.        , 100.        , 100.        , 100.        ,\n",
       "       100.        , 100.        , 100.        , 100.        ,\n",
       "       100.        ])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA \n",
    "pca = PCA().fit(train_f0)\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') # for each component\n",
    "plt.show()\n",
    "np.cumsum(pca.explained_variance_ratio_) * 100\n",
    "# reach 85% variance explained with 23 principle components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "e186f113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 18.66241111,  35.84253923,  45.30504038,  52.922487  ,\n",
       "        60.4248241 ,  67.50426855,  74.21093435,  80.54626761,\n",
       "        84.05727658,  86.62596149,  88.99254744,  91.1645831 ,\n",
       "        92.92216156,  94.55803141,  95.52117579,  96.38660887,\n",
       "        97.08481547,  97.60281808,  98.08808651,  98.32139431,\n",
       "        98.54934806,  98.75599665,  98.94597887,  99.12335478,\n",
       "        99.26581491,  99.39748682,  99.50860948,  99.5814469 ,\n",
       "        99.64646238,  99.70346206,  99.75636888,  99.8053512 ,\n",
       "        99.85332717,  99.89527546,  99.92696851,  99.95199898,\n",
       "        99.97634481,  99.99802256, 100.        , 100.        ])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PCA with 40 best components\n",
    "pca_1 = PCA().fit(train_f0[feats])\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca_1.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') # for each component\n",
    "plt.show()\n",
    "np.cumsum(pca_1.explained_variance_ratio_) * 100\n",
    "# can use 8 principle compents now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338b2cc0",
   "metadata": {},
   "source": [
    "Keeping score: Will test 5 models with Ford_0 data variations,\n",
    "- Model_0_0 = All varaibles,\n",
    "- Model_0_1 = PCA All varaibles\n",
    "- Model_0_2 = 40 best k score\n",
    "- Model_0_3 = PCA of 40 Best K Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a449c60",
   "metadata": {},
   "source": [
    "### Model_0_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "b9ef8b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_0_0 final data prep\n",
    "\n",
    "# converting to window format, in this case 5 periods\n",
    "train_X_0_0, train_f0t_tc = df_to_X_y2(train_f0,train_f0t)\n",
    "val_X_0_0, val_f0t_tc= df_to_X_y2(val_f0, val_f0t)\n",
    "test_X_0_0, test_f0t_tc = df_to_X_y2(test_f0,test_f0t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "9c108603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496, 491)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_f0t), len(train_X_0_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "602a57f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_0_0.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "0375a1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 16ms/step - loss: 0.6946 - accuracy: 0.5153 - val_loss: 0.6989 - val_accuracy: 0.4599\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6915 - accuracy: 0.5316 - val_loss: 0.6978 - val_accuracy: 0.4599\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6905 - accuracy: 0.5173 - val_loss: 0.6924 - val_accuracy: 0.4964\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6899 - accuracy: 0.5214 - val_loss: 0.6921 - val_accuracy: 0.5328\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.5377 - val_loss: 0.6949 - val_accuracy: 0.5255\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6879 - accuracy: 0.5193 - val_loss: 0.6891 - val_accuracy: 0.5547\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6855 - accuracy: 0.5336 - val_loss: 0.6933 - val_accuracy: 0.5401\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6846 - accuracy: 0.5316 - val_loss: 0.6890 - val_accuracy: 0.5474\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6865 - accuracy: 0.5234 - val_loss: 0.6881 - val_accuracy: 0.5401\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6858 - accuracy: 0.5295 - val_loss: 0.6869 - val_accuracy: 0.5547\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6866 - accuracy: 0.5234 - val_loss: 0.6862 - val_accuracy: 0.5547\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6801 - accuracy: 0.5295 - val_loss: 0.6919 - val_accuracy: 0.5182\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6785 - accuracy: 0.5438 - val_loss: 0.6852 - val_accuracy: 0.5766\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6762 - accuracy: 0.5560 - val_loss: 0.6910 - val_accuracy: 0.4891\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6714 - accuracy: 0.5723 - val_loss: 0.6834 - val_accuracy: 0.5693\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6694 - accuracy: 0.6212 - val_loss: 0.6885 - val_accuracy: 0.5328\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6671 - accuracy: 0.5845 - val_loss: 0.6883 - val_accuracy: 0.5401\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6627 - accuracy: 0.6029 - val_loss: 0.6910 - val_accuracy: 0.5182\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6604 - accuracy: 0.5723 - val_loss: 0.6946 - val_accuracy: 0.4818\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6516 - accuracy: 0.6314 - val_loss: 0.6927 - val_accuracy: 0.5328\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6474 - accuracy: 0.6375 - val_loss: 0.6935 - val_accuracy: 0.5255\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6450 - accuracy: 0.6456 - val_loss: 0.6980 - val_accuracy: 0.5109\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6358 - accuracy: 0.6375 - val_loss: 0.7037 - val_accuracy: 0.5255\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6308 - accuracy: 0.6538 - val_loss: 0.7094 - val_accuracy: 0.5328\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6271 - accuracy: 0.6558 - val_loss: 0.7126 - val_accuracy: 0.4964\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6188 - accuracy: 0.6599 - val_loss: 0.7193 - val_accuracy: 0.5109\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6160 - accuracy: 0.6802 - val_loss: 0.7159 - val_accuracy: 0.4818\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6093 - accuracy: 0.6864 - val_loss: 0.7251 - val_accuracy: 0.5182\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6025 - accuracy: 0.6802 - val_loss: 0.7327 - val_accuracy: 0.5036\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6028 - accuracy: 0.6843 - val_loss: 0.7321 - val_accuracy: 0.5036\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5987 - accuracy: 0.6945 - val_loss: 0.7365 - val_accuracy: 0.4891\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6001 - accuracy: 0.6721 - val_loss: 0.7525 - val_accuracy: 0.4818\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5895 - accuracy: 0.7047 - val_loss: 0.7489 - val_accuracy: 0.5109\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5882 - accuracy: 0.6945 - val_loss: 0.7552 - val_accuracy: 0.5255\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5786 - accuracy: 0.7088 - val_loss: 0.7561 - val_accuracy: 0.5182\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5745 - accuracy: 0.7108 - val_loss: 0.7660 - val_accuracy: 0.5109\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5710 - accuracy: 0.7210 - val_loss: 0.7724 - val_accuracy: 0.4891\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5701 - accuracy: 0.7210 - val_loss: 0.7820 - val_accuracy: 0.4891\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5669 - accuracy: 0.7026 - val_loss: 0.7792 - val_accuracy: 0.5036\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5582 - accuracy: 0.7108 - val_loss: 0.7935 - val_accuracy: 0.5036\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5572 - accuracy: 0.7454 - val_loss: 0.7924 - val_accuracy: 0.5182\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5510 - accuracy: 0.7332 - val_loss: 0.8038 - val_accuracy: 0.5109\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5477 - accuracy: 0.7393 - val_loss: 0.8042 - val_accuracy: 0.5036\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5414 - accuracy: 0.7373 - val_loss: 0.8194 - val_accuracy: 0.4599\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5548 - accuracy: 0.7271 - val_loss: 0.8130 - val_accuracy: 0.5328\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5360 - accuracy: 0.7230 - val_loss: 0.8152 - val_accuracy: 0.5255\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5358 - accuracy: 0.7332 - val_loss: 0.8195 - val_accuracy: 0.5182\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5318 - accuracy: 0.7495 - val_loss: 0.8306 - val_accuracy: 0.5109\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5310 - accuracy: 0.7271 - val_loss: 0.8274 - val_accuracy: 0.5255\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5251 - accuracy: 0.7413 - val_loss: 0.8332 - val_accuracy: 0.5109\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5175 - accuracy: 0.7536 - val_loss: 0.8410 - val_accuracy: 0.5328\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5143 - accuracy: 0.7454 - val_loss: 0.8414 - val_accuracy: 0.5182\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5155 - accuracy: 0.7352 - val_loss: 0.8506 - val_accuracy: 0.5109\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5123 - accuracy: 0.7536 - val_loss: 0.8498 - val_accuracy: 0.5182\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5217 - accuracy: 0.7352 - val_loss: 0.8542 - val_accuracy: 0.5109\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5049 - accuracy: 0.7413 - val_loss: 0.8494 - val_accuracy: 0.5182\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5008 - accuracy: 0.7393 - val_loss: 0.8575 - val_accuracy: 0.5109\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4974 - accuracy: 0.7393 - val_loss: 0.8675 - val_accuracy: 0.5182\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5041 - accuracy: 0.7454 - val_loss: 0.8754 - val_accuracy: 0.5036\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4963 - accuracy: 0.7658 - val_loss: 0.8815 - val_accuracy: 0.4964\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4906 - accuracy: 0.7576 - val_loss: 0.8820 - val_accuracy: 0.5109\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4939 - accuracy: 0.7597 - val_loss: 0.8980 - val_accuracy: 0.4964\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4855 - accuracy: 0.7637 - val_loss: 0.9012 - val_accuracy: 0.5182\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.4905 - accuracy: 0.7536 - val_loss: 0.9018 - val_accuracy: 0.5109\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4816 - accuracy: 0.7475 - val_loss: 0.8947 - val_accuracy: 0.5109\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4793 - accuracy: 0.7821 - val_loss: 0.8952 - val_accuracy: 0.4891\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4893 - accuracy: 0.7576 - val_loss: 0.8896 - val_accuracy: 0.5182\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4743 - accuracy: 0.7658 - val_loss: 0.9025 - val_accuracy: 0.5182\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7821 - val_loss: 0.9283 - val_accuracy: 0.5182\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.7617 - val_loss: 0.9209 - val_accuracy: 0.5328\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7841 - val_loss: 0.9153 - val_accuracy: 0.5328\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4611 - accuracy: 0.7739 - val_loss: 0.9233 - val_accuracy: 0.5255\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.4555 - accuracy: 0.7862 - val_loss: 0.9270 - val_accuracy: 0.5109\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4624 - accuracy: 0.7719 - val_loss: 0.9434 - val_accuracy: 0.5109\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7821 - val_loss: 0.9404 - val_accuracy: 0.5255\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.7658 - val_loss: 0.9729 - val_accuracy: 0.5109\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7821 - val_loss: 0.9481 - val_accuracy: 0.5401\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.8004 - val_loss: 0.9598 - val_accuracy: 0.5182\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.7943 - val_loss: 0.9560 - val_accuracy: 0.5328\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7984 - val_loss: 0.9828 - val_accuracy: 0.5255\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4384 - accuracy: 0.7862 - val_loss: 0.9819 - val_accuracy: 0.5182\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.8045 - val_loss: 0.9902 - val_accuracy: 0.5109\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4382 - accuracy: 0.8024 - val_loss: 1.0015 - val_accuracy: 0.5182\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.8004 - val_loss: 1.0092 - val_accuracy: 0.5036\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7821 - val_loss: 1.0182 - val_accuracy: 0.4964\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4351 - accuracy: 0.7841 - val_loss: 0.9972 - val_accuracy: 0.5328\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4247 - accuracy: 0.8045 - val_loss: 1.0237 - val_accuracy: 0.5109\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.8004 - val_loss: 1.0417 - val_accuracy: 0.5036\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4316 - accuracy: 0.7862 - val_loss: 1.0401 - val_accuracy: 0.5036\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4479 - accuracy: 0.7739 - val_loss: 1.0217 - val_accuracy: 0.5328\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4168 - accuracy: 0.8045 - val_loss: 1.0445 - val_accuracy: 0.5109\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7963 - val_loss: 1.0412 - val_accuracy: 0.5182\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7739 - val_loss: 1.0247 - val_accuracy: 0.4891\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4205 - accuracy: 0.7984 - val_loss: 1.0615 - val_accuracy: 0.5182\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.8004 - val_loss: 1.0452 - val_accuracy: 0.5109\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4089 - accuracy: 0.8086 - val_loss: 1.0825 - val_accuracy: 0.5109\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8126 - val_loss: 1.0596 - val_accuracy: 0.5255\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8167 - val_loss: 1.0740 - val_accuracy: 0.4891\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4029 - accuracy: 0.8065 - val_loss: 1.0698 - val_accuracy: 0.5255\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8106 - val_loss: 1.0938 - val_accuracy: 0.5036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x159b3ad90>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = train_X_0_0.shape[1]\n",
    "n_features = train_X_0_0.shape[2]\n",
    "\n",
    "model_0_0_1 = Sequential()\n",
    "model_0_0_1.add(Conv1D(filters=5, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model_0_0_1.add(MaxPooling1D(pool_size=2)) \n",
    "model_0_0_1.add(Flatten())\n",
    "model_0_0_1.add(Dense(50, activation='relu')) \n",
    "model_0_0_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_0_0_1.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_0_0_1.fit(train_X_0_0, train_f0t_tc,epochs=100,  validation_data=(val_X_0_0, val_f0t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "2cc060af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 15ms/step - loss: 0.7052 - accuracy: 0.4949 - val_loss: 0.6997 - val_accuracy: 0.5182\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6860 - accuracy: 0.5438 - val_loss: 0.6880 - val_accuracy: 0.5036\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6743 - accuracy: 0.5743 - val_loss: 0.6986 - val_accuracy: 0.5182\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6659 - accuracy: 0.6191 - val_loss: 0.6875 - val_accuracy: 0.5401\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6541 - accuracy: 0.6415 - val_loss: 0.7213 - val_accuracy: 0.5182\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6575 - accuracy: 0.6130 - val_loss: 0.6913 - val_accuracy: 0.5036\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6449 - accuracy: 0.6354 - val_loss: 0.7141 - val_accuracy: 0.4964\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6399 - accuracy: 0.6456 - val_loss: 0.7026 - val_accuracy: 0.5474\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6097 - accuracy: 0.6925 - val_loss: 0.7119 - val_accuracy: 0.5255\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5879 - accuracy: 0.7576 - val_loss: 0.7092 - val_accuracy: 0.5255\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.7475 - val_loss: 0.7029 - val_accuracy: 0.5109\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5671 - accuracy: 0.7352 - val_loss: 0.7258 - val_accuracy: 0.5036\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5554 - accuracy: 0.7210 - val_loss: 0.7299 - val_accuracy: 0.5036\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5143 - accuracy: 0.8024 - val_loss: 0.7242 - val_accuracy: 0.5109\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4937 - accuracy: 0.8004 - val_loss: 0.7587 - val_accuracy: 0.5109\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4775 - accuracy: 0.8045 - val_loss: 0.7985 - val_accuracy: 0.4745\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.4708 - accuracy: 0.7862 - val_loss: 0.7578 - val_accuracy: 0.5109\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.8350 - val_loss: 0.8046 - val_accuracy: 0.5182\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7882 - val_loss: 0.7837 - val_accuracy: 0.5255\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8676 - val_loss: 0.7969 - val_accuracy: 0.5182\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3806 - accuracy: 0.8697 - val_loss: 0.8023 - val_accuracy: 0.4964\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3425 - accuracy: 0.9104 - val_loss: 0.8434 - val_accuracy: 0.5109\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3183 - accuracy: 0.9043 - val_loss: 0.8984 - val_accuracy: 0.4745\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3109 - accuracy: 0.8921 - val_loss: 0.9988 - val_accuracy: 0.5474\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3432 - accuracy: 0.8452 - val_loss: 0.9613 - val_accuracy: 0.4453\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3205 - accuracy: 0.8697 - val_loss: 0.8926 - val_accuracy: 0.4745\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2689 - accuracy: 0.9185 - val_loss: 0.9515 - val_accuracy: 0.4672\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2479 - accuracy: 0.9348 - val_loss: 0.9727 - val_accuracy: 0.5036\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2223 - accuracy: 0.9430 - val_loss: 1.0456 - val_accuracy: 0.4891\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2146 - accuracy: 0.9369 - val_loss: 1.0678 - val_accuracy: 0.5474\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2189 - accuracy: 0.9267 - val_loss: 1.0578 - val_accuracy: 0.5036\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2032 - accuracy: 0.9389 - val_loss: 1.0754 - val_accuracy: 0.4964\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1747 - accuracy: 0.9572 - val_loss: 1.1061 - val_accuracy: 0.4745\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1612 - accuracy: 0.9756 - val_loss: 1.1368 - val_accuracy: 0.4891\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1470 - accuracy: 0.9817 - val_loss: 1.2082 - val_accuracy: 0.4818\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1355 - accuracy: 0.9735 - val_loss: 1.2423 - val_accuracy: 0.5036\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1251 - accuracy: 0.9817 - val_loss: 1.2426 - val_accuracy: 0.4818\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1135 - accuracy: 0.9837 - val_loss: 1.2886 - val_accuracy: 0.4891\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1175 - accuracy: 0.9756 - val_loss: 1.3106 - val_accuracy: 0.4891\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1271 - accuracy: 0.9715 - val_loss: 1.3518 - val_accuracy: 0.4818\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1151 - accuracy: 0.9796 - val_loss: 1.3409 - val_accuracy: 0.4745\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1087 - accuracy: 0.9735 - val_loss: 1.3720 - val_accuracy: 0.4891\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0829 - accuracy: 0.9959 - val_loss: 1.4284 - val_accuracy: 0.5182\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1093 - accuracy: 0.9776 - val_loss: 1.4223 - val_accuracy: 0.4891\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0860 - accuracy: 0.9857 - val_loss: 1.4541 - val_accuracy: 0.4964\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0776 - accuracy: 0.9939 - val_loss: 1.4891 - val_accuracy: 0.4818\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0659 - accuracy: 0.9939 - val_loss: 1.5108 - val_accuracy: 0.5109\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 1.5538 - val_accuracy: 0.5036\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0531 - accuracy: 0.9980 - val_loss: 1.6192 - val_accuracy: 0.5036\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 1.6509 - val_accuracy: 0.4818\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0506 - accuracy: 0.9980 - val_loss: 1.6933 - val_accuracy: 0.5109\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 1.6819 - val_accuracy: 0.4964\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 1.7017 - val_accuracy: 0.4964\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 1.7422 - val_accuracy: 0.5109\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 1.7421 - val_accuracy: 0.5109\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 1.7736 - val_accuracy: 0.5182\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 1.7979 - val_accuracy: 0.5036\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 1.8257 - val_accuracy: 0.5036\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 1.8478 - val_accuracy: 0.5109\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 1.8835 - val_accuracy: 0.4964\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 1.9937 - val_accuracy: 0.5328\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 0.9980 - val_loss: 1.9263 - val_accuracy: 0.5182\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 1.9775 - val_accuracy: 0.5182\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 1.9838 - val_accuracy: 0.5182\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 2.0261 - val_accuracy: 0.5109\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.0051 - val_accuracy: 0.5255\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.0407 - val_accuracy: 0.5109\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.0918 - val_accuracy: 0.5182\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.0885 - val_accuracy: 0.5255\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 2.1187 - val_accuracy: 0.5255\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 2.1370 - val_accuracy: 0.5255\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 2.1720 - val_accuracy: 0.5255\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 2.1755 - val_accuracy: 0.5328\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 2.1993 - val_accuracy: 0.4891\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.2069 - val_accuracy: 0.5401\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.2330 - val_accuracy: 0.5182\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.2372 - val_accuracy: 0.5401\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.2547 - val_accuracy: 0.5109\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.2736 - val_accuracy: 0.5255\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.3015 - val_accuracy: 0.5182\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.3142 - val_accuracy: 0.5255\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.3341 - val_accuracy: 0.5255\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.3586 - val_accuracy: 0.5255\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.3614 - val_accuracy: 0.5109\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.3771 - val_accuracy: 0.5401\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.4066 - val_accuracy: 0.5182\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.4060 - val_accuracy: 0.5255\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.4261 - val_accuracy: 0.5255\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.4369 - val_accuracy: 0.5328\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.4691 - val_accuracy: 0.5255\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.4742 - val_accuracy: 0.5255\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.4919 - val_accuracy: 0.5401\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.4802 - val_accuracy: 0.5182\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.5144 - val_accuracy: 0.5401\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.5552 - val_accuracy: 0.5255\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.5588 - val_accuracy: 0.5328\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.5568 - val_accuracy: 0.5255\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.5574 - val_accuracy: 0.5255\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.5665 - val_accuracy: 0.5328\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.5952 - val_accuracy: 0.5328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x159cb6c40>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_0_2 = Sequential()\n",
    "model_0_0_2.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model_0_0_2.add(MaxPooling1D(pool_size=2)) \n",
    "model_0_0_2.add(Flatten())\n",
    "model_0_0_2.add(Dense(50, activation='relu')) \n",
    "model_0_0_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_0_0_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_0_0_2.fit(train_X_0_0,train_f0t_tc,epochs=100,  validation_data=(val_X_0_0, val_f0t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "38d44d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 17ms/step - loss: 0.7076 - accuracy: 0.4827 - val_loss: 0.6956 - val_accuracy: 0.5109\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6906 - accuracy: 0.5499 - val_loss: 0.6920 - val_accuracy: 0.4891\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6944 - accuracy: 0.5214 - val_loss: 0.6907 - val_accuracy: 0.5328\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6875 - accuracy: 0.5479 - val_loss: 0.6884 - val_accuracy: 0.5401\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6894 - accuracy: 0.5336 - val_loss: 0.6911 - val_accuracy: 0.5109\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6780 - accuracy: 0.5743 - val_loss: 0.6874 - val_accuracy: 0.5401\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6679 - accuracy: 0.5927 - val_loss: 0.6846 - val_accuracy: 0.5401\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6579 - accuracy: 0.5886 - val_loss: 0.6802 - val_accuracy: 0.5474\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6631 - accuracy: 0.5845 - val_loss: 0.7061 - val_accuracy: 0.5182\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6525 - accuracy: 0.5927 - val_loss: 0.6918 - val_accuracy: 0.5620\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.6558 - val_loss: 0.6899 - val_accuracy: 0.5328\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6132 - accuracy: 0.7006 - val_loss: 0.6762 - val_accuracy: 0.5839\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6145 - accuracy: 0.6558 - val_loss: 0.7174 - val_accuracy: 0.5255\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6087 - accuracy: 0.6619 - val_loss: 0.7110 - val_accuracy: 0.5036\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5722 - accuracy: 0.7434 - val_loss: 0.6870 - val_accuracy: 0.4964\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5447 - accuracy: 0.7434 - val_loss: 0.6916 - val_accuracy: 0.5766\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5139 - accuracy: 0.7760 - val_loss: 0.7173 - val_accuracy: 0.5328\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5029 - accuracy: 0.7576 - val_loss: 0.7608 - val_accuracy: 0.5839\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5337 - accuracy: 0.7271 - val_loss: 0.8631 - val_accuracy: 0.5109\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5287 - accuracy: 0.7475 - val_loss: 0.7075 - val_accuracy: 0.5547\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7984 - val_loss: 0.7171 - val_accuracy: 0.5985\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.8187 - val_loss: 0.7385 - val_accuracy: 0.5620\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8574 - val_loss: 0.7487 - val_accuracy: 0.5693\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3788 - accuracy: 0.8595 - val_loss: 0.7346 - val_accuracy: 0.6350\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3685 - accuracy: 0.8758 - val_loss: 0.7585 - val_accuracy: 0.5620\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3355 - accuracy: 0.8900 - val_loss: 0.8079 - val_accuracy: 0.5766\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3300 - accuracy: 0.8676 - val_loss: 0.8174 - val_accuracy: 0.5620\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3223 - accuracy: 0.8574 - val_loss: 0.8499 - val_accuracy: 0.5985\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2720 - accuracy: 0.9308 - val_loss: 0.8648 - val_accuracy: 0.5985\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2465 - accuracy: 0.9389 - val_loss: 0.8682 - val_accuracy: 0.6569\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2384 - accuracy: 0.9389 - val_loss: 1.0451 - val_accuracy: 0.5839\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2302 - accuracy: 0.9226 - val_loss: 0.9302 - val_accuracy: 0.5839\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1956 - accuracy: 0.9593 - val_loss: 0.9872 - val_accuracy: 0.5620\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1678 - accuracy: 0.9695 - val_loss: 0.9777 - val_accuracy: 0.6204\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1485 - accuracy: 0.9796 - val_loss: 1.0658 - val_accuracy: 0.5912\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1476 - accuracy: 0.9715 - val_loss: 1.1232 - val_accuracy: 0.5693\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1420 - accuracy: 0.9756 - val_loss: 1.1698 - val_accuracy: 0.5839\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1344 - accuracy: 0.9654 - val_loss: 1.1266 - val_accuracy: 0.6131\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1324 - accuracy: 0.9735 - val_loss: 1.1961 - val_accuracy: 0.5693\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1120 - accuracy: 0.9735 - val_loss: 1.1816 - val_accuracy: 0.5912\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1046 - accuracy: 0.9817 - val_loss: 1.3867 - val_accuracy: 0.5912\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.9959 - val_loss: 1.3474 - val_accuracy: 0.5693\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0729 - accuracy: 0.9939 - val_loss: 1.3231 - val_accuracy: 0.5912\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0650 - accuracy: 0.9959 - val_loss: 1.5035 - val_accuracy: 0.5547\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0582 - accuracy: 0.9980 - val_loss: 1.4254 - val_accuracy: 0.5839\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 1.4482 - val_accuracy: 0.5620\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 1.4996 - val_accuracy: 0.5547\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 1.6078 - val_accuracy: 0.5401\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 1.4811 - val_accuracy: 0.5766\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 1.6899 - val_accuracy: 0.5985\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0372 - accuracy: 0.9980 - val_loss: 1.5762 - val_accuracy: 0.5766\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 1.6070 - val_accuracy: 0.5766\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 1.6968 - val_accuracy: 0.5620\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 1.7316 - val_accuracy: 0.5839\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 1.8121 - val_accuracy: 0.5912\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 1.8213 - val_accuracy: 0.5474\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 1.8031 - val_accuracy: 0.5547\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.8135 - val_accuracy: 0.5766\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.8722 - val_accuracy: 0.5693\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.8425 - val_accuracy: 0.5693\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.8975 - val_accuracy: 0.5547\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.9610 - val_accuracy: 0.5766\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 2.0103 - val_accuracy: 0.5693\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 2.0063 - val_accuracy: 0.5401\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.9483 - val_accuracy: 0.5693\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.0352 - val_accuracy: 0.5401\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.0233 - val_accuracy: 0.5693\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.0887 - val_accuracy: 0.5693\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.0741 - val_accuracy: 0.5474\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.1213 - val_accuracy: 0.5474\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.1210 - val_accuracy: 0.5474\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.1317 - val_accuracy: 0.5547\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.1568 - val_accuracy: 0.5693\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.1699 - val_accuracy: 0.5620\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.2341 - val_accuracy: 0.5766\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.2092 - val_accuracy: 0.5693\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.2184 - val_accuracy: 0.5474\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.2671 - val_accuracy: 0.5620\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.2957 - val_accuracy: 0.5839\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.3178 - val_accuracy: 0.5766\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.3101 - val_accuracy: 0.5620\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.3203 - val_accuracy: 0.5474\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.3159 - val_accuracy: 0.5474\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.3483 - val_accuracy: 0.5547\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.4199 - val_accuracy: 0.5766\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.3870 - val_accuracy: 0.5620\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.4009 - val_accuracy: 0.5620\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.4278 - val_accuracy: 0.5547\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.4053 - val_accuracy: 0.5547\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.4321 - val_accuracy: 0.5693\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.4248 - val_accuracy: 0.5547\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.4572 - val_accuracy: 0.5693\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.4474 - val_accuracy: 0.5620\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.4576 - val_accuracy: 0.5474\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.4649 - val_accuracy: 0.5547\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.4956 - val_accuracy: 0.5547\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.5112 - val_accuracy: 0.5547\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.5104 - val_accuracy: 0.5474\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.5293 - val_accuracy: 0.5620\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.5583 - val_accuracy: 0.5839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x159da8f70>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_0_3 = Sequential()\n",
    "model_0_0_3.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features)))\n",
    "model_0_0_3.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_0_0_3.add(MaxPooling1D(pool_size=2)) \n",
    "model_0_0_3.add(Flatten())\n",
    "model_0_0_3.add(Dense(50, activation='relu')) \n",
    "model_0_0_3.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model_0_0_3.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_0_0_3.fit(train_X_0_0,train_f0t_tc,epochs=100,  validation_data=(val_X_0_0, val_f0t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "79a0e4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 17ms/step - loss: 0.6953 - accuracy: 0.4786 - val_loss: 0.6952 - val_accuracy: 0.4745\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6917 - accuracy: 0.5214 - val_loss: 0.6930 - val_accuracy: 0.5182\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6892 - accuracy: 0.5540 - val_loss: 0.6941 - val_accuracy: 0.4891\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6881 - accuracy: 0.5601 - val_loss: 0.6955 - val_accuracy: 0.4672\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6800 - accuracy: 0.5438 - val_loss: 0.6959 - val_accuracy: 0.5182\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6749 - accuracy: 0.6191 - val_loss: 0.7020 - val_accuracy: 0.5255\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6634 - accuracy: 0.6171 - val_loss: 0.7025 - val_accuracy: 0.5109\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6508 - accuracy: 0.6049 - val_loss: 0.7060 - val_accuracy: 0.4599\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6305 - accuracy: 0.6558 - val_loss: 0.7144 - val_accuracy: 0.5328\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6068 - accuracy: 0.6843 - val_loss: 0.7956 - val_accuracy: 0.5036\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6215 - accuracy: 0.6212 - val_loss: 0.8038 - val_accuracy: 0.5182\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6258 - accuracy: 0.6130 - val_loss: 0.7081 - val_accuracy: 0.5766\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5710 - accuracy: 0.7312 - val_loss: 0.7234 - val_accuracy: 0.5620\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5231 - accuracy: 0.7739 - val_loss: 0.8380 - val_accuracy: 0.5401\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5680 - accuracy: 0.6802 - val_loss: 0.7390 - val_accuracy: 0.5328\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5015 - accuracy: 0.7760 - val_loss: 0.7853 - val_accuracy: 0.5620\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.8167 - val_loss: 0.8246 - val_accuracy: 0.5255\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.8167 - val_loss: 0.8729 - val_accuracy: 0.5839\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3785 - accuracy: 0.8391 - val_loss: 0.9032 - val_accuracy: 0.5474\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3393 - accuracy: 0.8737 - val_loss: 0.9418 - val_accuracy: 0.5620\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3039 - accuracy: 0.8921 - val_loss: 1.1278 - val_accuracy: 0.5255\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8452 - val_loss: 0.9757 - val_accuracy: 0.5255\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2847 - accuracy: 0.9063 - val_loss: 1.1144 - val_accuracy: 0.5182\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2672 - accuracy: 0.8982 - val_loss: 1.1115 - val_accuracy: 0.5255\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2192 - accuracy: 0.9287 - val_loss: 1.2067 - val_accuracy: 0.5474\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1869 - accuracy: 0.9430 - val_loss: 1.3156 - val_accuracy: 0.4891\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2006 - accuracy: 0.9348 - val_loss: 1.5187 - val_accuracy: 0.4891\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2024 - accuracy: 0.9145 - val_loss: 1.2603 - val_accuracy: 0.5474\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1772 - accuracy: 0.9430 - val_loss: 1.3874 - val_accuracy: 0.4818\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1123 - accuracy: 0.9674 - val_loss: 1.4654 - val_accuracy: 0.4964\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0930 - accuracy: 0.9756 - val_loss: 1.5094 - val_accuracy: 0.5182\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0859 - accuracy: 0.9817 - val_loss: 1.6485 - val_accuracy: 0.4818\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.9857 - val_loss: 1.7288 - val_accuracy: 0.5036\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0726 - accuracy: 0.9796 - val_loss: 1.8317 - val_accuracy: 0.5109\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0533 - accuracy: 0.9919 - val_loss: 1.7948 - val_accuracy: 0.5036\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0588 - accuracy: 0.9878 - val_loss: 1.8634 - val_accuracy: 0.4891\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0375 - accuracy: 0.9939 - val_loss: 1.9362 - val_accuracy: 0.5036\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0299 - accuracy: 0.9959 - val_loss: 2.0503 - val_accuracy: 0.5036\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0273 - accuracy: 0.9939 - val_loss: 2.2108 - val_accuracy: 0.4964\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0179 - accuracy: 0.9959 - val_loss: 2.3176 - val_accuracy: 0.5036\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.3206 - val_accuracy: 0.4964\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.4074 - val_accuracy: 0.5182\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.4832 - val_accuracy: 0.5109\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.5546 - val_accuracy: 0.5036\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.6243 - val_accuracy: 0.5255\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.6599 - val_accuracy: 0.5182\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.7015 - val_accuracy: 0.5109\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.7384 - val_accuracy: 0.5109\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.7736 - val_accuracy: 0.5109\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.8246 - val_accuracy: 0.5109\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.8679 - val_accuracy: 0.5182\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.8828 - val_accuracy: 0.5109\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9419 - val_accuracy: 0.5182\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9917 - val_accuracy: 0.5182\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0050 - val_accuracy: 0.5182\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.0556 - val_accuracy: 0.5182\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.0875 - val_accuracy: 0.5182\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.1311 - val_accuracy: 0.5182\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.1662 - val_accuracy: 0.5182\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.1958 - val_accuracy: 0.5182\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.2415 - val_accuracy: 0.5182\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.2722 - val_accuracy: 0.5182\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.3111 - val_accuracy: 0.5182\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.7887e-04 - accuracy: 1.0000 - val_loss: 3.3343 - val_accuracy: 0.5182\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.9660e-04 - accuracy: 1.0000 - val_loss: 3.3755 - val_accuracy: 0.5109\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.3820e-04 - accuracy: 1.0000 - val_loss: 3.4074 - val_accuracy: 0.5182\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.8252e-04 - accuracy: 1.0000 - val_loss: 3.4405 - val_accuracy: 0.5109\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.2758e-04 - accuracy: 1.0000 - val_loss: 3.4730 - val_accuracy: 0.5182\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.7368e-04 - accuracy: 1.0000 - val_loss: 3.5144 - val_accuracy: 0.5182\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 6.2221e-04 - accuracy: 1.0000 - val_loss: 3.5433 - val_accuracy: 0.5109\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 5.7733e-04 - accuracy: 1.0000 - val_loss: 3.5692 - val_accuracy: 0.5109\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.4731e-04 - accuracy: 1.0000 - val_loss: 3.6018 - val_accuracy: 0.5109\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.1755e-04 - accuracy: 1.0000 - val_loss: 3.6339 - val_accuracy: 0.5182\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 4.8105e-04 - accuracy: 1.0000 - val_loss: 3.6610 - val_accuracy: 0.5182\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.4885e-04 - accuracy: 1.0000 - val_loss: 3.6834 - val_accuracy: 0.5109\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.2084e-04 - accuracy: 1.0000 - val_loss: 3.7106 - val_accuracy: 0.5109\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.0148e-04 - accuracy: 1.0000 - val_loss: 3.7437 - val_accuracy: 0.5182\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.8153e-04 - accuracy: 1.0000 - val_loss: 3.7673 - val_accuracy: 0.5109\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.5310e-04 - accuracy: 1.0000 - val_loss: 3.7872 - val_accuracy: 0.5109\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.3546e-04 - accuracy: 1.0000 - val_loss: 3.8131 - val_accuracy: 0.5109\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.1527e-04 - accuracy: 1.0000 - val_loss: 3.8385 - val_accuracy: 0.5109\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.0223e-04 - accuracy: 1.0000 - val_loss: 3.8619 - val_accuracy: 0.5109\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.8487e-04 - accuracy: 1.0000 - val_loss: 3.8826 - val_accuracy: 0.5109\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.7109e-04 - accuracy: 1.0000 - val_loss: 3.9065 - val_accuracy: 0.5109\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.5830e-04 - accuracy: 1.0000 - val_loss: 3.9265 - val_accuracy: 0.5109\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.4862e-04 - accuracy: 1.0000 - val_loss: 3.9476 - val_accuracy: 0.5109\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 2.3333e-04 - accuracy: 1.0000 - val_loss: 3.9668 - val_accuracy: 0.5109\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 2.2608e-04 - accuracy: 1.0000 - val_loss: 3.9865 - val_accuracy: 0.5109\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.1557e-04 - accuracy: 1.0000 - val_loss: 4.0065 - val_accuracy: 0.5109\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.0465e-04 - accuracy: 1.0000 - val_loss: 4.0266 - val_accuracy: 0.5109\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.9553e-04 - accuracy: 1.0000 - val_loss: 4.0492 - val_accuracy: 0.5109\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.8851e-04 - accuracy: 1.0000 - val_loss: 4.0734 - val_accuracy: 0.5109\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.8035e-04 - accuracy: 1.0000 - val_loss: 4.0908 - val_accuracy: 0.5109\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.7120e-04 - accuracy: 1.0000 - val_loss: 4.1087 - val_accuracy: 0.5109\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.6503e-04 - accuracy: 1.0000 - val_loss: 4.1244 - val_accuracy: 0.5109\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6108e-04 - accuracy: 1.0000 - val_loss: 4.1440 - val_accuracy: 0.5109\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5173e-04 - accuracy: 1.0000 - val_loss: 4.1623 - val_accuracy: 0.5109\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4609e-04 - accuracy: 1.0000 - val_loss: 4.1807 - val_accuracy: 0.5109\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4035e-04 - accuracy: 1.0000 - val_loss: 4.1969 - val_accuracy: 0.5109\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3483e-04 - accuracy: 1.0000 - val_loss: 4.2155 - val_accuracy: 0.5109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x159fb0fa0>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_0_4 = Sequential()\n",
    "model_0_0_4.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features)))\n",
    "model_0_0_4.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_0_0_4.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_0_0_4.add(MaxPooling1D(pool_size=2)) \n",
    "model_0_0_4.add(Conv1D(filters=32, kernel_size=1, activation='relu')) \n",
    "model_0_0_4.add(Flatten())\n",
    "model_0_0_4.add(Dense(50, activation='relu')) \n",
    "model_0_0_4.add(Dense(1, activation='sigmoid')) \n",
    "model_0_0_4.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_0_0_4.fit(train_X_0_0,train_f0t_tc,epochs=100,  validation_data=(val_X_0_0, val_f0t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "19af56ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 19ms/step - loss: 0.6944 - accuracy: 0.5193 - val_loss: 0.6983 - val_accuracy: 0.5182\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6959 - accuracy: 0.5214 - val_loss: 0.6907 - val_accuracy: 0.5182\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6968 - accuracy: 0.4725 - val_loss: 0.6947 - val_accuracy: 0.5036\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6923 - accuracy: 0.5234 - val_loss: 0.6935 - val_accuracy: 0.5182\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6913 - accuracy: 0.5214 - val_loss: 0.6927 - val_accuracy: 0.5182\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6896 - accuracy: 0.5255 - val_loss: 0.6938 - val_accuracy: 0.5182\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6891 - accuracy: 0.5356 - val_loss: 0.6955 - val_accuracy: 0.5182\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6858 - accuracy: 0.5275 - val_loss: 0.6952 - val_accuracy: 0.4745\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6877 - accuracy: 0.5316 - val_loss: 0.6939 - val_accuracy: 0.5255\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6876 - accuracy: 0.5438 - val_loss: 0.6992 - val_accuracy: 0.4380\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6685 - accuracy: 0.6151 - val_loss: 0.7081 - val_accuracy: 0.4891\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6984 - accuracy: 0.4807 - val_loss: 0.6956 - val_accuracy: 0.4891\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6835 - accuracy: 0.5275 - val_loss: 0.7107 - val_accuracy: 0.5182\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6651 - accuracy: 0.5764 - val_loss: 0.7116 - val_accuracy: 0.4818\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6699 - accuracy: 0.5642 - val_loss: 0.7338 - val_accuracy: 0.4307\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6429 - accuracy: 0.6130 - val_loss: 0.7379 - val_accuracy: 0.5109\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6281 - accuracy: 0.6436 - val_loss: 0.7481 - val_accuracy: 0.4745\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6239 - accuracy: 0.6477 - val_loss: 0.7663 - val_accuracy: 0.4818\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5803 - accuracy: 0.6986 - val_loss: 0.7944 - val_accuracy: 0.5109\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5487 - accuracy: 0.7312 - val_loss: 0.7939 - val_accuracy: 0.4672\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5709 - accuracy: 0.6864 - val_loss: 0.7745 - val_accuracy: 0.4672\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5127 - accuracy: 0.7454 - val_loss: 0.8900 - val_accuracy: 0.4891\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4903 - accuracy: 0.7495 - val_loss: 0.8556 - val_accuracy: 0.5182\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4540 - accuracy: 0.7984 - val_loss: 0.8974 - val_accuracy: 0.5109\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4607 - accuracy: 0.7678 - val_loss: 0.8613 - val_accuracy: 0.5109\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.7821 - val_loss: 1.0167 - val_accuracy: 0.4526\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3621 - accuracy: 0.8432 - val_loss: 1.0316 - val_accuracy: 0.4818\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3640 - accuracy: 0.8432 - val_loss: 1.1765 - val_accuracy: 0.4818\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3112 - accuracy: 0.8798 - val_loss: 1.2142 - val_accuracy: 0.5328\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3153 - accuracy: 0.8574 - val_loss: 1.1669 - val_accuracy: 0.4599\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2788 - accuracy: 0.8859 - val_loss: 1.1669 - val_accuracy: 0.4818\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2117 - accuracy: 0.9267 - val_loss: 1.3558 - val_accuracy: 0.5036\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1866 - accuracy: 0.9430 - val_loss: 1.3755 - val_accuracy: 0.4818\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1773 - accuracy: 0.9267 - val_loss: 1.5678 - val_accuracy: 0.4891\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1983 - accuracy: 0.9226 - val_loss: 1.3425 - val_accuracy: 0.5109\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1989 - accuracy: 0.9287 - val_loss: 1.4207 - val_accuracy: 0.4745\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1201 - accuracy: 0.9593 - val_loss: 1.7080 - val_accuracy: 0.4891\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0934 - accuracy: 0.9796 - val_loss: 1.7701 - val_accuracy: 0.5182\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0950 - accuracy: 0.9735 - val_loss: 1.7429 - val_accuracy: 0.4818\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0877 - accuracy: 0.9817 - val_loss: 1.9439 - val_accuracy: 0.4891\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0803 - accuracy: 0.9756 - val_loss: 1.8752 - val_accuracy: 0.4672\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0594 - accuracy: 0.9837 - val_loss: 2.0612 - val_accuracy: 0.5182\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0501 - accuracy: 0.9919 - val_loss: 2.1520 - val_accuracy: 0.4526\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0363 - accuracy: 0.9959 - val_loss: 2.1597 - val_accuracy: 0.5036\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0174 - accuracy: 0.9980 - val_loss: 2.3688 - val_accuracy: 0.5109\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 2.4697 - val_accuracy: 0.4964\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0103 - accuracy: 0.9980 - val_loss: 2.4481 - val_accuracy: 0.5036\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 2.6542 - val_accuracy: 0.5036\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.7850 - val_accuracy: 0.5036\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.6828 - val_accuracy: 0.4964\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.6872 - val_accuracy: 0.4745\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.7853 - val_accuracy: 0.4964\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.9284 - val_accuracy: 0.5109\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.9130 - val_accuracy: 0.4964\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.8477 - val_accuracy: 0.4818\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.9216 - val_accuracy: 0.4818\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.0668 - val_accuracy: 0.4964\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.9604 - val_accuracy: 0.4745\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0630 - val_accuracy: 0.4964\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0651 - val_accuracy: 0.4818\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1083 - val_accuracy: 0.4964\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1582 - val_accuracy: 0.4964\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1204 - val_accuracy: 0.4818\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2134 - val_accuracy: 0.4964\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2500 - val_accuracy: 0.4964\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.2251 - val_accuracy: 0.4891\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.2532 - val_accuracy: 0.4964\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.2908 - val_accuracy: 0.4964\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.2925 - val_accuracy: 0.4964\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.3521 - val_accuracy: 0.4964\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.3694 - val_accuracy: 0.4964\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.3360 - val_accuracy: 0.4745\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.4351 - val_accuracy: 0.4891\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.6616e-04 - accuracy: 1.0000 - val_loss: 3.4174 - val_accuracy: 0.4964\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.7811e-04 - accuracy: 1.0000 - val_loss: 3.4639 - val_accuracy: 0.4964\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.6259e-04 - accuracy: 1.0000 - val_loss: 3.4774 - val_accuracy: 0.4964\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.1718e-04 - accuracy: 1.0000 - val_loss: 3.4720 - val_accuracy: 0.4818\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.7691e-04 - accuracy: 1.0000 - val_loss: 3.5232 - val_accuracy: 0.4964\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 7.3218e-04 - accuracy: 1.0000 - val_loss: 3.5476 - val_accuracy: 0.4964\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.7906e-04 - accuracy: 1.0000 - val_loss: 3.5389 - val_accuracy: 0.4891\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.6061e-04 - accuracy: 1.0000 - val_loss: 3.5902 - val_accuracy: 0.4964\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.1563e-04 - accuracy: 1.0000 - val_loss: 3.5987 - val_accuracy: 0.4964\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.8972e-04 - accuracy: 1.0000 - val_loss: 3.6343 - val_accuracy: 0.4964\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.7009e-04 - accuracy: 1.0000 - val_loss: 3.6411 - val_accuracy: 0.4964\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.4205e-04 - accuracy: 1.0000 - val_loss: 3.6633 - val_accuracy: 0.4964\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.2398e-04 - accuracy: 1.0000 - val_loss: 3.6739 - val_accuracy: 0.4891\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.9501e-04 - accuracy: 1.0000 - val_loss: 3.7044 - val_accuracy: 0.4964\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.7883e-04 - accuracy: 1.0000 - val_loss: 3.7113 - val_accuracy: 0.4964\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.7954e-04 - accuracy: 1.0000 - val_loss: 3.7557 - val_accuracy: 0.4964\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.4874e-04 - accuracy: 1.0000 - val_loss: 3.7503 - val_accuracy: 0.4891\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.2524e-04 - accuracy: 1.0000 - val_loss: 3.7809 - val_accuracy: 0.4964\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.1883e-04 - accuracy: 1.0000 - val_loss: 3.7874 - val_accuracy: 0.4964\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.9749e-04 - accuracy: 1.0000 - val_loss: 3.7942 - val_accuracy: 0.4964\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.8942e-04 - accuracy: 1.0000 - val_loss: 3.8330 - val_accuracy: 0.4964\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.7008e-04 - accuracy: 1.0000 - val_loss: 3.8238 - val_accuracy: 0.4891\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.5831e-04 - accuracy: 1.0000 - val_loss: 3.8556 - val_accuracy: 0.4964\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.4291e-04 - accuracy: 1.0000 - val_loss: 3.8647 - val_accuracy: 0.4964\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.3531e-04 - accuracy: 1.0000 - val_loss: 3.8740 - val_accuracy: 0.4964\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.2643e-04 - accuracy: 1.0000 - val_loss: 3.8969 - val_accuracy: 0.4964\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.1516e-04 - accuracy: 1.0000 - val_loss: 3.9049 - val_accuracy: 0.4964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15a181ee0>"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_0_5 = Sequential()\n",
    "model_0_0_5.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features)))\n",
    "model_0_0_5.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_0_0_5.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_0_0_5.add(MaxPooling1D(pool_size=2)) \n",
    "model_0_0_5.add(Conv1D(filters=32, kernel_size=1, activation='relu')) \n",
    "model_0_0_5.add(Flatten())\n",
    "model_0_0_5.add(Dense(50, activation='relu')) \n",
    "model_0_0_5.add(Dense(1, activation='sigmoid')) \n",
    "model_0_0_5.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_0_0_5.fit(train_X_0_0,train_f0t_tc,epochs=100,  validation_data=(val_X_0_0, val_f0t_tc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1614b3b8",
   "metadata": {},
   "source": [
    "Model_0_0_3 appears to be an initial best using all the data. Will use this one with the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb0ade9",
   "metadata": {},
   "source": [
    "### Model_0_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "f47487ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_0_1 final data prep \n",
    "\n",
    "# PCA with 23 components to explain 85% of variance\n",
    "sklearn_pca = PCA(n_components=23)\n",
    "train_X_0_1 = pd.DataFrame(sklearn_pca.fit_transform(train_f0))\n",
    "val_X_0_1 = pd.DataFrame(sklearn_pca.transform(val_f0))\n",
    "test_X_0_1 = pd.DataFrame(sklearn_pca.transform(test_f0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c7c40f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.219217</td>\n",
       "      <td>-1.462922</td>\n",
       "      <td>1.178301</td>\n",
       "      <td>-1.158433</td>\n",
       "      <td>-0.310762</td>\n",
       "      <td>-0.971497</td>\n",
       "      <td>-0.755831</td>\n",
       "      <td>-0.230518</td>\n",
       "      <td>-0.494264</td>\n",
       "      <td>0.538112</td>\n",
       "      <td>-0.219431</td>\n",
       "      <td>0.110541</td>\n",
       "      <td>0.489966</td>\n",
       "      <td>0.258522</td>\n",
       "      <td>-0.183544</td>\n",
       "      <td>-0.996880</td>\n",
       "      <td>-0.325106</td>\n",
       "      <td>0.077066</td>\n",
       "      <td>0.605346</td>\n",
       "      <td>0.326053</td>\n",
       "      <td>-0.370117</td>\n",
       "      <td>-0.036833</td>\n",
       "      <td>-0.773960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.074831</td>\n",
       "      <td>-0.975247</td>\n",
       "      <td>-1.117501</td>\n",
       "      <td>1.467582</td>\n",
       "      <td>0.600116</td>\n",
       "      <td>0.752940</td>\n",
       "      <td>-0.501049</td>\n",
       "      <td>0.335687</td>\n",
       "      <td>-0.131784</td>\n",
       "      <td>0.433012</td>\n",
       "      <td>0.971562</td>\n",
       "      <td>-0.671462</td>\n",
       "      <td>0.304404</td>\n",
       "      <td>0.032035</td>\n",
       "      <td>0.698974</td>\n",
       "      <td>0.178367</td>\n",
       "      <td>0.673246</td>\n",
       "      <td>-0.525624</td>\n",
       "      <td>-0.297949</td>\n",
       "      <td>0.272397</td>\n",
       "      <td>-0.351474</td>\n",
       "      <td>0.338810</td>\n",
       "      <td>0.609654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.709315</td>\n",
       "      <td>-1.138903</td>\n",
       "      <td>-1.021033</td>\n",
       "      <td>-0.682275</td>\n",
       "      <td>-0.695543</td>\n",
       "      <td>0.764778</td>\n",
       "      <td>-0.214868</td>\n",
       "      <td>-0.390358</td>\n",
       "      <td>0.666524</td>\n",
       "      <td>-0.413437</td>\n",
       "      <td>-0.139482</td>\n",
       "      <td>-0.195169</td>\n",
       "      <td>-1.277626</td>\n",
       "      <td>0.280918</td>\n",
       "      <td>-0.169060</td>\n",
       "      <td>0.222243</td>\n",
       "      <td>-0.186811</td>\n",
       "      <td>0.107063</td>\n",
       "      <td>-0.120785</td>\n",
       "      <td>-0.109009</td>\n",
       "      <td>-0.166495</td>\n",
       "      <td>0.097733</td>\n",
       "      <td>-0.190754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.663753</td>\n",
       "      <td>-0.627343</td>\n",
       "      <td>0.902401</td>\n",
       "      <td>0.203277</td>\n",
       "      <td>-1.282240</td>\n",
       "      <td>0.595241</td>\n",
       "      <td>-0.127063</td>\n",
       "      <td>-0.537176</td>\n",
       "      <td>-0.238251</td>\n",
       "      <td>0.242232</td>\n",
       "      <td>0.642603</td>\n",
       "      <td>-0.382570</td>\n",
       "      <td>-0.783190</td>\n",
       "      <td>0.615173</td>\n",
       "      <td>-0.315056</td>\n",
       "      <td>-0.221828</td>\n",
       "      <td>0.419174</td>\n",
       "      <td>-0.571787</td>\n",
       "      <td>-0.581266</td>\n",
       "      <td>0.398642</td>\n",
       "      <td>-0.176412</td>\n",
       "      <td>-0.606962</td>\n",
       "      <td>0.271133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.700241</td>\n",
       "      <td>-0.873808</td>\n",
       "      <td>-0.584979</td>\n",
       "      <td>1.089007</td>\n",
       "      <td>0.456954</td>\n",
       "      <td>1.263407</td>\n",
       "      <td>1.250353</td>\n",
       "      <td>-0.869443</td>\n",
       "      <td>0.494251</td>\n",
       "      <td>-0.086577</td>\n",
       "      <td>0.916465</td>\n",
       "      <td>0.613792</td>\n",
       "      <td>-0.102432</td>\n",
       "      <td>0.155376</td>\n",
       "      <td>-0.608668</td>\n",
       "      <td>-0.055980</td>\n",
       "      <td>-0.542087</td>\n",
       "      <td>0.043258</td>\n",
       "      <td>0.271773</td>\n",
       "      <td>-0.561970</td>\n",
       "      <td>0.263052</td>\n",
       "      <td>0.130627</td>\n",
       "      <td>-0.436842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.215505</td>\n",
       "      <td>1.415952</td>\n",
       "      <td>1.284548</td>\n",
       "      <td>-1.906232</td>\n",
       "      <td>1.640753</td>\n",
       "      <td>0.031301</td>\n",
       "      <td>0.003976</td>\n",
       "      <td>-0.619236</td>\n",
       "      <td>-0.205285</td>\n",
       "      <td>0.207232</td>\n",
       "      <td>-0.327709</td>\n",
       "      <td>-0.513953</td>\n",
       "      <td>-0.226027</td>\n",
       "      <td>0.608667</td>\n",
       "      <td>-0.341245</td>\n",
       "      <td>0.302062</td>\n",
       "      <td>-0.176278</td>\n",
       "      <td>0.025857</td>\n",
       "      <td>-0.183068</td>\n",
       "      <td>0.119498</td>\n",
       "      <td>-0.056718</td>\n",
       "      <td>0.063401</td>\n",
       "      <td>0.425254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>-1.855585</td>\n",
       "      <td>1.815472</td>\n",
       "      <td>1.542833</td>\n",
       "      <td>-0.925159</td>\n",
       "      <td>0.407913</td>\n",
       "      <td>-0.316808</td>\n",
       "      <td>0.891505</td>\n",
       "      <td>-0.587438</td>\n",
       "      <td>-0.011707</td>\n",
       "      <td>-0.090071</td>\n",
       "      <td>0.917244</td>\n",
       "      <td>-0.334305</td>\n",
       "      <td>-0.091007</td>\n",
       "      <td>-0.375539</td>\n",
       "      <td>0.028622</td>\n",
       "      <td>-0.060973</td>\n",
       "      <td>0.260019</td>\n",
       "      <td>-0.619008</td>\n",
       "      <td>0.185277</td>\n",
       "      <td>-0.507739</td>\n",
       "      <td>0.072617</td>\n",
       "      <td>-0.163648</td>\n",
       "      <td>-0.072349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>-0.344175</td>\n",
       "      <td>2.714250</td>\n",
       "      <td>-0.050140</td>\n",
       "      <td>1.376521</td>\n",
       "      <td>-0.163887</td>\n",
       "      <td>0.344485</td>\n",
       "      <td>1.132100</td>\n",
       "      <td>0.093943</td>\n",
       "      <td>1.117169</td>\n",
       "      <td>0.132252</td>\n",
       "      <td>-0.223988</td>\n",
       "      <td>0.390860</td>\n",
       "      <td>-0.403981</td>\n",
       "      <td>-0.299661</td>\n",
       "      <td>0.802703</td>\n",
       "      <td>-0.494383</td>\n",
       "      <td>0.226498</td>\n",
       "      <td>-0.423929</td>\n",
       "      <td>-0.091523</td>\n",
       "      <td>0.236133</td>\n",
       "      <td>-0.281697</td>\n",
       "      <td>0.132193</td>\n",
       "      <td>-0.145807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>1.359647</td>\n",
       "      <td>2.496757</td>\n",
       "      <td>-0.654457</td>\n",
       "      <td>-0.348960</td>\n",
       "      <td>-0.545734</td>\n",
       "      <td>0.588113</td>\n",
       "      <td>0.224513</td>\n",
       "      <td>0.563510</td>\n",
       "      <td>1.070476</td>\n",
       "      <td>0.663969</td>\n",
       "      <td>-0.192287</td>\n",
       "      <td>0.316345</td>\n",
       "      <td>0.036057</td>\n",
       "      <td>-0.203978</td>\n",
       "      <td>0.410482</td>\n",
       "      <td>-0.595080</td>\n",
       "      <td>0.101182</td>\n",
       "      <td>-0.634113</td>\n",
       "      <td>-0.960526</td>\n",
       "      <td>-0.359390</td>\n",
       "      <td>0.367505</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.150783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1.151745</td>\n",
       "      <td>2.187918</td>\n",
       "      <td>-0.498737</td>\n",
       "      <td>-0.924619</td>\n",
       "      <td>0.119817</td>\n",
       "      <td>-0.005517</td>\n",
       "      <td>-0.762025</td>\n",
       "      <td>0.464947</td>\n",
       "      <td>0.333831</td>\n",
       "      <td>0.880404</td>\n",
       "      <td>0.345708</td>\n",
       "      <td>-0.569200</td>\n",
       "      <td>-0.029051</td>\n",
       "      <td>0.585565</td>\n",
       "      <td>0.245967</td>\n",
       "      <td>-0.217486</td>\n",
       "      <td>-0.136106</td>\n",
       "      <td>0.672648</td>\n",
       "      <td>-0.881246</td>\n",
       "      <td>0.286066</td>\n",
       "      <td>-0.545320</td>\n",
       "      <td>-0.169566</td>\n",
       "      <td>-0.138191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0   -0.219217 -1.462922  1.178301 -1.158433 -0.310762 -0.971497 -0.755831   \n",
       "1   -1.074831 -0.975247 -1.117501  1.467582  0.600116  0.752940 -0.501049   \n",
       "2   -1.709315 -1.138903 -1.021033 -0.682275 -0.695543  0.764778 -0.214868   \n",
       "3    1.663753 -0.627343  0.902401  0.203277 -1.282240  0.595241 -0.127063   \n",
       "4   -0.700241 -0.873808 -0.584979  1.089007  0.456954  1.263407  1.250353   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "491  0.215505  1.415952  1.284548 -1.906232  1.640753  0.031301  0.003976   \n",
       "492 -1.855585  1.815472  1.542833 -0.925159  0.407913 -0.316808  0.891505   \n",
       "493 -0.344175  2.714250 -0.050140  1.376521 -0.163887  0.344485  1.132100   \n",
       "494  1.359647  2.496757 -0.654457 -0.348960 -0.545734  0.588113  0.224513   \n",
       "495  1.151745  2.187918 -0.498737 -0.924619  0.119817 -0.005517 -0.762025   \n",
       "\n",
       "           7         8         9         10        11        12        13  \\\n",
       "0   -0.230518 -0.494264  0.538112 -0.219431  0.110541  0.489966  0.258522   \n",
       "1    0.335687 -0.131784  0.433012  0.971562 -0.671462  0.304404  0.032035   \n",
       "2   -0.390358  0.666524 -0.413437 -0.139482 -0.195169 -1.277626  0.280918   \n",
       "3   -0.537176 -0.238251  0.242232  0.642603 -0.382570 -0.783190  0.615173   \n",
       "4   -0.869443  0.494251 -0.086577  0.916465  0.613792 -0.102432  0.155376   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "491 -0.619236 -0.205285  0.207232 -0.327709 -0.513953 -0.226027  0.608667   \n",
       "492 -0.587438 -0.011707 -0.090071  0.917244 -0.334305 -0.091007 -0.375539   \n",
       "493  0.093943  1.117169  0.132252 -0.223988  0.390860 -0.403981 -0.299661   \n",
       "494  0.563510  1.070476  0.663969 -0.192287  0.316345  0.036057 -0.203978   \n",
       "495  0.464947  0.333831  0.880404  0.345708 -0.569200 -0.029051  0.585565   \n",
       "\n",
       "           14        15        16        17        18        19        20  \\\n",
       "0   -0.183544 -0.996880 -0.325106  0.077066  0.605346  0.326053 -0.370117   \n",
       "1    0.698974  0.178367  0.673246 -0.525624 -0.297949  0.272397 -0.351474   \n",
       "2   -0.169060  0.222243 -0.186811  0.107063 -0.120785 -0.109009 -0.166495   \n",
       "3   -0.315056 -0.221828  0.419174 -0.571787 -0.581266  0.398642 -0.176412   \n",
       "4   -0.608668 -0.055980 -0.542087  0.043258  0.271773 -0.561970  0.263052   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "491 -0.341245  0.302062 -0.176278  0.025857 -0.183068  0.119498 -0.056718   \n",
       "492  0.028622 -0.060973  0.260019 -0.619008  0.185277 -0.507739  0.072617   \n",
       "493  0.802703 -0.494383  0.226498 -0.423929 -0.091523  0.236133 -0.281697   \n",
       "494  0.410482 -0.595080  0.101182 -0.634113 -0.960526 -0.359390  0.367505   \n",
       "495  0.245967 -0.217486 -0.136106  0.672648 -0.881246  0.286066 -0.545320   \n",
       "\n",
       "           21        22  \n",
       "0   -0.036833 -0.773960  \n",
       "1    0.338810  0.609654  \n",
       "2    0.097733 -0.190754  \n",
       "3   -0.606962  0.271133  \n",
       "4    0.130627 -0.436842  \n",
       "..        ...       ...  \n",
       "491  0.063401  0.425254  \n",
       "492 -0.163648 -0.072349  \n",
       "493  0.132193 -0.145807  \n",
       "494  0.000487  0.150783  \n",
       "495 -0.169566 -0.138191  \n",
       "\n",
       "[496 rows x 23 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_0_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "5a07cc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reworked function to handle numpy arrays\n",
    "# Time series data modifier, will be used later\n",
    "\n",
    "def df_to_X_np(df, window_size=5):\n",
    "  df_as_np = df.to_numpy()\n",
    "  X = []\n",
    "  y = []\n",
    "  for i in range(len(df_as_np)-window_size):\n",
    "    row = [r for r in df_as_np[i:i+window_size]]\n",
    "    X.append(row)\n",
    "    label = df_as_np[i+window_size][0] # the y will get thrown out, but for some reason the function refuses to work without it there\n",
    "    y.append(label)\n",
    "  return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "9f9b0673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to window format, in this case 5 periods\n",
    "train_X_0_1, _ = df_to_X_np(train_X_0_1)\n",
    "val_X_0_1, _ = df_to_X_np(val_X_0_1)\n",
    "test_X_0_1, _ = df_to_X_np(test_X_0_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "958cb837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 14ms/step - loss: 0.7057 - accuracy: 0.4888 - val_loss: 0.7061 - val_accuracy: 0.4745\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6958 - accuracy: 0.5234 - val_loss: 0.7035 - val_accuracy: 0.5182\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6906 - accuracy: 0.5336 - val_loss: 0.7026 - val_accuracy: 0.5182\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.5458 - val_loss: 0.7018 - val_accuracy: 0.5036\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6834 - accuracy: 0.5540 - val_loss: 0.7005 - val_accuracy: 0.4891\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6794 - accuracy: 0.5703 - val_loss: 0.7020 - val_accuracy: 0.4891\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6760 - accuracy: 0.5784 - val_loss: 0.7011 - val_accuracy: 0.5109\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6742 - accuracy: 0.5804 - val_loss: 0.7025 - val_accuracy: 0.4818\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6700 - accuracy: 0.5866 - val_loss: 0.7003 - val_accuracy: 0.5036\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6680 - accuracy: 0.6069 - val_loss: 0.7015 - val_accuracy: 0.5036\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6653 - accuracy: 0.6090 - val_loss: 0.7030 - val_accuracy: 0.4891\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6622 - accuracy: 0.6069 - val_loss: 0.7027 - val_accuracy: 0.4891\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6588 - accuracy: 0.6171 - val_loss: 0.7026 - val_accuracy: 0.4964\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6562 - accuracy: 0.6212 - val_loss: 0.7029 - val_accuracy: 0.5109\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6539 - accuracy: 0.6273 - val_loss: 0.7027 - val_accuracy: 0.4891\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6507 - accuracy: 0.6253 - val_loss: 0.7022 - val_accuracy: 0.5036\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6483 - accuracy: 0.6334 - val_loss: 0.7042 - val_accuracy: 0.5036\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6439 - accuracy: 0.6456 - val_loss: 0.7040 - val_accuracy: 0.4964\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.6538 - val_loss: 0.7051 - val_accuracy: 0.4891\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6378 - accuracy: 0.6456 - val_loss: 0.7038 - val_accuracy: 0.5109\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.6538 - val_loss: 0.7039 - val_accuracy: 0.5109\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6322 - accuracy: 0.6660 - val_loss: 0.7046 - val_accuracy: 0.4964\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6296 - accuracy: 0.6680 - val_loss: 0.7054 - val_accuracy: 0.4891\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6269 - accuracy: 0.6762 - val_loss: 0.7061 - val_accuracy: 0.5109\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6228 - accuracy: 0.6925 - val_loss: 0.7099 - val_accuracy: 0.5182\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6200 - accuracy: 0.6884 - val_loss: 0.7114 - val_accuracy: 0.5255\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6172 - accuracy: 0.6945 - val_loss: 0.7146 - val_accuracy: 0.5109\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6136 - accuracy: 0.6904 - val_loss: 0.7144 - val_accuracy: 0.5182\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6107 - accuracy: 0.6904 - val_loss: 0.7182 - val_accuracy: 0.5182\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6904 - val_loss: 0.7174 - val_accuracy: 0.5401\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6044 - accuracy: 0.7026 - val_loss: 0.7225 - val_accuracy: 0.5328\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6012 - accuracy: 0.7047 - val_loss: 0.7266 - val_accuracy: 0.5182\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6007 - accuracy: 0.7006 - val_loss: 0.7283 - val_accuracy: 0.5401\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.7128 - val_loss: 0.7328 - val_accuracy: 0.5182\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5900 - accuracy: 0.7067 - val_loss: 0.7284 - val_accuracy: 0.5474\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5881 - accuracy: 0.7251 - val_loss: 0.7360 - val_accuracy: 0.5328\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5861 - accuracy: 0.7169 - val_loss: 0.7356 - val_accuracy: 0.5255\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5813 - accuracy: 0.7230 - val_loss: 0.7372 - val_accuracy: 0.5401\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5793 - accuracy: 0.7312 - val_loss: 0.7445 - val_accuracy: 0.5255\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.7271 - val_loss: 0.7410 - val_accuracy: 0.5401\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5716 - accuracy: 0.7352 - val_loss: 0.7449 - val_accuracy: 0.5474\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.7352 - val_loss: 0.7467 - val_accuracy: 0.5328\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5659 - accuracy: 0.7291 - val_loss: 0.7498 - val_accuracy: 0.5401\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5625 - accuracy: 0.7373 - val_loss: 0.7517 - val_accuracy: 0.5401\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5590 - accuracy: 0.7475 - val_loss: 0.7545 - val_accuracy: 0.5182\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5559 - accuracy: 0.7434 - val_loss: 0.7607 - val_accuracy: 0.5401\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5520 - accuracy: 0.7454 - val_loss: 0.7608 - val_accuracy: 0.5255\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.7434 - val_loss: 0.7643 - val_accuracy: 0.5474\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5447 - accuracy: 0.7515 - val_loss: 0.7662 - val_accuracy: 0.5255\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7556 - val_loss: 0.7701 - val_accuracy: 0.5401\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.7454 - val_loss: 0.7735 - val_accuracy: 0.5401\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5347 - accuracy: 0.7658 - val_loss: 0.7733 - val_accuracy: 0.5328\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5305 - accuracy: 0.7556 - val_loss: 0.7758 - val_accuracy: 0.5620\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5274 - accuracy: 0.7637 - val_loss: 0.7792 - val_accuracy: 0.5547\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5241 - accuracy: 0.7556 - val_loss: 0.7815 - val_accuracy: 0.5547\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7739 - val_loss: 0.7838 - val_accuracy: 0.5474\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5151 - accuracy: 0.7495 - val_loss: 0.7878 - val_accuracy: 0.5693\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5110 - accuracy: 0.7699 - val_loss: 0.7927 - val_accuracy: 0.5620\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5073 - accuracy: 0.7760 - val_loss: 0.7988 - val_accuracy: 0.5620\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5052 - accuracy: 0.7658 - val_loss: 0.8037 - val_accuracy: 0.5620\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.7841 - val_loss: 0.8074 - val_accuracy: 0.5620\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4974 - accuracy: 0.7923 - val_loss: 0.8091 - val_accuracy: 0.5547\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.7821 - val_loss: 0.8094 - val_accuracy: 0.5693\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7882 - val_loss: 0.8143 - val_accuracy: 0.5693\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7882 - val_loss: 0.8198 - val_accuracy: 0.5766\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.8004 - val_loss: 0.8247 - val_accuracy: 0.5620\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4778 - accuracy: 0.7984 - val_loss: 0.8308 - val_accuracy: 0.5693\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4748 - accuracy: 0.8065 - val_loss: 0.8321 - val_accuracy: 0.5766\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7963 - val_loss: 0.8373 - val_accuracy: 0.5693\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.8024 - val_loss: 0.8418 - val_accuracy: 0.5693\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4629 - accuracy: 0.8045 - val_loss: 0.8430 - val_accuracy: 0.5766\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7984 - val_loss: 0.8467 - val_accuracy: 0.5766\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.8024 - val_loss: 0.8581 - val_accuracy: 0.5766\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.8147 - val_loss: 0.8551 - val_accuracy: 0.5912\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.8065 - val_loss: 0.8613 - val_accuracy: 0.5839\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.8045 - val_loss: 0.8668 - val_accuracy: 0.5766\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.8126 - val_loss: 0.8725 - val_accuracy: 0.5912\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.8126 - val_loss: 0.8736 - val_accuracy: 0.5839\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.8126 - val_loss: 0.8718 - val_accuracy: 0.6058\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.8228 - val_loss: 0.8850 - val_accuracy: 0.5985\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.8086 - val_loss: 0.8892 - val_accuracy: 0.5912\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.8187 - val_loss: 0.8876 - val_accuracy: 0.5912\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8167 - val_loss: 0.8991 - val_accuracy: 0.5912\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.8289 - val_loss: 0.9027 - val_accuracy: 0.5839\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.8228 - val_loss: 0.9074 - val_accuracy: 0.5766\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.8310 - val_loss: 0.9159 - val_accuracy: 0.5766\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8289 - val_loss: 0.9213 - val_accuracy: 0.5766\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8289 - val_loss: 0.9226 - val_accuracy: 0.5766\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8310 - val_loss: 0.9286 - val_accuracy: 0.5839\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8269 - val_loss: 0.9320 - val_accuracy: 0.5766\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8371 - val_loss: 0.9414 - val_accuracy: 0.5620\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3975 - accuracy: 0.8350 - val_loss: 0.9417 - val_accuracy: 0.5766\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3933 - accuracy: 0.8350 - val_loss: 0.9452 - val_accuracy: 0.5693\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3907 - accuracy: 0.8371 - val_loss: 0.9554 - val_accuracy: 0.5693\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3884 - accuracy: 0.8330 - val_loss: 0.9569 - val_accuracy: 0.5693\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3850 - accuracy: 0.8432 - val_loss: 0.9679 - val_accuracy: 0.5693\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3824 - accuracy: 0.8432 - val_loss: 0.9782 - val_accuracy: 0.5693\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3792 - accuracy: 0.8473 - val_loss: 0.9778 - val_accuracy: 0.5693\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3777 - accuracy: 0.8513 - val_loss: 0.9780 - val_accuracy: 0.5693\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3757 - accuracy: 0.8432 - val_loss: 0.9874 - val_accuracy: 0.5766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15a33b130>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = train_X_0_1.shape[1]\n",
    "n_features = train_X_0_1.shape[2]\n",
    "\n",
    "model_0_1_1 = Sequential()\n",
    "model_0_1_1.add(Conv1D(filters=5, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model_0_1_1.add(MaxPooling1D(pool_size=2)) \n",
    "model_0_1_1.add(Flatten())\n",
    "model_0_1_1.add(Dense(50, activation='relu')) \n",
    "model_0_1_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_0_1_1.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_0_1_1.fit(train_X_0_1, train_f0t_tc,epochs=100,  validation_data=(val_X_0_1, val_f0t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "55b67373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 14ms/step - loss: 0.7084 - accuracy: 0.5214 - val_loss: 0.7164 - val_accuracy: 0.4526\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6660 - accuracy: 0.6171 - val_loss: 0.7164 - val_accuracy: 0.4380\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.6823 - val_loss: 0.7195 - val_accuracy: 0.4818\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6208 - accuracy: 0.6843 - val_loss: 0.7263 - val_accuracy: 0.4599\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5970 - accuracy: 0.7617 - val_loss: 0.7296 - val_accuracy: 0.4745\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5728 - accuracy: 0.7536 - val_loss: 0.7302 - val_accuracy: 0.4672\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5493 - accuracy: 0.8086 - val_loss: 0.7424 - val_accuracy: 0.4964\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.8228 - val_loss: 0.7508 - val_accuracy: 0.4891\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.8330 - val_loss: 0.7541 - val_accuracy: 0.5182\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.8391 - val_loss: 0.7658 - val_accuracy: 0.4891\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.8635 - val_loss: 0.7782 - val_accuracy: 0.4745\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.8819 - val_loss: 0.7812 - val_accuracy: 0.4672\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8839 - val_loss: 0.7958 - val_accuracy: 0.4672\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3687 - accuracy: 0.8880 - val_loss: 0.8109 - val_accuracy: 0.4599\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3437 - accuracy: 0.9043 - val_loss: 0.8265 - val_accuracy: 0.4599\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3235 - accuracy: 0.9084 - val_loss: 0.8513 - val_accuracy: 0.4672\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2997 - accuracy: 0.9124 - val_loss: 0.8978 - val_accuracy: 0.5036\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2783 - accuracy: 0.9450 - val_loss: 0.8840 - val_accuracy: 0.4891\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2600 - accuracy: 0.9450 - val_loss: 0.9160 - val_accuracy: 0.4453\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2303 - accuracy: 0.9572 - val_loss: 0.9249 - val_accuracy: 0.4599\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2098 - accuracy: 0.9674 - val_loss: 0.9475 - val_accuracy: 0.4380\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1894 - accuracy: 0.9735 - val_loss: 0.9718 - val_accuracy: 0.4599\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1698 - accuracy: 0.9837 - val_loss: 1.0059 - val_accuracy: 0.4307\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1553 - accuracy: 0.9878 - val_loss: 1.0534 - val_accuracy: 0.4380\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1394 - accuracy: 0.9898 - val_loss: 1.0772 - val_accuracy: 0.4453\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1253 - accuracy: 0.9959 - val_loss: 1.1483 - val_accuracy: 0.4964\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1194 - accuracy: 0.9959 - val_loss: 1.1554 - val_accuracy: 0.4599\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0995 - accuracy: 1.0000 - val_loss: 1.1757 - val_accuracy: 0.4380\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0895 - accuracy: 1.0000 - val_loss: 1.2350 - val_accuracy: 0.4672\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0818 - accuracy: 1.0000 - val_loss: 1.2515 - val_accuracy: 0.4672\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0733 - accuracy: 1.0000 - val_loss: 1.3129 - val_accuracy: 0.4672\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 1.0000 - val_loss: 1.3303 - val_accuracy: 0.4526\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 1.3526 - val_accuracy: 0.4672\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 1.4245 - val_accuracy: 0.4672\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 1.4474 - val_accuracy: 0.4818\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 1.4629 - val_accuracy: 0.4818\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 1.5362 - val_accuracy: 0.4818\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 1.5441 - val_accuracy: 0.4672\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 1.5724 - val_accuracy: 0.4745\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 1.5902 - val_accuracy: 0.4818\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 1.6480 - val_accuracy: 0.4745\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 1.6743 - val_accuracy: 0.4745\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 1.7085 - val_accuracy: 0.4672\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 1.7214 - val_accuracy: 0.4745\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 1.7806 - val_accuracy: 0.4891\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 1.7696 - val_accuracy: 0.4672\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.8039 - val_accuracy: 0.4745\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.8386 - val_accuracy: 0.4745\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.8641 - val_accuracy: 0.4672\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.8803 - val_accuracy: 0.4599\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.9121 - val_accuracy: 0.4745\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.9321 - val_accuracy: 0.4818\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.9665 - val_accuracy: 0.4818\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.9784 - val_accuracy: 0.4818\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.9882 - val_accuracy: 0.4745\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.0151 - val_accuracy: 0.4818\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.0361 - val_accuracy: 0.4745\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.0656 - val_accuracy: 0.4818\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.0828 - val_accuracy: 0.4745\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.1032 - val_accuracy: 0.4745\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.1296 - val_accuracy: 0.4818\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.1426 - val_accuracy: 0.4599\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.1580 - val_accuracy: 0.4672\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.1890 - val_accuracy: 0.4745\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.1981 - val_accuracy: 0.4526\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.2148 - val_accuracy: 0.4818\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.2384 - val_accuracy: 0.4599\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.2585 - val_accuracy: 0.4745\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.2661 - val_accuracy: 0.4599\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.2946 - val_accuracy: 0.4745\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.3070 - val_accuracy: 0.4745\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.3344 - val_accuracy: 0.4672\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.3290 - val_accuracy: 0.4672\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.3470 - val_accuracy: 0.4672\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.3750 - val_accuracy: 0.4672\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.3848 - val_accuracy: 0.4745\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.4009 - val_accuracy: 0.4745\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.4167 - val_accuracy: 0.4818\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.4136 - val_accuracy: 0.4745\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.4431 - val_accuracy: 0.4672\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.4515 - val_accuracy: 0.4745\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.4727 - val_accuracy: 0.4745\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.4803 - val_accuracy: 0.4745\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.4972 - val_accuracy: 0.4745\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.5124 - val_accuracy: 0.4745\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.5309 - val_accuracy: 0.4745\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.5386 - val_accuracy: 0.4745\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.5453 - val_accuracy: 0.4745\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.5626 - val_accuracy: 0.4745\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.5735 - val_accuracy: 0.4672\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.5843 - val_accuracy: 0.4745\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.5992 - val_accuracy: 0.4745\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.6060 - val_accuracy: 0.4672\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.6262 - val_accuracy: 0.4672\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.6333 - val_accuracy: 0.4672\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.6346 - val_accuracy: 0.4672\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.6518 - val_accuracy: 0.4599\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.6678 - val_accuracy: 0.4672\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6794 - val_accuracy: 0.4526\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6888 - val_accuracy: 0.4599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15a4b9bb0>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_1_2 = Sequential()\n",
    "model_0_1_2.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model_0_1_2.add(MaxPooling1D(pool_size=2)) \n",
    "model_0_1_2.add(Flatten())\n",
    "model_0_1_2.add(Dense(50, activation='relu')) \n",
    "model_0_1_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_0_1_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_0_1_2.fit(train_X_0_1,train_f0t_tc,epochs=100,  validation_data=(val_X_0_1, val_f0t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "14b830b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 15ms/step - loss: 0.7032 - accuracy: 0.5255 - val_loss: 0.6879 - val_accuracy: 0.5255\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.6293 - val_loss: 0.6903 - val_accuracy: 0.5328\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6571 - accuracy: 0.6354 - val_loss: 0.6916 - val_accuracy: 0.5255\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6404 - accuracy: 0.7251 - val_loss: 0.6964 - val_accuracy: 0.4964\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6199 - accuracy: 0.7108 - val_loss: 0.7002 - val_accuracy: 0.5036\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5938 - accuracy: 0.7699 - val_loss: 0.7147 - val_accuracy: 0.4818\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5659 - accuracy: 0.7943 - val_loss: 0.7153 - val_accuracy: 0.4526\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.7862 - val_loss: 0.7379 - val_accuracy: 0.5401\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.8106 - val_loss: 0.7469 - val_accuracy: 0.5255\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.8310 - val_loss: 0.7854 - val_accuracy: 0.5182\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.8778 - val_loss: 0.7850 - val_accuracy: 0.4672\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3721 - accuracy: 0.8880 - val_loss: 0.8151 - val_accuracy: 0.4599\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3301 - accuracy: 0.9043 - val_loss: 0.8650 - val_accuracy: 0.4453\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2858 - accuracy: 0.9206 - val_loss: 0.9185 - val_accuracy: 0.5328\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2511 - accuracy: 0.9470 - val_loss: 0.9527 - val_accuracy: 0.4745\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2065 - accuracy: 0.9715 - val_loss: 1.0179 - val_accuracy: 0.4891\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1782 - accuracy: 0.9735 - val_loss: 1.0637 - val_accuracy: 0.4599\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1548 - accuracy: 0.9715 - val_loss: 1.1494 - val_accuracy: 0.4453\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1339 - accuracy: 0.9817 - val_loss: 1.2040 - val_accuracy: 0.4818\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1135 - accuracy: 0.9857 - val_loss: 1.2625 - val_accuracy: 0.4672\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0828 - accuracy: 1.0000 - val_loss: 1.2907 - val_accuracy: 0.4818\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 1.3578 - val_accuracy: 0.4672\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 1.4296 - val_accuracy: 0.4745\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 1.5054 - val_accuracy: 0.4307\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 1.5312 - val_accuracy: 0.4307\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 1.6017 - val_accuracy: 0.4453\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 1.6448 - val_accuracy: 0.4453\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 1.6860 - val_accuracy: 0.4453\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 1.7475 - val_accuracy: 0.4453\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.8045 - val_accuracy: 0.4380\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.8075 - val_accuracy: 0.4526\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.8520 - val_accuracy: 0.4526\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.9137 - val_accuracy: 0.4380\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.9326 - val_accuracy: 0.4453\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.9638 - val_accuracy: 0.4453\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.0028 - val_accuracy: 0.4453\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.0384 - val_accuracy: 0.4526\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.0595 - val_accuracy: 0.4453\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.1091 - val_accuracy: 0.4526\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.1254 - val_accuracy: 0.4526\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.1512 - val_accuracy: 0.4453\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.1806 - val_accuracy: 0.4526\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.2161 - val_accuracy: 0.4526\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.2278 - val_accuracy: 0.4599\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.2700 - val_accuracy: 0.4526\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.2874 - val_accuracy: 0.4526\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.3100 - val_accuracy: 0.4453\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.3326 - val_accuracy: 0.4526\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.3550 - val_accuracy: 0.4599\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.3762 - val_accuracy: 0.4526\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.3996 - val_accuracy: 0.4599\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.4240 - val_accuracy: 0.4599\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.4349 - val_accuracy: 0.4526\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.4575 - val_accuracy: 0.4526\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4859 - val_accuracy: 0.4526\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.5044 - val_accuracy: 0.4599\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.5164 - val_accuracy: 0.4599\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.5388 - val_accuracy: 0.4599\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.5538 - val_accuracy: 0.4526\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.5716 - val_accuracy: 0.4599\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.5931 - val_accuracy: 0.4599\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.6084 - val_accuracy: 0.4672\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.6235 - val_accuracy: 0.4599\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.6424 - val_accuracy: 0.4599\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.6595 - val_accuracy: 0.4599\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6786 - val_accuracy: 0.4672\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6936 - val_accuracy: 0.4672\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.7104 - val_accuracy: 0.4599\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.7246 - val_accuracy: 0.4599\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.7410 - val_accuracy: 0.4672\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.7577 - val_accuracy: 0.4599\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.7699 - val_accuracy: 0.4599\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.6486e-04 - accuracy: 1.0000 - val_loss: 2.7789 - val_accuracy: 0.4599\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.2910e-04 - accuracy: 1.0000 - val_loss: 2.7956 - val_accuracy: 0.4672\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.9733e-04 - accuracy: 1.0000 - val_loss: 2.8126 - val_accuracy: 0.4672\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.6958e-04 - accuracy: 1.0000 - val_loss: 2.8282 - val_accuracy: 0.4672\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.2829e-04 - accuracy: 1.0000 - val_loss: 2.8399 - val_accuracy: 0.4672\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.9828e-04 - accuracy: 1.0000 - val_loss: 2.8521 - val_accuracy: 0.4672\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.7423e-04 - accuracy: 1.0000 - val_loss: 2.8654 - val_accuracy: 0.4599\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.4688e-04 - accuracy: 1.0000 - val_loss: 2.8814 - val_accuracy: 0.4672\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.1811e-04 - accuracy: 1.0000 - val_loss: 2.8907 - val_accuracy: 0.4672\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.9396e-04 - accuracy: 1.0000 - val_loss: 2.9041 - val_accuracy: 0.4672\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.7216e-04 - accuracy: 1.0000 - val_loss: 2.9178 - val_accuracy: 0.4672\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.5402e-04 - accuracy: 1.0000 - val_loss: 2.9348 - val_accuracy: 0.4672\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.2723e-04 - accuracy: 1.0000 - val_loss: 2.9437 - val_accuracy: 0.4672\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.0933e-04 - accuracy: 1.0000 - val_loss: 2.9575 - val_accuracy: 0.4672\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.9106e-04 - accuracy: 1.0000 - val_loss: 2.9713 - val_accuracy: 0.4745\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.7539e-04 - accuracy: 1.0000 - val_loss: 2.9858 - val_accuracy: 0.4745\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.5485e-04 - accuracy: 1.0000 - val_loss: 2.9960 - val_accuracy: 0.4672\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.3537e-04 - accuracy: 1.0000 - val_loss: 3.0067 - val_accuracy: 0.4672\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.1911e-04 - accuracy: 1.0000 - val_loss: 3.0155 - val_accuracy: 0.4672\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.0252e-04 - accuracy: 1.0000 - val_loss: 3.0307 - val_accuracy: 0.4672\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.8702e-04 - accuracy: 1.0000 - val_loss: 3.0397 - val_accuracy: 0.4672\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.7256e-04 - accuracy: 1.0000 - val_loss: 3.0523 - val_accuracy: 0.4672\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.6314e-04 - accuracy: 1.0000 - val_loss: 3.0667 - val_accuracy: 0.4745\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.4846e-04 - accuracy: 1.0000 - val_loss: 3.0758 - val_accuracy: 0.4745\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.3513e-04 - accuracy: 1.0000 - val_loss: 3.0864 - val_accuracy: 0.4672\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.2154e-04 - accuracy: 1.0000 - val_loss: 3.0945 - val_accuracy: 0.4745\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.0949e-04 - accuracy: 1.0000 - val_loss: 3.1077 - val_accuracy: 0.4745\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.9921e-04 - accuracy: 1.0000 - val_loss: 3.1162 - val_accuracy: 0.4745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15a621cd0>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_1_3 = Sequential()\n",
    "model_0_1_3.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features)))\n",
    "model_0_1_3.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_0_1_3.add(MaxPooling1D(pool_size=2)) \n",
    "model_0_1_3.add(Flatten())\n",
    "model_0_1_3.add(Dense(50, activation='relu')) \n",
    "model_0_1_3.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model_0_1_3.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_0_1_3.fit(train_X_0_1,train_f0t_tc,epochs=100,  validation_data=(val_X_0_1, val_f0t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "61279601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 18ms/step - loss: 0.6939 - accuracy: 0.5051 - val_loss: 0.6989 - val_accuracy: 0.4672\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6831 - accuracy: 0.6191 - val_loss: 0.7057 - val_accuracy: 0.3723\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6693 - accuracy: 0.6762 - val_loss: 0.7114 - val_accuracy: 0.3650\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6451 - accuracy: 0.7189 - val_loss: 0.7227 - val_accuracy: 0.4088\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6028 - accuracy: 0.7373 - val_loss: 0.7557 - val_accuracy: 0.3504\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5407 - accuracy: 0.7413 - val_loss: 0.7927 - val_accuracy: 0.3942\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7963 - val_loss: 0.8229 - val_accuracy: 0.4015\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.8513 - val_loss: 0.8734 - val_accuracy: 0.4161\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3262 - accuracy: 0.8839 - val_loss: 0.9019 - val_accuracy: 0.4672\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2682 - accuracy: 0.9043 - val_loss: 1.0649 - val_accuracy: 0.4161\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2143 - accuracy: 0.9348 - val_loss: 1.0360 - val_accuracy: 0.4891\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2052 - accuracy: 0.9226 - val_loss: 1.1704 - val_accuracy: 0.4234\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1392 - accuracy: 0.9532 - val_loss: 1.1844 - val_accuracy: 0.4818\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0969 - accuracy: 0.9857 - val_loss: 1.3430 - val_accuracy: 0.4380\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.9898 - val_loss: 1.3967 - val_accuracy: 0.4672\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0625 - accuracy: 0.9919 - val_loss: 1.5239 - val_accuracy: 0.4818\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0437 - accuracy: 0.9980 - val_loss: 1.5985 - val_accuracy: 0.4672\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0387 - accuracy: 0.9919 - val_loss: 1.6535 - val_accuracy: 0.4891\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 1.7894 - val_accuracy: 0.4818\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0208 - accuracy: 0.9980 - val_loss: 1.8314 - val_accuracy: 0.4526\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.9284 - val_accuracy: 0.4599\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.9776 - val_accuracy: 0.4088\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.0077 - val_accuracy: 0.4526\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.0603 - val_accuracy: 0.4745\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.1057 - val_accuracy: 0.4745\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.1547 - val_accuracy: 0.4526\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.1789 - val_accuracy: 0.4672\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.2198 - val_accuracy: 0.4672\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.2603 - val_accuracy: 0.4745\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.2930 - val_accuracy: 0.4599\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.3191 - val_accuracy: 0.4672\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.3599 - val_accuracy: 0.4672\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.3704 - val_accuracy: 0.4745\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.3993 - val_accuracy: 0.4818\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.4269 - val_accuracy: 0.4818\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.4614 - val_accuracy: 0.4745\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.4816 - val_accuracy: 0.4745\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.5079 - val_accuracy: 0.4818\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.5262 - val_accuracy: 0.4745\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.5558 - val_accuracy: 0.4745\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.5733 - val_accuracy: 0.4745\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.5920 - val_accuracy: 0.4745\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.6583e-04 - accuracy: 1.0000 - val_loss: 2.6201 - val_accuracy: 0.4745\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.0199e-04 - accuracy: 1.0000 - val_loss: 2.6344 - val_accuracy: 0.4745\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.3950e-04 - accuracy: 1.0000 - val_loss: 2.6564 - val_accuracy: 0.4745\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.0112e-04 - accuracy: 1.0000 - val_loss: 2.6737 - val_accuracy: 0.4672\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.4788e-04 - accuracy: 1.0000 - val_loss: 2.6946 - val_accuracy: 0.4672\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.0644e-04 - accuracy: 1.0000 - val_loss: 2.7114 - val_accuracy: 0.4672\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.7241e-04 - accuracy: 1.0000 - val_loss: 2.7282 - val_accuracy: 0.4672\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.3982e-04 - accuracy: 1.0000 - val_loss: 2.7462 - val_accuracy: 0.4745\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.0392e-04 - accuracy: 1.0000 - val_loss: 2.7648 - val_accuracy: 0.4672\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.9344e-04 - accuracy: 1.0000 - val_loss: 2.7820 - val_accuracy: 0.4745\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.4915e-04 - accuracy: 1.0000 - val_loss: 2.7981 - val_accuracy: 0.4672\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.2995e-04 - accuracy: 1.0000 - val_loss: 2.8138 - val_accuracy: 0.4672\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.0001e-04 - accuracy: 1.0000 - val_loss: 2.8286 - val_accuracy: 0.4672\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.6977e-04 - accuracy: 1.0000 - val_loss: 2.8411 - val_accuracy: 0.4672\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4464e-04 - accuracy: 1.0000 - val_loss: 2.8572 - val_accuracy: 0.4672\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.3002e-04 - accuracy: 1.0000 - val_loss: 2.8747 - val_accuracy: 0.4672\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.0937e-04 - accuracy: 1.0000 - val_loss: 2.8891 - val_accuracy: 0.4672\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.9346e-04 - accuracy: 1.0000 - val_loss: 2.9001 - val_accuracy: 0.4672\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.7718e-04 - accuracy: 1.0000 - val_loss: 2.9138 - val_accuracy: 0.4745\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.6414e-04 - accuracy: 1.0000 - val_loss: 2.9320 - val_accuracy: 0.4672\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.4752e-04 - accuracy: 1.0000 - val_loss: 2.9396 - val_accuracy: 0.4745\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.3418e-04 - accuracy: 1.0000 - val_loss: 2.9542 - val_accuracy: 0.4672\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.2645e-04 - accuracy: 1.0000 - val_loss: 2.9665 - val_accuracy: 0.4745\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.0953e-04 - accuracy: 1.0000 - val_loss: 2.9762 - val_accuracy: 0.4745\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.9804e-04 - accuracy: 1.0000 - val_loss: 2.9873 - val_accuracy: 0.4745\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.8421e-04 - accuracy: 1.0000 - val_loss: 2.9992 - val_accuracy: 0.4672\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.7472e-04 - accuracy: 1.0000 - val_loss: 3.0122 - val_accuracy: 0.4745\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.6389e-04 - accuracy: 1.0000 - val_loss: 3.0260 - val_accuracy: 0.4745\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.5628e-04 - accuracy: 1.0000 - val_loss: 3.0387 - val_accuracy: 0.4745\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.4605e-04 - accuracy: 1.0000 - val_loss: 3.0522 - val_accuracy: 0.4745\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.3894e-04 - accuracy: 1.0000 - val_loss: 3.0630 - val_accuracy: 0.4672\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.3023e-04 - accuracy: 1.0000 - val_loss: 3.0729 - val_accuracy: 0.4745\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.2254e-04 - accuracy: 1.0000 - val_loss: 3.0850 - val_accuracy: 0.4745\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.1564e-04 - accuracy: 1.0000 - val_loss: 3.0933 - val_accuracy: 0.4745\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.0931e-04 - accuracy: 1.0000 - val_loss: 3.1044 - val_accuracy: 0.4745\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0106e-04 - accuracy: 1.0000 - val_loss: 3.1143 - val_accuracy: 0.4745\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.9657e-04 - accuracy: 1.0000 - val_loss: 3.1269 - val_accuracy: 0.4672\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.9065e-04 - accuracy: 1.0000 - val_loss: 3.1382 - val_accuracy: 0.4745\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8331e-04 - accuracy: 1.0000 - val_loss: 3.1468 - val_accuracy: 0.4745\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7729e-04 - accuracy: 1.0000 - val_loss: 3.1564 - val_accuracy: 0.4745\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7240e-04 - accuracy: 1.0000 - val_loss: 3.1685 - val_accuracy: 0.4745\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.6725e-04 - accuracy: 1.0000 - val_loss: 3.1786 - val_accuracy: 0.4745\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6136e-04 - accuracy: 1.0000 - val_loss: 3.1861 - val_accuracy: 0.4672\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5773e-04 - accuracy: 1.0000 - val_loss: 3.1939 - val_accuracy: 0.4745\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5400e-04 - accuracy: 1.0000 - val_loss: 3.2052 - val_accuracy: 0.4745\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4832e-04 - accuracy: 1.0000 - val_loss: 3.2172 - val_accuracy: 0.4745\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4417e-04 - accuracy: 1.0000 - val_loss: 3.2250 - val_accuracy: 0.4745\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4065e-04 - accuracy: 1.0000 - val_loss: 3.2336 - val_accuracy: 0.4745\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3595e-04 - accuracy: 1.0000 - val_loss: 3.2434 - val_accuracy: 0.4745\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.3398e-04 - accuracy: 1.0000 - val_loss: 3.2515 - val_accuracy: 0.4745\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.3108e-04 - accuracy: 1.0000 - val_loss: 3.2616 - val_accuracy: 0.4745\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2675e-04 - accuracy: 1.0000 - val_loss: 3.2719 - val_accuracy: 0.4745\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2195e-04 - accuracy: 1.0000 - val_loss: 3.2794 - val_accuracy: 0.4818\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.1890e-04 - accuracy: 1.0000 - val_loss: 3.2884 - val_accuracy: 0.4818\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.1547e-04 - accuracy: 1.0000 - val_loss: 3.2983 - val_accuracy: 0.4818\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.1325e-04 - accuracy: 1.0000 - val_loss: 3.3055 - val_accuracy: 0.4745\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.1016e-04 - accuracy: 1.0000 - val_loss: 3.3151 - val_accuracy: 0.4818\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.0712e-04 - accuracy: 1.0000 - val_loss: 3.3222 - val_accuracy: 0.4818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15a4655e0>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_1_4 = Sequential()\n",
    "model_0_1_4.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features)))\n",
    "model_0_1_4.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_0_1_4.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_0_1_4.add(MaxPooling1D(pool_size=2)) \n",
    "model_0_1_4.add(Conv1D(filters=32, kernel_size=1, activation='relu')) \n",
    "model_0_1_4.add(Flatten())\n",
    "model_0_1_4.add(Dense(50, activation='relu')) \n",
    "model_0_1_4.add(Dense(1, activation='sigmoid')) \n",
    "model_0_1_4.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_0_1_4.fit(train_X_0_1,train_f0t_tc,epochs=100,  validation_data=(val_X_0_1, val_f0t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "78b60c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "16/16 [==============================] - 1s 16ms/step - loss: 0.6976 - accuracy: 0.5173 - val_loss: 0.6938 - val_accuracy: 0.5255\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6837 - accuracy: 0.5336 - val_loss: 0.6964 - val_accuracy: 0.5109\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6733 - accuracy: 0.5621 - val_loss: 0.6966 - val_accuracy: 0.5109\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6607 - accuracy: 0.5723 - val_loss: 0.6997 - val_accuracy: 0.5401\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6413 - accuracy: 0.7251 - val_loss: 0.7118 - val_accuracy: 0.4818\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6133 - accuracy: 0.6884 - val_loss: 0.7073 - val_accuracy: 0.4745\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.7923 - val_loss: 0.7219 - val_accuracy: 0.5255\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5023 - accuracy: 0.8310 - val_loss: 0.7661 - val_accuracy: 0.4891\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.8697 - val_loss: 0.8484 - val_accuracy: 0.4672\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3362 - accuracy: 0.8982 - val_loss: 0.9102 - val_accuracy: 0.5182\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2589 - accuracy: 0.9246 - val_loss: 1.0065 - val_accuracy: 0.4964\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1941 - accuracy: 0.9450 - val_loss: 1.1238 - val_accuracy: 0.4818\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1313 - accuracy: 0.9735 - val_loss: 1.2495 - val_accuracy: 0.4818\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0960 - accuracy: 0.9817 - val_loss: 1.3673 - val_accuracy: 0.5547\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1125 - accuracy: 0.9715 - val_loss: 1.4552 - val_accuracy: 0.5182\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0560 - accuracy: 0.9980 - val_loss: 1.5926 - val_accuracy: 0.5036\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 1.6399 - val_accuracy: 0.5109\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 1.7326 - val_accuracy: 0.5328\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.7975 - val_accuracy: 0.5036\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.8809 - val_accuracy: 0.4891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15a9a4eb0>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_1_5 = Sequential()\n",
    "model_0_1_5.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features)))\n",
    "model_0_1_5.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_0_1_5.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_0_1_5.add(MaxPooling1D(pool_size=2)) \n",
    "model_0_1_5.add(Conv1D(filters=32, kernel_size=1, activation='relu')) \n",
    "model_0_1_5.add(Flatten())\n",
    "model_0_1_5.add(Dense(50, activation='relu')) \n",
    "model_0_1_5.add(Dense(1, activation='sigmoid')) \n",
    "model_0_1_5.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_0_1_5.fit(train_X_0_1,train_f0t_tc,epochs=20,  validation_data=(val_X_0_1, val_f0t_tc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa754d7",
   "metadata": {},
   "source": [
    "### Model_0_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "bda6210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_0_0 final data prep\n",
    "\n",
    "# converting to window format, in this case 5 periods\n",
    "train_X_0_2, _ = df_to_X_y2(train_f0[feats],train_f0t)\n",
    "val_X_0_2, _ = df_to_X_y2(val_f0[feats], val_f0t)\n",
    "test_X_0_2, _ = df_to_X_y2(test_f0[feats],test_f0t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "7bcfded7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 13ms/step - loss: 0.7128 - accuracy: 0.5132 - val_loss: 0.6993 - val_accuracy: 0.4745\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6908 - accuracy: 0.5336 - val_loss: 0.6990 - val_accuracy: 0.4672\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6908 - accuracy: 0.5295 - val_loss: 0.6979 - val_accuracy: 0.4526\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6892 - accuracy: 0.5275 - val_loss: 0.6956 - val_accuracy: 0.5109\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6887 - accuracy: 0.5356 - val_loss: 0.6955 - val_accuracy: 0.4672\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6872 - accuracy: 0.5621 - val_loss: 0.6948 - val_accuracy: 0.5109\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6875 - accuracy: 0.5295 - val_loss: 0.6940 - val_accuracy: 0.5182\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6860 - accuracy: 0.5316 - val_loss: 0.6941 - val_accuracy: 0.5328\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.5336 - val_loss: 0.6937 - val_accuracy: 0.5255\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6840 - accuracy: 0.5438 - val_loss: 0.6937 - val_accuracy: 0.4818\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6832 - accuracy: 0.5540 - val_loss: 0.6937 - val_accuracy: 0.5036\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6820 - accuracy: 0.5804 - val_loss: 0.6935 - val_accuracy: 0.4891\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6820 - accuracy: 0.5906 - val_loss: 0.6938 - val_accuracy: 0.5255\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6799 - accuracy: 0.5967 - val_loss: 0.6930 - val_accuracy: 0.4964\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6794 - accuracy: 0.5743 - val_loss: 0.6938 - val_accuracy: 0.5182\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6784 - accuracy: 0.6008 - val_loss: 0.6945 - val_accuracy: 0.5182\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6767 - accuracy: 0.6293 - val_loss: 0.6941 - val_accuracy: 0.4964\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6760 - accuracy: 0.5967 - val_loss: 0.6942 - val_accuracy: 0.4964\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6753 - accuracy: 0.5886 - val_loss: 0.6934 - val_accuracy: 0.5109\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6749 - accuracy: 0.5927 - val_loss: 0.6935 - val_accuracy: 0.5182\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.6069 - val_loss: 0.6935 - val_accuracy: 0.5328\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6729 - accuracy: 0.5988 - val_loss: 0.6940 - val_accuracy: 0.5182\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6705 - accuracy: 0.6191 - val_loss: 0.6939 - val_accuracy: 0.5328\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6705 - accuracy: 0.6069 - val_loss: 0.6948 - val_accuracy: 0.5328\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6696 - accuracy: 0.5947 - val_loss: 0.6954 - val_accuracy: 0.4891\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6672 - accuracy: 0.6293 - val_loss: 0.6961 - val_accuracy: 0.4964\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6666 - accuracy: 0.6090 - val_loss: 0.6971 - val_accuracy: 0.5036\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6649 - accuracy: 0.6314 - val_loss: 0.6947 - val_accuracy: 0.5182\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6679 - accuracy: 0.5866 - val_loss: 0.6965 - val_accuracy: 0.5620\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6630 - accuracy: 0.6151 - val_loss: 0.6987 - val_accuracy: 0.5109\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6602 - accuracy: 0.6232 - val_loss: 0.6969 - val_accuracy: 0.4964\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6608 - accuracy: 0.6008 - val_loss: 0.6982 - val_accuracy: 0.4891\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6587 - accuracy: 0.6212 - val_loss: 0.6992 - val_accuracy: 0.5036\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6564 - accuracy: 0.6151 - val_loss: 0.6975 - val_accuracy: 0.5109\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6552 - accuracy: 0.6293 - val_loss: 0.7013 - val_accuracy: 0.4672\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6550 - accuracy: 0.6171 - val_loss: 0.7001 - val_accuracy: 0.5109\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6520 - accuracy: 0.6293 - val_loss: 0.7020 - val_accuracy: 0.5255\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6506 - accuracy: 0.6375 - val_loss: 0.7025 - val_accuracy: 0.5036\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6487 - accuracy: 0.6334 - val_loss: 0.7014 - val_accuracy: 0.5109\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6478 - accuracy: 0.6354 - val_loss: 0.7053 - val_accuracy: 0.4891\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.6375 - val_loss: 0.7035 - val_accuracy: 0.5109\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6476 - accuracy: 0.6171 - val_loss: 0.7051 - val_accuracy: 0.5036\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6425 - accuracy: 0.6375 - val_loss: 0.7069 - val_accuracy: 0.5036\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6417 - accuracy: 0.6273 - val_loss: 0.7069 - val_accuracy: 0.5255\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6399 - accuracy: 0.6436 - val_loss: 0.7096 - val_accuracy: 0.5401\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6387 - accuracy: 0.6293 - val_loss: 0.7120 - val_accuracy: 0.5109\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6378 - accuracy: 0.6415 - val_loss: 0.7139 - val_accuracy: 0.4964\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6344 - accuracy: 0.6558 - val_loss: 0.7163 - val_accuracy: 0.5109\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6338 - accuracy: 0.6477 - val_loss: 0.7132 - val_accuracy: 0.5182\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.6395 - val_loss: 0.7191 - val_accuracy: 0.5036\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6289 - accuracy: 0.6517 - val_loss: 0.7205 - val_accuracy: 0.5182\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6270 - accuracy: 0.6660 - val_loss: 0.7175 - val_accuracy: 0.5328\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6271 - accuracy: 0.6538 - val_loss: 0.7254 - val_accuracy: 0.5255\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6248 - accuracy: 0.6456 - val_loss: 0.7221 - val_accuracy: 0.5474\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6249 - accuracy: 0.6680 - val_loss: 0.7238 - val_accuracy: 0.5036\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6244 - accuracy: 0.6517 - val_loss: 0.7195 - val_accuracy: 0.5036\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6190 - accuracy: 0.6619 - val_loss: 0.7282 - val_accuracy: 0.5036\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6180 - accuracy: 0.6599 - val_loss: 0.7284 - val_accuracy: 0.5401\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6199 - accuracy: 0.6660 - val_loss: 0.7303 - val_accuracy: 0.5328\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6136 - accuracy: 0.6640 - val_loss: 0.7343 - val_accuracy: 0.5255\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6132 - accuracy: 0.6640 - val_loss: 0.7388 - val_accuracy: 0.5182\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6178 - accuracy: 0.6680 - val_loss: 0.7353 - val_accuracy: 0.5328\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6094 - accuracy: 0.6864 - val_loss: 0.7413 - val_accuracy: 0.5036\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6104 - accuracy: 0.6823 - val_loss: 0.7460 - val_accuracy: 0.5182\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6055 - accuracy: 0.6864 - val_loss: 0.7388 - val_accuracy: 0.5109\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6057 - accuracy: 0.6701 - val_loss: 0.7476 - val_accuracy: 0.5255\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6047 - accuracy: 0.6802 - val_loss: 0.7468 - val_accuracy: 0.5328\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6012 - accuracy: 0.6802 - val_loss: 0.7487 - val_accuracy: 0.5182\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5997 - accuracy: 0.6925 - val_loss: 0.7470 - val_accuracy: 0.5328\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5982 - accuracy: 0.6884 - val_loss: 0.7526 - val_accuracy: 0.5328\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5992 - accuracy: 0.6904 - val_loss: 0.7536 - val_accuracy: 0.5328\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5946 - accuracy: 0.6843 - val_loss: 0.7547 - val_accuracy: 0.5255\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5931 - accuracy: 0.7026 - val_loss: 0.7539 - val_accuracy: 0.5328\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5931 - accuracy: 0.6802 - val_loss: 0.7568 - val_accuracy: 0.5109\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5926 - accuracy: 0.6884 - val_loss: 0.7562 - val_accuracy: 0.5328\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5903 - accuracy: 0.6864 - val_loss: 0.7634 - val_accuracy: 0.5401\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5922 - accuracy: 0.7047 - val_loss: 0.7575 - val_accuracy: 0.5109\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5879 - accuracy: 0.6904 - val_loss: 0.7631 - val_accuracy: 0.5328\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5838 - accuracy: 0.7026 - val_loss: 0.7636 - val_accuracy: 0.5328\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5818 - accuracy: 0.7006 - val_loss: 0.7646 - val_accuracy: 0.5328\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5817 - accuracy: 0.6904 - val_loss: 0.7640 - val_accuracy: 0.5182\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5811 - accuracy: 0.6965 - val_loss: 0.7696 - val_accuracy: 0.5109\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5796 - accuracy: 0.6986 - val_loss: 0.7667 - val_accuracy: 0.5036\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5782 - accuracy: 0.6965 - val_loss: 0.7726 - val_accuracy: 0.5109\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5757 - accuracy: 0.7067 - val_loss: 0.7685 - val_accuracy: 0.5328\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5744 - accuracy: 0.7169 - val_loss: 0.7713 - val_accuracy: 0.5182\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5716 - accuracy: 0.7026 - val_loss: 0.7681 - val_accuracy: 0.5474\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.7108 - val_loss: 0.7765 - val_accuracy: 0.5182\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5719 - accuracy: 0.7067 - val_loss: 0.7634 - val_accuracy: 0.5328\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5752 - accuracy: 0.7128 - val_loss: 0.7765 - val_accuracy: 0.5547\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5751 - accuracy: 0.6965 - val_loss: 0.7755 - val_accuracy: 0.5547\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5675 - accuracy: 0.7067 - val_loss: 0.7750 - val_accuracy: 0.5255\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5659 - accuracy: 0.7312 - val_loss: 0.7860 - val_accuracy: 0.5547\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5614 - accuracy: 0.7128 - val_loss: 0.7768 - val_accuracy: 0.5547\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5629 - accuracy: 0.7352 - val_loss: 0.7815 - val_accuracy: 0.5255\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5601 - accuracy: 0.7108 - val_loss: 0.7767 - val_accuracy: 0.5255\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5600 - accuracy: 0.7088 - val_loss: 0.7848 - val_accuracy: 0.5401\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5562 - accuracy: 0.7251 - val_loss: 0.7801 - val_accuracy: 0.5255\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5586 - accuracy: 0.7210 - val_loss: 0.7915 - val_accuracy: 0.4964\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5557 - accuracy: 0.7169 - val_loss: 0.7927 - val_accuracy: 0.5182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15ab54f10>"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = train_X_0_2.shape[1]\n",
    "n_features = train_X_0_2.shape[2]\n",
    "\n",
    "model_0_2_1 = Sequential()\n",
    "model_0_2_1.add(Conv1D(filters=5, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model_0_2_1.add(MaxPooling1D(pool_size=2)) \n",
    "model_0_2_1.add(Flatten())\n",
    "model_0_2_1.add(Dense(50, activation='relu')) \n",
    "model_0_2_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_0_2_1.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_0_2_1.fit(train_X_0_2, train_f0t_tc,epochs=100,  validation_data=(val_X_0_2, val_f0t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "d4bf6fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 13ms/step - loss: 0.7026 - accuracy: 0.5356 - val_loss: 0.7045 - val_accuracy: 0.4745\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6905 - accuracy: 0.5275 - val_loss: 0.6890 - val_accuracy: 0.5912\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6803 - accuracy: 0.5866 - val_loss: 0.6905 - val_accuracy: 0.5036\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6773 - accuracy: 0.5621 - val_loss: 0.6888 - val_accuracy: 0.5401\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6719 - accuracy: 0.6110 - val_loss: 0.6862 - val_accuracy: 0.5693\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6636 - accuracy: 0.6293 - val_loss: 0.6862 - val_accuracy: 0.5766\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6594 - accuracy: 0.6090 - val_loss: 0.6855 - val_accuracy: 0.5839\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6540 - accuracy: 0.6232 - val_loss: 0.6865 - val_accuracy: 0.5547\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6496 - accuracy: 0.6273 - val_loss: 0.6846 - val_accuracy: 0.5620\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6488 - accuracy: 0.6212 - val_loss: 0.6875 - val_accuracy: 0.5328\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6336 - accuracy: 0.6660 - val_loss: 0.6850 - val_accuracy: 0.5693\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6203 - accuracy: 0.6986 - val_loss: 0.6840 - val_accuracy: 0.5766\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.7149 - val_loss: 0.7146 - val_accuracy: 0.5328\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6198 - accuracy: 0.6456 - val_loss: 0.6963 - val_accuracy: 0.5547\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5915 - accuracy: 0.7108 - val_loss: 0.6917 - val_accuracy: 0.5255\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5719 - accuracy: 0.7434 - val_loss: 0.6982 - val_accuracy: 0.5912\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5628 - accuracy: 0.7454 - val_loss: 0.7034 - val_accuracy: 0.5474\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.7617 - val_loss: 0.7126 - val_accuracy: 0.5985\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7862 - val_loss: 0.7137 - val_accuracy: 0.5693\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7576 - val_loss: 0.7287 - val_accuracy: 0.5620\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7800 - val_loss: 0.7309 - val_accuracy: 0.5474\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7862 - val_loss: 0.7396 - val_accuracy: 0.5401\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.8167 - val_loss: 0.8474 - val_accuracy: 0.5182\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.8187 - val_loss: 0.7637 - val_accuracy: 0.5328\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.8187 - val_loss: 0.7865 - val_accuracy: 0.5401\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.8411 - val_loss: 0.7970 - val_accuracy: 0.5255\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.8554 - val_loss: 0.8111 - val_accuracy: 0.5109\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3834 - accuracy: 0.8411 - val_loss: 0.8268 - val_accuracy: 0.5182\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3761 - accuracy: 0.8493 - val_loss: 0.9072 - val_accuracy: 0.5182\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3759 - accuracy: 0.8574 - val_loss: 0.8860 - val_accuracy: 0.5401\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8024 - val_loss: 0.8676 - val_accuracy: 0.5109\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3379 - accuracy: 0.8961 - val_loss: 0.9329 - val_accuracy: 0.5401\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3134 - accuracy: 0.8961 - val_loss: 0.8958 - val_accuracy: 0.5255\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2997 - accuracy: 0.9022 - val_loss: 0.9661 - val_accuracy: 0.5182\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2778 - accuracy: 0.9226 - val_loss: 0.9734 - val_accuracy: 0.5109\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2608 - accuracy: 0.9389 - val_loss: 1.0336 - val_accuracy: 0.5109\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2560 - accuracy: 0.9246 - val_loss: 0.9809 - val_accuracy: 0.5328\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2523 - accuracy: 0.9287 - val_loss: 1.0216 - val_accuracy: 0.5401\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2392 - accuracy: 0.9287 - val_loss: 1.0628 - val_accuracy: 0.5036\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2336 - accuracy: 0.9287 - val_loss: 1.0721 - val_accuracy: 0.4964\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1982 - accuracy: 0.9695 - val_loss: 1.1385 - val_accuracy: 0.5182\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1915 - accuracy: 0.9674 - val_loss: 1.2283 - val_accuracy: 0.5401\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1801 - accuracy: 0.9756 - val_loss: 1.1680 - val_accuracy: 0.4891\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1742 - accuracy: 0.9735 - val_loss: 1.4341 - val_accuracy: 0.4818\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1726 - accuracy: 0.9552 - val_loss: 1.1802 - val_accuracy: 0.4964\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1682 - accuracy: 0.9511 - val_loss: 1.2836 - val_accuracy: 0.5328\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.9776 - val_loss: 1.3517 - val_accuracy: 0.5547\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1522 - accuracy: 0.9756 - val_loss: 1.4300 - val_accuracy: 0.5328\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1507 - accuracy: 0.9695 - val_loss: 1.3838 - val_accuracy: 0.5255\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1248 - accuracy: 0.9796 - val_loss: 1.3447 - val_accuracy: 0.5109\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1190 - accuracy: 0.9878 - val_loss: 1.5937 - val_accuracy: 0.4891\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1478 - accuracy: 0.9572 - val_loss: 1.3439 - val_accuracy: 0.5182\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1287 - accuracy: 0.9695 - val_loss: 1.6231 - val_accuracy: 0.4964\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0934 - accuracy: 0.9980 - val_loss: 1.6098 - val_accuracy: 0.5109\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0874 - accuracy: 0.9980 - val_loss: 1.5507 - val_accuracy: 0.5036\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0800 - accuracy: 0.9980 - val_loss: 1.6988 - val_accuracy: 0.5182\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0734 - accuracy: 0.9980 - val_loss: 1.7086 - val_accuracy: 0.5109\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.9980 - val_loss: 1.7025 - val_accuracy: 0.5255\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.9980 - val_loss: 1.7363 - val_accuracy: 0.5255\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0654 - accuracy: 1.0000 - val_loss: 1.9219 - val_accuracy: 0.4672\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0596 - accuracy: 0.9980 - val_loss: 1.8796 - val_accuracy: 0.4964\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0555 - accuracy: 0.9980 - val_loss: 1.9093 - val_accuracy: 0.4891\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0536 - accuracy: 0.9980 - val_loss: 1.9154 - val_accuracy: 0.4964\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 1.8704 - val_accuracy: 0.5182\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 2.1324 - val_accuracy: 0.4745\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 2.0781 - val_accuracy: 0.4891\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0439 - accuracy: 1.0000 - val_loss: 2.1002 - val_accuracy: 0.4818\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 2.1097 - val_accuracy: 0.5109\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 2.1258 - val_accuracy: 0.4891\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 2.2845 - val_accuracy: 0.4818\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 2.2196 - val_accuracy: 0.4891\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 2.2109 - val_accuracy: 0.4818\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 2.3146 - val_accuracy: 0.4818\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 2.3035 - val_accuracy: 0.4891\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 2.2234 - val_accuracy: 0.5109\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 2.2226 - val_accuracy: 0.5182\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 2.6118 - val_accuracy: 0.4599\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 2.2570 - val_accuracy: 0.5036\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 2.4446 - val_accuracy: 0.5036\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 2.5312 - val_accuracy: 0.4818\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 2.5192 - val_accuracy: 0.4818\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 2.5625 - val_accuracy: 0.4818\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.6945 - val_accuracy: 0.4672\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 2.5510 - val_accuracy: 0.5036\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.5984 - val_accuracy: 0.4964\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.6059 - val_accuracy: 0.4964\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.7467 - val_accuracy: 0.4672\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.7650 - val_accuracy: 0.4599\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.6325 - val_accuracy: 0.4891\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 2.8220 - val_accuracy: 0.4599\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 2.7367 - val_accuracy: 0.4964\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 2.8389 - val_accuracy: 0.4818\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 2.8709 - val_accuracy: 0.4745\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.9136 - val_accuracy: 0.4745\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.8168 - val_accuracy: 0.4891\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.7160 - val_accuracy: 0.5182\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.8540 - val_accuracy: 0.4964\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.9479 - val_accuracy: 0.4818\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.9330 - val_accuracy: 0.4964\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 3.0438 - val_accuracy: 0.4745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15ac4aeb0>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_2_2 = Sequential()\n",
    "model_0_2_2.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model_0_2_2.add(MaxPooling1D(pool_size=2)) \n",
    "model_0_2_2.add(Flatten())\n",
    "model_0_2_2.add(Dense(50, activation='relu')) \n",
    "model_0_2_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_0_2_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_0_2_2.fit(train_X_0_2,train_f0t_tc,epochs=100,  validation_data=(val_X_0_2, val_f0t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "41c7a58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 14ms/step - loss: 0.6989 - accuracy: 0.4949 - val_loss: 0.7032 - val_accuracy: 0.4380\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5193 - val_loss: 0.6941 - val_accuracy: 0.5328\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6881 - accuracy: 0.5295 - val_loss: 0.6931 - val_accuracy: 0.5182\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6825 - accuracy: 0.5560 - val_loss: 0.6930 - val_accuracy: 0.4891\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6769 - accuracy: 0.6029 - val_loss: 0.6930 - val_accuracy: 0.5255\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6710 - accuracy: 0.6538 - val_loss: 0.6981 - val_accuracy: 0.5036\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6637 - accuracy: 0.6273 - val_loss: 0.6972 - val_accuracy: 0.5182\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6539 - accuracy: 0.6314 - val_loss: 0.7039 - val_accuracy: 0.4161\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6490 - accuracy: 0.6517 - val_loss: 0.7041 - val_accuracy: 0.4891\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6422 - accuracy: 0.6232 - val_loss: 0.7212 - val_accuracy: 0.5036\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6214 - accuracy: 0.6619 - val_loss: 0.7216 - val_accuracy: 0.5109\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6010 - accuracy: 0.7047 - val_loss: 0.7632 - val_accuracy: 0.5474\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.6945 - val_loss: 0.7648 - val_accuracy: 0.5036\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5709 - accuracy: 0.7352 - val_loss: 0.7762 - val_accuracy: 0.4818\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5516 - accuracy: 0.7556 - val_loss: 0.7647 - val_accuracy: 0.4891\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5349 - accuracy: 0.7393 - val_loss: 0.8050 - val_accuracy: 0.4745\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7678 - val_loss: 0.8227 - val_accuracy: 0.4745\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7576 - val_loss: 0.8967 - val_accuracy: 0.5255\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7475 - val_loss: 0.8873 - val_accuracy: 0.4818\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.7658 - val_loss: 0.9203 - val_accuracy: 0.5255\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7902 - val_loss: 0.8793 - val_accuracy: 0.4891\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3992 - accuracy: 0.8473 - val_loss: 0.9351 - val_accuracy: 0.4891\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3764 - accuracy: 0.8717 - val_loss: 1.0663 - val_accuracy: 0.5109\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3648 - accuracy: 0.8574 - val_loss: 1.0462 - val_accuracy: 0.5036\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3503 - accuracy: 0.8635 - val_loss: 1.0344 - val_accuracy: 0.5036\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3391 - accuracy: 0.8656 - val_loss: 1.0986 - val_accuracy: 0.4964\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3037 - accuracy: 0.9043 - val_loss: 1.2089 - val_accuracy: 0.5036\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2995 - accuracy: 0.8941 - val_loss: 1.0800 - val_accuracy: 0.5036\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2908 - accuracy: 0.8900 - val_loss: 1.4003 - val_accuracy: 0.5182\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2548 - accuracy: 0.9022 - val_loss: 1.1722 - val_accuracy: 0.4818\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2713 - accuracy: 0.8982 - val_loss: 1.3598 - val_accuracy: 0.5401\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2244 - accuracy: 0.9409 - val_loss: 1.3762 - val_accuracy: 0.5182\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1938 - accuracy: 0.9654 - val_loss: 1.4010 - val_accuracy: 0.5182\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1878 - accuracy: 0.9572 - val_loss: 1.5410 - val_accuracy: 0.5255\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1666 - accuracy: 0.9756 - val_loss: 1.7252 - val_accuracy: 0.5474\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1489 - accuracy: 0.9817 - val_loss: 1.8912 - val_accuracy: 0.5255\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1503 - accuracy: 0.9756 - val_loss: 1.7093 - val_accuracy: 0.5109\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1484 - accuracy: 0.9715 - val_loss: 1.6641 - val_accuracy: 0.5182\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1195 - accuracy: 0.9878 - val_loss: 1.7389 - val_accuracy: 0.5109\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1030 - accuracy: 0.9878 - val_loss: 1.9099 - val_accuracy: 0.5328\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0977 - accuracy: 0.9898 - val_loss: 1.8556 - val_accuracy: 0.5328\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0888 - accuracy: 0.9959 - val_loss: 2.0405 - val_accuracy: 0.5182\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0818 - accuracy: 0.9939 - val_loss: 1.9725 - val_accuracy: 0.5255\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0693 - accuracy: 1.0000 - val_loss: 2.1563 - val_accuracy: 0.5255\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.9980 - val_loss: 2.1656 - val_accuracy: 0.5182\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 2.2517 - val_accuracy: 0.5109\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 2.2850 - val_accuracy: 0.5328\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.9980 - val_loss: 2.4611 - val_accuracy: 0.5474\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 2.3202 - val_accuracy: 0.5182\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 2.4020 - val_accuracy: 0.5328\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0344 - accuracy: 0.9980 - val_loss: 2.4890 - val_accuracy: 0.5255\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 2.7061 - val_accuracy: 0.5474\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 2.6631 - val_accuracy: 0.5255\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 2.6607 - val_accuracy: 0.5182\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 2.6638 - val_accuracy: 0.5255\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 2.7361 - val_accuracy: 0.5255\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 2.7874 - val_accuracy: 0.5109\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 2.8773 - val_accuracy: 0.5255\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.9070 - val_accuracy: 0.5255\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.9582 - val_accuracy: 0.5255\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 3.1313 - val_accuracy: 0.5474\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 3.2490 - val_accuracy: 0.5547\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 3.0605 - val_accuracy: 0.5328\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 2.9023 - val_accuracy: 0.5182\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 3.2402 - val_accuracy: 0.5401\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 3.4352 - val_accuracy: 0.5620\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 3.2864 - val_accuracy: 0.5328\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 3.2825 - val_accuracy: 0.5328\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 3.2918 - val_accuracy: 0.5401\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 3.4287 - val_accuracy: 0.5401\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 3.3979 - val_accuracy: 0.5328\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 3.3838 - val_accuracy: 0.5328\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 3.5902 - val_accuracy: 0.5547\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 3.5712 - val_accuracy: 0.5401\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 3.4810 - val_accuracy: 0.5401\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 3.6572 - val_accuracy: 0.5401\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 3.7275 - val_accuracy: 0.5474\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 3.7501 - val_accuracy: 0.5474\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 3.6725 - val_accuracy: 0.5401\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 3.6143 - val_accuracy: 0.5328\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 3.6452 - val_accuracy: 0.5401\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 3.7809 - val_accuracy: 0.5401\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 3.7261 - val_accuracy: 0.5328\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 3.8452 - val_accuracy: 0.5474\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 3.7769 - val_accuracy: 0.5328\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 3.8717 - val_accuracy: 0.5328\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 3.8713 - val_accuracy: 0.5401\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.9040 - val_accuracy: 0.5401\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.8755 - val_accuracy: 0.5401\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.9369 - val_accuracy: 0.5401\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.9262 - val_accuracy: 0.5328\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 4.0085 - val_accuracy: 0.5401\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.0753 - val_accuracy: 0.5401\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 4.0823 - val_accuracy: 0.5401\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 4.1393 - val_accuracy: 0.5401\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 4.0609 - val_accuracy: 0.5328\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 4.0380 - val_accuracy: 0.5328\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 4.0762 - val_accuracy: 0.5328\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.9920 - val_accuracy: 0.5328\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 4.1333 - val_accuracy: 0.5401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15ae23370>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_2_3 = Sequential()\n",
    "model_0_2_3.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features)))\n",
    "model_0_2_3.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_0_2_3.add(MaxPooling1D(pool_size=2)) \n",
    "model_0_2_3.add(Flatten())\n",
    "model_0_2_3.add(Dense(50, activation='relu')) \n",
    "model_0_2_3.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model_0_2_3.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_0_2_3.fit(train_X_0_2,train_f0t_tc,epochs=100,  validation_data=(val_X_0_2, val_f0t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "5d0874fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 16ms/step - loss: 0.6957 - accuracy: 0.5071 - val_loss: 0.6931 - val_accuracy: 0.5182\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6923 - accuracy: 0.5275 - val_loss: 0.6945 - val_accuracy: 0.5182\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6903 - accuracy: 0.5193 - val_loss: 0.6955 - val_accuracy: 0.5182\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6862 - accuracy: 0.5397 - val_loss: 0.6951 - val_accuracy: 0.5109\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6800 - accuracy: 0.5682 - val_loss: 0.6990 - val_accuracy: 0.4891\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6762 - accuracy: 0.6232 - val_loss: 0.6989 - val_accuracy: 0.5109\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6585 - accuracy: 0.6436 - val_loss: 0.7107 - val_accuracy: 0.5182\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6736 - accuracy: 0.5723 - val_loss: 0.7033 - val_accuracy: 0.5036\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6354 - accuracy: 0.6680 - val_loss: 0.7131 - val_accuracy: 0.5036\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6038 - accuracy: 0.7088 - val_loss: 0.7209 - val_accuracy: 0.5109\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5644 - accuracy: 0.7373 - val_loss: 0.7695 - val_accuracy: 0.5182\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5276 - accuracy: 0.7454 - val_loss: 0.8421 - val_accuracy: 0.5547\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5300 - accuracy: 0.7251 - val_loss: 0.8070 - val_accuracy: 0.4891\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5106 - accuracy: 0.7413 - val_loss: 0.8100 - val_accuracy: 0.5182\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7719 - val_loss: 0.8375 - val_accuracy: 0.5036\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.8208 - val_loss: 0.8472 - val_accuracy: 0.4599\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3927 - accuracy: 0.8371 - val_loss: 0.9406 - val_accuracy: 0.5036\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3403 - accuracy: 0.8676 - val_loss: 0.9648 - val_accuracy: 0.5036\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3117 - accuracy: 0.8859 - val_loss: 1.0206 - val_accuracy: 0.4891\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2674 - accuracy: 0.9185 - val_loss: 1.1119 - val_accuracy: 0.4891\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2387 - accuracy: 0.9104 - val_loss: 1.1509 - val_accuracy: 0.4964\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2142 - accuracy: 0.9409 - val_loss: 1.2715 - val_accuracy: 0.4891\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2077 - accuracy: 0.9450 - val_loss: 1.4260 - val_accuracy: 0.4672\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1792 - accuracy: 0.9491 - val_loss: 1.4527 - val_accuracy: 0.4672\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1560 - accuracy: 0.9409 - val_loss: 1.4068 - val_accuracy: 0.5036\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1273 - accuracy: 0.9674 - val_loss: 1.6075 - val_accuracy: 0.4964\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1081 - accuracy: 0.9674 - val_loss: 1.6859 - val_accuracy: 0.4964\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0844 - accuracy: 0.9837 - val_loss: 1.7569 - val_accuracy: 0.4818\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0665 - accuracy: 0.9959 - val_loss: 1.7893 - val_accuracy: 0.4599\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0742 - accuracy: 0.9857 - val_loss: 2.0178 - val_accuracy: 0.4891\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0564 - accuracy: 0.9857 - val_loss: 2.0330 - val_accuracy: 0.4526\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0361 - accuracy: 0.9980 - val_loss: 2.0539 - val_accuracy: 0.4745\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 2.1679 - val_accuracy: 0.4672\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 2.2158 - val_accuracy: 0.4745\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0241 - accuracy: 0.9980 - val_loss: 2.2986 - val_accuracy: 0.4891\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0247 - accuracy: 0.9980 - val_loss: 2.3494 - val_accuracy: 0.4891\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.4260 - val_accuracy: 0.4745\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.4905 - val_accuracy: 0.4818\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0177 - accuracy: 0.9980 - val_loss: 2.5527 - val_accuracy: 0.4672\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.6161 - val_accuracy: 0.4745\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.6398 - val_accuracy: 0.4818\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.7133 - val_accuracy: 0.4745\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.7587 - val_accuracy: 0.4599\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.8196 - val_accuracy: 0.4599\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.8202 - val_accuracy: 0.4599\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.8926 - val_accuracy: 0.4891\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.9255 - val_accuracy: 0.4672\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.9387 - val_accuracy: 0.4599\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.9731 - val_accuracy: 0.4745\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.0163 - val_accuracy: 0.4745\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.0311 - val_accuracy: 0.4599\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.0559 - val_accuracy: 0.4745\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0830 - val_accuracy: 0.4672\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.1179 - val_accuracy: 0.4745\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1349 - val_accuracy: 0.4745\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1652 - val_accuracy: 0.4745\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1847 - val_accuracy: 0.4745\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.1993 - val_accuracy: 0.4599\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2341 - val_accuracy: 0.4745\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.2610 - val_accuracy: 0.4818\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.2658 - val_accuracy: 0.4672\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.2963 - val_accuracy: 0.4745\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.3255 - val_accuracy: 0.4745\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.3286 - val_accuracy: 0.4745\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.3689 - val_accuracy: 0.4745\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.3884 - val_accuracy: 0.4818\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.4077 - val_accuracy: 0.4818\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.4197 - val_accuracy: 0.4745\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.4451 - val_accuracy: 0.4745\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.9225e-04 - accuracy: 1.0000 - val_loss: 3.4639 - val_accuracy: 0.4818\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 9.4883e-04 - accuracy: 1.0000 - val_loss: 3.4771 - val_accuracy: 0.4745\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.3474e-04 - accuracy: 1.0000 - val_loss: 3.5035 - val_accuracy: 0.4745\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.7296e-04 - accuracy: 1.0000 - val_loss: 3.5127 - val_accuracy: 0.4745\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.4669e-04 - accuracy: 1.0000 - val_loss: 3.5334 - val_accuracy: 0.4818\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.0657e-04 - accuracy: 1.0000 - val_loss: 3.5542 - val_accuracy: 0.4745\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.8154e-04 - accuracy: 1.0000 - val_loss: 3.5826 - val_accuracy: 0.4818\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.5543e-04 - accuracy: 1.0000 - val_loss: 3.5898 - val_accuracy: 0.4745\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.3591e-04 - accuracy: 1.0000 - val_loss: 3.5950 - val_accuracy: 0.4672\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 7.1090e-04 - accuracy: 1.0000 - val_loss: 3.6282 - val_accuracy: 0.4745\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 6.8973e-04 - accuracy: 1.0000 - val_loss: 3.6464 - val_accuracy: 0.4818\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 6.5401e-04 - accuracy: 1.0000 - val_loss: 3.6467 - val_accuracy: 0.4818\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 6.3424e-04 - accuracy: 1.0000 - val_loss: 3.6765 - val_accuracy: 0.4818\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 6.1646e-04 - accuracy: 1.0000 - val_loss: 3.6842 - val_accuracy: 0.4818\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 5.9543e-04 - accuracy: 1.0000 - val_loss: 3.7112 - val_accuracy: 0.4745\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 5.7078e-04 - accuracy: 1.0000 - val_loss: 3.7154 - val_accuracy: 0.4745\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5.5415e-04 - accuracy: 1.0000 - val_loss: 3.7343 - val_accuracy: 0.4745\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5.3623e-04 - accuracy: 1.0000 - val_loss: 3.7475 - val_accuracy: 0.4745\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5.2060e-04 - accuracy: 1.0000 - val_loss: 3.7617 - val_accuracy: 0.4745\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5.0656e-04 - accuracy: 1.0000 - val_loss: 3.7739 - val_accuracy: 0.4745\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.9024e-04 - accuracy: 1.0000 - val_loss: 3.7824 - val_accuracy: 0.4745\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.8402e-04 - accuracy: 1.0000 - val_loss: 3.8099 - val_accuracy: 0.4818\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 4.6610e-04 - accuracy: 1.0000 - val_loss: 3.8149 - val_accuracy: 0.4745\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.5286e-04 - accuracy: 1.0000 - val_loss: 3.8332 - val_accuracy: 0.4745\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.5210e-04 - accuracy: 1.0000 - val_loss: 3.8603 - val_accuracy: 0.4891\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.2333e-04 - accuracy: 1.0000 - val_loss: 3.8653 - val_accuracy: 0.4745\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 4.1039e-04 - accuracy: 1.0000 - val_loss: 3.8875 - val_accuracy: 0.4745\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 3.9876e-04 - accuracy: 1.0000 - val_loss: 3.8891 - val_accuracy: 0.4745\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.8482e-04 - accuracy: 1.0000 - val_loss: 3.9069 - val_accuracy: 0.4818\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.7802e-04 - accuracy: 1.0000 - val_loss: 3.9210 - val_accuracy: 0.4818\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.7289e-04 - accuracy: 1.0000 - val_loss: 3.9267 - val_accuracy: 0.4818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x158031b20>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_2_4 = Sequential()\n",
    "model_0_2_4.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features)))\n",
    "model_0_2_4.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_0_2_4.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_0_2_4.add(MaxPooling1D(pool_size=2)) \n",
    "model_0_2_4.add(Conv1D(filters=32, kernel_size=1, activation='relu')) \n",
    "model_0_2_4.add(Flatten())\n",
    "model_0_2_4.add(Dense(50, activation='relu')) \n",
    "model_0_2_4.add(Dense(1, activation='sigmoid')) \n",
    "model_0_2_4.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_0_2_4.fit(train_X_0_2,train_f0t_tc,epochs=100,  validation_data=(val_X_0_2, val_f0t_tc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cb55cb",
   "metadata": {},
   "source": [
    "Model_0_2_4 best, and most consistent so far"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5aada2",
   "metadata": {},
   "source": [
    "### Model_0_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "9e15e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with 8 components to explain 85% of variance\n",
    "sklearn_pca = PCA(n_components=8)\n",
    "train_X_0_3 = pd.DataFrame(sklearn_pca.fit_transform(train_f0[feats]))\n",
    "val_X_0_3 = pd.DataFrame(sklearn_pca.transform(val_f0[feats]))\n",
    "test_X_0_3 = pd.DataFrame(sklearn_pca.transform(test_f0[feats]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "ab93c528",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_0_3, _ = df_to_X_np(train_X_0_3)\n",
    "val_X_0_3, _ = df_to_X_np(val_X_0_3)\n",
    "test_X_0_3, _ = df_to_X_np(test_X_0_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "252b2c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "16/16 [==============================] - 1s 22ms/step - loss: 0.7055 - accuracy: 0.4827 - val_loss: 0.6944 - val_accuracy: 0.5182\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6989 - accuracy: 0.4990 - val_loss: 0.6942 - val_accuracy: 0.5401\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6951 - accuracy: 0.5051 - val_loss: 0.6932 - val_accuracy: 0.5328\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6925 - accuracy: 0.5336 - val_loss: 0.6916 - val_accuracy: 0.5547\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6883 - accuracy: 0.5479 - val_loss: 0.6911 - val_accuracy: 0.5401\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6856 - accuracy: 0.5540 - val_loss: 0.6902 - val_accuracy: 0.5401\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6835 - accuracy: 0.5784 - val_loss: 0.6900 - val_accuracy: 0.5255\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.6826 - accuracy: 0.5784 - val_loss: 0.6899 - val_accuracy: 0.5620\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6792 - accuracy: 0.5784 - val_loss: 0.6907 - val_accuracy: 0.5255\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6783 - accuracy: 0.5682 - val_loss: 0.6906 - val_accuracy: 0.5328\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6758 - accuracy: 0.5906 - val_loss: 0.6898 - val_accuracy: 0.5693\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6751 - accuracy: 0.6232 - val_loss: 0.6883 - val_accuracy: 0.5547\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6721 - accuracy: 0.6212 - val_loss: 0.6881 - val_accuracy: 0.5547\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6699 - accuracy: 0.6110 - val_loss: 0.6888 - val_accuracy: 0.5328\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6688 - accuracy: 0.6110 - val_loss: 0.6882 - val_accuracy: 0.5401\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6667 - accuracy: 0.6293 - val_loss: 0.6878 - val_accuracy: 0.5328\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6650 - accuracy: 0.6232 - val_loss: 0.6876 - val_accuracy: 0.5182\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6634 - accuracy: 0.6314 - val_loss: 0.6860 - val_accuracy: 0.5474\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6614 - accuracy: 0.6497 - val_loss: 0.6859 - val_accuracy: 0.5766\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6589 - accuracy: 0.6497 - val_loss: 0.6859 - val_accuracy: 0.5474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1593dc850>"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = train_X_0_3.shape[1]\n",
    "n_features = train_X_0_3.shape[2]\n",
    "\n",
    "model_0_3_1 = Sequential()\n",
    "model_0_3_1.add(Conv1D(filters=5, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model_0_3_1.add(MaxPooling1D(pool_size=2)) \n",
    "model_0_3_1.add(Flatten())\n",
    "model_0_3_1.add(Dense(50, activation='relu')) \n",
    "model_0_3_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_0_3_1.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_0_3_1.fit(train_X_0_3, train_f0t_tc,epochs=20,  validation_data=(val_X_0_3, val_f0t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "7327a512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 7s 49ms/step - loss: 0.7015 - accuracy: 0.4969 - val_loss: 0.6963 - val_accuracy: 0.4964\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6777 - accuracy: 0.5866 - val_loss: 0.6895 - val_accuracy: 0.5401\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6612 - accuracy: 0.6212 - val_loss: 0.6902 - val_accuracy: 0.5109\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6448 - accuracy: 0.6660 - val_loss: 0.6912 - val_accuracy: 0.5036\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6314 - accuracy: 0.6986 - val_loss: 0.6903 - val_accuracy: 0.5401\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.6168 - accuracy: 0.7169 - val_loss: 0.6939 - val_accuracy: 0.5401\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6032 - accuracy: 0.7312 - val_loss: 0.6950 - val_accuracy: 0.5401\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5886 - accuracy: 0.7515 - val_loss: 0.6956 - val_accuracy: 0.5547\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5722 - accuracy: 0.7495 - val_loss: 0.7057 - val_accuracy: 0.4672\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5575 - accuracy: 0.7821 - val_loss: 0.7080 - val_accuracy: 0.5547\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.5393 - accuracy: 0.7902 - val_loss: 0.7201 - val_accuracy: 0.5109\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5237 - accuracy: 0.8106 - val_loss: 0.7194 - val_accuracy: 0.5109\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.5090 - accuracy: 0.8167 - val_loss: 0.7322 - val_accuracy: 0.5693\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4906 - accuracy: 0.8228 - val_loss: 0.7435 - val_accuracy: 0.4964\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4774 - accuracy: 0.8554 - val_loss: 0.7501 - val_accuracy: 0.5036\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.4540 - accuracy: 0.8473 - val_loss: 0.7505 - val_accuracy: 0.5547\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.4356 - accuracy: 0.8554 - val_loss: 0.7692 - val_accuracy: 0.4964\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4151 - accuracy: 0.8921 - val_loss: 0.7732 - val_accuracy: 0.4599\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.3941 - accuracy: 0.8941 - val_loss: 0.7746 - val_accuracy: 0.5109\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3742 - accuracy: 0.9104 - val_loss: 0.7878 - val_accuracy: 0.5182\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.3553 - accuracy: 0.9185 - val_loss: 0.7954 - val_accuracy: 0.4964\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.3332 - accuracy: 0.9287 - val_loss: 0.8032 - val_accuracy: 0.5474\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3267 - accuracy: 0.9165 - val_loss: 0.8464 - val_accuracy: 0.4745\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2996 - accuracy: 0.9409 - val_loss: 0.8377 - val_accuracy: 0.5109\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2804 - accuracy: 0.9552 - val_loss: 0.8449 - val_accuracy: 0.5474\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2698 - accuracy: 0.9450 - val_loss: 0.8718 - val_accuracy: 0.5255\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2480 - accuracy: 0.9674 - val_loss: 0.8806 - val_accuracy: 0.5255\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2389 - accuracy: 0.9735 - val_loss: 0.8912 - val_accuracy: 0.5182\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2209 - accuracy: 0.9756 - val_loss: 0.9230 - val_accuracy: 0.5109\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2043 - accuracy: 0.9857 - val_loss: 0.9229 - val_accuracy: 0.5182\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1910 - accuracy: 0.9857 - val_loss: 0.9416 - val_accuracy: 0.5255\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1791 - accuracy: 0.9919 - val_loss: 0.9564 - val_accuracy: 0.5328\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1729 - accuracy: 0.9857 - val_loss: 0.9767 - val_accuracy: 0.5328\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1614 - accuracy: 0.9857 - val_loss: 0.9852 - val_accuracy: 0.5401\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1438 - accuracy: 0.9980 - val_loss: 1.0088 - val_accuracy: 0.5255\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1344 - accuracy: 0.9959 - val_loss: 1.0399 - val_accuracy: 0.5328\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1300 - accuracy: 0.9980 - val_loss: 1.0403 - val_accuracy: 0.5474\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1157 - accuracy: 0.9980 - val_loss: 1.0598 - val_accuracy: 0.5693\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1074 - accuracy: 0.9980 - val_loss: 1.1008 - val_accuracy: 0.5036\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1015 - accuracy: 0.9980 - val_loss: 1.0890 - val_accuracy: 0.5255\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0942 - accuracy: 1.0000 - val_loss: 1.1204 - val_accuracy: 0.5474\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0865 - accuracy: 1.0000 - val_loss: 1.1183 - val_accuracy: 0.5255\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0822 - accuracy: 1.0000 - val_loss: 1.1303 - val_accuracy: 0.5474\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0801 - accuracy: 1.0000 - val_loss: 1.1672 - val_accuracy: 0.5255\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0748 - accuracy: 1.0000 - val_loss: 1.1797 - val_accuracy: 0.5255\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0672 - accuracy: 1.0000 - val_loss: 1.1756 - val_accuracy: 0.5328\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 1.2061 - val_accuracy: 0.5620\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0583 - accuracy: 1.0000 - val_loss: 1.2341 - val_accuracy: 0.5328\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0548 - accuracy: 1.0000 - val_loss: 1.2302 - val_accuracy: 0.5328\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0509 - accuracy: 1.0000 - val_loss: 1.2544 - val_accuracy: 0.5474\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0482 - accuracy: 1.0000 - val_loss: 1.2536 - val_accuracy: 0.5401\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 1.2797 - val_accuracy: 0.5328\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 1.3001 - val_accuracy: 0.5401\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 1.3143 - val_accuracy: 0.5620\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 1.3282 - val_accuracy: 0.5328\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 1.3410 - val_accuracy: 0.5401\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 1.3432 - val_accuracy: 0.5328\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 1.3738 - val_accuracy: 0.5474\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 1.3764 - val_accuracy: 0.5328\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 1.4040 - val_accuracy: 0.5401\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 1.4013 - val_accuracy: 0.5401\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 1.4182 - val_accuracy: 0.5401\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 1.4470 - val_accuracy: 0.5474\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 1.4356 - val_accuracy: 0.5474\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 1.4570 - val_accuracy: 0.5620\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 1.4807 - val_accuracy: 0.5474\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 1.4746 - val_accuracy: 0.5255\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 1.4947 - val_accuracy: 0.5547\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 1.5036 - val_accuracy: 0.5474\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.5208 - val_accuracy: 0.5255\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.5288 - val_accuracy: 0.5547\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.5365 - val_accuracy: 0.5474\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.5523 - val_accuracy: 0.5401\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.5638 - val_accuracy: 0.5401\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.5683 - val_accuracy: 0.5474\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.5838 - val_accuracy: 0.5328\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.5977 - val_accuracy: 0.5401\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.6005 - val_accuracy: 0.5255\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.6138 - val_accuracy: 0.5401\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.6277 - val_accuracy: 0.5401\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.6369 - val_accuracy: 0.5401\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.6414 - val_accuracy: 0.5401\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.6617 - val_accuracy: 0.5255\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.6687 - val_accuracy: 0.5328\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.6754 - val_accuracy: 0.5328\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.6865 - val_accuracy: 0.5328\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.6949 - val_accuracy: 0.5328\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.7035 - val_accuracy: 0.5328\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.7174 - val_accuracy: 0.5401\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.7204 - val_accuracy: 0.5255\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.7265 - val_accuracy: 0.5401\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.7367 - val_accuracy: 0.5328\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.7447 - val_accuracy: 0.5328\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.7555 - val_accuracy: 0.5328\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.7682 - val_accuracy: 0.5109\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.7734 - val_accuracy: 0.5401\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.7825 - val_accuracy: 0.5255\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.7892 - val_accuracy: 0.5401\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.7995 - val_accuracy: 0.5255\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.8030 - val_accuracy: 0.5328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15d984f70>"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_3_2 = Sequential()\n",
    "model_0_3_2.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model_0_3_2.add(MaxPooling1D(pool_size=2)) \n",
    "model_0_3_2.add(Flatten())\n",
    "model_0_3_2.add(Dense(50, activation='relu')) \n",
    "model_0_3_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_0_3_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_0_3_2.fit(train_X_0_3,train_f0t_tc,epochs=100,  validation_data=(val_X_0_3, val_f0t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "3ca8a815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 21ms/step - loss: 0.6985 - accuracy: 0.5031 - val_loss: 0.6900 - val_accuracy: 0.4964\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6857 - accuracy: 0.5316 - val_loss: 0.6892 - val_accuracy: 0.4818\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.6777 - accuracy: 0.5927 - val_loss: 0.6865 - val_accuracy: 0.5255\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6691 - accuracy: 0.6456 - val_loss: 0.6877 - val_accuracy: 0.5182\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6595 - accuracy: 0.6619 - val_loss: 0.6875 - val_accuracy: 0.4964\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6480 - accuracy: 0.6701 - val_loss: 0.6891 - val_accuracy: 0.5401\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6374 - accuracy: 0.6721 - val_loss: 0.6889 - val_accuracy: 0.5328\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6185 - accuracy: 0.6965 - val_loss: 0.6922 - val_accuracy: 0.5474\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5998 - accuracy: 0.7413 - val_loss: 0.6961 - val_accuracy: 0.5401\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5852 - accuracy: 0.7495 - val_loss: 0.7037 - val_accuracy: 0.5474\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5546 - accuracy: 0.7841 - val_loss: 0.7049 - val_accuracy: 0.5474\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5337 - accuracy: 0.8045 - val_loss: 0.7202 - val_accuracy: 0.5182\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.5063 - accuracy: 0.8106 - val_loss: 0.7269 - val_accuracy: 0.5109\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4942 - accuracy: 0.7821 - val_loss: 0.7441 - val_accuracy: 0.4672\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4736 - accuracy: 0.8126 - val_loss: 0.7526 - val_accuracy: 0.5328\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.8452 - val_loss: 0.7585 - val_accuracy: 0.5182\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4021 - accuracy: 0.8778 - val_loss: 0.7852 - val_accuracy: 0.4891\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.3773 - accuracy: 0.8778 - val_loss: 0.8098 - val_accuracy: 0.5036\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3511 - accuracy: 0.8839 - val_loss: 0.8154 - val_accuracy: 0.5036\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3317 - accuracy: 0.8778 - val_loss: 0.8312 - val_accuracy: 0.5255\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3078 - accuracy: 0.9104 - val_loss: 0.8628 - val_accuracy: 0.4891\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2951 - accuracy: 0.8982 - val_loss: 0.8780 - val_accuracy: 0.5109\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2640 - accuracy: 0.9246 - val_loss: 0.8777 - val_accuracy: 0.5620\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2454 - accuracy: 0.9409 - val_loss: 0.9348 - val_accuracy: 0.5109\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2194 - accuracy: 0.9267 - val_loss: 0.9453 - val_accuracy: 0.5036\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2051 - accuracy: 0.9511 - val_loss: 0.9763 - val_accuracy: 0.5328\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1946 - accuracy: 0.9532 - val_loss: 1.0877 - val_accuracy: 0.5255\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1819 - accuracy: 0.9491 - val_loss: 1.0459 - val_accuracy: 0.5182\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1469 - accuracy: 0.9776 - val_loss: 1.1143 - val_accuracy: 0.5036\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1315 - accuracy: 0.9796 - val_loss: 1.1142 - val_accuracy: 0.5109\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1198 - accuracy: 0.9857 - val_loss: 1.1576 - val_accuracy: 0.5474\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1100 - accuracy: 0.9939 - val_loss: 1.2025 - val_accuracy: 0.5182\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0991 - accuracy: 0.9919 - val_loss: 1.2578 - val_accuracy: 0.4891\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0978 - accuracy: 0.9898 - val_loss: 1.2401 - val_accuracy: 0.5255\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0764 - accuracy: 0.9939 - val_loss: 1.2974 - val_accuracy: 0.5182\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0699 - accuracy: 1.0000 - val_loss: 1.3194 - val_accuracy: 0.5182\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0620 - accuracy: 0.9980 - val_loss: 1.3556 - val_accuracy: 0.5109\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0677 - accuracy: 0.9980 - val_loss: 1.4038 - val_accuracy: 0.5036\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0545 - accuracy: 0.9959 - val_loss: 1.3937 - val_accuracy: 0.5109\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 1.4635 - val_accuracy: 0.5182\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0407 - accuracy: 0.9980 - val_loss: 1.4844 - val_accuracy: 0.5109\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 1.5146 - val_accuracy: 0.5182\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 1.5363 - val_accuracy: 0.4964\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 1.5410 - val_accuracy: 0.5328\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 1.5945 - val_accuracy: 0.5036\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 1.6305 - val_accuracy: 0.4964\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 1.6468 - val_accuracy: 0.5182\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 1.6813 - val_accuracy: 0.5109\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 1.7157 - val_accuracy: 0.5036\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 1.7317 - val_accuracy: 0.5109\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.7540 - val_accuracy: 0.5109\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.7738 - val_accuracy: 0.5182\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.7957 - val_accuracy: 0.5109\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.8271 - val_accuracy: 0.5109\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.8426 - val_accuracy: 0.4964\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.8632 - val_accuracy: 0.5036\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.8772 - val_accuracy: 0.5182\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.8852 - val_accuracy: 0.5036\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.9120 - val_accuracy: 0.5109\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.9266 - val_accuracy: 0.5182\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.9374 - val_accuracy: 0.5036\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.9548 - val_accuracy: 0.5036\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.9791 - val_accuracy: 0.5036\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.9965 - val_accuracy: 0.5182\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.0064 - val_accuracy: 0.5036\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.0278 - val_accuracy: 0.4964\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.0452 - val_accuracy: 0.4964\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.0569 - val_accuracy: 0.5036\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.0645 - val_accuracy: 0.5036\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.0809 - val_accuracy: 0.5036\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.1025 - val_accuracy: 0.5109\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.1135 - val_accuracy: 0.5109\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.1288 - val_accuracy: 0.5109\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.1340 - val_accuracy: 0.5036\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.1549 - val_accuracy: 0.5109\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.1574 - val_accuracy: 0.5036\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.1799 - val_accuracy: 0.5182\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.1780 - val_accuracy: 0.5036\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.2028 - val_accuracy: 0.5182\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.2172 - val_accuracy: 0.5109\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.2165 - val_accuracy: 0.5182\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.2320 - val_accuracy: 0.5036\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.2446 - val_accuracy: 0.5182\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.2512 - val_accuracy: 0.5182\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.2647 - val_accuracy: 0.5182\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.2792 - val_accuracy: 0.5182\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.2842 - val_accuracy: 0.5182\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.2920 - val_accuracy: 0.5036\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.3037 - val_accuracy: 0.5109\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.3109 - val_accuracy: 0.5109\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.3200 - val_accuracy: 0.5182\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.3263 - val_accuracy: 0.5182\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.3461 - val_accuracy: 0.5182\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.3598 - val_accuracy: 0.5182\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.3617 - val_accuracy: 0.5182\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.3682 - val_accuracy: 0.5109\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.3814 - val_accuracy: 0.5182\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.3813 - val_accuracy: 0.5109\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.3953 - val_accuracy: 0.5182\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.4072 - val_accuracy: 0.5182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15d6091f0>"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_3_3 = Sequential()\n",
    "model_0_3_3.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features)))\n",
    "model_0_3_3.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_0_3_3.add(MaxPooling1D(pool_size=2)) \n",
    "model_0_3_3.add(Flatten())\n",
    "model_0_3_3.add(Dense(50, activation='relu')) \n",
    "model_0_3_3.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model_0_3_3.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_0_3_3.fit(train_X_0_3,train_f0t_tc,epochs=100,  validation_data=(val_X_0_3, val_f0t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "b778221d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 16ms/step - loss: 0.6927 - accuracy: 0.5071 - val_loss: 0.6909 - val_accuracy: 0.5109\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6841 - accuracy: 0.5255 - val_loss: 0.6890 - val_accuracy: 0.5109\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6752 - accuracy: 0.5336 - val_loss: 0.6884 - val_accuracy: 0.5328\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6579 - accuracy: 0.6314 - val_loss: 0.6871 - val_accuracy: 0.5109\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6246 - accuracy: 0.7067 - val_loss: 0.6903 - val_accuracy: 0.5109\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5827 - accuracy: 0.7128 - val_loss: 0.6982 - val_accuracy: 0.5255\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5267 - accuracy: 0.7841 - val_loss: 0.7200 - val_accuracy: 0.5255\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7984 - val_loss: 0.7859 - val_accuracy: 0.5255\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8371 - val_loss: 0.8547 - val_accuracy: 0.5328\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8391 - val_loss: 0.8386 - val_accuracy: 0.5474\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3525 - accuracy: 0.8697 - val_loss: 0.8201 - val_accuracy: 0.5401\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3156 - accuracy: 0.8798 - val_loss: 0.8328 - val_accuracy: 0.5474\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2402 - accuracy: 0.9348 - val_loss: 0.9269 - val_accuracy: 0.4745\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1949 - accuracy: 0.9532 - val_loss: 1.0133 - val_accuracy: 0.5036\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1692 - accuracy: 0.9532 - val_loss: 1.0388 - val_accuracy: 0.5474\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1215 - accuracy: 0.9837 - val_loss: 1.1484 - val_accuracy: 0.4964\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1052 - accuracy: 0.9817 - val_loss: 1.2076 - val_accuracy: 0.5401\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0802 - accuracy: 0.9939 - val_loss: 1.2950 - val_accuracy: 0.5109\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 1.3649 - val_accuracy: 0.5036\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 1.5069 - val_accuracy: 0.5255\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 1.5393 - val_accuracy: 0.5182\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 1.5895 - val_accuracy: 0.5182\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 1.6738 - val_accuracy: 0.5182\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.7047 - val_accuracy: 0.5109\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.7568 - val_accuracy: 0.5109\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.8245 - val_accuracy: 0.5255\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.8668 - val_accuracy: 0.4964\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.9040 - val_accuracy: 0.5182\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.9275 - val_accuracy: 0.5109\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.9720 - val_accuracy: 0.5036\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.0051 - val_accuracy: 0.5109\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.0296 - val_accuracy: 0.5109\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.0689 - val_accuracy: 0.5036\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.1011 - val_accuracy: 0.5109\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1370 - val_accuracy: 0.4964\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.1693 - val_accuracy: 0.4964\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1784 - val_accuracy: 0.5182\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.2234 - val_accuracy: 0.5036\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.2337 - val_accuracy: 0.5109\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.2549 - val_accuracy: 0.5109\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.2826 - val_accuracy: 0.5109\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.3063 - val_accuracy: 0.5036\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.3240 - val_accuracy: 0.5036\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.3469 - val_accuracy: 0.5109\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.3691 - val_accuracy: 0.5109\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.3915 - val_accuracy: 0.5182\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.4156 - val_accuracy: 0.5182\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.4347 - val_accuracy: 0.5182\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.9093e-04 - accuracy: 1.0000 - val_loss: 2.4608 - val_accuracy: 0.5182\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.4327e-04 - accuracy: 1.0000 - val_loss: 2.4787 - val_accuracy: 0.5182\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.6988e-04 - accuracy: 1.0000 - val_loss: 2.4996 - val_accuracy: 0.5109\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.1516e-04 - accuracy: 1.0000 - val_loss: 2.5162 - val_accuracy: 0.5109\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.6318e-04 - accuracy: 1.0000 - val_loss: 2.5369 - val_accuracy: 0.5109\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.2213e-04 - accuracy: 1.0000 - val_loss: 2.5485 - val_accuracy: 0.5109\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.7764e-04 - accuracy: 1.0000 - val_loss: 2.5649 - val_accuracy: 0.5109\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.3961e-04 - accuracy: 1.0000 - val_loss: 2.5862 - val_accuracy: 0.5109\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.1012e-04 - accuracy: 1.0000 - val_loss: 2.6050 - val_accuracy: 0.5182\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.7523e-04 - accuracy: 1.0000 - val_loss: 2.6169 - val_accuracy: 0.5109\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.4586e-04 - accuracy: 1.0000 - val_loss: 2.6349 - val_accuracy: 0.5109\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.1597e-04 - accuracy: 1.0000 - val_loss: 2.6540 - val_accuracy: 0.5109\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.8695e-04 - accuracy: 1.0000 - val_loss: 2.6645 - val_accuracy: 0.5109\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.6189e-04 - accuracy: 1.0000 - val_loss: 2.6813 - val_accuracy: 0.5255\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4461e-04 - accuracy: 1.0000 - val_loss: 2.7014 - val_accuracy: 0.5182\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.2008e-04 - accuracy: 1.0000 - val_loss: 2.7112 - val_accuracy: 0.5182\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.9615e-04 - accuracy: 1.0000 - val_loss: 2.7299 - val_accuracy: 0.5255\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.7921e-04 - accuracy: 1.0000 - val_loss: 2.7425 - val_accuracy: 0.5255\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.6081e-04 - accuracy: 1.0000 - val_loss: 2.7596 - val_accuracy: 0.5255\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.4074e-04 - accuracy: 1.0000 - val_loss: 2.7778 - val_accuracy: 0.5182\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.2660e-04 - accuracy: 1.0000 - val_loss: 2.7905 - val_accuracy: 0.5255\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.1143e-04 - accuracy: 1.0000 - val_loss: 2.8037 - val_accuracy: 0.5182\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.0205e-04 - accuracy: 1.0000 - val_loss: 2.8157 - val_accuracy: 0.5255\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.8679e-04 - accuracy: 1.0000 - val_loss: 2.8309 - val_accuracy: 0.5182\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.7288e-04 - accuracy: 1.0000 - val_loss: 2.8416 - val_accuracy: 0.5182\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.6267e-04 - accuracy: 1.0000 - val_loss: 2.8541 - val_accuracy: 0.5109\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.5007e-04 - accuracy: 1.0000 - val_loss: 2.8680 - val_accuracy: 0.5182\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.3943e-04 - accuracy: 1.0000 - val_loss: 2.8810 - val_accuracy: 0.5182\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.3145e-04 - accuracy: 1.0000 - val_loss: 2.8932 - val_accuracy: 0.5182\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.2317e-04 - accuracy: 1.0000 - val_loss: 2.9029 - val_accuracy: 0.5255\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.1477e-04 - accuracy: 1.0000 - val_loss: 2.9165 - val_accuracy: 0.5255\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0496e-04 - accuracy: 1.0000 - val_loss: 2.9277 - val_accuracy: 0.5255\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.9713e-04 - accuracy: 1.0000 - val_loss: 2.9416 - val_accuracy: 0.5255\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8949e-04 - accuracy: 1.0000 - val_loss: 2.9524 - val_accuracy: 0.5255\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8080e-04 - accuracy: 1.0000 - val_loss: 2.9643 - val_accuracy: 0.5255\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.7435e-04 - accuracy: 1.0000 - val_loss: 2.9783 - val_accuracy: 0.5255\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.6836e-04 - accuracy: 1.0000 - val_loss: 2.9904 - val_accuracy: 0.5255\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.6220e-04 - accuracy: 1.0000 - val_loss: 3.0027 - val_accuracy: 0.5255\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5681e-04 - accuracy: 1.0000 - val_loss: 3.0119 - val_accuracy: 0.5255\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.5094e-04 - accuracy: 1.0000 - val_loss: 3.0220 - val_accuracy: 0.5255\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4525e-04 - accuracy: 1.0000 - val_loss: 3.0342 - val_accuracy: 0.5328\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.4057e-04 - accuracy: 1.0000 - val_loss: 3.0418 - val_accuracy: 0.5255\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3582e-04 - accuracy: 1.0000 - val_loss: 3.0531 - val_accuracy: 0.5328\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.3157e-04 - accuracy: 1.0000 - val_loss: 3.0651 - val_accuracy: 0.5328\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2663e-04 - accuracy: 1.0000 - val_loss: 3.0751 - val_accuracy: 0.5328\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2225e-04 - accuracy: 1.0000 - val_loss: 3.0848 - val_accuracy: 0.5255\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.1828e-04 - accuracy: 1.0000 - val_loss: 3.0955 - val_accuracy: 0.5255\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.1468e-04 - accuracy: 1.0000 - val_loss: 3.1048 - val_accuracy: 0.5255\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.1066e-04 - accuracy: 1.0000 - val_loss: 3.1154 - val_accuracy: 0.5328\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0728e-04 - accuracy: 1.0000 - val_loss: 3.1237 - val_accuracy: 0.5328\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0410e-04 - accuracy: 1.0000 - val_loss: 3.1344 - val_accuracy: 0.5328\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.0085e-04 - accuracy: 1.0000 - val_loss: 3.1427 - val_accuracy: 0.5255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15b19dd90>"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_3_4 = Sequential()\n",
    "model_0_3_4.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features)))\n",
    "model_0_3_4.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_0_3_4.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_0_3_4.add(MaxPooling1D(pool_size=2)) \n",
    "model_0_3_4.add(Conv1D(filters=32, kernel_size=1, activation='relu')) \n",
    "model_0_3_4.add(Flatten())\n",
    "model_0_3_4.add(Dense(50, activation='relu')) \n",
    "model_0_3_4.add(Dense(1, activation='sigmoid')) \n",
    "model_0_3_4.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_0_3_4.fit(train_X_0_3,train_f0t_tc,epochs=100,  validation_data=(val_X_0_3, val_f0t_tc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd18708c",
   "metadata": {},
   "source": [
    "Generally the data from Model_0_3 has been the best. Keeping High NaN variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354fc2b0",
   "metadata": {},
   "source": [
    "## Modeling with Ford_1, high NaN Vairables Removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "24d92000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Features     Score\n",
      "51     Wiki_Disparity_Move  8.520859\n",
      "52   Wiki_Disparity_s_Move  4.667946\n",
      "47               Wiki_Move  3.661746\n",
      "10               Dividends  2.140155\n",
      "120               Dow_Rocp  1.922620\n",
      "124          Dow_MAvg_Move  1.807208\n",
      "41        Wiki_Disparity_s  1.668192\n",
      "48          Wiki_MAvg_Move  1.587642\n",
      "104               Nas_Move  1.314520\n",
      "69         Google_EMA_Move  1.314435\n",
      "4               Ford Stock  1.263268\n",
      "117        Dow_Disparity_s  1.176291\n",
      "75        Stock_Moment_2_s  1.080846\n",
      "53         Google_Moment_1  1.070130\n",
      "61              Google_ROC  1.070130\n",
      "109   Nas_Disparity_s_Move  1.052392\n",
      "35           Wiki_Moment_2  1.020869\n",
      "3           Ford Mustang_x  0.942637\n",
      "73          Stock_Moment_2  0.923135\n",
      "54         Google_Moment_2  0.913539\n",
      "98         Nas_Disparity_s  0.905635\n",
      "63             Google_Rocp  0.904094\n",
      "15           Ford Bronco_y  0.891439\n",
      "82              Stock_Rocp  0.878127\n",
      "46               Wiki_diff  0.839884\n",
      "7                      Low  0.819942\n",
      "8                    Close  0.815244\n",
      "31             Stock_total  0.815244\n",
      "6                     High  0.809481\n",
      "116          Dow_Disparity  0.778133\n",
      "1                    F-150  0.764257\n",
      "88          Stock_EMA_Move  0.764071\n",
      "105          Nas_MAvg_Move  0.755661\n",
      "9                   Volume  0.752727\n",
      "77            Stock_MAvg_s  0.750561\n",
      "5                     Open  0.738885\n",
      "80               Stock_ROC  0.705679\n",
      "72          Stock_Moment_1  0.705679\n",
      "76              Stock_MAvg  0.699737\n",
      "83               Stock_EMA  0.681845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "# apply SelectKBest class to extract top 40 best features\n",
    "bestfeatures = SelectKBest(score_func=f_regression, k=40)\n",
    "best_fit = bestfeatures.fit(train_f1, train_f1t)\n",
    "best_scores = pd.DataFrame(best_fit.scores_)\n",
    "best_columns = pd.DataFrame(Ford_1.columns)\n",
    "\n",
    "# concatenate the dataframes for better visualization\n",
    "features_score = pd.concat([best_columns, best_scores], axis=1)\n",
    "features_score.columns = ['Features', 'Score']  # naming the dataframe columns\n",
    "print(features_score.nlargest(40, 'Score'))  # print the top 40 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "683d2281",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_1 = list(features_score.nlargest(40, 'Score')['Features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "048d7967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 16.98316578,  27.34516601,  36.70636765,  45.24164289,\n",
       "        52.98779207,  58.58736929,  62.65046152,  65.98630289,\n",
       "        69.00818095,  71.88462111,  74.30738492,  76.60388819,\n",
       "        78.32273091,  79.9721231 ,  81.42187884,  82.70002996,\n",
       "        83.92393946,  85.05094905,  86.12073991,  87.09685162,\n",
       "        88.03650244,  88.86005707,  89.66252715,  90.40823802,\n",
       "        91.07053522,  91.72757079,  92.35530657,  92.93604888,\n",
       "        93.50975167,  94.03841633,  94.51725671,  94.97270045,\n",
       "        95.41110121,  95.83705963,  96.23255204,  96.59667955,\n",
       "        96.90883224,  97.1921651 ,  97.4572665 ,  97.69354652,\n",
       "        97.91995976,  98.11848802,  98.31219318,  98.49686805,\n",
       "        98.66770333,  98.80566854,  98.93588768,  99.05649548,\n",
       "        99.15845596,  99.23906433,  99.31004431,  99.37373898,\n",
       "        99.43236925,  99.48218315,  99.5287526 ,  99.57210852,\n",
       "        99.61519771,  99.64945729,  99.67893466,  99.70614872,\n",
       "        99.7297222 ,  99.75282075,  99.77429121,  99.79276735,\n",
       "        99.81086682,  99.82859354,  99.84573123,  99.86136484,\n",
       "        99.8762125 ,  99.89024442,  99.90385013,  99.91669627,\n",
       "        99.92861041,  99.93931094,  99.94871753,  99.95540807,\n",
       "        99.96139753,  99.96693087,  99.97185998,  99.97610807,\n",
       "        99.97964956,  99.98254297,  99.98480729,  99.98673238,\n",
       "        99.98854193,  99.99012853,  99.9916836 ,  99.99308491,\n",
       "        99.99399188,  99.99483913,  99.99545786,  99.99606967,\n",
       "        99.99662533,  99.99712888,  99.99762604,  99.99807555,\n",
       "        99.99850341,  99.99879366,  99.9990365 ,  99.99923519,\n",
       "        99.9994001 ,  99.99952558,  99.99961632,  99.9997023 ,\n",
       "        99.99977828,  99.99984011,  99.9998914 ,  99.99993112,\n",
       "        99.99995247,  99.99997062,  99.99998825,  99.99999457,\n",
       "        99.9999986 , 100.        , 100.        , 100.        ,\n",
       "       100.        , 100.        , 100.        , 100.        ,\n",
       "       100.        , 100.        , 100.        , 100.        ,\n",
       "       100.        , 100.        , 100.        , 100.        ,\n",
       "       100.        , 100.        ])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA \n",
    "pca = PCA().fit(train_f1)\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') # for each component\n",
    "plt.show()\n",
    "np.cumsum(pca.explained_variance_ratio_) * 100\n",
    "# reach 85% variance explained with 18 principle components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "e186f113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 20.24212885,  38.02617731,  50.44856687,  61.13988758,\n",
       "        69.92592078,  77.79039734,  84.17845677,  87.15725677,\n",
       "        89.78415452,  92.07319006,  93.87212393,  94.99799805,\n",
       "        96.05968155,  96.91522444,  97.72541737,  98.45547762,\n",
       "        98.79644648,  99.07616783,  99.31039486,  99.45970401,\n",
       "        99.59219281,  99.66594409,  99.72615157,  99.78073907,\n",
       "        99.83190133,  99.87760143,  99.91403726,  99.93814699,\n",
       "        99.9604413 ,  99.97672229,  99.98891876,  99.99416623,\n",
       "        99.99669772,  99.99818394,  99.99899062,  99.99957681,\n",
       "       100.        , 100.        , 100.        , 100.        ])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PCA with 40 best components\n",
    "pca_1 = PCA().fit(train_f1[feats_1])\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca_1.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') # for each component\n",
    "plt.show()\n",
    "np.cumsum(pca_1.explained_variance_ratio_) * 100\n",
    "# can use 7 principle compents now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338b2cc0",
   "metadata": {},
   "source": [
    "Keeping score: Will test 4 models with Ford_1 data variations,\n",
    "- Model_1_0 = All varaibles,\n",
    "- Model_1_1 = PCA All varaibles\n",
    "- Model_1_2 = 40 best k score\n",
    "- Model_1_3 = PCA of 40 Best K Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f78ca9",
   "metadata": {},
   "source": [
    "### Model_1_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "6208918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_1_0 final data prep\n",
    "\n",
    "# converting to window format, in this case 5 periods\n",
    "train_X_1_0, train_f1t_tc = df_to_X_y2(train_f1,train_f1t)\n",
    "val_X_1_0, val_f1t_tc= df_to_X_y2(val_f1, val_f1t)\n",
    "test_X_1_0, test_f1t_tc = df_to_X_y2(test_f1,test_f1t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "ebf33260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 14ms/step - loss: 0.6948 - accuracy: 0.5113 - val_loss: 0.6949 - val_accuracy: 0.5101\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6921 - accuracy: 0.5376 - val_loss: 0.6956 - val_accuracy: 0.5101\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6914 - accuracy: 0.5338 - val_loss: 0.6940 - val_accuracy: 0.5235\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6887 - accuracy: 0.5376 - val_loss: 0.6976 - val_accuracy: 0.4966\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6867 - accuracy: 0.5583 - val_loss: 0.6972 - val_accuracy: 0.4832\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6850 - accuracy: 0.5620 - val_loss: 0.6983 - val_accuracy: 0.5101\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.5639 - val_loss: 0.7003 - val_accuracy: 0.4966\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6816 - accuracy: 0.5714 - val_loss: 0.6987 - val_accuracy: 0.4698\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6783 - accuracy: 0.5677 - val_loss: 0.7033 - val_accuracy: 0.4631\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6750 - accuracy: 0.5977 - val_loss: 0.7076 - val_accuracy: 0.4698\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.5827 - val_loss: 0.7086 - val_accuracy: 0.4698\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6693 - accuracy: 0.5846 - val_loss: 0.7101 - val_accuracy: 0.4497\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6644 - accuracy: 0.6222 - val_loss: 0.7233 - val_accuracy: 0.4564\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6607 - accuracy: 0.6241 - val_loss: 0.7206 - val_accuracy: 0.4497\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6578 - accuracy: 0.6259 - val_loss: 0.7277 - val_accuracy: 0.4631\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6585 - accuracy: 0.6147 - val_loss: 0.7245 - val_accuracy: 0.4899\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6618 - accuracy: 0.5921 - val_loss: 0.7234 - val_accuracy: 0.4430\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6500 - accuracy: 0.6447 - val_loss: 0.7356 - val_accuracy: 0.4765\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.6353 - val_loss: 0.7426 - val_accuracy: 0.4564\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6385 - accuracy: 0.6466 - val_loss: 0.7494 - val_accuracy: 0.4564\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6357 - accuracy: 0.6485 - val_loss: 0.7609 - val_accuracy: 0.4631\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6329 - accuracy: 0.6504 - val_loss: 0.7633 - val_accuracy: 0.4631\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6271 - accuracy: 0.6579 - val_loss: 0.7764 - val_accuracy: 0.4698\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6249 - accuracy: 0.6523 - val_loss: 0.7774 - val_accuracy: 0.4698\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6216 - accuracy: 0.6729 - val_loss: 0.7550 - val_accuracy: 0.4631\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6283 - accuracy: 0.6485 - val_loss: 0.7481 - val_accuracy: 0.4430\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6181 - accuracy: 0.6617 - val_loss: 0.7950 - val_accuracy: 0.4765\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6144 - accuracy: 0.6654 - val_loss: 0.8098 - val_accuracy: 0.4832\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6072 - accuracy: 0.6729 - val_loss: 0.7756 - val_accuracy: 0.4698\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6117 - accuracy: 0.6729 - val_loss: 0.7672 - val_accuracy: 0.4564\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6073 - accuracy: 0.6767 - val_loss: 0.8035 - val_accuracy: 0.4698\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6019 - accuracy: 0.6729 - val_loss: 0.7990 - val_accuracy: 0.4698\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5976 - accuracy: 0.6861 - val_loss: 0.7971 - val_accuracy: 0.4564\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5939 - accuracy: 0.6767 - val_loss: 0.8208 - val_accuracy: 0.4899\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5900 - accuracy: 0.6917 - val_loss: 0.8056 - val_accuracy: 0.4899\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5865 - accuracy: 0.6861 - val_loss: 0.8197 - val_accuracy: 0.4698\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5860 - accuracy: 0.6974 - val_loss: 0.8043 - val_accuracy: 0.4832\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5906 - accuracy: 0.7011 - val_loss: 0.8196 - val_accuracy: 0.4899\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5858 - accuracy: 0.6898 - val_loss: 0.7756 - val_accuracy: 0.5168\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5887 - accuracy: 0.6974 - val_loss: 0.8081 - val_accuracy: 0.4698\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5790 - accuracy: 0.6880 - val_loss: 0.8260 - val_accuracy: 0.4698\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5744 - accuracy: 0.7068 - val_loss: 0.8491 - val_accuracy: 0.4765\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5696 - accuracy: 0.7030 - val_loss: 0.7854 - val_accuracy: 0.4899\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5772 - accuracy: 0.6898 - val_loss: 0.8636 - val_accuracy: 0.4765\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5669 - accuracy: 0.6974 - val_loss: 0.8226 - val_accuracy: 0.4765\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5616 - accuracy: 0.7105 - val_loss: 0.8617 - val_accuracy: 0.4832\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5613 - accuracy: 0.7162 - val_loss: 0.8398 - val_accuracy: 0.4497\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5648 - accuracy: 0.7030 - val_loss: 0.7945 - val_accuracy: 0.4899\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5680 - accuracy: 0.6936 - val_loss: 0.8932 - val_accuracy: 0.4430\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5579 - accuracy: 0.7068 - val_loss: 0.8506 - val_accuracy: 0.4430\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5518 - accuracy: 0.7143 - val_loss: 0.8386 - val_accuracy: 0.4631\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5533 - accuracy: 0.7030 - val_loss: 0.8400 - val_accuracy: 0.4564\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5462 - accuracy: 0.7086 - val_loss: 0.8493 - val_accuracy: 0.4698\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.7218 - val_loss: 0.8246 - val_accuracy: 0.4564\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.7030 - val_loss: 0.9141 - val_accuracy: 0.4631\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.7237 - val_loss: 0.8796 - val_accuracy: 0.4497\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7387 - val_loss: 0.9573 - val_accuracy: 0.4497\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.7387 - val_loss: 0.8580 - val_accuracy: 0.4765\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7256 - val_loss: 0.9310 - val_accuracy: 0.4698\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5255 - accuracy: 0.7368 - val_loss: 0.8767 - val_accuracy: 0.4765\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5318 - accuracy: 0.7274 - val_loss: 0.9641 - val_accuracy: 0.4765\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7387 - val_loss: 0.9017 - val_accuracy: 0.4631\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5223 - accuracy: 0.7274 - val_loss: 0.9286 - val_accuracy: 0.4631\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7556 - val_loss: 0.9459 - val_accuracy: 0.4497\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5258 - accuracy: 0.7293 - val_loss: 0.8894 - val_accuracy: 0.4631\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5152 - accuracy: 0.7218 - val_loss: 0.9152 - val_accuracy: 0.4564\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7350 - val_loss: 0.9868 - val_accuracy: 0.4698\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7462 - val_loss: 0.9496 - val_accuracy: 0.4631\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7425 - val_loss: 1.0158 - val_accuracy: 0.4832\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7538 - val_loss: 1.0002 - val_accuracy: 0.4631\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5010 - accuracy: 0.7594 - val_loss: 1.0483 - val_accuracy: 0.4832\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4946 - accuracy: 0.7726 - val_loss: 1.0243 - val_accuracy: 0.4564\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7575 - val_loss: 0.9777 - val_accuracy: 0.4564\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.7650 - val_loss: 1.0462 - val_accuracy: 0.4899\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4913 - accuracy: 0.7632 - val_loss: 1.0430 - val_accuracy: 0.4966\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4868 - accuracy: 0.7707 - val_loss: 1.1249 - val_accuracy: 0.4698\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7613 - val_loss: 1.0648 - val_accuracy: 0.4765\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7538 - val_loss: 1.0227 - val_accuracy: 0.4832\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7707 - val_loss: 1.0396 - val_accuracy: 0.4765\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7594 - val_loss: 1.0394 - val_accuracy: 0.4832\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7707 - val_loss: 1.0560 - val_accuracy: 0.4631\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7669 - val_loss: 1.0757 - val_accuracy: 0.4966\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7726 - val_loss: 1.1313 - val_accuracy: 0.4698\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7744 - val_loss: 1.0763 - val_accuracy: 0.4899\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7782 - val_loss: 1.1428 - val_accuracy: 0.4832\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7838 - val_loss: 1.1823 - val_accuracy: 0.4832\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7688 - val_loss: 1.2113 - val_accuracy: 0.4832\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4693 - accuracy: 0.7594 - val_loss: 1.1670 - val_accuracy: 0.4899\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7763 - val_loss: 1.1054 - val_accuracy: 0.4899\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.4582 - accuracy: 0.7895 - val_loss: 1.0864 - val_accuracy: 0.5101\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4515 - accuracy: 0.7876 - val_loss: 1.1583 - val_accuracy: 0.4899\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7932 - val_loss: 1.1425 - val_accuracy: 0.4966\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7876 - val_loss: 1.2767 - val_accuracy: 0.4765\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.7838 - val_loss: 1.1948 - val_accuracy: 0.4564\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.8045 - val_loss: 1.2475 - val_accuracy: 0.4832\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7914 - val_loss: 1.2232 - val_accuracy: 0.4631\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7989 - val_loss: 1.2100 - val_accuracy: 0.4698\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.8064 - val_loss: 1.1866 - val_accuracy: 0.4698\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7744 - val_loss: 1.3056 - val_accuracy: 0.4765\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7876 - val_loss: 1.3003 - val_accuracy: 0.4765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15b4089d0>"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = train_X_1_0.shape[1]\n",
    "n_features = train_X_1_0.shape[2]\n",
    "\n",
    "model_1_0_1 = Sequential()\n",
    "model_1_0_1.add(Conv1D(filters=5, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model_1_0_1.add(MaxPooling1D(pool_size=2)) \n",
    "model_1_0_1.add(Flatten())\n",
    "model_1_0_1.add(Dense(50, activation='relu')) \n",
    "model_1_0_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_1_0_1.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_1_0_1.fit(train_X_1_0, train_f1t_tc,epochs=100,  validation_data=(val_X_1_0, val_f1t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "26a26fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 13ms/step - loss: 0.7285 - accuracy: 0.4812 - val_loss: 0.6882 - val_accuracy: 0.5638\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6945 - accuracy: 0.5282 - val_loss: 0.6959 - val_accuracy: 0.4966\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6829 - accuracy: 0.5620 - val_loss: 0.6924 - val_accuracy: 0.4899\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6737 - accuracy: 0.6165 - val_loss: 0.6933 - val_accuracy: 0.5168\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6751 - accuracy: 0.5846 - val_loss: 0.7414 - val_accuracy: 0.4966\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6652 - accuracy: 0.5771 - val_loss: 0.6950 - val_accuracy: 0.5168\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6447 - accuracy: 0.6936 - val_loss: 0.7239 - val_accuracy: 0.4631\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.7143 - val_loss: 0.7548 - val_accuracy: 0.4698\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6136 - accuracy: 0.7199 - val_loss: 0.7495 - val_accuracy: 0.4497\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6030 - accuracy: 0.6861 - val_loss: 0.7900 - val_accuracy: 0.4564\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5805 - accuracy: 0.7293 - val_loss: 0.7563 - val_accuracy: 0.4295\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5608 - accuracy: 0.7444 - val_loss: 0.7794 - val_accuracy: 0.4295\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.7914 - val_loss: 0.8026 - val_accuracy: 0.4631\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.7744 - val_loss: 0.8683 - val_accuracy: 0.4564\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5002 - accuracy: 0.7707 - val_loss: 0.9823 - val_accuracy: 0.4765\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.8008 - val_loss: 0.8515 - val_accuracy: 0.4497\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.8271 - val_loss: 0.8715 - val_accuracy: 0.4497\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7876 - val_loss: 1.2373 - val_accuracy: 0.4899\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.8177 - val_loss: 0.9166 - val_accuracy: 0.4497\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3816 - accuracy: 0.8553 - val_loss: 1.2421 - val_accuracy: 0.4765\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3883 - accuracy: 0.8402 - val_loss: 0.9164 - val_accuracy: 0.4228\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3640 - accuracy: 0.8590 - val_loss: 1.1862 - val_accuracy: 0.4631\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3181 - accuracy: 0.9060 - val_loss: 1.0840 - val_accuracy: 0.4497\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2903 - accuracy: 0.9192 - val_loss: 1.0771 - val_accuracy: 0.4564\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3184 - accuracy: 0.8741 - val_loss: 1.3404 - val_accuracy: 0.4698\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2685 - accuracy: 0.9229 - val_loss: 1.1697 - val_accuracy: 0.4497\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2840 - accuracy: 0.8910 - val_loss: 1.3157 - val_accuracy: 0.4698\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2560 - accuracy: 0.9173 - val_loss: 1.1880 - val_accuracy: 0.4430\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2379 - accuracy: 0.9192 - val_loss: 1.3231 - val_accuracy: 0.4430\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2126 - accuracy: 0.9511 - val_loss: 1.5784 - val_accuracy: 0.4631\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2086 - accuracy: 0.9380 - val_loss: 1.3385 - val_accuracy: 0.4564\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1758 - accuracy: 0.9643 - val_loss: 1.7101 - val_accuracy: 0.4698\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1581 - accuracy: 0.9718 - val_loss: 1.4929 - val_accuracy: 0.4698\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1379 - accuracy: 0.9756 - val_loss: 1.8592 - val_accuracy: 0.4698\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1317 - accuracy: 0.9868 - val_loss: 2.2213 - val_accuracy: 0.4564\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1521 - accuracy: 0.9680 - val_loss: 1.8461 - val_accuracy: 0.4765\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1197 - accuracy: 0.9774 - val_loss: 2.0251 - val_accuracy: 0.4765\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1063 - accuracy: 0.9868 - val_loss: 1.8683 - val_accuracy: 0.4832\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1099 - accuracy: 0.9831 - val_loss: 2.0590 - val_accuracy: 0.4765\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0923 - accuracy: 0.9887 - val_loss: 2.2283 - val_accuracy: 0.4832\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0827 - accuracy: 0.9925 - val_loss: 2.5691 - val_accuracy: 0.4832\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1125 - accuracy: 0.9718 - val_loss: 2.7958 - val_accuracy: 0.4966\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0989 - accuracy: 0.9850 - val_loss: 2.3539 - val_accuracy: 0.4698\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1029 - accuracy: 0.9756 - val_loss: 1.9805 - val_accuracy: 0.4765\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0851 - accuracy: 0.9831 - val_loss: 2.0582 - val_accuracy: 0.4564\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.9944 - val_loss: 2.4128 - val_accuracy: 0.4832\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 0.9944 - val_loss: 2.7651 - val_accuracy: 0.4899\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0530 - accuracy: 0.9944 - val_loss: 2.4437 - val_accuracy: 0.4966\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0464 - accuracy: 0.9981 - val_loss: 2.5781 - val_accuracy: 0.4765\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 0.9962 - val_loss: 2.4639 - val_accuracy: 0.4832\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 0.9944 - val_loss: 2.9189 - val_accuracy: 0.4698\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0364 - accuracy: 0.9981 - val_loss: 2.7483 - val_accuracy: 0.4698\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0334 - accuracy: 0.9981 - val_loss: 2.6682 - val_accuracy: 0.4966\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 0.9981 - val_loss: 2.8810 - val_accuracy: 0.4765\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.9981 - val_loss: 2.8083 - val_accuracy: 0.4832\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0379 - accuracy: 0.9962 - val_loss: 2.9046 - val_accuracy: 0.5034\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0284 - accuracy: 0.9981 - val_loss: 2.7716 - val_accuracy: 0.4899\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9981 - val_loss: 2.8650 - val_accuracy: 0.4899\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 0.9962 - val_loss: 3.4822 - val_accuracy: 0.4832\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 0.9981 - val_loss: 3.0266 - val_accuracy: 0.4899\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 3.1462 - val_accuracy: 0.4698\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 3.2482 - val_accuracy: 0.4832\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 3.2521 - val_accuracy: 0.4832\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 3.1385 - val_accuracy: 0.4899\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 3.3654 - val_accuracy: 0.4899\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.9852 - val_accuracy: 0.4832\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 3.5381 - val_accuracy: 0.4899\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 3.0126 - val_accuracy: 0.4966\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 3.3949 - val_accuracy: 0.4899\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 3.2137 - val_accuracy: 0.4899\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 3.6538 - val_accuracy: 0.4899\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 3.3412 - val_accuracy: 0.5034\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 3.2189 - val_accuracy: 0.4899\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 3.9025 - val_accuracy: 0.4899\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 3.7554 - val_accuracy: 0.4966\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 3.6408 - val_accuracy: 0.4899\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 3.7166 - val_accuracy: 0.4966\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 3.6249 - val_accuracy: 0.4832\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 3.8541 - val_accuracy: 0.4966\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 3.7675 - val_accuracy: 0.4899\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 3.8366 - val_accuracy: 0.4966\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 3.8576 - val_accuracy: 0.4966\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 4.1817 - val_accuracy: 0.4966\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 4.2715 - val_accuracy: 0.4966\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 3.8272 - val_accuracy: 0.4899\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 4.1787 - val_accuracy: 0.4966\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 4.0693 - val_accuracy: 0.5034\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 4.1413 - val_accuracy: 0.4966\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 3.8639 - val_accuracy: 0.4832\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 3.9760 - val_accuracy: 0.4899\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 4.2170 - val_accuracy: 0.4966\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 4.1350 - val_accuracy: 0.4899\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 3.9233 - val_accuracy: 0.4899\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.0529 - val_accuracy: 0.4966\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 4.3420 - val_accuracy: 0.4966\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 4.1772 - val_accuracy: 0.4899\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 4.1364 - val_accuracy: 0.4966\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 4.1294 - val_accuracy: 0.4966\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.3907 - val_accuracy: 0.4966\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.5527 - val_accuracy: 0.5034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15b584850>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_0_2 = Sequential()\n",
    "model_1_0_2.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model_1_0_2.add(MaxPooling1D(pool_size=2)) \n",
    "model_1_0_2.add(Flatten())\n",
    "model_1_0_2.add(Dense(50, activation='relu')) \n",
    "model_1_0_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_1_0_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_1_0_2.fit(train_X_1_0,train_f1t_tc,epochs=100,  validation_data=(val_X_1_0, val_f1t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "15ce139a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 16ms/step - loss: 0.6965 - accuracy: 0.5132 - val_loss: 0.7026 - val_accuracy: 0.5168\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.6938 - accuracy: 0.5038 - val_loss: 0.6958 - val_accuracy: 0.4765\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6830 - accuracy: 0.5789 - val_loss: 0.7035 - val_accuracy: 0.4765\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6778 - accuracy: 0.5752 - val_loss: 0.7042 - val_accuracy: 0.4295\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6655 - accuracy: 0.6034 - val_loss: 0.7187 - val_accuracy: 0.4966\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6803 - accuracy: 0.5526 - val_loss: 0.7076 - val_accuracy: 0.4765\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6603 - accuracy: 0.6316 - val_loss: 0.7072 - val_accuracy: 0.4631\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6413 - accuracy: 0.6523 - val_loss: 0.7202 - val_accuracy: 0.4497\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6297 - accuracy: 0.6635 - val_loss: 0.7350 - val_accuracy: 0.4631\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6088 - accuracy: 0.6898 - val_loss: 0.8143 - val_accuracy: 0.4966\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6026 - accuracy: 0.6936 - val_loss: 0.8668 - val_accuracy: 0.4832\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5709 - accuracy: 0.7256 - val_loss: 0.7947 - val_accuracy: 0.4698\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5602 - accuracy: 0.7575 - val_loss: 0.9369 - val_accuracy: 0.4966\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5454 - accuracy: 0.7350 - val_loss: 0.8900 - val_accuracy: 0.4631\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5056 - accuracy: 0.7669 - val_loss: 0.8884 - val_accuracy: 0.4631\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7895 - val_loss: 0.9993 - val_accuracy: 0.4832\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.8383 - val_loss: 0.8987 - val_accuracy: 0.4362\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.8158 - val_loss: 1.1839 - val_accuracy: 0.4765\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.8045 - val_loss: 0.9922 - val_accuracy: 0.4765\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.8139 - val_loss: 0.9313 - val_accuracy: 0.4765\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.8026 - val_loss: 1.0096 - val_accuracy: 0.4765\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3697 - accuracy: 0.8665 - val_loss: 1.0510 - val_accuracy: 0.4430\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3258 - accuracy: 0.8778 - val_loss: 1.1077 - val_accuracy: 0.4698\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3087 - accuracy: 0.8947 - val_loss: 1.3238 - val_accuracy: 0.4698\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2975 - accuracy: 0.9004 - val_loss: 1.0837 - val_accuracy: 0.4899\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2787 - accuracy: 0.9098 - val_loss: 1.2087 - val_accuracy: 0.4631\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2422 - accuracy: 0.9342 - val_loss: 1.1949 - val_accuracy: 0.4899\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2195 - accuracy: 0.9436 - val_loss: 1.3643 - val_accuracy: 0.4698\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2017 - accuracy: 0.9492 - val_loss: 1.2264 - val_accuracy: 0.4295\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1828 - accuracy: 0.9455 - val_loss: 1.3386 - val_accuracy: 0.4765\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1739 - accuracy: 0.9530 - val_loss: 1.3143 - val_accuracy: 0.4564\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1344 - accuracy: 0.9831 - val_loss: 1.6276 - val_accuracy: 0.4631\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1253 - accuracy: 0.9850 - val_loss: 1.5783 - val_accuracy: 0.4631\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1309 - accuracy: 0.9831 - val_loss: 1.9275 - val_accuracy: 0.4631\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1182 - accuracy: 0.9756 - val_loss: 1.6816 - val_accuracy: 0.4698\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1206 - accuracy: 0.9774 - val_loss: 1.5283 - val_accuracy: 0.4966\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1013 - accuracy: 0.9812 - val_loss: 2.0393 - val_accuracy: 0.4698\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0861 - accuracy: 0.9887 - val_loss: 1.7246 - val_accuracy: 0.4698\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 1.8911 - val_accuracy: 0.4765\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 1.0000 - val_loss: 1.9085 - val_accuracy: 0.4765\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 2.0616 - val_accuracy: 0.4765\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 1.9377 - val_accuracy: 0.4899\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 1.9161 - val_accuracy: 0.4564\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 2.1510 - val_accuracy: 0.4765\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 2.2755 - val_accuracy: 0.4564\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0299 - accuracy: 0.9981 - val_loss: 1.9913 - val_accuracy: 0.4497\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 2.2662 - val_accuracy: 0.4698\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 2.2856 - val_accuracy: 0.4899\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 2.3921 - val_accuracy: 0.4832\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 2.1884 - val_accuracy: 0.4765\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 2.4537 - val_accuracy: 0.4966\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 2.5421 - val_accuracy: 0.5034\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.4346 - val_accuracy: 0.5034\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 2.5426 - val_accuracy: 0.4899\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 2.5906 - val_accuracy: 0.4832\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 2.5609 - val_accuracy: 0.4832\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.6999 - val_accuracy: 0.4765\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.6080 - val_accuracy: 0.4832\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.6376 - val_accuracy: 0.4832\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 2.6653 - val_accuracy: 0.4765\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.7037 - val_accuracy: 0.4832\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.7961 - val_accuracy: 0.4832\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.7200 - val_accuracy: 0.4765\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.6740 - val_accuracy: 0.4631\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.7431 - val_accuracy: 0.4631\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.9374 - val_accuracy: 0.4832\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 3.0024 - val_accuracy: 0.4899\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.8631 - val_accuracy: 0.4698\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.9053 - val_accuracy: 0.4832\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.9319 - val_accuracy: 0.4832\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.9833 - val_accuracy: 0.4832\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 3.0069 - val_accuracy: 0.4832\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 3.0823 - val_accuracy: 0.4832\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.0923 - val_accuracy: 0.4765\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 3.1091 - val_accuracy: 0.4765\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.0948 - val_accuracy: 0.4832\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.0643 - val_accuracy: 0.4832\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.2050 - val_accuracy: 0.4765\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.2872 - val_accuracy: 0.4832\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.2357 - val_accuracy: 0.4832\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.2875 - val_accuracy: 0.4832\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.3132 - val_accuracy: 0.4832\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.2394 - val_accuracy: 0.4765\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.2882 - val_accuracy: 0.4832\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.3382 - val_accuracy: 0.4765\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.3843 - val_accuracy: 0.4832\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.3896 - val_accuracy: 0.4832\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.3354 - val_accuracy: 0.4832\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.4104 - val_accuracy: 0.4698\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.3279 - val_accuracy: 0.4698\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.3089 - val_accuracy: 0.4698\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.3623 - val_accuracy: 0.4765\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.4934 - val_accuracy: 0.4765\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.4745 - val_accuracy: 0.4832\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.4851 - val_accuracy: 0.4832\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.5174 - val_accuracy: 0.4765\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.5598 - val_accuracy: 0.4765\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.5442 - val_accuracy: 0.4765\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.5208 - val_accuracy: 0.4832\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.5605 - val_accuracy: 0.4765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15b6d0f70>"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_0_3 = Sequential()\n",
    "model_1_0_3.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features)))\n",
    "model_1_0_3.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_1_0_3.add(MaxPooling1D(pool_size=2)) \n",
    "model_1_0_3.add(Flatten())\n",
    "model_1_0_3.add(Dense(50, activation='relu')) \n",
    "model_1_0_3.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model_1_0_3.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_1_0_3.fit(train_X_1_0,train_f1t_tc,epochs=100,  validation_data=(val_X_1_0, val_f1t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "6e00b548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 16ms/step - loss: 0.6979 - accuracy: 0.4774 - val_loss: 0.6938 - val_accuracy: 0.4899\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6919 - accuracy: 0.5282 - val_loss: 0.6952 - val_accuracy: 0.5034\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6905 - accuracy: 0.5282 - val_loss: 0.6948 - val_accuracy: 0.5034\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6878 - accuracy: 0.5620 - val_loss: 0.6988 - val_accuracy: 0.4966\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.6824 - accuracy: 0.5789 - val_loss: 0.6975 - val_accuracy: 0.5302\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6778 - accuracy: 0.5883 - val_loss: 0.7003 - val_accuracy: 0.4966\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6604 - accuracy: 0.6504 - val_loss: 0.7439 - val_accuracy: 0.4832\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6644 - accuracy: 0.5902 - val_loss: 0.7220 - val_accuracy: 0.4765\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.6447 - val_loss: 0.7310 - val_accuracy: 0.4362\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6128 - accuracy: 0.6748 - val_loss: 0.8278 - val_accuracy: 0.4765\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5929 - accuracy: 0.6917 - val_loss: 0.8455 - val_accuracy: 0.4430\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5494 - accuracy: 0.7575 - val_loss: 0.9658 - val_accuracy: 0.4631\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5513 - accuracy: 0.7105 - val_loss: 0.7979 - val_accuracy: 0.4228\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4872 - accuracy: 0.8026 - val_loss: 0.9235 - val_accuracy: 0.4362\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.8158 - val_loss: 1.1677 - val_accuracy: 0.4765\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8346 - val_loss: 1.1123 - val_accuracy: 0.4631\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3805 - accuracy: 0.8383 - val_loss: 1.1758 - val_accuracy: 0.4564\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3294 - accuracy: 0.8797 - val_loss: 1.3246 - val_accuracy: 0.4899\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2854 - accuracy: 0.8985 - val_loss: 1.9008 - val_accuracy: 0.4966\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3658 - accuracy: 0.8365 - val_loss: 1.1598 - val_accuracy: 0.4430\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2393 - accuracy: 0.9361 - val_loss: 1.4009 - val_accuracy: 0.4430\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2040 - accuracy: 0.9380 - val_loss: 1.6329 - val_accuracy: 0.4631\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1971 - accuracy: 0.9305 - val_loss: 1.5417 - val_accuracy: 0.4430\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1733 - accuracy: 0.9455 - val_loss: 1.6120 - val_accuracy: 0.4966\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1320 - accuracy: 0.9643 - val_loss: 1.5428 - val_accuracy: 0.4832\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1070 - accuracy: 0.9850 - val_loss: 1.8338 - val_accuracy: 0.4564\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0812 - accuracy: 0.9887 - val_loss: 2.1185 - val_accuracy: 0.4698\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0533 - accuracy: 0.9962 - val_loss: 2.3736 - val_accuracy: 0.4295\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 0.9962 - val_loss: 2.2505 - val_accuracy: 0.4899\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 2.4736 - val_accuracy: 0.4832\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0265 - accuracy: 0.9981 - val_loss: 2.5504 - val_accuracy: 0.4430\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 2.8754 - val_accuracy: 0.4430\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.6017 - val_accuracy: 0.4698\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 2.9180 - val_accuracy: 0.4564\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.9440 - val_accuracy: 0.4564\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.8618 - val_accuracy: 0.4631\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 3.0827 - val_accuracy: 0.4698\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 3.1065 - val_accuracy: 0.4698\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 3.2000 - val_accuracy: 0.4698\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 3.2743 - val_accuracy: 0.4631\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 3.3428 - val_accuracy: 0.4631\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 3.2552 - val_accuracy: 0.4765\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.4221 - val_accuracy: 0.4631\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.4414 - val_accuracy: 0.4631\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.4891 - val_accuracy: 0.4631\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.5415 - val_accuracy: 0.4631\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.5695 - val_accuracy: 0.4631\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.5460 - val_accuracy: 0.4698\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.6497 - val_accuracy: 0.4698\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.6081 - val_accuracy: 0.4631\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.5708 - val_accuracy: 0.4698\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.6288 - val_accuracy: 0.4631\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.7136 - val_accuracy: 0.4631\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.7757 - val_accuracy: 0.4631\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.6752 - val_accuracy: 0.4631\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.7393 - val_accuracy: 0.4765\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.8051 - val_accuracy: 0.4698\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.8807 - val_accuracy: 0.4698\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.8766 - val_accuracy: 0.4631\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.8721 - val_accuracy: 0.4765\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.9152 - val_accuracy: 0.4631\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.9321 - val_accuracy: 0.4631\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.6233e-04 - accuracy: 1.0000 - val_loss: 3.9801 - val_accuracy: 0.4631\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.1258e-04 - accuracy: 1.0000 - val_loss: 3.9635 - val_accuracy: 0.4631\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.7432e-04 - accuracy: 1.0000 - val_loss: 4.0003 - val_accuracy: 0.4631\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.4289e-04 - accuracy: 1.0000 - val_loss: 4.0319 - val_accuracy: 0.4631\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 8.0585e-04 - accuracy: 1.0000 - val_loss: 4.0213 - val_accuracy: 0.4698\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 7.7133e-04 - accuracy: 1.0000 - val_loss: 4.1258 - val_accuracy: 0.4698\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.4621e-04 - accuracy: 1.0000 - val_loss: 4.0755 - val_accuracy: 0.4631\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.1897e-04 - accuracy: 1.0000 - val_loss: 4.0807 - val_accuracy: 0.4698\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 6.9483e-04 - accuracy: 1.0000 - val_loss: 4.1424 - val_accuracy: 0.4631\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.5781e-04 - accuracy: 1.0000 - val_loss: 4.1414 - val_accuracy: 0.4698\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.3506e-04 - accuracy: 1.0000 - val_loss: 4.1359 - val_accuracy: 0.4698\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 6.1789e-04 - accuracy: 1.0000 - val_loss: 4.2034 - val_accuracy: 0.4631\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 6.0034e-04 - accuracy: 1.0000 - val_loss: 4.2108 - val_accuracy: 0.4631\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.7179e-04 - accuracy: 1.0000 - val_loss: 4.2559 - val_accuracy: 0.4631\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.5795e-04 - accuracy: 1.0000 - val_loss: 4.2160 - val_accuracy: 0.4698\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.3103e-04 - accuracy: 1.0000 - val_loss: 4.2862 - val_accuracy: 0.4631\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5.1464e-04 - accuracy: 1.0000 - val_loss: 4.2611 - val_accuracy: 0.4698\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4.9947e-04 - accuracy: 1.0000 - val_loss: 4.3228 - val_accuracy: 0.4631\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4.8607e-04 - accuracy: 1.0000 - val_loss: 4.2946 - val_accuracy: 0.4698\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4.6610e-04 - accuracy: 1.0000 - val_loss: 4.3049 - val_accuracy: 0.4698\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4.5111e-04 - accuracy: 1.0000 - val_loss: 4.3626 - val_accuracy: 0.4631\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 4.3668e-04 - accuracy: 1.0000 - val_loss: 4.3393 - val_accuracy: 0.4698\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4.2063e-04 - accuracy: 1.0000 - val_loss: 4.3618 - val_accuracy: 0.4698\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4.0806e-04 - accuracy: 1.0000 - val_loss: 4.3786 - val_accuracy: 0.4698\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.9716e-04 - accuracy: 1.0000 - val_loss: 4.4006 - val_accuracy: 0.4698\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.8467e-04 - accuracy: 1.0000 - val_loss: 4.4250 - val_accuracy: 0.4631\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.7879e-04 - accuracy: 1.0000 - val_loss: 4.4056 - val_accuracy: 0.4631\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.6102e-04 - accuracy: 1.0000 - val_loss: 4.4616 - val_accuracy: 0.4631\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.5164e-04 - accuracy: 1.0000 - val_loss: 4.4513 - val_accuracy: 0.4698\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.4281e-04 - accuracy: 1.0000 - val_loss: 4.4529 - val_accuracy: 0.4631\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3.3227e-04 - accuracy: 1.0000 - val_loss: 4.5096 - val_accuracy: 0.4631\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 3.2350e-04 - accuracy: 1.0000 - val_loss: 4.4722 - val_accuracy: 0.4631\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.1728e-04 - accuracy: 1.0000 - val_loss: 4.5024 - val_accuracy: 0.4698\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.0576e-04 - accuracy: 1.0000 - val_loss: 4.5211 - val_accuracy: 0.4631\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.9781e-04 - accuracy: 1.0000 - val_loss: 4.5352 - val_accuracy: 0.4698\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.9295e-04 - accuracy: 1.0000 - val_loss: 4.5272 - val_accuracy: 0.4631\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.8285e-04 - accuracy: 1.0000 - val_loss: 4.5612 - val_accuracy: 0.4698\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.7518e-04 - accuracy: 1.0000 - val_loss: 4.5713 - val_accuracy: 0.4631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15b887220>"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_0_4 = Sequential()\n",
    "model_1_0_4.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features)))\n",
    "model_1_0_4.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_1_0_4.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_1_0_4.add(MaxPooling1D(pool_size=2)) \n",
    "model_1_0_4.add(Conv1D(filters=32, kernel_size=1, activation='relu')) \n",
    "model_1_0_4.add(Flatten())\n",
    "model_1_0_4.add(Dense(50, activation='relu')) \n",
    "model_1_0_4.add(Dense(1, activation='sigmoid')) \n",
    "model_1_0_4.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_1_0_4.fit(train_X_1_0,train_f1t_tc,epochs=100,  validation_data=(val_X_1_0, val_f1t_tc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b709fb",
   "metadata": {},
   "source": [
    "## Model_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "f969675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_0_1 final data prep \n",
    "\n",
    "# PCA with 23 components to explain 85% of variance\n",
    "sklearn_pca = PCA(n_components=18)\n",
    "train_X_1_1 = pd.DataFrame(sklearn_pca.fit_transform(train_f1))\n",
    "val_X_1_1 = pd.DataFrame(sklearn_pca.transform(val_f1))\n",
    "test_X_1_1 = pd.DataFrame(sklearn_pca.transform(test_f1))\n",
    "\n",
    "\n",
    "# converting to window format, in this case 5 periods\n",
    "train_X_1_1, _ = df_to_X_np(train_X_1_1)\n",
    "val_X_1_1, _ = df_to_X_np(val_X_1_1)\n",
    "test_X_1_1, _ = df_to_X_np(test_X_1_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "559db236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 12ms/step - loss: 0.7012 - accuracy: 0.5207 - val_loss: 0.6944 - val_accuracy: 0.5369\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6940 - accuracy: 0.5207 - val_loss: 0.6938 - val_accuracy: 0.5302\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6905 - accuracy: 0.5282 - val_loss: 0.6942 - val_accuracy: 0.5503\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6865 - accuracy: 0.5320 - val_loss: 0.6946 - val_accuracy: 0.5369\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6844 - accuracy: 0.5376 - val_loss: 0.6953 - val_accuracy: 0.5302\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6817 - accuracy: 0.5451 - val_loss: 0.6951 - val_accuracy: 0.5369\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6799 - accuracy: 0.5489 - val_loss: 0.6950 - val_accuracy: 0.5436\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6777 - accuracy: 0.5714 - val_loss: 0.6953 - val_accuracy: 0.5369\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6768 - accuracy: 0.5695 - val_loss: 0.6957 - val_accuracy: 0.5436\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6737 - accuracy: 0.5827 - val_loss: 0.6948 - val_accuracy: 0.5369\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6721 - accuracy: 0.5808 - val_loss: 0.6950 - val_accuracy: 0.5235\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6703 - accuracy: 0.5827 - val_loss: 0.6954 - val_accuracy: 0.5369\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6684 - accuracy: 0.5846 - val_loss: 0.6959 - val_accuracy: 0.5235\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6662 - accuracy: 0.5959 - val_loss: 0.6958 - val_accuracy: 0.5235\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6643 - accuracy: 0.6034 - val_loss: 0.6962 - val_accuracy: 0.5235\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6624 - accuracy: 0.6109 - val_loss: 0.6968 - val_accuracy: 0.5235\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.6259 - val_loss: 0.6969 - val_accuracy: 0.4966\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6576 - accuracy: 0.6297 - val_loss: 0.6973 - val_accuracy: 0.5101\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6553 - accuracy: 0.6278 - val_loss: 0.6985 - val_accuracy: 0.4966\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6528 - accuracy: 0.6372 - val_loss: 0.6991 - val_accuracy: 0.5101\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6503 - accuracy: 0.6654 - val_loss: 0.6997 - val_accuracy: 0.5101\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6485 - accuracy: 0.6617 - val_loss: 0.7006 - val_accuracy: 0.5101\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6450 - accuracy: 0.6729 - val_loss: 0.7016 - val_accuracy: 0.5235\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6426 - accuracy: 0.6748 - val_loss: 0.7030 - val_accuracy: 0.5101\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6393 - accuracy: 0.6767 - val_loss: 0.7034 - val_accuracy: 0.5235\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.6767 - val_loss: 0.7054 - val_accuracy: 0.5168\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6344 - accuracy: 0.6842 - val_loss: 0.7076 - val_accuracy: 0.5101\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6322 - accuracy: 0.6917 - val_loss: 0.7083 - val_accuracy: 0.5302\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6270 - accuracy: 0.6974 - val_loss: 0.7094 - val_accuracy: 0.5235\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6246 - accuracy: 0.6936 - val_loss: 0.7096 - val_accuracy: 0.5302\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6210 - accuracy: 0.6955 - val_loss: 0.7121 - val_accuracy: 0.5235\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6180 - accuracy: 0.7068 - val_loss: 0.7148 - val_accuracy: 0.5101\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6147 - accuracy: 0.7105 - val_loss: 0.7142 - val_accuracy: 0.5302\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6120 - accuracy: 0.7086 - val_loss: 0.7167 - val_accuracy: 0.5369\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.7011 - val_loss: 0.7194 - val_accuracy: 0.5302\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6049 - accuracy: 0.7162 - val_loss: 0.7207 - val_accuracy: 0.5436\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6020 - accuracy: 0.7143 - val_loss: 0.7219 - val_accuracy: 0.5369\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5984 - accuracy: 0.7274 - val_loss: 0.7254 - val_accuracy: 0.5503\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5946 - accuracy: 0.7256 - val_loss: 0.7293 - val_accuracy: 0.5570\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.7293 - val_loss: 0.7299 - val_accuracy: 0.5369\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5878 - accuracy: 0.7312 - val_loss: 0.7314 - val_accuracy: 0.5369\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5844 - accuracy: 0.7256 - val_loss: 0.7353 - val_accuracy: 0.5436\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5811 - accuracy: 0.7331 - val_loss: 0.7362 - val_accuracy: 0.5436\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5774 - accuracy: 0.7425 - val_loss: 0.7377 - val_accuracy: 0.5369\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5735 - accuracy: 0.7406 - val_loss: 0.7394 - val_accuracy: 0.5369\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5709 - accuracy: 0.7406 - val_loss: 0.7406 - val_accuracy: 0.5705\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5688 - accuracy: 0.7387 - val_loss: 0.7445 - val_accuracy: 0.5302\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5645 - accuracy: 0.7387 - val_loss: 0.7454 - val_accuracy: 0.5772\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.7425 - val_loss: 0.7500 - val_accuracy: 0.5302\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5581 - accuracy: 0.7462 - val_loss: 0.7496 - val_accuracy: 0.5570\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.7556 - val_loss: 0.7524 - val_accuracy: 0.5503\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.7500 - val_loss: 0.7534 - val_accuracy: 0.5436\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5488 - accuracy: 0.7575 - val_loss: 0.7568 - val_accuracy: 0.5772\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5458 - accuracy: 0.7556 - val_loss: 0.7584 - val_accuracy: 0.5503\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5429 - accuracy: 0.7519 - val_loss: 0.7626 - val_accuracy: 0.5302\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.7481 - val_loss: 0.7614 - val_accuracy: 0.5168\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7538 - val_loss: 0.7641 - val_accuracy: 0.5369\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7650 - val_loss: 0.7650 - val_accuracy: 0.5302\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7556 - val_loss: 0.7692 - val_accuracy: 0.5302\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5271 - accuracy: 0.7688 - val_loss: 0.7693 - val_accuracy: 0.5235\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5247 - accuracy: 0.7632 - val_loss: 0.7684 - val_accuracy: 0.5369\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5210 - accuracy: 0.7744 - val_loss: 0.7691 - val_accuracy: 0.5235\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5195 - accuracy: 0.7650 - val_loss: 0.7708 - val_accuracy: 0.5302\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.5179 - accuracy: 0.7613 - val_loss: 0.7746 - val_accuracy: 0.5369\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5130 - accuracy: 0.7726 - val_loss: 0.7742 - val_accuracy: 0.5436\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5112 - accuracy: 0.7763 - val_loss: 0.7792 - val_accuracy: 0.5235\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.7763 - val_loss: 0.7774 - val_accuracy: 0.5235\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7857 - val_loss: 0.7801 - val_accuracy: 0.5302\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.5023 - accuracy: 0.7838 - val_loss: 0.7835 - val_accuracy: 0.5436\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.5000 - accuracy: 0.7782 - val_loss: 0.7844 - val_accuracy: 0.5302\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4969 - accuracy: 0.7838 - val_loss: 0.7860 - val_accuracy: 0.5436\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.7857 - val_loss: 0.7892 - val_accuracy: 0.5235\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4926 - accuracy: 0.7914 - val_loss: 0.7929 - val_accuracy: 0.5369\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.7895 - val_loss: 0.7962 - val_accuracy: 0.5436\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.7895 - val_loss: 0.7988 - val_accuracy: 0.5235\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4836 - accuracy: 0.7932 - val_loss: 0.8011 - val_accuracy: 0.5369\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4834 - accuracy: 0.7820 - val_loss: 0.8019 - val_accuracy: 0.5302\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7914 - val_loss: 0.8005 - val_accuracy: 0.5436\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7914 - val_loss: 0.8080 - val_accuracy: 0.5436\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7989 - val_loss: 0.8087 - val_accuracy: 0.5503\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7932 - val_loss: 0.8114 - val_accuracy: 0.5369\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7951 - val_loss: 0.8169 - val_accuracy: 0.5235\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7895 - val_loss: 0.8146 - val_accuracy: 0.5503\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7989 - val_loss: 0.8204 - val_accuracy: 0.5302\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7989 - val_loss: 0.8228 - val_accuracy: 0.5302\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7951 - val_loss: 0.8222 - val_accuracy: 0.5369\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4617 - accuracy: 0.7970 - val_loss: 0.8223 - val_accuracy: 0.5302\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4567 - accuracy: 0.7951 - val_loss: 0.8287 - val_accuracy: 0.5302\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7970 - val_loss: 0.8285 - val_accuracy: 0.5369\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.8064 - val_loss: 0.8326 - val_accuracy: 0.5302\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4518 - accuracy: 0.7989 - val_loss: 0.8358 - val_accuracy: 0.5570\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.7989 - val_loss: 0.8360 - val_accuracy: 0.5503\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.8045 - val_loss: 0.8372 - val_accuracy: 0.5436\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.8045 - val_loss: 0.8404 - val_accuracy: 0.5436\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7932 - val_loss: 0.8442 - val_accuracy: 0.5369\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.8083 - val_loss: 0.8426 - val_accuracy: 0.5436\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.8102 - val_loss: 0.8476 - val_accuracy: 0.5369\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.8158 - val_loss: 0.8519 - val_accuracy: 0.5436\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.8195 - val_loss: 0.8543 - val_accuracy: 0.5369\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.8158 - val_loss: 0.8524 - val_accuracy: 0.5369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15ba3efa0>"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "n_steps = train_X_1_1.shape[1]\n",
    "n_features = train_X_1_1.shape[2]\n",
    "\n",
    "model_1_1_1 = Sequential()\n",
    "model_1_1_1.add(Conv1D(filters=5, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model_1_1_1.add(MaxPooling1D(pool_size=2)) \n",
    "model_1_1_1.add(Flatten())\n",
    "model_1_1_1.add(Dense(50, activation='relu')) \n",
    "model_1_1_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_1_1_1.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_1_1_1.fit(train_X_1_1, train_f1t_tc,epochs=100,  validation_data=(val_X_1_1, val_f1t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "6060a947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 12ms/step - loss: 0.7115 - accuracy: 0.5113 - val_loss: 0.7056 - val_accuracy: 0.4832\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6888 - accuracy: 0.5583 - val_loss: 0.6960 - val_accuracy: 0.5503\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6641 - accuracy: 0.6090 - val_loss: 0.6975 - val_accuracy: 0.5436\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6531 - accuracy: 0.6165 - val_loss: 0.7014 - val_accuracy: 0.5369\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.6767 - val_loss: 0.7053 - val_accuracy: 0.5101\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6259 - accuracy: 0.6767 - val_loss: 0.7070 - val_accuracy: 0.4966\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.7274 - val_loss: 0.7100 - val_accuracy: 0.4966\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.7632 - val_loss: 0.7146 - val_accuracy: 0.4832\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.7688 - val_loss: 0.7225 - val_accuracy: 0.4765\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5526 - accuracy: 0.7820 - val_loss: 0.7275 - val_accuracy: 0.4832\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.8102 - val_loss: 0.7358 - val_accuracy: 0.4631\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5139 - accuracy: 0.8289 - val_loss: 0.7454 - val_accuracy: 0.4497\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.8233 - val_loss: 0.7577 - val_accuracy: 0.4564\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.8440 - val_loss: 0.7692 - val_accuracy: 0.4497\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.8609 - val_loss: 0.7800 - val_accuracy: 0.4497\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.8872 - val_loss: 0.7996 - val_accuracy: 0.4899\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8966 - val_loss: 0.8109 - val_accuracy: 0.4497\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3861 - accuracy: 0.8985 - val_loss: 0.8447 - val_accuracy: 0.4698\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3658 - accuracy: 0.9060 - val_loss: 0.8526 - val_accuracy: 0.4564\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3444 - accuracy: 0.9267 - val_loss: 0.8657 - val_accuracy: 0.4698\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3196 - accuracy: 0.9342 - val_loss: 0.8977 - val_accuracy: 0.4698\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2978 - accuracy: 0.9455 - val_loss: 0.9200 - val_accuracy: 0.4698\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2845 - accuracy: 0.9530 - val_loss: 0.9452 - val_accuracy: 0.4564\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2626 - accuracy: 0.9511 - val_loss: 0.9708 - val_accuracy: 0.4497\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2410 - accuracy: 0.9737 - val_loss: 1.0187 - val_accuracy: 0.4564\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2218 - accuracy: 0.9812 - val_loss: 1.0489 - val_accuracy: 0.4497\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2049 - accuracy: 0.9756 - val_loss: 1.0751 - val_accuracy: 0.4564\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1883 - accuracy: 0.9868 - val_loss: 1.1184 - val_accuracy: 0.4564\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1742 - accuracy: 0.9831 - val_loss: 1.1525 - val_accuracy: 0.4765\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1627 - accuracy: 0.9906 - val_loss: 1.1890 - val_accuracy: 0.4698\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1460 - accuracy: 0.9868 - val_loss: 1.2233 - val_accuracy: 0.4698\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1365 - accuracy: 0.9944 - val_loss: 1.2727 - val_accuracy: 0.4698\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1255 - accuracy: 0.9925 - val_loss: 1.3212 - val_accuracy: 0.4765\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1145 - accuracy: 0.9925 - val_loss: 1.3458 - val_accuracy: 0.4631\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1039 - accuracy: 0.9981 - val_loss: 1.3680 - val_accuracy: 0.4899\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9962 - val_loss: 1.4402 - val_accuracy: 0.4765\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0887 - accuracy: 0.9981 - val_loss: 1.4666 - val_accuracy: 0.4899\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0789 - accuracy: 0.9981 - val_loss: 1.5006 - val_accuracy: 0.4765\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0747 - accuracy: 0.9981 - val_loss: 1.5318 - val_accuracy: 0.4899\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.9981 - val_loss: 1.5746 - val_accuracy: 0.4832\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9981 - val_loss: 1.6101 - val_accuracy: 0.4765\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9981 - val_loss: 1.6338 - val_accuracy: 0.4832\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0513 - accuracy: 0.9981 - val_loss: 1.6927 - val_accuracy: 0.4765\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9981 - val_loss: 1.6945 - val_accuracy: 0.4698\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 1.7477 - val_accuracy: 0.4899\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 1.7737 - val_accuracy: 0.4832\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 1.8040 - val_accuracy: 0.4899\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 1.8375 - val_accuracy: 0.4765\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 1.8729 - val_accuracy: 0.4698\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 1.9005 - val_accuracy: 0.4765\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 1.9132 - val_accuracy: 0.4765\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 1.9575 - val_accuracy: 0.4899\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 1.9866 - val_accuracy: 0.4832\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 2.0085 - val_accuracy: 0.4765\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 2.0347 - val_accuracy: 0.4966\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 2.0717 - val_accuracy: 0.4899\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 2.0932 - val_accuracy: 0.4832\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 2.1219 - val_accuracy: 0.4899\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.1354 - val_accuracy: 0.4832\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.1767 - val_accuracy: 0.4899\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.1988 - val_accuracy: 0.4899\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.2073 - val_accuracy: 0.4899\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 2.2425 - val_accuracy: 0.4899\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 2.2702 - val_accuracy: 0.4765\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 2.2926 - val_accuracy: 0.4899\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.3014 - val_accuracy: 0.4899\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.3361 - val_accuracy: 0.4899\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.3562 - val_accuracy: 0.4899\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.3747 - val_accuracy: 0.4899\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.3930 - val_accuracy: 0.4899\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.4081 - val_accuracy: 0.4899\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.4388 - val_accuracy: 0.4899\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.4570 - val_accuracy: 0.4899\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.4753 - val_accuracy: 0.4899\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.4885 - val_accuracy: 0.4899\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.5050 - val_accuracy: 0.4899\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.5399 - val_accuracy: 0.4966\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.5378 - val_accuracy: 0.4899\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.5620 - val_accuracy: 0.4966\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.5877 - val_accuracy: 0.4966\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.5918 - val_accuracy: 0.4899\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.6112 - val_accuracy: 0.4899\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.6405 - val_accuracy: 0.4966\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.6447 - val_accuracy: 0.4966\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.6687 - val_accuracy: 0.4966\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.6883 - val_accuracy: 0.4966\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.7059 - val_accuracy: 0.4966\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.7123 - val_accuracy: 0.4966\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.7314 - val_accuracy: 0.4899\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.7479 - val_accuracy: 0.4899\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.7568 - val_accuracy: 0.4899\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.7738 - val_accuracy: 0.4899\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.7922 - val_accuracy: 0.4966\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.8052 - val_accuracy: 0.4966\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.8166 - val_accuracy: 0.4966\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.8294 - val_accuracy: 0.4899\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.8497 - val_accuracy: 0.4899\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.8587 - val_accuracy: 0.4899\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.8793 - val_accuracy: 0.4966\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.8934 - val_accuracy: 0.4966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15bb32fa0>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_1_2 = Sequential()\n",
    "model_1_1_2.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model_1_1_2.add(MaxPooling1D(pool_size=2)) \n",
    "model_1_1_2.add(Flatten())\n",
    "model_1_1_2.add(Dense(50, activation='relu')) \n",
    "model_1_1_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_1_1_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_1_1_2.fit(train_X_1_1,train_f1t_tc,epochs=100,  validation_data=(val_X_1_1, val_f1t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "f28df892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 13ms/step - loss: 0.7130 - accuracy: 0.5169 - val_loss: 0.7057 - val_accuracy: 0.3960\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6826 - accuracy: 0.5658 - val_loss: 0.7037 - val_accuracy: 0.4497\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6676 - accuracy: 0.6053 - val_loss: 0.7059 - val_accuracy: 0.4765\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6559 - accuracy: 0.6673 - val_loss: 0.7078 - val_accuracy: 0.4765\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6394 - accuracy: 0.6673 - val_loss: 0.7134 - val_accuracy: 0.4631\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6200 - accuracy: 0.7331 - val_loss: 0.7223 - val_accuracy: 0.4765\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5972 - accuracy: 0.7688 - val_loss: 0.7324 - val_accuracy: 0.4295\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5686 - accuracy: 0.7895 - val_loss: 0.7497 - val_accuracy: 0.4430\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.8083 - val_loss: 0.7633 - val_accuracy: 0.4497\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.8271 - val_loss: 0.8148 - val_accuracy: 0.4430\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.8459 - val_loss: 0.8196 - val_accuracy: 0.4497\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8741 - val_loss: 0.8475 - val_accuracy: 0.4295\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3911 - accuracy: 0.8665 - val_loss: 0.8872 - val_accuracy: 0.4497\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3517 - accuracy: 0.8985 - val_loss: 0.9165 - val_accuracy: 0.4430\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3158 - accuracy: 0.9023 - val_loss: 0.9582 - val_accuracy: 0.4295\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2802 - accuracy: 0.9192 - val_loss: 1.0283 - val_accuracy: 0.4430\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2408 - accuracy: 0.9492 - val_loss: 1.0512 - val_accuracy: 0.4430\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2056 - accuracy: 0.9511 - val_loss: 1.1091 - val_accuracy: 0.4295\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1804 - accuracy: 0.9699 - val_loss: 1.2305 - val_accuracy: 0.4430\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1654 - accuracy: 0.9737 - val_loss: 1.2400 - val_accuracy: 0.4362\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1362 - accuracy: 0.9850 - val_loss: 1.2757 - val_accuracy: 0.4564\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1097 - accuracy: 0.9944 - val_loss: 1.3760 - val_accuracy: 0.4497\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0955 - accuracy: 0.9962 - val_loss: 1.4144 - val_accuracy: 0.4228\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0847 - accuracy: 0.9925 - val_loss: 1.4898 - val_accuracy: 0.4430\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0718 - accuracy: 0.9944 - val_loss: 1.4976 - val_accuracy: 0.4564\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.9981 - val_loss: 1.6579 - val_accuracy: 0.4228\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0556 - accuracy: 0.9981 - val_loss: 1.6315 - val_accuracy: 0.4295\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0432 - accuracy: 0.9981 - val_loss: 1.7228 - val_accuracy: 0.4430\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 1.7543 - val_accuracy: 0.4497\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 1.8138 - val_accuracy: 0.4228\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 1.8540 - val_accuracy: 0.4430\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 1.9065 - val_accuracy: 0.4430\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 1.9584 - val_accuracy: 0.4362\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 1.9746 - val_accuracy: 0.4564\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.0390 - val_accuracy: 0.4497\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.0664 - val_accuracy: 0.4497\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.0894 - val_accuracy: 0.4564\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 2.1503 - val_accuracy: 0.4430\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.1594 - val_accuracy: 0.4497\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.1985 - val_accuracy: 0.4497\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.2462 - val_accuracy: 0.4430\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.2612 - val_accuracy: 0.4430\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.2863 - val_accuracy: 0.4362\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.3033 - val_accuracy: 0.4497\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.3393 - val_accuracy: 0.4362\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.3762 - val_accuracy: 0.4430\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.4034 - val_accuracy: 0.4564\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.4132 - val_accuracy: 0.4497\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.4512 - val_accuracy: 0.4362\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.4673 - val_accuracy: 0.4631\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.4778 - val_accuracy: 0.4631\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.5139 - val_accuracy: 0.4631\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.5225 - val_accuracy: 0.4430\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.5434 - val_accuracy: 0.4497\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.5695 - val_accuracy: 0.4631\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.5848 - val_accuracy: 0.4564\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.6088 - val_accuracy: 0.4564\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.6272 - val_accuracy: 0.4564\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.6480 - val_accuracy: 0.4497\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.6604 - val_accuracy: 0.4564\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.6861 - val_accuracy: 0.4631\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.6821 - val_accuracy: 0.4497\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.7305 - val_accuracy: 0.4564\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.7275 - val_accuracy: 0.4497\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.7487 - val_accuracy: 0.4497\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.7615 - val_accuracy: 0.4564\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.7844 - val_accuracy: 0.4564\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.7891 - val_accuracy: 0.4564\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.8011 - val_accuracy: 0.4564\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.8264 - val_accuracy: 0.4631\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.8414 - val_accuracy: 0.4497\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.8572 - val_accuracy: 0.4564\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.8711 - val_accuracy: 0.4698\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.8744 - val_accuracy: 0.4564\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.8946 - val_accuracy: 0.4497\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.9067 - val_accuracy: 0.4497\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.9180 - val_accuracy: 0.4564\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.9403 - val_accuracy: 0.4631\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.9385 - val_accuracy: 0.4564\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.9563 - val_accuracy: 0.4497\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.9649 - val_accuracy: 0.4564\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.9847 - val_accuracy: 0.4497\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.9886 - val_accuracy: 0.4631\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.0046 - val_accuracy: 0.4497\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.0072 - val_accuracy: 0.4564\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.0301 - val_accuracy: 0.4497\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.0391 - val_accuracy: 0.4631\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.7689e-04 - accuracy: 1.0000 - val_loss: 3.0459 - val_accuracy: 0.4497\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.6458e-04 - accuracy: 1.0000 - val_loss: 3.0594 - val_accuracy: 0.4631\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.3175e-04 - accuracy: 1.0000 - val_loss: 3.0727 - val_accuracy: 0.4497\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.0538e-04 - accuracy: 1.0000 - val_loss: 3.0823 - val_accuracy: 0.4497\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.7714e-04 - accuracy: 1.0000 - val_loss: 3.0929 - val_accuracy: 0.4564\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.6104e-04 - accuracy: 1.0000 - val_loss: 3.1034 - val_accuracy: 0.4564\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.3526e-04 - accuracy: 1.0000 - val_loss: 3.1148 - val_accuracy: 0.4564\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.1204e-04 - accuracy: 1.0000 - val_loss: 3.1231 - val_accuracy: 0.4564\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.8663e-04 - accuracy: 1.0000 - val_loss: 3.1357 - val_accuracy: 0.4631\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.6034e-04 - accuracy: 1.0000 - val_loss: 3.1452 - val_accuracy: 0.4564\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.4471e-04 - accuracy: 1.0000 - val_loss: 3.1592 - val_accuracy: 0.4631\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.2855e-04 - accuracy: 1.0000 - val_loss: 3.1620 - val_accuracy: 0.4564\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.0505e-04 - accuracy: 1.0000 - val_loss: 3.1797 - val_accuracy: 0.4564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15bd0beb0>"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_1_3 = Sequential()\n",
    "model_1_1_3.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features)))\n",
    "model_1_1_3.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_1_1_3.add(MaxPooling1D(pool_size=2)) \n",
    "model_1_1_3.add(Flatten())\n",
    "model_1_1_3.add(Dense(50, activation='relu')) \n",
    "model_1_1_3.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model_1_1_3.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_1_1_3.fit(train_X_1_1,train_f1t_tc,epochs=100,  validation_data=(val_X_1_1, val_f1t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "17ac623d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 19ms/step - loss: 0.6959 - accuracy: 0.5075 - val_loss: 0.6923 - val_accuracy: 0.5235\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.5451 - val_loss: 0.6952 - val_accuracy: 0.5168\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6762 - accuracy: 0.5959 - val_loss: 0.6953 - val_accuracy: 0.4631\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6626 - accuracy: 0.6917 - val_loss: 0.6977 - val_accuracy: 0.5235\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6398 - accuracy: 0.7331 - val_loss: 0.7073 - val_accuracy: 0.4161\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6028 - accuracy: 0.7425 - val_loss: 0.7325 - val_accuracy: 0.4832\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.5520 - accuracy: 0.7857 - val_loss: 0.7568 - val_accuracy: 0.4832\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.4835 - accuracy: 0.8195 - val_loss: 0.8209 - val_accuracy: 0.5101\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4076 - accuracy: 0.8383 - val_loss: 0.9195 - val_accuracy: 0.4765\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3360 - accuracy: 0.8722 - val_loss: 0.9586 - val_accuracy: 0.4966\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2644 - accuracy: 0.9154 - val_loss: 1.0334 - val_accuracy: 0.5369\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2074 - accuracy: 0.9492 - val_loss: 1.1962 - val_accuracy: 0.4631\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1790 - accuracy: 0.9455 - val_loss: 1.2892 - val_accuracy: 0.4899\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1452 - accuracy: 0.9756 - val_loss: 1.2406 - val_accuracy: 0.5101\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1198 - accuracy: 0.9680 - val_loss: 1.4116 - val_accuracy: 0.4765\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0733 - accuracy: 0.9925 - val_loss: 1.4491 - val_accuracy: 0.4966\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0546 - accuracy: 0.9944 - val_loss: 1.6705 - val_accuracy: 0.4765\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 0.9962 - val_loss: 1.6892 - val_accuracy: 0.4966\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 0.9981 - val_loss: 1.7891 - val_accuracy: 0.4966\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 1.8594 - val_accuracy: 0.4832\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 0.9981 - val_loss: 1.9125 - val_accuracy: 0.5302\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.9805 - val_accuracy: 0.5235\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.0390 - val_accuracy: 0.5034\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.1307 - val_accuracy: 0.5034\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.1990 - val_accuracy: 0.4966\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.2277 - val_accuracy: 0.5034\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.2450 - val_accuracy: 0.5235\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.3191 - val_accuracy: 0.5034\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.3699 - val_accuracy: 0.5101\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.4093 - val_accuracy: 0.5034\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.4163 - val_accuracy: 0.5235\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.4595 - val_accuracy: 0.5168\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.5178 - val_accuracy: 0.5034\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.5378 - val_accuracy: 0.5034\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.5819 - val_accuracy: 0.5168\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.5983 - val_accuracy: 0.5034\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.6261 - val_accuracy: 0.5034\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6569 - val_accuracy: 0.5034\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.6881 - val_accuracy: 0.5034\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7099 - val_accuracy: 0.5034\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.7442 - val_accuracy: 0.5034\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.7585 - val_accuracy: 0.5034\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.7940 - val_accuracy: 0.5034\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.7953 - val_accuracy: 0.5101\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.8541 - val_accuracy: 0.5034\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.5889e-04 - accuracy: 1.0000 - val_loss: 2.8465 - val_accuracy: 0.5034\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.8959e-04 - accuracy: 1.0000 - val_loss: 2.8725 - val_accuracy: 0.5034\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.4404e-04 - accuracy: 1.0000 - val_loss: 2.8856 - val_accuracy: 0.5034\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.9663e-04 - accuracy: 1.0000 - val_loss: 2.9178 - val_accuracy: 0.5034\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.5396e-04 - accuracy: 1.0000 - val_loss: 2.9255 - val_accuracy: 0.5034\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.2596e-04 - accuracy: 1.0000 - val_loss: 2.9678 - val_accuracy: 0.5034\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 6.6849e-04 - accuracy: 1.0000 - val_loss: 2.9750 - val_accuracy: 0.5034\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 6.3465e-04 - accuracy: 1.0000 - val_loss: 2.9931 - val_accuracy: 0.5034\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 6.1099e-04 - accuracy: 1.0000 - val_loss: 2.9979 - val_accuracy: 0.5034\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5.7685e-04 - accuracy: 1.0000 - val_loss: 3.0413 - val_accuracy: 0.5034\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5.4767e-04 - accuracy: 1.0000 - val_loss: 3.0499 - val_accuracy: 0.5034\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5.3021e-04 - accuracy: 1.0000 - val_loss: 3.0724 - val_accuracy: 0.4966\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5.0356e-04 - accuracy: 1.0000 - val_loss: 3.0845 - val_accuracy: 0.5034\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.7631e-04 - accuracy: 1.0000 - val_loss: 3.0909 - val_accuracy: 0.5034\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 4.5639e-04 - accuracy: 1.0000 - val_loss: 3.1226 - val_accuracy: 0.4966\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.3228e-04 - accuracy: 1.0000 - val_loss: 3.1320 - val_accuracy: 0.5034\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 4.1298e-04 - accuracy: 1.0000 - val_loss: 3.1568 - val_accuracy: 0.4966\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.9721e-04 - accuracy: 1.0000 - val_loss: 3.1701 - val_accuracy: 0.4966\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.8319e-04 - accuracy: 1.0000 - val_loss: 3.1763 - val_accuracy: 0.5034\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.6766e-04 - accuracy: 1.0000 - val_loss: 3.2010 - val_accuracy: 0.4966\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.5759e-04 - accuracy: 1.0000 - val_loss: 3.2077 - val_accuracy: 0.4966\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.3896e-04 - accuracy: 1.0000 - val_loss: 3.2280 - val_accuracy: 0.4966\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.2950e-04 - accuracy: 1.0000 - val_loss: 3.2462 - val_accuracy: 0.4966\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.1388e-04 - accuracy: 1.0000 - val_loss: 3.2560 - val_accuracy: 0.4966\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.0183e-04 - accuracy: 1.0000 - val_loss: 3.2775 - val_accuracy: 0.4966\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.9070e-04 - accuracy: 1.0000 - val_loss: 3.2901 - val_accuracy: 0.4966\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.7876e-04 - accuracy: 1.0000 - val_loss: 3.3025 - val_accuracy: 0.4966\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.6905e-04 - accuracy: 1.0000 - val_loss: 3.3158 - val_accuracy: 0.4966\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.5937e-04 - accuracy: 1.0000 - val_loss: 3.3359 - val_accuracy: 0.4966\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.5093e-04 - accuracy: 1.0000 - val_loss: 3.3525 - val_accuracy: 0.5034\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.4157e-04 - accuracy: 1.0000 - val_loss: 3.3640 - val_accuracy: 0.5034\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.3308e-04 - accuracy: 1.0000 - val_loss: 3.3720 - val_accuracy: 0.5034\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.2515e-04 - accuracy: 1.0000 - val_loss: 3.3944 - val_accuracy: 0.5034\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.1761e-04 - accuracy: 1.0000 - val_loss: 3.4035 - val_accuracy: 0.5034\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.1365e-04 - accuracy: 1.0000 - val_loss: 3.4196 - val_accuracy: 0.5034\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 2.0300e-04 - accuracy: 1.0000 - val_loss: 3.4169 - val_accuracy: 0.4966\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.9664e-04 - accuracy: 1.0000 - val_loss: 3.4478 - val_accuracy: 0.5101\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.9139e-04 - accuracy: 1.0000 - val_loss: 3.4597 - val_accuracy: 0.5101\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.8537e-04 - accuracy: 1.0000 - val_loss: 3.4702 - val_accuracy: 0.5034\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.7801e-04 - accuracy: 1.0000 - val_loss: 3.4782 - val_accuracy: 0.5034\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.7340e-04 - accuracy: 1.0000 - val_loss: 3.4951 - val_accuracy: 0.5034\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.6935e-04 - accuracy: 1.0000 - val_loss: 3.5069 - val_accuracy: 0.5034\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.6207e-04 - accuracy: 1.0000 - val_loss: 3.5282 - val_accuracy: 0.5101\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.5714e-04 - accuracy: 1.0000 - val_loss: 3.5301 - val_accuracy: 0.5034\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.5309e-04 - accuracy: 1.0000 - val_loss: 3.5514 - val_accuracy: 0.5101\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.4850e-04 - accuracy: 1.0000 - val_loss: 3.5567 - val_accuracy: 0.5101\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.4318e-04 - accuracy: 1.0000 - val_loss: 3.5649 - val_accuracy: 0.4966\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.4052e-04 - accuracy: 1.0000 - val_loss: 3.5860 - val_accuracy: 0.5101\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.3611e-04 - accuracy: 1.0000 - val_loss: 3.5783 - val_accuracy: 0.4966\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.3041e-04 - accuracy: 1.0000 - val_loss: 3.6078 - val_accuracy: 0.5101\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.2752e-04 - accuracy: 1.0000 - val_loss: 3.6082 - val_accuracy: 0.4966\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.2246e-04 - accuracy: 1.0000 - val_loss: 3.6329 - val_accuracy: 0.5034\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.1859e-04 - accuracy: 1.0000 - val_loss: 3.6437 - val_accuracy: 0.5034\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.1535e-04 - accuracy: 1.0000 - val_loss: 3.6511 - val_accuracy: 0.5034\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.1181e-04 - accuracy: 1.0000 - val_loss: 3.6675 - val_accuracy: 0.5034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15bea0880>"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_1_4 = Sequential()\n",
    "model_1_1_4.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features)))\n",
    "model_1_1_4.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_1_1_4.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_1_1_4.add(MaxPooling1D(pool_size=2)) \n",
    "model_1_1_4.add(Conv1D(filters=32, kernel_size=1, activation='relu')) \n",
    "model_1_1_4.add(Flatten())\n",
    "model_1_1_4.add(Dense(50, activation='relu')) \n",
    "model_1_1_4.add(Dense(1, activation='sigmoid')) \n",
    "model_1_1_4.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_1_1_4.fit(train_X_1_1,train_f1t_tc,epochs=100,  validation_data=(val_X_1_1, val_f1t_tc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e7bbbf",
   "metadata": {},
   "source": [
    "## Model_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "d9176dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to window format, in this case 5 periods\n",
    "train_X_1_2, train_f1t_tc = df_to_X_y2(train_f1[feats_1],train_f1t)\n",
    "val_X_1_2, val_f1t_tc= df_to_X_y2(val_f1[feats_1], val_f1t)\n",
    "test_X_1_2, test_f1t_tc = df_to_X_y2(test_f1[feats_1],test_f1t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "f2267b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 12ms/step - loss: 0.6956 - accuracy: 0.5094 - val_loss: 0.6882 - val_accuracy: 0.5369\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.5038 - val_loss: 0.6875 - val_accuracy: 0.5436\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6919 - accuracy: 0.5244 - val_loss: 0.6906 - val_accuracy: 0.5034\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6897 - accuracy: 0.5376 - val_loss: 0.6902 - val_accuracy: 0.5168\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.5320 - val_loss: 0.6880 - val_accuracy: 0.5369\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6879 - accuracy: 0.5357 - val_loss: 0.6906 - val_accuracy: 0.5168\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6879 - accuracy: 0.5414 - val_loss: 0.6889 - val_accuracy: 0.4966\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6863 - accuracy: 0.5620 - val_loss: 0.6901 - val_accuracy: 0.5101\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6857 - accuracy: 0.5526 - val_loss: 0.6889 - val_accuracy: 0.5168\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6851 - accuracy: 0.5545 - val_loss: 0.6887 - val_accuracy: 0.5101\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6837 - accuracy: 0.5639 - val_loss: 0.6899 - val_accuracy: 0.5034\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6832 - accuracy: 0.5602 - val_loss: 0.6890 - val_accuracy: 0.5034\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6825 - accuracy: 0.5639 - val_loss: 0.6896 - val_accuracy: 0.4765\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6827 - accuracy: 0.5714 - val_loss: 0.6884 - val_accuracy: 0.5302\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6790 - accuracy: 0.5545 - val_loss: 0.6900 - val_accuracy: 0.4832\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6786 - accuracy: 0.5733 - val_loss: 0.6877 - val_accuracy: 0.5436\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6768 - accuracy: 0.5789 - val_loss: 0.6897 - val_accuracy: 0.5168\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6772 - accuracy: 0.5695 - val_loss: 0.6886 - val_accuracy: 0.5436\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6736 - accuracy: 0.5827 - val_loss: 0.6891 - val_accuracy: 0.4966\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.5789 - val_loss: 0.6908 - val_accuracy: 0.5101\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6719 - accuracy: 0.5714 - val_loss: 0.6891 - val_accuracy: 0.5302\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6722 - accuracy: 0.5902 - val_loss: 0.6904 - val_accuracy: 0.5168\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6687 - accuracy: 0.5752 - val_loss: 0.6908 - val_accuracy: 0.4966\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6676 - accuracy: 0.6109 - val_loss: 0.6916 - val_accuracy: 0.5235\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6663 - accuracy: 0.5921 - val_loss: 0.6922 - val_accuracy: 0.5168\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6634 - accuracy: 0.6203 - val_loss: 0.6936 - val_accuracy: 0.5168\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6620 - accuracy: 0.5940 - val_loss: 0.6959 - val_accuracy: 0.5034\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6597 - accuracy: 0.6053 - val_loss: 0.6958 - val_accuracy: 0.5034\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.6203 - val_loss: 0.6963 - val_accuracy: 0.4966\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6564 - accuracy: 0.6184 - val_loss: 0.6980 - val_accuracy: 0.4966\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6536 - accuracy: 0.6147 - val_loss: 0.6993 - val_accuracy: 0.4899\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6539 - accuracy: 0.6109 - val_loss: 0.7017 - val_accuracy: 0.4832\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6503 - accuracy: 0.6071 - val_loss: 0.7034 - val_accuracy: 0.4899\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6515 - accuracy: 0.6109 - val_loss: 0.7077 - val_accuracy: 0.4966\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6499 - accuracy: 0.6034 - val_loss: 0.7064 - val_accuracy: 0.4832\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6460 - accuracy: 0.6579 - val_loss: 0.7091 - val_accuracy: 0.4765\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6445 - accuracy: 0.6222 - val_loss: 0.7115 - val_accuracy: 0.4899\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6430 - accuracy: 0.6410 - val_loss: 0.7130 - val_accuracy: 0.4899\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6400 - accuracy: 0.6391 - val_loss: 0.7161 - val_accuracy: 0.4832\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6387 - accuracy: 0.6391 - val_loss: 0.7181 - val_accuracy: 0.4899\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.6504 - val_loss: 0.7230 - val_accuracy: 0.5034\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6362 - accuracy: 0.6241 - val_loss: 0.7258 - val_accuracy: 0.5101\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6368 - accuracy: 0.6466 - val_loss: 0.7281 - val_accuracy: 0.5034\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6312 - accuracy: 0.6410 - val_loss: 0.7284 - val_accuracy: 0.5168\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6308 - accuracy: 0.6523 - val_loss: 0.7333 - val_accuracy: 0.5034\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6278 - accuracy: 0.6598 - val_loss: 0.7403 - val_accuracy: 0.5101\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6264 - accuracy: 0.6466 - val_loss: 0.7365 - val_accuracy: 0.5101\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6241 - accuracy: 0.6711 - val_loss: 0.7546 - val_accuracy: 0.4966\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6252 - accuracy: 0.6786 - val_loss: 0.7377 - val_accuracy: 0.4765\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6226 - accuracy: 0.6598 - val_loss: 0.7512 - val_accuracy: 0.4765\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6197 - accuracy: 0.6711 - val_loss: 0.7568 - val_accuracy: 0.4966\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6201 - accuracy: 0.6711 - val_loss: 0.7564 - val_accuracy: 0.4832\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6167 - accuracy: 0.6673 - val_loss: 0.7575 - val_accuracy: 0.4966\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6197 - accuracy: 0.6635 - val_loss: 0.7691 - val_accuracy: 0.5101\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6126 - accuracy: 0.6842 - val_loss: 0.7560 - val_accuracy: 0.4899\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6122 - accuracy: 0.6805 - val_loss: 0.7715 - val_accuracy: 0.4966\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.6692 - val_loss: 0.7731 - val_accuracy: 0.4899\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6186 - accuracy: 0.6523 - val_loss: 0.7992 - val_accuracy: 0.5034\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6090 - accuracy: 0.6861 - val_loss: 0.7681 - val_accuracy: 0.4832\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6094 - accuracy: 0.6748 - val_loss: 0.7909 - val_accuracy: 0.5101\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6065 - accuracy: 0.6861 - val_loss: 0.7868 - val_accuracy: 0.5034\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6013 - accuracy: 0.6842 - val_loss: 0.7760 - val_accuracy: 0.4832\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6020 - accuracy: 0.6936 - val_loss: 0.7871 - val_accuracy: 0.4966\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6015 - accuracy: 0.6880 - val_loss: 0.7882 - val_accuracy: 0.4966\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.6880 - val_loss: 0.7812 - val_accuracy: 0.5034\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.6974 - val_loss: 0.7879 - val_accuracy: 0.4899\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5968 - accuracy: 0.6861 - val_loss: 0.8099 - val_accuracy: 0.4899\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5986 - accuracy: 0.6898 - val_loss: 0.8306 - val_accuracy: 0.5101\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5939 - accuracy: 0.6992 - val_loss: 0.7874 - val_accuracy: 0.4698\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5952 - accuracy: 0.6917 - val_loss: 0.8298 - val_accuracy: 0.4966\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5932 - accuracy: 0.6992 - val_loss: 0.8309 - val_accuracy: 0.4966\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.6880 - val_loss: 0.8348 - val_accuracy: 0.5034\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5933 - accuracy: 0.6974 - val_loss: 0.8072 - val_accuracy: 0.4899\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.6880 - val_loss: 0.8169 - val_accuracy: 0.5034\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5927 - accuracy: 0.6898 - val_loss: 0.8434 - val_accuracy: 0.4966\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5897 - accuracy: 0.6955 - val_loss: 0.8000 - val_accuracy: 0.4966\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5845 - accuracy: 0.6974 - val_loss: 0.8555 - val_accuracy: 0.4966\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5852 - accuracy: 0.7105 - val_loss: 0.8244 - val_accuracy: 0.4765\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.6917 - val_loss: 0.8533 - val_accuracy: 0.4765\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5883 - accuracy: 0.6823 - val_loss: 0.8445 - val_accuracy: 0.4966\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5835 - accuracy: 0.7011 - val_loss: 0.8699 - val_accuracy: 0.4966\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5746 - accuracy: 0.7199 - val_loss: 0.8417 - val_accuracy: 0.4765\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5767 - accuracy: 0.7011 - val_loss: 0.8843 - val_accuracy: 0.4899\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5811 - accuracy: 0.6898 - val_loss: 0.8678 - val_accuracy: 0.4765\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5705 - accuracy: 0.7180 - val_loss: 0.8525 - val_accuracy: 0.4765\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5761 - accuracy: 0.7030 - val_loss: 0.8777 - val_accuracy: 0.4966\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5740 - accuracy: 0.7011 - val_loss: 0.8825 - val_accuracy: 0.4966\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5709 - accuracy: 0.7011 - val_loss: 0.8930 - val_accuracy: 0.4966\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5680 - accuracy: 0.6955 - val_loss: 0.8710 - val_accuracy: 0.4832\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.7086 - val_loss: 0.8444 - val_accuracy: 0.4966\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5685 - accuracy: 0.7030 - val_loss: 0.9058 - val_accuracy: 0.4899\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.5641 - accuracy: 0.7162 - val_loss: 0.8884 - val_accuracy: 0.4698\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5680 - accuracy: 0.7030 - val_loss: 0.8489 - val_accuracy: 0.4832\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5733 - accuracy: 0.6861 - val_loss: 0.8731 - val_accuracy: 0.4698\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5599 - accuracy: 0.7218 - val_loss: 0.9145 - val_accuracy: 0.4899\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5607 - accuracy: 0.7030 - val_loss: 0.9066 - val_accuracy: 0.4899\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5608 - accuracy: 0.7105 - val_loss: 0.9012 - val_accuracy: 0.4698\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5605 - accuracy: 0.7105 - val_loss: 0.8984 - val_accuracy: 0.4832\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5558 - accuracy: 0.7256 - val_loss: 0.9147 - val_accuracy: 0.4631\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.7086 - val_loss: 0.9044 - val_accuracy: 0.4698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15bce0c10>"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = train_X_1_2.shape[1]\n",
    "n_features = train_X_1_2.shape[2]\n",
    "\n",
    "model_1_2_1 = Sequential()\n",
    "model_1_2_1.add(Conv1D(filters=5, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model_1_2_1.add(MaxPooling1D(pool_size=2)) \n",
    "model_1_2_1.add(Flatten())\n",
    "model_1_2_1.add(Dense(50, activation='relu')) \n",
    "model_1_2_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_1_2_1.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_1_2_1.fit(train_X_1_2, train_f1t_tc,epochs=100,  validation_data=(val_X_1_2, val_f1t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "24b8a13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 13ms/step - loss: 0.7096 - accuracy: 0.5169 - val_loss: 0.7176 - val_accuracy: 0.4966\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6863 - accuracy: 0.5526 - val_loss: 0.7066 - val_accuracy: 0.5101\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6868 - accuracy: 0.5432 - val_loss: 0.6985 - val_accuracy: 0.5101\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6819 - accuracy: 0.5620 - val_loss: 0.7063 - val_accuracy: 0.4899\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6751 - accuracy: 0.5583 - val_loss: 0.6997 - val_accuracy: 0.5034\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6613 - accuracy: 0.6560 - val_loss: 0.6986 - val_accuracy: 0.4832\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6533 - accuracy: 0.6805 - val_loss: 0.7057 - val_accuracy: 0.4899\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6560 - accuracy: 0.6053 - val_loss: 0.7044 - val_accuracy: 0.4899\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6489 - accuracy: 0.6297 - val_loss: 0.7121 - val_accuracy: 0.4899\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.6372 - val_loss: 0.7229 - val_accuracy: 0.5034\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6547 - accuracy: 0.5789 - val_loss: 0.7061 - val_accuracy: 0.4966\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6217 - accuracy: 0.7049 - val_loss: 0.7159 - val_accuracy: 0.4765\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6273 - accuracy: 0.6673 - val_loss: 0.7153 - val_accuracy: 0.4899\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.7143 - val_loss: 0.7309 - val_accuracy: 0.4832\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5947 - accuracy: 0.7030 - val_loss: 0.7385 - val_accuracy: 0.4899\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5864 - accuracy: 0.7105 - val_loss: 0.7454 - val_accuracy: 0.4832\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5762 - accuracy: 0.7331 - val_loss: 0.7583 - val_accuracy: 0.4698\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5486 - accuracy: 0.7688 - val_loss: 0.7818 - val_accuracy: 0.4765\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7688 - val_loss: 0.7957 - val_accuracy: 0.4698\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5151 - accuracy: 0.7782 - val_loss: 0.8096 - val_accuracy: 0.4832\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.8102 - val_loss: 0.8422 - val_accuracy: 0.4564\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7895 - val_loss: 0.8558 - val_accuracy: 0.4564\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7707 - val_loss: 0.8784 - val_accuracy: 0.4631\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.8252 - val_loss: 0.8955 - val_accuracy: 0.4430\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.8008 - val_loss: 0.9317 - val_accuracy: 0.4362\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.8383 - val_loss: 0.9868 - val_accuracy: 0.4362\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8440 - val_loss: 1.0025 - val_accuracy: 0.4362\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3899 - accuracy: 0.8459 - val_loss: 1.0131 - val_accuracy: 0.4631\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4082 - accuracy: 0.8233 - val_loss: 1.0274 - val_accuracy: 0.4631\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.8440 - val_loss: 1.0383 - val_accuracy: 0.4497\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3582 - accuracy: 0.8590 - val_loss: 1.0662 - val_accuracy: 0.4698\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3348 - accuracy: 0.8910 - val_loss: 1.1174 - val_accuracy: 0.4362\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3277 - accuracy: 0.8891 - val_loss: 1.1385 - val_accuracy: 0.4497\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3116 - accuracy: 0.8947 - val_loss: 1.1690 - val_accuracy: 0.4564\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2953 - accuracy: 0.9060 - val_loss: 1.1970 - val_accuracy: 0.4295\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2977 - accuracy: 0.9023 - val_loss: 1.3030 - val_accuracy: 0.4564\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2994 - accuracy: 0.8778 - val_loss: 1.2571 - val_accuracy: 0.4430\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2629 - accuracy: 0.9286 - val_loss: 1.3011 - val_accuracy: 0.4295\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2655 - accuracy: 0.9192 - val_loss: 1.3607 - val_accuracy: 0.4430\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2524 - accuracy: 0.9305 - val_loss: 1.3711 - val_accuracy: 0.4362\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2313 - accuracy: 0.9323 - val_loss: 1.4037 - val_accuracy: 0.4430\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2204 - accuracy: 0.9549 - val_loss: 1.4396 - val_accuracy: 0.4430\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2094 - accuracy: 0.9530 - val_loss: 1.4749 - val_accuracy: 0.4430\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1962 - accuracy: 0.9455 - val_loss: 1.5215 - val_accuracy: 0.4362\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1932 - accuracy: 0.9568 - val_loss: 1.6072 - val_accuracy: 0.4228\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1844 - accuracy: 0.9530 - val_loss: 1.5984 - val_accuracy: 0.4497\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1828 - accuracy: 0.9474 - val_loss: 1.6079 - val_accuracy: 0.4564\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1621 - accuracy: 0.9699 - val_loss: 1.7556 - val_accuracy: 0.4362\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1654 - accuracy: 0.9530 - val_loss: 1.7279 - val_accuracy: 0.4295\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1587 - accuracy: 0.9718 - val_loss: 1.7196 - val_accuracy: 0.4430\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1418 - accuracy: 0.9756 - val_loss: 1.8621 - val_accuracy: 0.4430\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1415 - accuracy: 0.9680 - val_loss: 1.7977 - val_accuracy: 0.4564\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1394 - accuracy: 0.9737 - val_loss: 1.8475 - val_accuracy: 0.4295\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1202 - accuracy: 0.9831 - val_loss: 1.9720 - val_accuracy: 0.4228\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1128 - accuracy: 0.9906 - val_loss: 1.9788 - val_accuracy: 0.4362\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1084 - accuracy: 0.9850 - val_loss: 1.9569 - val_accuracy: 0.4430\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1009 - accuracy: 0.9925 - val_loss: 2.0153 - val_accuracy: 0.4295\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0950 - accuracy: 0.9944 - val_loss: 2.0735 - val_accuracy: 0.4430\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0993 - accuracy: 0.9887 - val_loss: 2.0200 - val_accuracy: 0.4161\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0980 - accuracy: 0.9850 - val_loss: 2.2339 - val_accuracy: 0.4430\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0838 - accuracy: 0.9962 - val_loss: 2.1317 - val_accuracy: 0.4430\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0924 - accuracy: 0.9887 - val_loss: 2.3449 - val_accuracy: 0.4430\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0799 - accuracy: 0.9944 - val_loss: 2.2509 - val_accuracy: 0.4430\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0839 - accuracy: 0.9906 - val_loss: 2.3026 - val_accuracy: 0.4362\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0933 - accuracy: 0.9793 - val_loss: 2.4278 - val_accuracy: 0.4362\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0719 - accuracy: 1.0000 - val_loss: 2.3643 - val_accuracy: 0.4362\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.9981 - val_loss: 2.5136 - val_accuracy: 0.4497\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0594 - accuracy: 0.9981 - val_loss: 2.5354 - val_accuracy: 0.4497\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 2.5323 - val_accuracy: 0.4295\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 2.5812 - val_accuracy: 0.4362\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0540 - accuracy: 0.9981 - val_loss: 2.5303 - val_accuracy: 0.4362\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 2.7943 - val_accuracy: 0.4362\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0573 - accuracy: 0.9962 - val_loss: 2.5928 - val_accuracy: 0.4362\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0518 - accuracy: 0.9981 - val_loss: 2.8432 - val_accuracy: 0.4497\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 1.0000 - val_loss: 2.7741 - val_accuracy: 0.4362\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 2.7883 - val_accuracy: 0.4430\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.9981 - val_loss: 2.9785 - val_accuracy: 0.4430\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 2.8670 - val_accuracy: 0.4497\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 2.8749 - val_accuracy: 0.4094\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 2.9780 - val_accuracy: 0.4564\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 2.9609 - val_accuracy: 0.4362\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 2.9653 - val_accuracy: 0.4430\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 3.0352 - val_accuracy: 0.4295\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 3.0402 - val_accuracy: 0.4362\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 3.0508 - val_accuracy: 0.4295\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 3.1922 - val_accuracy: 0.4564\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 3.1582 - val_accuracy: 0.4295\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 3.2544 - val_accuracy: 0.4631\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 3.2358 - val_accuracy: 0.4295\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 3.2717 - val_accuracy: 0.4497\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 3.2072 - val_accuracy: 0.4295\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 3.2806 - val_accuracy: 0.4362\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 3.4115 - val_accuracy: 0.4564\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 3.3896 - val_accuracy: 0.4497\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 3.4501 - val_accuracy: 0.4497\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 3.4079 - val_accuracy: 0.4295\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 3.4840 - val_accuracy: 0.4430\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 3.4844 - val_accuracy: 0.4362\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 3.5826 - val_accuracy: 0.4564\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 3.5530 - val_accuracy: 0.4430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15c1dceb0>"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_2_2 = Sequential()\n",
    "model_1_2_2.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model_1_2_2.add(MaxPooling1D(pool_size=2)) \n",
    "model_1_2_2.add(Flatten())\n",
    "model_1_2_2.add(Dense(50, activation='relu')) \n",
    "model_1_2_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_1_2_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_1_2_2.fit(train_X_1_2,train_f1t_tc,epochs=100,  validation_data=(val_X_1_2, val_f1t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "a1ec1d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 13ms/step - loss: 0.6952 - accuracy: 0.5301 - val_loss: 0.6945 - val_accuracy: 0.4966\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6891 - accuracy: 0.5338 - val_loss: 0.6955 - val_accuracy: 0.4832\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6844 - accuracy: 0.5883 - val_loss: 0.6931 - val_accuracy: 0.5101\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6816 - accuracy: 0.5620 - val_loss: 0.6934 - val_accuracy: 0.5101\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6779 - accuracy: 0.5752 - val_loss: 0.6949 - val_accuracy: 0.4966\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6637 - accuracy: 0.6109 - val_loss: 0.7075 - val_accuracy: 0.4564\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6552 - accuracy: 0.6541 - val_loss: 0.7014 - val_accuracy: 0.5101\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6519 - accuracy: 0.6109 - val_loss: 0.7008 - val_accuracy: 0.5436\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.5789 - val_loss: 0.7135 - val_accuracy: 0.5168\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6266 - accuracy: 0.6729 - val_loss: 0.7216 - val_accuracy: 0.4899\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6028 - accuracy: 0.7143 - val_loss: 0.7157 - val_accuracy: 0.5235\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5815 - accuracy: 0.7331 - val_loss: 0.7699 - val_accuracy: 0.4631\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5598 - accuracy: 0.7312 - val_loss: 0.8366 - val_accuracy: 0.4899\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.7876 - val_loss: 0.7811 - val_accuracy: 0.4631\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.7575 - val_loss: 0.8634 - val_accuracy: 0.4832\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4946 - accuracy: 0.8026 - val_loss: 0.8960 - val_accuracy: 0.4631\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.8064 - val_loss: 0.8227 - val_accuracy: 0.5101\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.8083 - val_loss: 0.9704 - val_accuracy: 0.4631\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.8383 - val_loss: 0.8638 - val_accuracy: 0.5034\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8383 - val_loss: 0.9473 - val_accuracy: 0.4631\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3917 - accuracy: 0.8534 - val_loss: 0.9723 - val_accuracy: 0.4832\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3567 - accuracy: 0.8910 - val_loss: 1.0952 - val_accuracy: 0.4631\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3374 - accuracy: 0.8835 - val_loss: 1.1159 - val_accuracy: 0.4631\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3381 - accuracy: 0.8741 - val_loss: 1.0772 - val_accuracy: 0.4564\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3016 - accuracy: 0.8872 - val_loss: 1.0184 - val_accuracy: 0.5168\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2882 - accuracy: 0.9023 - val_loss: 1.0989 - val_accuracy: 0.4899\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2796 - accuracy: 0.9117 - val_loss: 1.2692 - val_accuracy: 0.4430\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2536 - accuracy: 0.9286 - val_loss: 1.3384 - val_accuracy: 0.4564\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2618 - accuracy: 0.8985 - val_loss: 1.4165 - val_accuracy: 0.4899\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2249 - accuracy: 0.9474 - val_loss: 1.5166 - val_accuracy: 0.4497\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2273 - accuracy: 0.9248 - val_loss: 1.3347 - val_accuracy: 0.4832\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1988 - accuracy: 0.9530 - val_loss: 1.2829 - val_accuracy: 0.5235\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2544 - accuracy: 0.8835 - val_loss: 1.3730 - val_accuracy: 0.5302\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2518 - accuracy: 0.9041 - val_loss: 1.3936 - val_accuracy: 0.4832\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1708 - accuracy: 0.9643 - val_loss: 1.3926 - val_accuracy: 0.4966\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1749 - accuracy: 0.9530 - val_loss: 1.4920 - val_accuracy: 0.5168\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1756 - accuracy: 0.9511 - val_loss: 1.5771 - val_accuracy: 0.4564\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1375 - accuracy: 0.9793 - val_loss: 1.5860 - val_accuracy: 0.4564\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1177 - accuracy: 0.9831 - val_loss: 1.6235 - val_accuracy: 0.4698\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1125 - accuracy: 0.9944 - val_loss: 1.7540 - val_accuracy: 0.4362\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1152 - accuracy: 0.9756 - val_loss: 1.7381 - val_accuracy: 0.4765\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0976 - accuracy: 0.9925 - val_loss: 1.7931 - val_accuracy: 0.4564\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0859 - accuracy: 0.9944 - val_loss: 1.8441 - val_accuracy: 0.4698\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0831 - accuracy: 0.9925 - val_loss: 1.7769 - val_accuracy: 0.5235\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1035 - accuracy: 0.9756 - val_loss: 1.8241 - val_accuracy: 0.5168\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0798 - accuracy: 0.9962 - val_loss: 2.0117 - val_accuracy: 0.4631\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.9944 - val_loss: 2.0318 - val_accuracy: 0.4698\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.9944 - val_loss: 1.9623 - val_accuracy: 0.5168\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0788 - accuracy: 0.9831 - val_loss: 2.2729 - val_accuracy: 0.4430\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1066 - accuracy: 0.9643 - val_loss: 1.9132 - val_accuracy: 0.4832\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0542 - accuracy: 0.9962 - val_loss: 2.0685 - val_accuracy: 0.4832\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0472 - accuracy: 0.9981 - val_loss: 1.9977 - val_accuracy: 0.5101\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 2.2555 - val_accuracy: 0.4497\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0368 - accuracy: 0.9981 - val_loss: 2.1945 - val_accuracy: 0.4832\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 2.1970 - val_accuracy: 0.5168\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 2.1701 - val_accuracy: 0.5168\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 2.4686 - val_accuracy: 0.4497\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0303 - accuracy: 0.9981 - val_loss: 2.3607 - val_accuracy: 0.4966\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0334 - accuracy: 0.9944 - val_loss: 2.3391 - val_accuracy: 0.4832\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 2.3719 - val_accuracy: 0.5034\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 2.4994 - val_accuracy: 0.4765\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 2.5533 - val_accuracy: 0.4698\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 2.5018 - val_accuracy: 0.5369\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 2.5135 - val_accuracy: 0.4832\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.6459 - val_accuracy: 0.4899\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.5051 - val_accuracy: 0.5369\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.6594 - val_accuracy: 0.4765\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.6372 - val_accuracy: 0.5168\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 2.7191 - val_accuracy: 0.4832\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 2.7298 - val_accuracy: 0.4966\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 2.7431 - val_accuracy: 0.4966\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 2.7000 - val_accuracy: 0.5235\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 2.7635 - val_accuracy: 0.5101\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 2.7914 - val_accuracy: 0.5101\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.8205 - val_accuracy: 0.4966\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.9411 - val_accuracy: 0.4564\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.9901 - val_accuracy: 0.4564\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.9508 - val_accuracy: 0.4832\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.9400 - val_accuracy: 0.5034\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.9886 - val_accuracy: 0.4832\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 3.0211 - val_accuracy: 0.4899\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 3.0933 - val_accuracy: 0.4698\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 3.0703 - val_accuracy: 0.4765\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.0434 - val_accuracy: 0.5034\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.0881 - val_accuracy: 0.4966\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 3.1373 - val_accuracy: 0.4899\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 3.1630 - val_accuracy: 0.4631\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 3.1701 - val_accuracy: 0.4765\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 3.2108 - val_accuracy: 0.4698\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 3.1926 - val_accuracy: 0.4899\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 3.1898 - val_accuracy: 0.4832\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 3.2086 - val_accuracy: 0.5034\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 3.1659 - val_accuracy: 0.5168\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 3.1904 - val_accuracy: 0.5168\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 3.2507 - val_accuracy: 0.4966\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 3.2501 - val_accuracy: 0.5034\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 3.2469 - val_accuracy: 0.5302\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 3.3217 - val_accuracy: 0.5034\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 3.3248 - val_accuracy: 0.5034\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.3870 - val_accuracy: 0.4832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15c360fa0>"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_2_3 = Sequential()\n",
    "model_1_2_3.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features)))\n",
    "model_1_2_3.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_1_2_3.add(MaxPooling1D(pool_size=2)) \n",
    "model_1_2_3.add(Flatten())\n",
    "model_1_2_3.add(Dense(50, activation='relu')) \n",
    "model_1_2_3.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model_1_2_3.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_1_2_3.fit(train_X_1_2,train_f1t_tc,epochs=100,  validation_data=(val_X_1_2, val_f1t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "4ed8dce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 16ms/step - loss: 0.6966 - accuracy: 0.5282 - val_loss: 0.6925 - val_accuracy: 0.5369\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6915 - accuracy: 0.5470 - val_loss: 0.6928 - val_accuracy: 0.5369\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.5357 - val_loss: 0.6926 - val_accuracy: 0.5369\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6870 - accuracy: 0.5338 - val_loss: 0.6934 - val_accuracy: 0.4832\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6838 - accuracy: 0.5639 - val_loss: 0.6919 - val_accuracy: 0.5369\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6738 - accuracy: 0.5865 - val_loss: 0.6942 - val_accuracy: 0.4765\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6670 - accuracy: 0.6278 - val_loss: 0.6988 - val_accuracy: 0.5235\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6555 - accuracy: 0.6372 - val_loss: 0.6984 - val_accuracy: 0.4899\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6408 - accuracy: 0.6466 - val_loss: 0.7304 - val_accuracy: 0.4899\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6432 - accuracy: 0.6071 - val_loss: 0.7172 - val_accuracy: 0.5034\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6125 - accuracy: 0.7049 - val_loss: 0.7197 - val_accuracy: 0.4899\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5913 - accuracy: 0.7068 - val_loss: 0.7258 - val_accuracy: 0.4832\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5614 - accuracy: 0.7105 - val_loss: 0.7193 - val_accuracy: 0.4832\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5258 - accuracy: 0.7462 - val_loss: 0.7803 - val_accuracy: 0.5369\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4822 - accuracy: 0.7669 - val_loss: 0.7673 - val_accuracy: 0.5302\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.8177 - val_loss: 0.8478 - val_accuracy: 0.5235\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7895 - val_loss: 0.8304 - val_accuracy: 0.5168\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.8139 - val_loss: 0.8108 - val_accuracy: 0.4899\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3960 - accuracy: 0.8327 - val_loss: 0.8367 - val_accuracy: 0.4698\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3274 - accuracy: 0.8853 - val_loss: 0.8227 - val_accuracy: 0.5570\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2990 - accuracy: 0.8985 - val_loss: 0.9339 - val_accuracy: 0.4966\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2685 - accuracy: 0.8985 - val_loss: 0.9575 - val_accuracy: 0.5101\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2175 - accuracy: 0.9361 - val_loss: 1.0550 - val_accuracy: 0.5101\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1917 - accuracy: 0.9455 - val_loss: 1.1621 - val_accuracy: 0.4430\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1674 - accuracy: 0.9492 - val_loss: 1.1643 - val_accuracy: 0.4832\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1857 - accuracy: 0.9398 - val_loss: 1.2882 - val_accuracy: 0.5503\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1643 - accuracy: 0.9436 - val_loss: 1.2197 - val_accuracy: 0.5436\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1410 - accuracy: 0.9549 - val_loss: 1.3242 - val_accuracy: 0.4698\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1193 - accuracy: 0.9511 - val_loss: 1.3536 - val_accuracy: 0.5034\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1183 - accuracy: 0.9680 - val_loss: 1.4006 - val_accuracy: 0.5168\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1040 - accuracy: 0.9643 - val_loss: 1.5202 - val_accuracy: 0.4966\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0771 - accuracy: 0.9831 - val_loss: 1.5679 - val_accuracy: 0.5101\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0599 - accuracy: 0.9906 - val_loss: 1.6828 - val_accuracy: 0.4832\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0584 - accuracy: 0.9868 - val_loss: 1.8386 - val_accuracy: 0.5101\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 0.9962 - val_loss: 1.8813 - val_accuracy: 0.5034\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 0.9906 - val_loss: 1.9131 - val_accuracy: 0.4899\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0305 - accuracy: 0.9944 - val_loss: 2.0370 - val_accuracy: 0.4631\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 1.9539 - val_accuracy: 0.4832\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.9981 - val_loss: 2.0617 - val_accuracy: 0.5101\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.1286 - val_accuracy: 0.4832\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0158 - accuracy: 0.9981 - val_loss: 2.1736 - val_accuracy: 0.5101\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9981 - val_loss: 2.2247 - val_accuracy: 0.5034\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.2925 - val_accuracy: 0.4966\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.3448 - val_accuracy: 0.4966\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 2.3934 - val_accuracy: 0.4966\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.4401 - val_accuracy: 0.4899\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.4256 - val_accuracy: 0.4966\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.4510 - val_accuracy: 0.5034\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.5053 - val_accuracy: 0.5101\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.5501 - val_accuracy: 0.4899\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.5749 - val_accuracy: 0.5101\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.6111 - val_accuracy: 0.4966\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.6341 - val_accuracy: 0.4899\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.6628 - val_accuracy: 0.4966\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.7015 - val_accuracy: 0.5034\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.7333 - val_accuracy: 0.4832\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.7585 - val_accuracy: 0.4899\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.7749 - val_accuracy: 0.4966\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.8036 - val_accuracy: 0.5101\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.8253 - val_accuracy: 0.5034\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.8412 - val_accuracy: 0.4966\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.8632 - val_accuracy: 0.5034\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.8983 - val_accuracy: 0.5034\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.9130 - val_accuracy: 0.4966\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.9378 - val_accuracy: 0.5034\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.9474 - val_accuracy: 0.4899\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.9611 - val_accuracy: 0.5034\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.9878 - val_accuracy: 0.5034\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.0091 - val_accuracy: 0.4899\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.0218 - val_accuracy: 0.5034\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.0385 - val_accuracy: 0.5034\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.0538 - val_accuracy: 0.4899\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.0678 - val_accuracy: 0.5034\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 9.9702e-04 - accuracy: 1.0000 - val_loss: 3.0841 - val_accuracy: 0.5101\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.7162e-04 - accuracy: 1.0000 - val_loss: 3.1127 - val_accuracy: 0.4966\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.7671e-04 - accuracy: 1.0000 - val_loss: 3.1271 - val_accuracy: 0.4966\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.0143e-04 - accuracy: 1.0000 - val_loss: 3.1293 - val_accuracy: 0.5034\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 8.8568e-04 - accuracy: 1.0000 - val_loss: 3.1477 - val_accuracy: 0.4966\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.2614e-04 - accuracy: 1.0000 - val_loss: 3.1706 - val_accuracy: 0.5034\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.3178e-04 - accuracy: 1.0000 - val_loss: 3.1834 - val_accuracy: 0.5101\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.8629e-04 - accuracy: 1.0000 - val_loss: 3.2007 - val_accuracy: 0.5034\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7718e-04 - accuracy: 1.0000 - val_loss: 3.2174 - val_accuracy: 0.4966\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.6800e-04 - accuracy: 1.0000 - val_loss: 3.2299 - val_accuracy: 0.4899\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.1961e-04 - accuracy: 1.0000 - val_loss: 3.2396 - val_accuracy: 0.4966\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.8948e-04 - accuracy: 1.0000 - val_loss: 3.2621 - val_accuracy: 0.5034\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 6.5296e-04 - accuracy: 1.0000 - val_loss: 3.2695 - val_accuracy: 0.5101\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 6.4805e-04 - accuracy: 1.0000 - val_loss: 3.2828 - val_accuracy: 0.4966\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 6.2588e-04 - accuracy: 1.0000 - val_loss: 3.2964 - val_accuracy: 0.5034\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 6.0108e-04 - accuracy: 1.0000 - val_loss: 3.3131 - val_accuracy: 0.5101\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5.8860e-04 - accuracy: 1.0000 - val_loss: 3.3249 - val_accuracy: 0.5034\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5.6841e-04 - accuracy: 1.0000 - val_loss: 3.3421 - val_accuracy: 0.5034\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.5143e-04 - accuracy: 1.0000 - val_loss: 3.3527 - val_accuracy: 0.5034\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5.3940e-04 - accuracy: 1.0000 - val_loss: 3.3689 - val_accuracy: 0.5034\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5.2002e-04 - accuracy: 1.0000 - val_loss: 3.3771 - val_accuracy: 0.5101\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5.2181e-04 - accuracy: 1.0000 - val_loss: 3.3825 - val_accuracy: 0.4966\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.0107e-04 - accuracy: 1.0000 - val_loss: 3.3964 - val_accuracy: 0.4966\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.8407e-04 - accuracy: 1.0000 - val_loss: 3.4137 - val_accuracy: 0.4966\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.6356e-04 - accuracy: 1.0000 - val_loss: 3.4295 - val_accuracy: 0.5034\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.5028e-04 - accuracy: 1.0000 - val_loss: 3.4340 - val_accuracy: 0.5034\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.3741e-04 - accuracy: 1.0000 - val_loss: 3.4508 - val_accuracy: 0.5034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15c4f4b80>"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_2_4 = Sequential()\n",
    "model_1_2_4.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features)))\n",
    "model_1_2_4.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_1_2_4.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_1_2_4.add(MaxPooling1D(pool_size=2)) \n",
    "model_1_2_4.add(Conv1D(filters=32, kernel_size=1, activation='relu')) \n",
    "model_1_2_4.add(Flatten())\n",
    "model_1_2_4.add(Dense(50, activation='relu')) \n",
    "model_1_2_4.add(Dense(1, activation='sigmoid')) \n",
    "model_1_2_4.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_1_2_4.fit(train_X_1_2,train_f1t_tc,epochs=100,  validation_data=(val_X_1_2, val_f1t_tc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872a84ba",
   "metadata": {},
   "source": [
    "## Model_1_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "e3b772d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with 8 components to explain 85% of variance\n",
    "sklearn_pca = PCA(n_components=7)\n",
    "train_X_1_3 = pd.DataFrame(sklearn_pca.fit_transform(train_f1[feats_1]))\n",
    "val_X_1_3 = pd.DataFrame(sklearn_pca.transform(val_f1[feats_1]))\n",
    "test_X_1_3 = pd.DataFrame(sklearn_pca.transform(test_f1[feats_1]))\n",
    "train_X_1_3, _ = df_to_X_np(train_X_1_3)\n",
    "val_X_1_3, _ = df_to_X_np(val_X_1_3)\n",
    "test_X_1_3, _ = df_to_X_np(test_X_1_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "d7ee7bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 12ms/step - loss: 0.6988 - accuracy: 0.5338 - val_loss: 0.7090 - val_accuracy: 0.4966\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5395 - val_loss: 0.7026 - val_accuracy: 0.5168\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6896 - accuracy: 0.5564 - val_loss: 0.7027 - val_accuracy: 0.5302\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.5639 - val_loss: 0.7003 - val_accuracy: 0.5235\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6853 - accuracy: 0.5658 - val_loss: 0.6997 - val_accuracy: 0.5101\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6843 - accuracy: 0.5677 - val_loss: 0.7013 - val_accuracy: 0.5034\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6823 - accuracy: 0.5752 - val_loss: 0.6966 - val_accuracy: 0.4966\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6809 - accuracy: 0.5789 - val_loss: 0.6991 - val_accuracy: 0.4698\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.6034 - val_loss: 0.6981 - val_accuracy: 0.4698\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6775 - accuracy: 0.5996 - val_loss: 0.6969 - val_accuracy: 0.4899\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6759 - accuracy: 0.6034 - val_loss: 0.6973 - val_accuracy: 0.5034\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6746 - accuracy: 0.6071 - val_loss: 0.6982 - val_accuracy: 0.4631\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6732 - accuracy: 0.6015 - val_loss: 0.6984 - val_accuracy: 0.4765\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.6109 - val_loss: 0.6989 - val_accuracy: 0.4698\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.5883 - val_loss: 0.6962 - val_accuracy: 0.5101\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6694 - accuracy: 0.6109 - val_loss: 0.6989 - val_accuracy: 0.4698\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.6015 - val_loss: 0.7001 - val_accuracy: 0.4765\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6678 - accuracy: 0.6015 - val_loss: 0.6998 - val_accuracy: 0.4631\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6660 - accuracy: 0.6034 - val_loss: 0.6982 - val_accuracy: 0.4765\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6654 - accuracy: 0.6090 - val_loss: 0.6980 - val_accuracy: 0.4899\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6636 - accuracy: 0.6053 - val_loss: 0.6973 - val_accuracy: 0.4966\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6625 - accuracy: 0.6184 - val_loss: 0.6992 - val_accuracy: 0.4765\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 0.6184 - val_loss: 0.6999 - val_accuracy: 0.4765\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6600 - accuracy: 0.6259 - val_loss: 0.7004 - val_accuracy: 0.4832\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6591 - accuracy: 0.6316 - val_loss: 0.6986 - val_accuracy: 0.4966\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6574 - accuracy: 0.6335 - val_loss: 0.7001 - val_accuracy: 0.4966\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6562 - accuracy: 0.6316 - val_loss: 0.6998 - val_accuracy: 0.4966\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6548 - accuracy: 0.6297 - val_loss: 0.6989 - val_accuracy: 0.4966\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6540 - accuracy: 0.6297 - val_loss: 0.6999 - val_accuracy: 0.5034\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6525 - accuracy: 0.6410 - val_loss: 0.7023 - val_accuracy: 0.4966\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6525 - accuracy: 0.6241 - val_loss: 0.7009 - val_accuracy: 0.5101\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6509 - accuracy: 0.6335 - val_loss: 0.7038 - val_accuracy: 0.5101\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6509 - accuracy: 0.6391 - val_loss: 0.7029 - val_accuracy: 0.5034\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6488 - accuracy: 0.6391 - val_loss: 0.7000 - val_accuracy: 0.5168\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6469 - accuracy: 0.6447 - val_loss: 0.7003 - val_accuracy: 0.5101\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6453 - accuracy: 0.6410 - val_loss: 0.7009 - val_accuracy: 0.5101\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6464 - accuracy: 0.6391 - val_loss: 0.7023 - val_accuracy: 0.5034\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6454 - accuracy: 0.6579 - val_loss: 0.7061 - val_accuracy: 0.5034\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.6410 - val_loss: 0.6999 - val_accuracy: 0.5034\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6417 - accuracy: 0.6447 - val_loss: 0.7020 - val_accuracy: 0.5235\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.6523 - val_loss: 0.7029 - val_accuracy: 0.5168\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6385 - accuracy: 0.6560 - val_loss: 0.7049 - val_accuracy: 0.5101\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.6366 - accuracy: 0.6541 - val_loss: 0.7010 - val_accuracy: 0.5034\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.6579 - val_loss: 0.7034 - val_accuracy: 0.5034\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6340 - accuracy: 0.6635 - val_loss: 0.7013 - val_accuracy: 0.5101\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.6635 - val_loss: 0.7014 - val_accuracy: 0.5168\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6326 - accuracy: 0.6579 - val_loss: 0.7017 - val_accuracy: 0.5101\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6316 - accuracy: 0.6635 - val_loss: 0.7042 - val_accuracy: 0.5101\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.6579 - val_loss: 0.7045 - val_accuracy: 0.5168\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6281 - accuracy: 0.6541 - val_loss: 0.7047 - val_accuracy: 0.5101\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6264 - accuracy: 0.6635 - val_loss: 0.7031 - val_accuracy: 0.5101\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6248 - accuracy: 0.6786 - val_loss: 0.7048 - val_accuracy: 0.5101\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6236 - accuracy: 0.6617 - val_loss: 0.7064 - val_accuracy: 0.5034\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6221 - accuracy: 0.6654 - val_loss: 0.7111 - val_accuracy: 0.5101\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.6767 - val_loss: 0.7073 - val_accuracy: 0.5101\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6192 - accuracy: 0.6805 - val_loss: 0.7068 - val_accuracy: 0.5034\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6189 - accuracy: 0.6617 - val_loss: 0.7061 - val_accuracy: 0.5101\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6167 - accuracy: 0.6805 - val_loss: 0.7113 - val_accuracy: 0.5302\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6150 - accuracy: 0.6805 - val_loss: 0.7077 - val_accuracy: 0.5302\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6150 - accuracy: 0.6711 - val_loss: 0.7094 - val_accuracy: 0.5034\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6140 - accuracy: 0.6786 - val_loss: 0.7080 - val_accuracy: 0.5101\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6098 - accuracy: 0.6955 - val_loss: 0.7138 - val_accuracy: 0.5101\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6102 - accuracy: 0.6936 - val_loss: 0.7112 - val_accuracy: 0.5101\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6936 - val_loss: 0.7141 - val_accuracy: 0.5034\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6067 - accuracy: 0.6974 - val_loss: 0.7122 - val_accuracy: 0.5235\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6065 - accuracy: 0.6955 - val_loss: 0.7114 - val_accuracy: 0.5168\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6040 - accuracy: 0.6974 - val_loss: 0.7130 - val_accuracy: 0.5235\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6027 - accuracy: 0.7049 - val_loss: 0.7135 - val_accuracy: 0.5235\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6012 - accuracy: 0.6974 - val_loss: 0.7134 - val_accuracy: 0.5168\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5989 - accuracy: 0.7124 - val_loss: 0.7168 - val_accuracy: 0.5235\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5975 - accuracy: 0.7180 - val_loss: 0.7151 - val_accuracy: 0.5101\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.7030 - val_loss: 0.7200 - val_accuracy: 0.5101\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5953 - accuracy: 0.7124 - val_loss: 0.7184 - val_accuracy: 0.5235\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5931 - accuracy: 0.7180 - val_loss: 0.7216 - val_accuracy: 0.5168\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5909 - accuracy: 0.7162 - val_loss: 0.7201 - val_accuracy: 0.5302\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5904 - accuracy: 0.7199 - val_loss: 0.7255 - val_accuracy: 0.5369\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5881 - accuracy: 0.7274 - val_loss: 0.7222 - val_accuracy: 0.5302\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5872 - accuracy: 0.7237 - val_loss: 0.7215 - val_accuracy: 0.5302\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5866 - accuracy: 0.7180 - val_loss: 0.7257 - val_accuracy: 0.5235\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5841 - accuracy: 0.7199 - val_loss: 0.7253 - val_accuracy: 0.5302\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.5821 - accuracy: 0.7274 - val_loss: 0.7241 - val_accuracy: 0.5302\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5806 - accuracy: 0.7256 - val_loss: 0.7248 - val_accuracy: 0.5369\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.7293 - val_loss: 0.7278 - val_accuracy: 0.5302\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5801 - accuracy: 0.7274 - val_loss: 0.7289 - val_accuracy: 0.5369\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5782 - accuracy: 0.7368 - val_loss: 0.7340 - val_accuracy: 0.5302\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5754 - accuracy: 0.7312 - val_loss: 0.7288 - val_accuracy: 0.5436\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5733 - accuracy: 0.7331 - val_loss: 0.7301 - val_accuracy: 0.5436\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.7350 - val_loss: 0.7318 - val_accuracy: 0.5369\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5706 - accuracy: 0.7387 - val_loss: 0.7367 - val_accuracy: 0.5302\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5706 - accuracy: 0.7387 - val_loss: 0.7357 - val_accuracy: 0.5302\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.7444 - val_loss: 0.7348 - val_accuracy: 0.5436\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.7387 - val_loss: 0.7353 - val_accuracy: 0.5369\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5661 - accuracy: 0.7462 - val_loss: 0.7386 - val_accuracy: 0.5436\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5644 - accuracy: 0.7481 - val_loss: 0.7356 - val_accuracy: 0.5369\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5627 - accuracy: 0.7481 - val_loss: 0.7399 - val_accuracy: 0.5369\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5620 - accuracy: 0.7538 - val_loss: 0.7425 - val_accuracy: 0.5369\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.7425 - val_loss: 0.7410 - val_accuracy: 0.5436\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5598 - accuracy: 0.7594 - val_loss: 0.7422 - val_accuracy: 0.5570\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5602 - accuracy: 0.7462 - val_loss: 0.7451 - val_accuracy: 0.5101\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.5556 - accuracy: 0.7707 - val_loss: 0.7465 - val_accuracy: 0.5436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15c6caee0>"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = train_X_1_3.shape[1]\n",
    "n_features = train_X_1_3.shape[2]\n",
    "\n",
    "model_1_3_1 = Sequential()\n",
    "model_1_3_1.add(Conv1D(filters=5, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model_1_3_1.add(MaxPooling1D(pool_size=2)) \n",
    "model_1_3_1.add(Flatten())\n",
    "model_1_3_1.add(Dense(50, activation='relu')) \n",
    "model_1_3_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_1_3_1.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_1_3_1.fit(train_X_1_3, train_f1t_tc,epochs=100,  validation_data=(val_X_1_3, val_f1t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "fd59010d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 13ms/step - loss: 0.6931 - accuracy: 0.5150 - val_loss: 0.6992 - val_accuracy: 0.5168\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6783 - accuracy: 0.5526 - val_loss: 0.7006 - val_accuracy: 0.5101\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6702 - accuracy: 0.5902 - val_loss: 0.7006 - val_accuracy: 0.5235\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6635 - accuracy: 0.6222 - val_loss: 0.7023 - val_accuracy: 0.5034\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6577 - accuracy: 0.6541 - val_loss: 0.7037 - val_accuracy: 0.5034\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6505 - accuracy: 0.6466 - val_loss: 0.7059 - val_accuracy: 0.4966\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6416 - accuracy: 0.6898 - val_loss: 0.7092 - val_accuracy: 0.4765\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6375 - accuracy: 0.6767 - val_loss: 0.7112 - val_accuracy: 0.4832\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6265 - accuracy: 0.6786 - val_loss: 0.7153 - val_accuracy: 0.4765\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6191 - accuracy: 0.7143 - val_loss: 0.7207 - val_accuracy: 0.4631\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6089 - accuracy: 0.7011 - val_loss: 0.7252 - val_accuracy: 0.4698\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6028 - accuracy: 0.7180 - val_loss: 0.7283 - val_accuracy: 0.4832\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5920 - accuracy: 0.7218 - val_loss: 0.7363 - val_accuracy: 0.4765\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5835 - accuracy: 0.7462 - val_loss: 0.7489 - val_accuracy: 0.4832\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5752 - accuracy: 0.7368 - val_loss: 0.7469 - val_accuracy: 0.4698\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5636 - accuracy: 0.7462 - val_loss: 0.7560 - val_accuracy: 0.4631\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5518 - accuracy: 0.7650 - val_loss: 0.7623 - val_accuracy: 0.4765\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.7650 - val_loss: 0.7700 - val_accuracy: 0.4497\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.7763 - val_loss: 0.7766 - val_accuracy: 0.4362\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5233 - accuracy: 0.7744 - val_loss: 0.7771 - val_accuracy: 0.4497\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7895 - val_loss: 0.7951 - val_accuracy: 0.4295\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7914 - val_loss: 0.8062 - val_accuracy: 0.4430\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.8064 - val_loss: 0.8136 - val_accuracy: 0.4362\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.8252 - val_loss: 0.8161 - val_accuracy: 0.4362\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.8252 - val_loss: 0.8265 - val_accuracy: 0.4430\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.8214 - val_loss: 0.8364 - val_accuracy: 0.4430\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.8214 - val_loss: 0.8508 - val_accuracy: 0.4497\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.8327 - val_loss: 0.8662 - val_accuracy: 0.4295\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.8477 - val_loss: 0.8695 - val_accuracy: 0.4497\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8534 - val_loss: 0.8763 - val_accuracy: 0.4430\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3932 - accuracy: 0.8665 - val_loss: 0.8899 - val_accuracy: 0.4497\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3850 - accuracy: 0.8703 - val_loss: 0.8967 - val_accuracy: 0.4497\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3742 - accuracy: 0.8703 - val_loss: 0.8996 - val_accuracy: 0.4631\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8797 - val_loss: 0.9174 - val_accuracy: 0.4497\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.3552 - accuracy: 0.8853 - val_loss: 0.9298 - val_accuracy: 0.4430\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.3388 - accuracy: 0.8910 - val_loss: 0.9295 - val_accuracy: 0.4497\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3274 - accuracy: 0.9079 - val_loss: 0.9632 - val_accuracy: 0.4362\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3176 - accuracy: 0.9004 - val_loss: 0.9677 - val_accuracy: 0.4430\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3077 - accuracy: 0.9229 - val_loss: 0.9742 - val_accuracy: 0.4362\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2966 - accuracy: 0.9173 - val_loss: 1.0017 - val_accuracy: 0.4362\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2846 - accuracy: 0.9267 - val_loss: 1.0277 - val_accuracy: 0.4161\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2846 - accuracy: 0.9323 - val_loss: 1.0059 - val_accuracy: 0.4631\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2726 - accuracy: 0.9342 - val_loss: 1.0345 - val_accuracy: 0.4027\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2548 - accuracy: 0.9455 - val_loss: 1.0571 - val_accuracy: 0.4430\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2454 - accuracy: 0.9586 - val_loss: 1.0603 - val_accuracy: 0.4295\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2382 - accuracy: 0.9474 - val_loss: 1.0686 - val_accuracy: 0.4362\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2325 - accuracy: 0.9549 - val_loss: 1.0763 - val_accuracy: 0.4228\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2202 - accuracy: 0.9756 - val_loss: 1.1246 - val_accuracy: 0.4094\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2158 - accuracy: 0.9624 - val_loss: 1.0962 - val_accuracy: 0.4161\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.2032 - accuracy: 0.9774 - val_loss: 1.1288 - val_accuracy: 0.4228\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1986 - accuracy: 0.9718 - val_loss: 1.1370 - val_accuracy: 0.4295\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1861 - accuracy: 0.9850 - val_loss: 1.1467 - val_accuracy: 0.4295\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1801 - accuracy: 0.9718 - val_loss: 1.1633 - val_accuracy: 0.4228\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1758 - accuracy: 0.9887 - val_loss: 1.1890 - val_accuracy: 0.4094\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1722 - accuracy: 0.9774 - val_loss: 1.2060 - val_accuracy: 0.4362\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1616 - accuracy: 0.9868 - val_loss: 1.2128 - val_accuracy: 0.3960\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1486 - accuracy: 0.9887 - val_loss: 1.2333 - val_accuracy: 0.4161\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1464 - accuracy: 0.9887 - val_loss: 1.2465 - val_accuracy: 0.4362\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1384 - accuracy: 0.9944 - val_loss: 1.2509 - val_accuracy: 0.4362\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1305 - accuracy: 0.9944 - val_loss: 1.2661 - val_accuracy: 0.4228\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1270 - accuracy: 0.9944 - val_loss: 1.2789 - val_accuracy: 0.4027\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1191 - accuracy: 0.9944 - val_loss: 1.2828 - val_accuracy: 0.4362\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1180 - accuracy: 0.9925 - val_loss: 1.3000 - val_accuracy: 0.4228\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1135 - accuracy: 0.9944 - val_loss: 1.3111 - val_accuracy: 0.4362\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1139 - accuracy: 0.9906 - val_loss: 1.3458 - val_accuracy: 0.4228\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1043 - accuracy: 0.9944 - val_loss: 1.3429 - val_accuracy: 0.4027\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0967 - accuracy: 1.0000 - val_loss: 1.3625 - val_accuracy: 0.4228\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0928 - accuracy: 0.9981 - val_loss: 1.3869 - val_accuracy: 0.4295\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0917 - accuracy: 0.9981 - val_loss: 1.3900 - val_accuracy: 0.4295\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0866 - accuracy: 1.0000 - val_loss: 1.4007 - val_accuracy: 0.4228\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0823 - accuracy: 0.9981 - val_loss: 1.4024 - val_accuracy: 0.4362\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0802 - accuracy: 1.0000 - val_loss: 1.4455 - val_accuracy: 0.4161\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0748 - accuracy: 1.0000 - val_loss: 1.4419 - val_accuracy: 0.4228\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0732 - accuracy: 1.0000 - val_loss: 1.4514 - val_accuracy: 0.4228\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 1.0000 - val_loss: 1.4783 - val_accuracy: 0.4228\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 1.0000 - val_loss: 1.4765 - val_accuracy: 0.4295\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 1.5087 - val_accuracy: 0.4228\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 1.5077 - val_accuracy: 0.4228\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 1.0000 - val_loss: 1.5288 - val_accuracy: 0.4362\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 1.5437 - val_accuracy: 0.4295\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0539 - accuracy: 1.0000 - val_loss: 1.5561 - val_accuracy: 0.4362\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 1.5464 - val_accuracy: 0.4295\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 1.5989 - val_accuracy: 0.4295\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 1.5904 - val_accuracy: 0.4362\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 1.6080 - val_accuracy: 0.4430\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 1.6193 - val_accuracy: 0.4362\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 1.6392 - val_accuracy: 0.4430\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 1.6471 - val_accuracy: 0.4430\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 1.6465 - val_accuracy: 0.4362\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 1.6707 - val_accuracy: 0.4497\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 1.6785 - val_accuracy: 0.4362\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 1.6847 - val_accuracy: 0.4228\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 1.6954 - val_accuracy: 0.4362\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 1.7158 - val_accuracy: 0.4497\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 1.7260 - val_accuracy: 0.4295\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 1.7338 - val_accuracy: 0.4295\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 1.7450 - val_accuracy: 0.4362\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 1.7643 - val_accuracy: 0.4430\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 1.7676 - val_accuracy: 0.4430\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 1.7859 - val_accuracy: 0.4295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15c844e80>"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_3_2 = Sequential()\n",
    "model_1_3_2.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features))) \n",
    "model_1_3_2.add(MaxPooling1D(pool_size=2)) \n",
    "model_1_3_2.add(Flatten())\n",
    "model_1_3_2.add(Dense(50, activation='relu')) \n",
    "model_1_3_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_1_3_2.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_1_3_2.fit(train_X_1_3,train_f1t_tc,epochs=100,  validation_data=(val_X_1_3, val_f1t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "037b2bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 13ms/step - loss: 0.6960 - accuracy: 0.4925 - val_loss: 0.6994 - val_accuracy: 0.4698\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6864 - accuracy: 0.5451 - val_loss: 0.7026 - val_accuracy: 0.4899\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6803 - accuracy: 0.5771 - val_loss: 0.7019 - val_accuracy: 0.4430\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6738 - accuracy: 0.5714 - val_loss: 0.7070 - val_accuracy: 0.4765\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6675 - accuracy: 0.5921 - val_loss: 0.7066 - val_accuracy: 0.4564\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6574 - accuracy: 0.6429 - val_loss: 0.7135 - val_accuracy: 0.4765\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.6673 - val_loss: 0.7159 - val_accuracy: 0.4698\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6326 - accuracy: 0.6898 - val_loss: 0.7199 - val_accuracy: 0.5101\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6177 - accuracy: 0.7218 - val_loss: 0.7249 - val_accuracy: 0.5369\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6003 - accuracy: 0.7162 - val_loss: 0.7272 - val_accuracy: 0.5168\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5800 - accuracy: 0.7312 - val_loss: 0.7395 - val_accuracy: 0.5101\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5649 - accuracy: 0.7425 - val_loss: 0.7828 - val_accuracy: 0.4899\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5349 - accuracy: 0.7688 - val_loss: 0.7628 - val_accuracy: 0.4631\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.7951 - val_loss: 0.7786 - val_accuracy: 0.4832\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4889 - accuracy: 0.8102 - val_loss: 0.8059 - val_accuracy: 0.5101\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.8026 - val_loss: 0.8194 - val_accuracy: 0.4765\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.8402 - val_loss: 0.8373 - val_accuracy: 0.4765\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8590 - val_loss: 0.8636 - val_accuracy: 0.4765\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3744 - accuracy: 0.8835 - val_loss: 0.9051 - val_accuracy: 0.4698\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3555 - accuracy: 0.8722 - val_loss: 0.9400 - val_accuracy: 0.4631\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3265 - accuracy: 0.8929 - val_loss: 0.9417 - val_accuracy: 0.4631\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3101 - accuracy: 0.8759 - val_loss: 1.0003 - val_accuracy: 0.4698\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2881 - accuracy: 0.9117 - val_loss: 1.0172 - val_accuracy: 0.4765\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2569 - accuracy: 0.9267 - val_loss: 1.0405 - val_accuracy: 0.4899\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2374 - accuracy: 0.9361 - val_loss: 1.0618 - val_accuracy: 0.4698\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2277 - accuracy: 0.9436 - val_loss: 1.1065 - val_accuracy: 0.4698\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2052 - accuracy: 0.9530 - val_loss: 1.1712 - val_accuracy: 0.4832\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1858 - accuracy: 0.9568 - val_loss: 1.2892 - val_accuracy: 0.4631\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1955 - accuracy: 0.9511 - val_loss: 1.1978 - val_accuracy: 0.4631\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1729 - accuracy: 0.9586 - val_loss: 1.3052 - val_accuracy: 0.4631\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1530 - accuracy: 0.9699 - val_loss: 1.2475 - val_accuracy: 0.4631\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1326 - accuracy: 0.9831 - val_loss: 1.3360 - val_accuracy: 0.4564\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1202 - accuracy: 0.9906 - val_loss: 1.3285 - val_accuracy: 0.4966\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1131 - accuracy: 0.9850 - val_loss: 1.4389 - val_accuracy: 0.4698\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1037 - accuracy: 0.9831 - val_loss: 1.4374 - val_accuracy: 0.4832\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0996 - accuracy: 0.9850 - val_loss: 1.4578 - val_accuracy: 0.4430\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0992 - accuracy: 0.9850 - val_loss: 1.4974 - val_accuracy: 0.4765\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0841 - accuracy: 0.9981 - val_loss: 1.5808 - val_accuracy: 0.4698\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0820 - accuracy: 0.9887 - val_loss: 1.5663 - val_accuracy: 0.4228\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0786 - accuracy: 0.9962 - val_loss: 1.6060 - val_accuracy: 0.4899\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.9962 - val_loss: 1.6143 - val_accuracy: 0.4698\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 0.9981 - val_loss: 1.6514 - val_accuracy: 0.4631\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.9981 - val_loss: 1.7063 - val_accuracy: 0.4564\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 1.7293 - val_accuracy: 0.4631\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 1.7559 - val_accuracy: 0.4765\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 1.7955 - val_accuracy: 0.4765\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 1.8209 - val_accuracy: 0.4564\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 1.8526 - val_accuracy: 0.4497\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 1.8948 - val_accuracy: 0.4497\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 1.9142 - val_accuracy: 0.4430\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 1.9930 - val_accuracy: 0.4631\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 1.9594 - val_accuracy: 0.4631\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 1.9907 - val_accuracy: 0.4564\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 2.0311 - val_accuracy: 0.4564\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 2.0537 - val_accuracy: 0.4564\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 2.0839 - val_accuracy: 0.4497\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.1018 - val_accuracy: 0.4497\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.1401 - val_accuracy: 0.4362\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.1708 - val_accuracy: 0.4430\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.1809 - val_accuracy: 0.4497\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 2.2161 - val_accuracy: 0.4362\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 2.2272 - val_accuracy: 0.4430\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.2509 - val_accuracy: 0.4295\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.2741 - val_accuracy: 0.4430\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.2842 - val_accuracy: 0.4497\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.3189 - val_accuracy: 0.4564\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.3244 - val_accuracy: 0.4228\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.3638 - val_accuracy: 0.4362\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.3831 - val_accuracy: 0.4362\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.3984 - val_accuracy: 0.4430\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.4181 - val_accuracy: 0.4430\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.4575 - val_accuracy: 0.4430\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.4521 - val_accuracy: 0.4430\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.4784 - val_accuracy: 0.4497\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.5043 - val_accuracy: 0.4497\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.5083 - val_accuracy: 0.4497\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.5286 - val_accuracy: 0.4430\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.5372 - val_accuracy: 0.4362\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.5619 - val_accuracy: 0.4430\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.5836 - val_accuracy: 0.4497\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.6037 - val_accuracy: 0.4430\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.6103 - val_accuracy: 0.4430\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.6197 - val_accuracy: 0.4362\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.6331 - val_accuracy: 0.4497\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.6648 - val_accuracy: 0.4497\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.6762 - val_accuracy: 0.4430\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.6967 - val_accuracy: 0.4430\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.7024 - val_accuracy: 0.4430\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.7231 - val_accuracy: 0.4362\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.7311 - val_accuracy: 0.4430\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.7464 - val_accuracy: 0.4564\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.7504 - val_accuracy: 0.4497\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.7861 - val_accuracy: 0.4362\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.7845 - val_accuracy: 0.4430\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.8029 - val_accuracy: 0.4430\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.8011 - val_accuracy: 0.4430\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.8308 - val_accuracy: 0.4362\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.8369 - val_accuracy: 0.4430\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.8435 - val_accuracy: 0.4430\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.8750 - val_accuracy: 0.4362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15c999bb0>"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_3_3 = Sequential()\n",
    "model_1_3_3.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features)))\n",
    "model_1_3_3.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_1_3_3.add(MaxPooling1D(pool_size=2)) \n",
    "model_1_3_3.add(Flatten())\n",
    "model_1_3_3.add(Dense(50, activation='relu')) \n",
    "model_1_3_3.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model_1_3_3.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_1_3_3.fit(train_X_1_3,train_f1t_tc,epochs=100,  validation_data=(val_X_1_3, val_f1t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "cc51754d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 16ms/step - loss: 0.6928 - accuracy: 0.5338 - val_loss: 0.6943 - val_accuracy: 0.5034\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6894 - accuracy: 0.5301 - val_loss: 0.6935 - val_accuracy: 0.5034\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6865 - accuracy: 0.5432 - val_loss: 0.6947 - val_accuracy: 0.5034\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6811 - accuracy: 0.5376 - val_loss: 0.6937 - val_accuracy: 0.5168\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.6737 - accuracy: 0.5564 - val_loss: 0.6933 - val_accuracy: 0.4899\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6624 - accuracy: 0.6184 - val_loss: 0.6956 - val_accuracy: 0.4966\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6444 - accuracy: 0.6805 - val_loss: 0.7027 - val_accuracy: 0.4362\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6116 - accuracy: 0.7030 - val_loss: 0.7090 - val_accuracy: 0.5235\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5703 - accuracy: 0.7519 - val_loss: 0.7342 - val_accuracy: 0.5369\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7556 - val_loss: 0.8199 - val_accuracy: 0.4228\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7914 - val_loss: 0.7971 - val_accuracy: 0.5034\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8346 - val_loss: 0.8631 - val_accuracy: 0.4430\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3557 - accuracy: 0.8665 - val_loss: 0.8925 - val_accuracy: 0.5369\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3160 - accuracy: 0.8703 - val_loss: 0.9493 - val_accuracy: 0.4899\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2622 - accuracy: 0.9154 - val_loss: 0.9933 - val_accuracy: 0.5235\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2130 - accuracy: 0.9323 - val_loss: 1.0047 - val_accuracy: 0.5101\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1719 - accuracy: 0.9624 - val_loss: 1.1353 - val_accuracy: 0.5101\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1633 - accuracy: 0.9530 - val_loss: 1.1649 - val_accuracy: 0.5235\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1291 - accuracy: 0.9643 - val_loss: 1.3751 - val_accuracy: 0.4966\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1044 - accuracy: 0.9737 - val_loss: 1.3487 - val_accuracy: 0.5168\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0801 - accuracy: 0.9887 - val_loss: 1.4090 - val_accuracy: 0.5101\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 1.5227 - val_accuracy: 0.5369\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0448 - accuracy: 0.9981 - val_loss: 1.6226 - val_accuracy: 0.5101\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9981 - val_loss: 1.6234 - val_accuracy: 0.4899\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 0.9981 - val_loss: 1.7121 - val_accuracy: 0.5101\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0336 - accuracy: 0.9981 - val_loss: 1.8250 - val_accuracy: 0.5302\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.9962 - val_loss: 1.9826 - val_accuracy: 0.5235\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0620 - accuracy: 0.9793 - val_loss: 1.9884 - val_accuracy: 0.4698\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9906 - val_loss: 1.9221 - val_accuracy: 0.5235\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0229 - accuracy: 0.9981 - val_loss: 1.8984 - val_accuracy: 0.5168\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.9654 - val_accuracy: 0.5235\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.0421 - val_accuracy: 0.5302\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.0763 - val_accuracy: 0.5168\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.1044 - val_accuracy: 0.5168\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.1412 - val_accuracy: 0.5168\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.1487 - val_accuracy: 0.5235\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.1904 - val_accuracy: 0.5235\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.2341 - val_accuracy: 0.5168\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.2515 - val_accuracy: 0.5235\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.2879 - val_accuracy: 0.5168\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.3037 - val_accuracy: 0.5235\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.3098 - val_accuracy: 0.5168\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.3513 - val_accuracy: 0.5235\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.3561 - val_accuracy: 0.5168\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.3897 - val_accuracy: 0.5168\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4089 - val_accuracy: 0.5168\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.4239 - val_accuracy: 0.5168\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.4363 - val_accuracy: 0.5168\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.4639 - val_accuracy: 0.5168\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.4758 - val_accuracy: 0.5168\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.5119 - val_accuracy: 0.5235\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5074 - val_accuracy: 0.5168\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.5376 - val_accuracy: 0.5168\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.5461 - val_accuracy: 0.5235\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.5682 - val_accuracy: 0.5168\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.5806 - val_accuracy: 0.5168\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.5980 - val_accuracy: 0.5168\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6144 - val_accuracy: 0.5168\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.6307 - val_accuracy: 0.5235\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.8562e-04 - accuracy: 1.0000 - val_loss: 2.6446 - val_accuracy: 0.5168\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.5099e-04 - accuracy: 1.0000 - val_loss: 2.6533 - val_accuracy: 0.5235\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.0847e-04 - accuracy: 1.0000 - val_loss: 2.6793 - val_accuracy: 0.5168\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.7961e-04 - accuracy: 1.0000 - val_loss: 2.6811 - val_accuracy: 0.5235\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 8.4177e-04 - accuracy: 1.0000 - val_loss: 2.7047 - val_accuracy: 0.5168\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.0245e-04 - accuracy: 1.0000 - val_loss: 2.7124 - val_accuracy: 0.5235\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 7.7550e-04 - accuracy: 1.0000 - val_loss: 2.7327 - val_accuracy: 0.5235\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.4010e-04 - accuracy: 1.0000 - val_loss: 2.7456 - val_accuracy: 0.5235\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.0923e-04 - accuracy: 1.0000 - val_loss: 2.7635 - val_accuracy: 0.5235\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 6.8843e-04 - accuracy: 1.0000 - val_loss: 2.7786 - val_accuracy: 0.5235\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 6.4983e-04 - accuracy: 1.0000 - val_loss: 2.7888 - val_accuracy: 0.5235\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 6.2391e-04 - accuracy: 1.0000 - val_loss: 2.8082 - val_accuracy: 0.5235\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5.9264e-04 - accuracy: 1.0000 - val_loss: 2.8268 - val_accuracy: 0.5235\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5.6575e-04 - accuracy: 1.0000 - val_loss: 2.8436 - val_accuracy: 0.5235\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 5.4394e-04 - accuracy: 1.0000 - val_loss: 2.8620 - val_accuracy: 0.5235\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5.1867e-04 - accuracy: 1.0000 - val_loss: 2.8794 - val_accuracy: 0.5235\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.9301e-04 - accuracy: 1.0000 - val_loss: 2.8963 - val_accuracy: 0.5235\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.6868e-04 - accuracy: 1.0000 - val_loss: 2.9145 - val_accuracy: 0.5235\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.4656e-04 - accuracy: 1.0000 - val_loss: 2.9278 - val_accuracy: 0.5235\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.2617e-04 - accuracy: 1.0000 - val_loss: 2.9473 - val_accuracy: 0.5235\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.0637e-04 - accuracy: 1.0000 - val_loss: 2.9615 - val_accuracy: 0.5235\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.8928e-04 - accuracy: 1.0000 - val_loss: 2.9845 - val_accuracy: 0.5235\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.7056e-04 - accuracy: 1.0000 - val_loss: 2.9958 - val_accuracy: 0.5235\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.5319e-04 - accuracy: 1.0000 - val_loss: 3.0150 - val_accuracy: 0.5235\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.3572e-04 - accuracy: 1.0000 - val_loss: 3.0331 - val_accuracy: 0.5235\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.2470e-04 - accuracy: 1.0000 - val_loss: 3.0500 - val_accuracy: 0.5235\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.0546e-04 - accuracy: 1.0000 - val_loss: 3.0700 - val_accuracy: 0.5235\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.9190e-04 - accuracy: 1.0000 - val_loss: 3.0870 - val_accuracy: 0.5235\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.7896e-04 - accuracy: 1.0000 - val_loss: 3.1049 - val_accuracy: 0.5235\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.6599e-04 - accuracy: 1.0000 - val_loss: 3.1262 - val_accuracy: 0.5235\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.5607e-04 - accuracy: 1.0000 - val_loss: 3.1390 - val_accuracy: 0.5235\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.4137e-04 - accuracy: 1.0000 - val_loss: 3.1590 - val_accuracy: 0.5235\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.3170e-04 - accuracy: 1.0000 - val_loss: 3.1773 - val_accuracy: 0.5235\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.2196e-04 - accuracy: 1.0000 - val_loss: 3.1897 - val_accuracy: 0.5235\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.1150e-04 - accuracy: 1.0000 - val_loss: 3.2090 - val_accuracy: 0.5235\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.0290e-04 - accuracy: 1.0000 - val_loss: 3.2237 - val_accuracy: 0.5235\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.9611e-04 - accuracy: 1.0000 - val_loss: 3.2370 - val_accuracy: 0.5235\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.8662e-04 - accuracy: 1.0000 - val_loss: 3.2575 - val_accuracy: 0.5235\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.7851e-04 - accuracy: 1.0000 - val_loss: 3.2689 - val_accuracy: 0.5235\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 1.7151e-04 - accuracy: 1.0000 - val_loss: 3.2838 - val_accuracy: 0.5235\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 1.6420e-04 - accuracy: 1.0000 - val_loss: 3.2985 - val_accuracy: 0.5235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15cb4beb0>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_3_4 = Sequential()\n",
    "model_1_3_4.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps,n_features)))\n",
    "model_1_3_4.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_1_3_4.add(Conv1D(filters=32, kernel_size=2, activation='relu')) \n",
    "model_1_3_4.add(MaxPooling1D(pool_size=2)) \n",
    "model_1_3_4.add(Conv1D(filters=32, kernel_size=1, activation='relu')) \n",
    "model_1_3_4.add(Flatten())\n",
    "model_1_3_4.add(Dense(50, activation='relu')) \n",
    "model_1_3_4.add(Dense(1, activation='sigmoid')) \n",
    "model_1_3_4.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_1_3_4.fit(train_X_1_3,train_f1t_tc,epochs=100,  validation_data=(val_X_1_3, val_f1t_tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80955093",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
