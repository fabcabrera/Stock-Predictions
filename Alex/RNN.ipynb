{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns   \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn import (\n",
    "    linear_model, metrics, neural_network, pipeline, model_selection\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, SimpleRNN, LSTM, TimeDistributed, BatchNormalization\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "netflix = pd.read_csv('netflix_model_ready.csv',\n",
    "                        parse_dates=True,\n",
    "                        infer_datetime_format=True,\n",
    "                        index_col=\"date\"\n",
    "                        )\n",
    "                      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix = netflix.drop(['target_1', 'target_2', 'target_4', 'target_5'], axis=1)\n",
    "target_3 = netflix[\"target_3\"]\n",
    "\n",
    "#splitting into training sets \n",
    "column_indices = {name: i for i, name in enumerate(netflix.columns)}\n",
    "\n",
    "n = len(netflix)\n",
    "X_train = netflix[0:int(n*0.7)]\n",
    "X_val = netflix[int(n*0.7):int(n*0.9)]\n",
    "X_test = netflix[int(n*0.9):]\n",
    "\n",
    "y_train = target_3[0:int(n*0.7)]\n",
    "y_val = target_3[int(n*0.7):int(n*0.9)]\n",
    "y_test = target_3[int(n*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mscaler = MinMaxScaler() # keeps binarys at zero and 1 :)\n",
    "\n",
    "X_train = pd.DataFrame(Mscaler.fit_transform(X_train), columns = netflix.columns)\n",
    "X_val = pd.DataFrame(Mscaler.fit_transform(X_val), columns = netflix.columns)\n",
    "X_test = pd.DataFrame(Mscaler.fit_transform(X_test), columns = netflix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_X_y2(df, target, window_size=10):\n",
    "  df_as_np = df.to_numpy() # converts to matrix of numpy arrays\n",
    "  X = []\n",
    "  y = []\n",
    "  for i in range(len(df_as_np)-window_size): # length of data frame - window_size so it does't take empty values at the end, \n",
    "    # does force you to loose the last 5 values, could fix with padding\n",
    "    row = [r for r in df_as_np[i:i+window_size]] # grabs row i and all rows above within the window size length\n",
    "    X.append(row) # creates 3 dimentional array, (# obseravtions, # rows in window, # features)\n",
    "    label = target[i+window_size] # pulls the target variable after the window, target varible needs to be column zero in this \n",
    "    y.append(label) # returns (N,) martix of targets i+window_length time periods away\n",
    "  return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(494, 10, 20) (494,)\n",
      "(134, 10, 20) (134,)\n",
      "(63, 10, 20) (63,)\n"
     ]
    }
   ],
   "source": [
    "sklearn_pca = PCA(n_components=20)\n",
    "X_train_1 = pd.DataFrame(sklearn_pca.fit_transform(X_train))\n",
    "X_val_1 = pd.DataFrame(sklearn_pca.fit_transform(X_val))\n",
    "X_test_1 = pd.DataFrame(sklearn_pca.fit_transform(X_test))\n",
    "\n",
    "# converting to window format, in this case 5 periods\n",
    "X_train_1, train_5w = df_to_X_y2(X_train_1,y_train)\n",
    "X_val_1, val_5w = df_to_X_y2(X_val_1, y_val)\n",
    "X_test_1, test_5w = df_to_X_y2(X_test_1,y_test) \n",
    "\n",
    "\n",
    "print(X_train_1.shape, train_5w.shape)\n",
    "print(X_val_1.shape, val_5w.shape)\n",
    "print(X_test_1.shape, test_5w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = X_train_1.shape[1]\n",
    "n_features = X_train_1.shape[2]\n",
    "\n",
    "# Let's make a list of CONSTANTS for modelling:\n",
    "LAYERS = [8, 8, 8, 1]                # number of units in hidden and output layers\n",
    "M_TRAIN = X_train_1.shape[0]           # number of training examples (2D)\n",
    "M_TEST = X_test_1.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = X_train_1.shape[2]                 # number of features\n",
    "BATCH = M_TRAIN                          # batch size\n",
    "EPOCH = 10                           # number of epochs\n",
    "LR = 5e-2                            # learning rate of the gradient descent\n",
    "LAMBD = 3e-2                         # lambda in L2 regularizaion\n",
    "DP = 0.0                             # dropout rate\n",
    "RDP = 0.0                            # recurrent dropout rate\n",
    "\n",
    "# Build the Model\n",
    "model = Sequential()\n",
    "model.add(LSTM(input_shape=(n_steps, n_features), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid', \n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=LAYERS[3], activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_17 (LSTM)              (None, 10, 8)             928       \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 10, 8)            32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lstm_18 (LSTM)              (None, 10, 8)             544       \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 10, 8)            32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 8)                 544       \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 8)                32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,121\n",
      "Trainable params: 2,073\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              optimizer=\"adam\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 5s 70ms/step - loss: 3.1107 - accuracy: 0.5101 - val_loss: 2.8014 - val_accuracy: 0.4851\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 2.8867 - accuracy: 0.5304 - val_loss: 2.6762 - val_accuracy: 0.4478\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 2.6863 - accuracy: 0.5324 - val_loss: 2.5551 - val_accuracy: 0.4776\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 2.5511 - accuracy: 0.5385 - val_loss: 2.4386 - val_accuracy: 0.4925\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 2.4153 - accuracy: 0.5567 - val_loss: 2.3280 - val_accuracy: 0.5149\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 2.3093 - accuracy: 0.5202 - val_loss: 2.2233 - val_accuracy: 0.5075\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 2.1890 - accuracy: 0.5547 - val_loss: 2.1246 - val_accuracy: 0.5224\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 2.0970 - accuracy: 0.5405 - val_loss: 2.0320 - val_accuracy: 0.5597\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.9961 - accuracy: 0.5567 - val_loss: 1.9457 - val_accuracy: 0.5299\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 1.9105 - accuracy: 0.5567 - val_loss: 1.8655 - val_accuracy: 0.5224\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.8361 - accuracy: 0.5526 - val_loss: 1.7894 - val_accuracy: 0.5224\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.7510 - accuracy: 0.5587 - val_loss: 1.7191 - val_accuracy: 0.5149\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.6743 - accuracy: 0.5547 - val_loss: 1.6529 - val_accuracy: 0.5224\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.6135 - accuracy: 0.5729 - val_loss: 1.5908 - val_accuracy: 0.5224\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.5535 - accuracy: 0.5688 - val_loss: 1.5336 - val_accuracy: 0.5149\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.4895 - accuracy: 0.5628 - val_loss: 1.4802 - val_accuracy: 0.5149\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.4381 - accuracy: 0.5850 - val_loss: 1.4310 - val_accuracy: 0.5224\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.3901 - accuracy: 0.5749 - val_loss: 1.3850 - val_accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.3457 - accuracy: 0.5688 - val_loss: 1.3422 - val_accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.2996 - accuracy: 0.5709 - val_loss: 1.3038 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.2624 - accuracy: 0.5648 - val_loss: 1.2688 - val_accuracy: 0.4851\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.2235 - accuracy: 0.5951 - val_loss: 1.2335 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.1889 - accuracy: 0.5870 - val_loss: 1.2008 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.1569 - accuracy: 0.5607 - val_loss: 1.1729 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.1285 - accuracy: 0.5850 - val_loss: 1.1457 - val_accuracy: 0.4776\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.0964 - accuracy: 0.6073 - val_loss: 1.1198 - val_accuracy: 0.4776\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.0693 - accuracy: 0.6093 - val_loss: 1.0956 - val_accuracy: 0.4851\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.0452 - accuracy: 0.6053 - val_loss: 1.0771 - val_accuracy: 0.4925\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.0291 - accuracy: 0.6032 - val_loss: 1.0565 - val_accuracy: 0.4925\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.0044 - accuracy: 0.5972 - val_loss: 1.0409 - val_accuracy: 0.4851\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.9837 - accuracy: 0.6093 - val_loss: 1.0243 - val_accuracy: 0.4851\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9616 - accuracy: 0.6275 - val_loss: 1.0066 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.9552 - accuracy: 0.5830 - val_loss: 0.9976 - val_accuracy: 0.4851\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9302 - accuracy: 0.6215 - val_loss: 0.9811 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9173 - accuracy: 0.6012 - val_loss: 0.9692 - val_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8974 - accuracy: 0.6296 - val_loss: 0.9634 - val_accuracy: 0.4851\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.8864 - accuracy: 0.6275 - val_loss: 0.9478 - val_accuracy: 0.4925\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.8761 - accuracy: 0.6255 - val_loss: 0.9384 - val_accuracy: 0.5149\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.8642 - accuracy: 0.6194 - val_loss: 0.9342 - val_accuracy: 0.4851\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8567 - accuracy: 0.6336 - val_loss: 0.9291 - val_accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8429 - accuracy: 0.6377 - val_loss: 0.9215 - val_accuracy: 0.5149\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8344 - accuracy: 0.6235 - val_loss: 0.9150 - val_accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.8236 - accuracy: 0.6457 - val_loss: 0.9155 - val_accuracy: 0.4925\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8127 - accuracy: 0.6457 - val_loss: 0.9132 - val_accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8050 - accuracy: 0.6498 - val_loss: 0.8992 - val_accuracy: 0.5224\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.7935 - accuracy: 0.6640 - val_loss: 0.9051 - val_accuracy: 0.5149\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7831 - accuracy: 0.6619 - val_loss: 0.9088 - val_accuracy: 0.5224\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.7781 - accuracy: 0.6579 - val_loss: 0.9050 - val_accuracy: 0.5299\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.7939 - accuracy: 0.6336 - val_loss: 0.9124 - val_accuracy: 0.5149\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.7739 - accuracy: 0.6619 - val_loss: 0.9041 - val_accuracy: 0.5149\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.7653 - accuracy: 0.6640 - val_loss: 0.9046 - val_accuracy: 0.5299\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.7481 - accuracy: 0.6964 - val_loss: 0.9033 - val_accuracy: 0.5149\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.7506 - accuracy: 0.6802 - val_loss: 0.9039 - val_accuracy: 0.5224\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.7415 - accuracy: 0.6700 - val_loss: 0.9116 - val_accuracy: 0.5149\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.7330 - accuracy: 0.6802 - val_loss: 0.9176 - val_accuracy: 0.5075\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.7317 - accuracy: 0.6903 - val_loss: 0.9356 - val_accuracy: 0.5149\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7210 - accuracy: 0.7065 - val_loss: 0.9380 - val_accuracy: 0.4851\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.7086 - accuracy: 0.7024 - val_loss: 0.9407 - val_accuracy: 0.4776\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.7181 - accuracy: 0.7024 - val_loss: 0.9726 - val_accuracy: 0.4776\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.7300 - accuracy: 0.6660 - val_loss: 0.9805 - val_accuracy: 0.4701\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.7095 - accuracy: 0.6943 - val_loss: 0.9700 - val_accuracy: 0.4925\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6988 - accuracy: 0.7287 - val_loss: 1.0013 - val_accuracy: 0.4851\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6978 - accuracy: 0.6943 - val_loss: 0.9812 - val_accuracy: 0.4701\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7062 - accuracy: 0.6802 - val_loss: 1.0185 - val_accuracy: 0.4851\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6790 - accuracy: 0.7186 - val_loss: 1.0256 - val_accuracy: 0.4851\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6996 - accuracy: 0.6781 - val_loss: 1.0328 - val_accuracy: 0.4478\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6754 - accuracy: 0.7105 - val_loss: 1.0948 - val_accuracy: 0.4701\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6719 - accuracy: 0.7510 - val_loss: 1.0815 - val_accuracy: 0.4627\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6631 - accuracy: 0.7227 - val_loss: 1.1159 - val_accuracy: 0.4627\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6687 - accuracy: 0.7206 - val_loss: 1.1310 - val_accuracy: 0.4701\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6648 - accuracy: 0.7166 - val_loss: 1.1752 - val_accuracy: 0.4552\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6697 - accuracy: 0.7308 - val_loss: 1.1737 - val_accuracy: 0.4627\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6745 - accuracy: 0.6984 - val_loss: 1.2054 - val_accuracy: 0.4776\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6538 - accuracy: 0.7429 - val_loss: 1.2461 - val_accuracy: 0.4851\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6453 - accuracy: 0.7470 - val_loss: 1.2422 - val_accuracy: 0.4627\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6391 - accuracy: 0.7328 - val_loss: 1.3518 - val_accuracy: 0.4627\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6394 - accuracy: 0.7632 - val_loss: 1.3071 - val_accuracy: 0.4328\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6292 - accuracy: 0.7632 - val_loss: 1.3817 - val_accuracy: 0.4776\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6372 - accuracy: 0.7287 - val_loss: 1.3766 - val_accuracy: 0.4627\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6593 - accuracy: 0.7287 - val_loss: 1.4498 - val_accuracy: 0.4552\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6364 - accuracy: 0.7510 - val_loss: 1.3552 - val_accuracy: 0.4328\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6313 - accuracy: 0.7449 - val_loss: 1.4929 - val_accuracy: 0.4478\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6299 - accuracy: 0.7510 - val_loss: 1.4830 - val_accuracy: 0.4478\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6235 - accuracy: 0.7713 - val_loss: 1.5013 - val_accuracy: 0.4104\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6187 - accuracy: 0.7571 - val_loss: 1.6368 - val_accuracy: 0.4403\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6105 - accuracy: 0.7591 - val_loss: 1.6355 - val_accuracy: 0.4328\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6076 - accuracy: 0.7591 - val_loss: 1.6260 - val_accuracy: 0.4254\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6248 - accuracy: 0.7510 - val_loss: 1.6343 - val_accuracy: 0.4254\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6145 - accuracy: 0.7551 - val_loss: 1.8652 - val_accuracy: 0.4104\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6218 - accuracy: 0.7692 - val_loss: 1.6798 - val_accuracy: 0.4104\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6161 - accuracy: 0.7571 - val_loss: 1.8298 - val_accuracy: 0.4104\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6120 - accuracy: 0.7733 - val_loss: 1.7643 - val_accuracy: 0.4030\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.5872 - accuracy: 0.7895 - val_loss: 1.8377 - val_accuracy: 0.4104\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.5900 - accuracy: 0.7490 - val_loss: 1.9073 - val_accuracy: 0.3955\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6016 - accuracy: 0.7692 - val_loss: 1.8873 - val_accuracy: 0.4104\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6060 - accuracy: 0.7632 - val_loss: 1.9199 - val_accuracy: 0.3881\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.5899 - accuracy: 0.7733 - val_loss: 1.9803 - val_accuracy: 0.3881\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6226 - accuracy: 0.7551 - val_loss: 2.0488 - val_accuracy: 0.4030\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.5840 - accuracy: 0.7753 - val_loss: 2.0104 - val_accuracy: 0.4030\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6015 - accuracy: 0.7773 - val_loss: 2.2448 - val_accuracy: 0.3881\n"
     ]
    }
   ],
   "source": [
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=30, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "\n",
    "history = model.fit(X_train_1, train_5w,\n",
    "                    epochs=100,\n",
    "                    batch_size=50,\n",
    "                    validation_data=(X_val_1, val_5w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "train accuracy = 75.3036%\n",
      "test accuracy = 58.7302%\n",
      "test error = 26 out of 63 examples\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model:\n",
    "train_loss, train_acc = model.evaluate(X_train_1, train_5w,\n",
    "                                       batch_size=M_TRAIN, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(X_test_1, test_5w,\n",
    "                                     batch_size=M_TEST, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1296x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss and accuracy curves over epochs:\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(18,6))\n",
    "axs[0].plot(history.history['loss'], color='b', label='Training loss')\n",
    "axs[0].plot(history.history['val_loss'], color='r', label='Validation loss')\n",
    "axs[0].set_title(\"Loss curves\")\n",
    "axs[0].legend(loc='best', shadow=True)\n",
    "axs[1].plot(history.history['accuracy'], color='b', label='Training accuracy')\n",
    "axs[1].plot(history.history['val_accuracy'], color='r', label='Validation accuracy')\n",
    "axs[1].set_title(\"Accuracy curves\")\n",
    "axs[1].legend(loc='best', shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 17ms/step\n",
      "2017-01-02 00:00:00 [0.02544427] [1]\n",
      "2017-01-03 00:00:00 [0.03112036] [0]\n",
      "2017-01-04 00:00:00 [0.02240884] [0]\n",
      "2017-01-05 00:00:00 [0.0214214] [0]\n",
      "2017-01-06 00:00:00 [0.02060744] [0]\n",
      "2017-01-09 00:00:00 [0.03876346] [0]\n",
      "2017-01-10 00:00:00 [0.06182319] [0]\n",
      "2017-01-11 00:00:00 [0.07037172] [1]\n",
      "2017-01-12 00:00:00 [0.09498399] [0]\n",
      "2017-01-13 00:00:00 [0.16495144] [0]\n",
      "2017-01-16 00:00:00 [0.23665068] [1]\n",
      "2017-01-17 00:00:00 [0.39069465] [0]\n",
      "2017-01-18 00:00:00 [0.43639162] [1]\n",
      "2017-01-19 00:00:00 [0.34020293] [0]\n",
      "2017-01-20 00:00:00 [0.424814] [0]\n",
      "2017-01-23 00:00:00 [0.34071386] [0]\n",
      "2017-01-24 00:00:00 [0.6368209] [0]\n",
      "2017-01-25 00:00:00 [0.57310915] [0]\n",
      "2017-01-26 00:00:00 [0.58939797] [1]\n",
      "2017-01-27 00:00:00 [0.5445704] [0]\n",
      "2017-01-30 00:00:00 [0.48154706] [1]\n",
      "2017-01-31 00:00:00 [0.43834355] [1]\n",
      "2017-02-01 00:00:00 [0.20859185] [0]\n",
      "2017-02-02 00:00:00 [0.04272592] [0]\n",
      "2017-02-03 00:00:00 [0.01790097] [1]\n",
      "2017-02-06 00:00:00 [0.01017243] [0]\n",
      "2017-02-07 00:00:00 [0.0294832] [1]\n",
      "2017-02-08 00:00:00 [0.1372649] [1]\n",
      "2017-02-09 00:00:00 [0.5003881] [0]\n",
      "2017-02-10 00:00:00 [0.72551] [0]\n",
      "2017-02-13 00:00:00 [0.9446306] [1]\n",
      "2017-02-14 00:00:00 [0.9962604] [1]\n",
      "2017-02-15 00:00:00 [0.9981727] [0]\n",
      "2017-02-16 00:00:00 [0.9975989] [0]\n",
      "2017-02-17 00:00:00 [0.9952487] [1]\n",
      "2017-02-20 00:00:00 [0.99727035] [0]\n",
      "2017-02-21 00:00:00 [0.9992941] [0]\n",
      "2017-02-22 00:00:00 [0.99961585] [1]\n",
      "2017-02-23 00:00:00 [0.99937797] [1]\n",
      "2017-02-24 00:00:00 [0.9932165] [1]\n",
      "2017-02-27 00:00:00 [0.86364657] [0]\n",
      "2017-02-28 00:00:00 [0.6655506] [0]\n",
      "2017-03-01 00:00:00 [0.6324472] [0]\n",
      "2017-03-02 00:00:00 [0.77165425] [0]\n",
      "2017-03-03 00:00:00 [0.59255177] [0]\n",
      "2017-03-06 00:00:00 [0.73931265] [0]\n",
      "2017-03-07 00:00:00 [0.8909906] [1]\n",
      "2017-03-08 00:00:00 [0.8488272] [0]\n",
      "2017-03-09 00:00:00 [0.78731227] [0]\n",
      "2017-03-10 00:00:00 [0.698996] [0]\n",
      "2017-03-13 00:00:00 [0.9335704] [1]\n",
      "2017-03-14 00:00:00 [0.95430964] [1]\n",
      "2017-03-15 00:00:00 [0.82764524] [1]\n",
      "2017-03-16 00:00:00 [0.56401646] [1]\n",
      "2017-03-17 00:00:00 [0.11231604] [0]\n",
      "2017-03-20 00:00:00 [0.02417776] [1]\n",
      "2017-03-21 00:00:00 [0.01049206] [0]\n",
      "2017-03-22 00:00:00 [0.00513458] [1]\n",
      "2017-03-23 00:00:00 [0.0024136] [0]\n",
      "2017-03-24 00:00:00 [0.00199535] [1]\n",
      "2017-03-27 00:00:00 [0.00203991] [1]\n",
      "2017-03-28 00:00:00 [0.00238436] [0]\n",
      "2017-03-29 00:00:00 [0.0038349] [0]\n"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict(X_test_1, batch_size=50, verbose=1)\n",
    "#score = sum(y_hat == y_test) / len(y_test)\n",
    "#print(f'Prediction accuracy = {score*100}%')\n",
    "index = pd.date_range(start='2017-01-02', end='2018-06-19', freq='B')\n",
    "for i in range(y_hat.shape[0]):\n",
    "    print(index[i], y_hat[i], test_5w[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'True: 0'), Text(0, 1.5, 'True: 1')]"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display confusion matrix results\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "ax = plt.subplot()\n",
    "predicted = model.predict(X_test_1)\n",
    "predicted = (predicted > 0.5)\n",
    "\n",
    "confusion = confusion_matrix(test_5w, predicted)\n",
    "\n",
    "sns.heatmap(confusion, annot=True, ax=ax)\n",
    "\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels([\"Predicted: 0\", \"Predicted: 1\"])\n",
    "ax.yaxis.set_ticklabels([\"True: 0\", \"True: 1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 32)                6784      \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,945\n",
      "Trainable params: 6,881\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 2s 37ms/step - loss: 2.6470 - accuracy: 0.5101 - val_loss: 2.4514 - val_accuracy: 0.4104\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 2.3550 - accuracy: 0.5486 - val_loss: 2.2212 - val_accuracy: 0.4701\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 2.1213 - accuracy: 0.5749 - val_loss: 2.0216 - val_accuracy: 0.4776\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.9259 - accuracy: 0.5850 - val_loss: 1.8478 - val_accuracy: 0.4328\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.7516 - accuracy: 0.5951 - val_loss: 1.6971 - val_accuracy: 0.4851\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.6058 - accuracy: 0.6336 - val_loss: 1.5688 - val_accuracy: 0.4925\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.4887 - accuracy: 0.6215 - val_loss: 1.4589 - val_accuracy: 0.4851\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.3818 - accuracy: 0.6154 - val_loss: 1.3653 - val_accuracy: 0.4776\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.2819 - accuracy: 0.6215 - val_loss: 1.2830 - val_accuracy: 0.5149\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.2045 - accuracy: 0.6377 - val_loss: 1.2149 - val_accuracy: 0.5075\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.1433 - accuracy: 0.6275 - val_loss: 1.1529 - val_accuracy: 0.5075\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.0831 - accuracy: 0.6235 - val_loss: 1.1036 - val_accuracy: 0.4925\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0339 - accuracy: 0.6336 - val_loss: 1.0576 - val_accuracy: 0.5075\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.9906 - accuracy: 0.6478 - val_loss: 1.0170 - val_accuracy: 0.5149\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.9523 - accuracy: 0.6255 - val_loss: 0.9847 - val_accuracy: 0.4925\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.9181 - accuracy: 0.6660 - val_loss: 0.9585 - val_accuracy: 0.5075\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.8925 - accuracy: 0.6538 - val_loss: 0.9316 - val_accuracy: 0.5075\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.8708 - accuracy: 0.6437 - val_loss: 0.9096 - val_accuracy: 0.5149\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.8446 - accuracy: 0.6559 - val_loss: 0.8919 - val_accuracy: 0.5224\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.8255 - accuracy: 0.6640 - val_loss: 0.8779 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.8093 - accuracy: 0.6660 - val_loss: 0.8632 - val_accuracy: 0.5075\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7954 - accuracy: 0.6457 - val_loss: 0.8502 - val_accuracy: 0.5075\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7863 - accuracy: 0.6538 - val_loss: 0.8435 - val_accuracy: 0.4925\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7761 - accuracy: 0.6660 - val_loss: 0.8312 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7642 - accuracy: 0.6437 - val_loss: 0.8226 - val_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7625 - accuracy: 0.6457 - val_loss: 0.8180 - val_accuracy: 0.5075\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7472 - accuracy: 0.6397 - val_loss: 0.8098 - val_accuracy: 0.5224\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7454 - accuracy: 0.6579 - val_loss: 0.8064 - val_accuracy: 0.5149\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7363 - accuracy: 0.6579 - val_loss: 0.7960 - val_accuracy: 0.5299\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7286 - accuracy: 0.6538 - val_loss: 0.7965 - val_accuracy: 0.5299\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7275 - accuracy: 0.6437 - val_loss: 0.7977 - val_accuracy: 0.5149\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7244 - accuracy: 0.6680 - val_loss: 0.7882 - val_accuracy: 0.5373\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.7182 - accuracy: 0.6538 - val_loss: 0.7838 - val_accuracy: 0.5299\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7208 - accuracy: 0.6437 - val_loss: 0.7840 - val_accuracy: 0.5448\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7172 - accuracy: 0.6478 - val_loss: 0.7804 - val_accuracy: 0.5373\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7118 - accuracy: 0.6660 - val_loss: 0.7807 - val_accuracy: 0.5373\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7069 - accuracy: 0.6518 - val_loss: 0.7796 - val_accuracy: 0.5299\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7118 - accuracy: 0.6498 - val_loss: 0.7734 - val_accuracy: 0.5746\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.7023 - accuracy: 0.6721 - val_loss: 0.7854 - val_accuracy: 0.5522\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7014 - accuracy: 0.6721 - val_loss: 0.7757 - val_accuracy: 0.5373\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7026 - accuracy: 0.6680 - val_loss: 0.7767 - val_accuracy: 0.5373\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6942 - accuracy: 0.6741 - val_loss: 0.7758 - val_accuracy: 0.5373\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6965 - accuracy: 0.6802 - val_loss: 0.7740 - val_accuracy: 0.5299\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6941 - accuracy: 0.6680 - val_loss: 0.7746 - val_accuracy: 0.5373\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.6741 - val_loss: 0.7817 - val_accuracy: 0.5597\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6899 - accuracy: 0.6478 - val_loss: 0.7780 - val_accuracy: 0.5522\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6877 - accuracy: 0.6559 - val_loss: 0.7798 - val_accuracy: 0.5373\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6890 - accuracy: 0.6700 - val_loss: 0.7697 - val_accuracy: 0.5522\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6902 - accuracy: 0.6700 - val_loss: 0.7742 - val_accuracy: 0.5672\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6851 - accuracy: 0.6741 - val_loss: 0.7791 - val_accuracy: 0.5299\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6887 - accuracy: 0.6842 - val_loss: 0.7665 - val_accuracy: 0.5746\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6878 - accuracy: 0.6660 - val_loss: 0.7955 - val_accuracy: 0.5373\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6874 - accuracy: 0.6599 - val_loss: 0.7822 - val_accuracy: 0.5597\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6822 - accuracy: 0.6761 - val_loss: 0.7743 - val_accuracy: 0.5522\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6829 - accuracy: 0.6579 - val_loss: 0.7865 - val_accuracy: 0.5672\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6903 - accuracy: 0.6559 - val_loss: 0.7846 - val_accuracy: 0.5896\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6946 - accuracy: 0.6255 - val_loss: 0.7975 - val_accuracy: 0.5522\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6833 - accuracy: 0.6741 - val_loss: 0.7789 - val_accuracy: 0.5672\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6786 - accuracy: 0.6660 - val_loss: 0.7916 - val_accuracy: 0.5672\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6756 - accuracy: 0.6822 - val_loss: 0.7918 - val_accuracy: 0.5821\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6796 - accuracy: 0.6761 - val_loss: 0.7892 - val_accuracy: 0.5597\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6751 - accuracy: 0.6822 - val_loss: 0.8020 - val_accuracy: 0.5522\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6757 - accuracy: 0.6559 - val_loss: 0.7956 - val_accuracy: 0.5597\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6762 - accuracy: 0.6640 - val_loss: 0.8051 - val_accuracy: 0.5448\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6726 - accuracy: 0.6700 - val_loss: 0.7975 - val_accuracy: 0.5672\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6790 - accuracy: 0.6518 - val_loss: 0.8089 - val_accuracy: 0.5597\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6754 - accuracy: 0.6579 - val_loss: 0.7951 - val_accuracy: 0.5672\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6698 - accuracy: 0.6923 - val_loss: 0.8052 - val_accuracy: 0.5746\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6733 - accuracy: 0.6680 - val_loss: 0.8194 - val_accuracy: 0.5821\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6703 - accuracy: 0.6680 - val_loss: 0.8041 - val_accuracy: 0.5821\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6711 - accuracy: 0.6721 - val_loss: 0.8170 - val_accuracy: 0.5672\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6775 - accuracy: 0.6579 - val_loss: 0.8101 - val_accuracy: 0.5597\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6687 - accuracy: 0.6903 - val_loss: 0.8237 - val_accuracy: 0.5746\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6665 - accuracy: 0.6660 - val_loss: 0.8233 - val_accuracy: 0.5522\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6662 - accuracy: 0.6741 - val_loss: 0.8149 - val_accuracy: 0.5672\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6635 - accuracy: 0.6862 - val_loss: 0.8176 - val_accuracy: 0.5672\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6605 - accuracy: 0.6822 - val_loss: 0.8357 - val_accuracy: 0.5597\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6619 - accuracy: 0.6619 - val_loss: 0.8216 - val_accuracy: 0.5821\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6607 - accuracy: 0.6721 - val_loss: 0.8358 - val_accuracy: 0.5746\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6605 - accuracy: 0.6923 - val_loss: 0.8328 - val_accuracy: 0.5597\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6663 - accuracy: 0.6579 - val_loss: 0.8288 - val_accuracy: 0.5672\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6671 - accuracy: 0.6741 - val_loss: 0.8405 - val_accuracy: 0.5448\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6623 - accuracy: 0.6822 - val_loss: 0.8302 - val_accuracy: 0.5373\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6558 - accuracy: 0.6721 - val_loss: 0.8475 - val_accuracy: 0.5522\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6586 - accuracy: 0.6822 - val_loss: 0.8540 - val_accuracy: 0.5821\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6653 - accuracy: 0.6781 - val_loss: 0.8517 - val_accuracy: 0.5597\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6616 - accuracy: 0.6640 - val_loss: 0.8350 - val_accuracy: 0.5522\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6628 - accuracy: 0.6822 - val_loss: 0.8127 - val_accuracy: 0.5373\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6604 - accuracy: 0.6579 - val_loss: 0.8727 - val_accuracy: 0.5299\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6617 - accuracy: 0.6680 - val_loss: 0.8551 - val_accuracy: 0.5522\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6638 - accuracy: 0.6619 - val_loss: 0.8368 - val_accuracy: 0.5597\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6541 - accuracy: 0.6943 - val_loss: 0.8804 - val_accuracy: 0.5448\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6555 - accuracy: 0.6964 - val_loss: 0.8626 - val_accuracy: 0.5299\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6629 - accuracy: 0.6862 - val_loss: 0.8558 - val_accuracy: 0.5373\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6635 - accuracy: 0.6761 - val_loss: 0.8698 - val_accuracy: 0.5522\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6509 - accuracy: 0.6802 - val_loss: 0.8414 - val_accuracy: 0.5299\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6580 - accuracy: 0.6822 - val_loss: 0.8602 - val_accuracy: 0.5522\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6551 - accuracy: 0.6923 - val_loss: 0.8572 - val_accuracy: 0.5373\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6524 - accuracy: 0.6943 - val_loss: 0.8791 - val_accuracy: 0.5224\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6485 - accuracy: 0.6984 - val_loss: 0.8951 - val_accuracy: 0.5224\n"
     ]
    }
   ],
   "source": [
    "n_steps = X_train_1.shape[1]\n",
    "n_features = X_train_1.shape[2]\n",
    "\n",
    "# Let's make a list of CONSTANTS for modelling:\n",
    "LAYERS = [32, 32, 32, 1]                # number of units in hidden and output layers\n",
    "M_TRAIN = X_train_1.shape[0]           # number of training examples (2D)\n",
    "M_TEST = X_test_1.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = X_train_1.shape[2]                 # number of features\n",
    "BATCH = M_TRAIN                          # batch size\n",
    "EPOCH = 10                           # number of epochs\n",
    "LR = 5e-2                            # learning rate of the gradient descent\n",
    "LAMBD = 3e-2                         # lambda in L2 regularizaion\n",
    "DP = 0.0                             # dropout rate\n",
    "RDP = 0.0                            # recurrent dropout rate\n",
    "\n",
    "# Build the Model\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(LSTM(units=LAYERS[2], input_shape=(n_steps, n_features),\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              optimizer=\"adam\")\n",
    "\n",
    "print(model2.summary())\n",
    "\n",
    "history2 = model2.fit(X_train_1, train_5w,\n",
    "                    epochs=100,\n",
    "                    batch_size=50,\n",
    "                    validation_data=(X_val_1, val_5w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "train accuracy = 69.4332%\n",
      "test accuracy = 55.5556%\n",
      "test error = 28 out of 63 examples\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model:\n",
    "train_loss, train_acc = model2.evaluate(X_train_1, train_5w,\n",
    "                                       batch_size=M_TRAIN, verbose=0)\n",
    "test_loss, test_acc = model2.evaluate(X_test_1, test_5w,\n",
    "                                     batch_size=M_TEST, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Correlation for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix = netflix.drop(['target_1', 'target_2', 'target_4', 'target_5'], axis=1)\n",
    "target_3 = netflix[\"target_3\"]\n",
    "\n",
    "#splitting into training sets \n",
    "column_indices = {name: i for i, name in enumerate(netflix.columns)}\n",
    "\n",
    "n = len(netflix)\n",
    "X_train = netflix[0:int(n*0.7)]\n",
    "X_val = netflix[int(n*0.7):int(n*0.9)]\n",
    "X_test = netflix[int(n*0.9):]\n",
    "\n",
    "y_train = target_3[0:int(n*0.7)]\n",
    "y_val = target_3[int(n*0.7):int(n*0.9)]\n",
    "y_test = target_3[int(n*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mscaler = MinMaxScaler() \n",
    "\n",
    "X_train = pd.DataFrame(Mscaler.fit_transform(X_train), columns = netflix.columns)\n",
    "X_val = pd.DataFrame(Mscaler.fit_transform(X_val), columns = netflix.columns)\n",
    "X_test = pd.DataFrame(Mscaler.fit_transform(X_test), columns = netflix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Netflix. Inc</th>\n",
       "      <th>Netflix_x</th>\n",
       "      <th>Netflix Stock</th>\n",
       "      <th>Streaming media</th>\n",
       "      <th>Reed Hastings_x</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>...</th>\n",
       "      <th>Dow_rs</th>\n",
       "      <th>Dow_RSI</th>\n",
       "      <th>Dow_Move</th>\n",
       "      <th>Dow_MAvg_Move</th>\n",
       "      <th>Dow_MAvg_s_Move</th>\n",
       "      <th>Dow_EMA_Move</th>\n",
       "      <th>Dow_Disparity_Move</th>\n",
       "      <th>Dow_Disparity_s_Move</th>\n",
       "      <th>Dow_RSI_Move</th>\n",
       "      <th>target_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Netflix. Inc</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netflix_x</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.120515</td>\n",
       "      <td>-0.036498</td>\n",
       "      <td>-0.023639</td>\n",
       "      <td>0.089669</td>\n",
       "      <td>0.093748</td>\n",
       "      <td>0.087067</td>\n",
       "      <td>0.094215</td>\n",
       "      <td>-0.005563</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010449</td>\n",
       "      <td>0.088147</td>\n",
       "      <td>-0.010146</td>\n",
       "      <td>-0.066488</td>\n",
       "      <td>-0.026574</td>\n",
       "      <td>-0.036132</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.017821</td>\n",
       "      <td>0.059777</td>\n",
       "      <td>0.016408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netflix Stock</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.120515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.084799</td>\n",
       "      <td>0.034103</td>\n",
       "      <td>0.042851</td>\n",
       "      <td>0.052182</td>\n",
       "      <td>0.032198</td>\n",
       "      <td>0.046048</td>\n",
       "      <td>0.416329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095930</td>\n",
       "      <td>0.027666</td>\n",
       "      <td>-0.008608</td>\n",
       "      <td>-0.036181</td>\n",
       "      <td>-0.046956</td>\n",
       "      <td>-0.001093</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>0.053164</td>\n",
       "      <td>-0.017190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Streaming media</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.036498</td>\n",
       "      <td>-0.084799</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002752</td>\n",
       "      <td>-0.082838</td>\n",
       "      <td>-0.083416</td>\n",
       "      <td>-0.084120</td>\n",
       "      <td>-0.085460</td>\n",
       "      <td>-0.007602</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025726</td>\n",
       "      <td>-0.039232</td>\n",
       "      <td>0.004281</td>\n",
       "      <td>-0.017550</td>\n",
       "      <td>-0.003948</td>\n",
       "      <td>-0.014024</td>\n",
       "      <td>0.040795</td>\n",
       "      <td>-0.015858</td>\n",
       "      <td>0.004197</td>\n",
       "      <td>0.057956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reed Hastings_x</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.023639</td>\n",
       "      <td>0.034103</td>\n",
       "      <td>-0.002752</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069944</td>\n",
       "      <td>0.069735</td>\n",
       "      <td>0.066182</td>\n",
       "      <td>0.064949</td>\n",
       "      <td>-0.023895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066170</td>\n",
       "      <td>-0.005692</td>\n",
       "      <td>-0.075937</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>-0.030094</td>\n",
       "      <td>-0.063439</td>\n",
       "      <td>-0.014711</td>\n",
       "      <td>-0.035616</td>\n",
       "      <td>0.058706</td>\n",
       "      <td>0.027614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dow_EMA_Move</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.036132</td>\n",
       "      <td>-0.001093</td>\n",
       "      <td>-0.014024</td>\n",
       "      <td>-0.063439</td>\n",
       "      <td>0.081622</td>\n",
       "      <td>0.077450</td>\n",
       "      <td>0.089444</td>\n",
       "      <td>0.089186</td>\n",
       "      <td>-0.101980</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.211371</td>\n",
       "      <td>0.146765</td>\n",
       "      <td>0.437229</td>\n",
       "      <td>0.646682</td>\n",
       "      <td>0.584085</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161978</td>\n",
       "      <td>0.098152</td>\n",
       "      <td>-0.118936</td>\n",
       "      <td>-0.039816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dow_Disparity_Move</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.040795</td>\n",
       "      <td>-0.014711</td>\n",
       "      <td>0.019873</td>\n",
       "      <td>0.021517</td>\n",
       "      <td>0.026030</td>\n",
       "      <td>0.034082</td>\n",
       "      <td>-0.013903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026077</td>\n",
       "      <td>-0.017773</td>\n",
       "      <td>0.685497</td>\n",
       "      <td>0.077847</td>\n",
       "      <td>0.351402</td>\n",
       "      <td>0.161978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.678417</td>\n",
       "      <td>-0.257943</td>\n",
       "      <td>-0.102270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dow_Disparity_s_Move</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017821</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>-0.015858</td>\n",
       "      <td>-0.035616</td>\n",
       "      <td>0.011081</td>\n",
       "      <td>0.015342</td>\n",
       "      <td>0.016836</td>\n",
       "      <td>0.028956</td>\n",
       "      <td>0.010360</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012761</td>\n",
       "      <td>-0.029004</td>\n",
       "      <td>0.639602</td>\n",
       "      <td>0.063734</td>\n",
       "      <td>0.281990</td>\n",
       "      <td>0.098152</td>\n",
       "      <td>0.678417</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.246003</td>\n",
       "      <td>-0.114530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dow_RSI_Move</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059777</td>\n",
       "      <td>0.053164</td>\n",
       "      <td>0.004197</td>\n",
       "      <td>0.058706</td>\n",
       "      <td>-0.007837</td>\n",
       "      <td>-0.004546</td>\n",
       "      <td>-0.007609</td>\n",
       "      <td>-0.004940</td>\n",
       "      <td>-0.012339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042549</td>\n",
       "      <td>0.266520</td>\n",
       "      <td>-0.292898</td>\n",
       "      <td>-0.141531</td>\n",
       "      <td>-0.184222</td>\n",
       "      <td>-0.118936</td>\n",
       "      <td>-0.257943</td>\n",
       "      <td>-0.246003</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016408</td>\n",
       "      <td>-0.017190</td>\n",
       "      <td>0.057956</td>\n",
       "      <td>0.027614</td>\n",
       "      <td>-0.039633</td>\n",
       "      <td>-0.044395</td>\n",
       "      <td>-0.040116</td>\n",
       "      <td>-0.052016</td>\n",
       "      <td>-0.070896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022905</td>\n",
       "      <td>-0.099381</td>\n",
       "      <td>-0.092477</td>\n",
       "      <td>0.026844</td>\n",
       "      <td>-0.047644</td>\n",
       "      <td>-0.039816</td>\n",
       "      <td>-0.102270</td>\n",
       "      <td>-0.114530</td>\n",
       "      <td>-0.004096</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Netflix. Inc  Netflix_x  Netflix Stock  Streaming media  \\\n",
       "Netflix. Inc                   NaN        NaN            NaN              NaN   \n",
       "Netflix_x                      NaN   1.000000       0.120515        -0.036498   \n",
       "Netflix Stock                  NaN   0.120515       1.000000        -0.084799   \n",
       "Streaming media                NaN  -0.036498      -0.084799         1.000000   \n",
       "Reed Hastings_x                NaN  -0.023639       0.034103        -0.002752   \n",
       "...                            ...        ...            ...              ...   \n",
       "Dow_EMA_Move                   NaN  -0.036132      -0.001093        -0.014024   \n",
       "Dow_Disparity_Move             NaN   0.066000       0.002790         0.040795   \n",
       "Dow_Disparity_s_Move           NaN   0.017821       0.002112        -0.015858   \n",
       "Dow_RSI_Move                   NaN   0.059777       0.053164         0.004197   \n",
       "target_3                       NaN   0.016408      -0.017190         0.057956   \n",
       "\n",
       "                      Reed Hastings_x      Open      High       Low     Close  \\\n",
       "Netflix. Inc                      NaN       NaN       NaN       NaN       NaN   \n",
       "Netflix_x                   -0.023639  0.089669  0.093748  0.087067  0.094215   \n",
       "Netflix Stock                0.034103  0.042851  0.052182  0.032198  0.046048   \n",
       "Streaming media             -0.002752 -0.082838 -0.083416 -0.084120 -0.085460   \n",
       "Reed Hastings_x              1.000000  0.069944  0.069735  0.066182  0.064949   \n",
       "...                               ...       ...       ...       ...       ...   \n",
       "Dow_EMA_Move                -0.063439  0.081622  0.077450  0.089444  0.089186   \n",
       "Dow_Disparity_Move          -0.014711  0.019873  0.021517  0.026030  0.034082   \n",
       "Dow_Disparity_s_Move        -0.035616  0.011081  0.015342  0.016836  0.028956   \n",
       "Dow_RSI_Move                 0.058706 -0.007837 -0.004546 -0.007609 -0.004940   \n",
       "target_3                     0.027614 -0.039633 -0.044395 -0.040116 -0.052016   \n",
       "\n",
       "                        Volume  ...    Dow_rs   Dow_RSI  Dow_Move  \\\n",
       "Netflix. Inc               NaN  ...       NaN       NaN       NaN   \n",
       "Netflix_x            -0.005563  ... -0.010449  0.088147 -0.010146   \n",
       "Netflix Stock         0.416329  ...  0.095930  0.027666 -0.008608   \n",
       "Streaming media      -0.007602  ... -0.025726 -0.039232  0.004281   \n",
       "Reed Hastings_x      -0.023895  ...  0.066170 -0.005692 -0.075937   \n",
       "...                        ...  ...       ...       ...       ...   \n",
       "Dow_EMA_Move         -0.101980  ... -0.211371  0.146765  0.437229   \n",
       "Dow_Disparity_Move   -0.013903  ... -0.026077 -0.017773  0.685497   \n",
       "Dow_Disparity_s_Move  0.010360  ... -0.012761 -0.029004  0.639602   \n",
       "Dow_RSI_Move         -0.012339  ...  0.042549  0.266520 -0.292898   \n",
       "target_3             -0.070896  ... -0.022905 -0.099381 -0.092477   \n",
       "\n",
       "                      Dow_MAvg_Move  Dow_MAvg_s_Move  Dow_EMA_Move  \\\n",
       "Netflix. Inc                    NaN              NaN           NaN   \n",
       "Netflix_x                 -0.066488        -0.026574     -0.036132   \n",
       "Netflix Stock             -0.036181        -0.046956     -0.001093   \n",
       "Streaming media           -0.017550        -0.003948     -0.014024   \n",
       "Reed Hastings_x            0.000363        -0.030094     -0.063439   \n",
       "...                             ...              ...           ...   \n",
       "Dow_EMA_Move               0.646682         0.584085      1.000000   \n",
       "Dow_Disparity_Move         0.077847         0.351402      0.161978   \n",
       "Dow_Disparity_s_Move       0.063734         0.281990      0.098152   \n",
       "Dow_RSI_Move              -0.141531        -0.184222     -0.118936   \n",
       "target_3                   0.026844        -0.047644     -0.039816   \n",
       "\n",
       "                      Dow_Disparity_Move  Dow_Disparity_s_Move  Dow_RSI_Move  \\\n",
       "Netflix. Inc                         NaN                   NaN           NaN   \n",
       "Netflix_x                       0.066000              0.017821      0.059777   \n",
       "Netflix Stock                   0.002790              0.002112      0.053164   \n",
       "Streaming media                 0.040795             -0.015858      0.004197   \n",
       "Reed Hastings_x                -0.014711             -0.035616      0.058706   \n",
       "...                                  ...                   ...           ...   \n",
       "Dow_EMA_Move                    0.161978              0.098152     -0.118936   \n",
       "Dow_Disparity_Move              1.000000              0.678417     -0.257943   \n",
       "Dow_Disparity_s_Move            0.678417              1.000000     -0.246003   \n",
       "Dow_RSI_Move                   -0.257943             -0.246003      1.000000   \n",
       "target_3                       -0.102270             -0.114530     -0.004096   \n",
       "\n",
       "                      target_3  \n",
       "Netflix. Inc               NaN  \n",
       "Netflix_x             0.016408  \n",
       "Netflix Stock        -0.017190  \n",
       "Streaming media       0.057956  \n",
       "Reed Hastings_x       0.027614  \n",
       "...                        ...  \n",
       "Dow_EMA_Move         -0.039816  \n",
       "Dow_Disparity_Move   -0.102270  \n",
       "Dow_Disparity_s_Move -0.114530  \n",
       "Dow_RSI_Move         -0.004096  \n",
       "target_3              1.000000  \n",
       "\n",
       "[160 rows x 160 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = X_train.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 40 variables by correlation with the target, not including target 3 which would have correlation = 1\n",
    "\n",
    "feats_corr = list(pd.DataFrame(corr_matrix['target_3'].sort_values(ascending=False).iloc[1:41]).reset_index()['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stock_rs',\n",
       " 'Nas_RSI_Move',\n",
       " 'Google_avg_loss',\n",
       " 'Nas_rs',\n",
       " 'Streaming media',\n",
       " 'dow_vol',\n",
       " 'Wiki_gain',\n",
       " 'Wiki_Disparity',\n",
       " 'Google_Rocp',\n",
       " 'Stock_Rocp',\n",
       " 'Wiki_Moment_2_s',\n",
       " 'Wiki_diff',\n",
       " 'Dow_Rocp',\n",
       " 'Wiki_Moment_1_s',\n",
       " 'Wiki_ROC_s',\n",
       " 'Wiki_avg_gain',\n",
       " 'Google_gain',\n",
       " 'Reed Hastings_x',\n",
       " 'Dow_MAvg_Move',\n",
       " 'Google_MAvg_s',\n",
       " 'Google_Disparity',\n",
       " 'Google_MAvg_s_Move',\n",
       " 'Google_Moment_2',\n",
       " 'nas_vol',\n",
       " 'Google_total',\n",
       " 'Netflix_y',\n",
       " 'Netflix_x',\n",
       " 'Google_RSI_Move',\n",
       " 'Google_Move',\n",
       " 'Wiki_Disparity_s',\n",
       " 'Wiki_total',\n",
       " 'Google_Disparity_Move',\n",
       " 'Nas_Move',\n",
       " 'Google_ROC_s',\n",
       " 'Google_Moment_1_s',\n",
       " 'Wiki_loss',\n",
       " 'Nas_Disparity_s_Move',\n",
       " 'Google_ROC',\n",
       " 'Google_Moment_1',\n",
       " 'Wiki_MAvg_s']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cr = X_train[feats_corr]\n",
    "X_val_cr = X_val[feats_corr]\n",
    "X_test_cr = X_test[feats_corr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_pca = PCA(n_components=20)\n",
    "X_train_cr = pd.DataFrame(sklearn_pca.fit_transform(X_train_cr))\n",
    "X_val_cr = pd.DataFrame(sklearn_pca.fit_transform(X_val_cr))\n",
    "X_test_cr = pd.DataFrame(sklearn_pca.fit_transform(X_test_cr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(494, 10, 20) (494,)\n",
      "(134, 10, 20) (134,)\n",
      "(63, 10, 20) (63,)\n"
     ]
    }
   ],
   "source": [
    "# converting to window format, in this case 10 periods\n",
    "X_train_cr, train_5w = df_to_X_y2(X_train_cr,y_train)\n",
    "X_val_cr, val_5w = df_to_X_y2(X_val_cr, y_val)\n",
    "X_test_cr, test_5w = df_to_X_y2(X_test_cr,y_test) \n",
    "\n",
    "\n",
    "print(X_train_cr.shape, train_5w.shape)\n",
    "print(X_val_cr.shape, val_5w.shape)\n",
    "print(X_test_cr.shape, test_5w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = X_train_cr.shape[1]\n",
    "n_features = X_train_cr.shape[2]\n",
    "\n",
    "# Let's make a list of CONSTANTS for modelling:\n",
    "LAYERS = [8, 8, 8, 1]                # number of units in hidden and output layers\n",
    "M_TRAIN = X_train_cr.shape[0]           # number of training examples (2D)\n",
    "M_TEST = X_test_cr.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = X_train_1.shape[2]                 # number of features\n",
    "BATCH = M_TRAIN                          # batch size\n",
    "EPOCH = 10                           # number of epochs\n",
    "LR = 5e-2                            # learning rate of the gradient descent\n",
    "LAMBD = 3e-2                         # lambda in L2 regularizaion\n",
    "DP = 0.0                             # dropout rate\n",
    "RDP = 0.0                            # recurrent dropout rate\n",
    "\n",
    "# Build the Model\n",
    "model3 = Sequential()\n",
    "model3.add(LSTM(input_shape=(n_steps, n_features), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid', \n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Dense(units=LAYERS[3], activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_20 (LSTM)              (None, 10, 8)             928       \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 10, 8)            32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lstm_21 (LSTM)              (None, 10, 8)             544       \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 10, 8)            32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, 8)                 544       \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 8)                32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,121\n",
      "Trainable params: 2,073\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model3.compile(loss='binary_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              optimizer=\"adam\")\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6621 - accuracy: 0.6923 - val_loss: 0.8330 - val_accuracy: 0.5746\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6568 - accuracy: 0.7004 - val_loss: 0.8117 - val_accuracy: 0.6045\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.6617 - accuracy: 0.6943 - val_loss: 0.8373 - val_accuracy: 0.6194\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6411 - accuracy: 0.7227 - val_loss: 0.8144 - val_accuracy: 0.5821\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6680 - accuracy: 0.7004 - val_loss: 0.8427 - val_accuracy: 0.5746\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6624 - accuracy: 0.6964 - val_loss: 0.8073 - val_accuracy: 0.5970\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6493 - accuracy: 0.7247 - val_loss: 0.8204 - val_accuracy: 0.5672\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6487 - accuracy: 0.6903 - val_loss: 0.8149 - val_accuracy: 0.5821\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6590 - accuracy: 0.6943 - val_loss: 0.8349 - val_accuracy: 0.6045\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6713 - accuracy: 0.6842 - val_loss: 0.8427 - val_accuracy: 0.5970\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6406 - accuracy: 0.7146 - val_loss: 0.8282 - val_accuracy: 0.5522\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6576 - accuracy: 0.7045 - val_loss: 0.8297 - val_accuracy: 0.5672\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6571 - accuracy: 0.7105 - val_loss: 0.8418 - val_accuracy: 0.5746\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6489 - accuracy: 0.7126 - val_loss: 0.8457 - val_accuracy: 0.5896\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6518 - accuracy: 0.6822 - val_loss: 0.8271 - val_accuracy: 0.5746\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6438 - accuracy: 0.7085 - val_loss: 0.8556 - val_accuracy: 0.5672\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6390 - accuracy: 0.6943 - val_loss: 0.8457 - val_accuracy: 0.5522\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6493 - accuracy: 0.7166 - val_loss: 0.8430 - val_accuracy: 0.5896\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6447 - accuracy: 0.7085 - val_loss: 0.8336 - val_accuracy: 0.5970\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6392 - accuracy: 0.7186 - val_loss: 0.8737 - val_accuracy: 0.5672\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6500 - accuracy: 0.7146 - val_loss: 0.8609 - val_accuracy: 0.5896\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6360 - accuracy: 0.7267 - val_loss: 0.8832 - val_accuracy: 0.5522\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6389 - accuracy: 0.7247 - val_loss: 0.8506 - val_accuracy: 0.5896\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6410 - accuracy: 0.6943 - val_loss: 0.8703 - val_accuracy: 0.5746\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6548 - accuracy: 0.6903 - val_loss: 0.8441 - val_accuracy: 0.5821\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.6350 - accuracy: 0.6964 - val_loss: 0.8531 - val_accuracy: 0.5746\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.6544 - accuracy: 0.7024 - val_loss: 0.8514 - val_accuracy: 0.5746\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.6313 - accuracy: 0.7186 - val_loss: 0.8447 - val_accuracy: 0.5896\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6352 - accuracy: 0.7227 - val_loss: 0.8382 - val_accuracy: 0.6045\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6354 - accuracy: 0.7146 - val_loss: 0.8537 - val_accuracy: 0.5597\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6385 - accuracy: 0.7065 - val_loss: 0.8586 - val_accuracy: 0.5597\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6449 - accuracy: 0.7065 - val_loss: 0.8753 - val_accuracy: 0.5746\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6275 - accuracy: 0.7065 - val_loss: 0.8628 - val_accuracy: 0.5522\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6208 - accuracy: 0.7389 - val_loss: 0.8560 - val_accuracy: 0.5746\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6206 - accuracy: 0.7308 - val_loss: 0.8674 - val_accuracy: 0.5746\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6246 - accuracy: 0.7045 - val_loss: 0.8543 - val_accuracy: 0.5746\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6297 - accuracy: 0.7186 - val_loss: 0.8683 - val_accuracy: 0.5522\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6182 - accuracy: 0.7166 - val_loss: 0.8614 - val_accuracy: 0.5821\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6250 - accuracy: 0.7186 - val_loss: 0.8664 - val_accuracy: 0.5597\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6245 - accuracy: 0.7287 - val_loss: 0.8761 - val_accuracy: 0.5522\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6164 - accuracy: 0.7348 - val_loss: 0.8866 - val_accuracy: 0.5672\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.6191 - accuracy: 0.7146 - val_loss: 0.8715 - val_accuracy: 0.5672\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.6222 - accuracy: 0.7247 - val_loss: 0.8806 - val_accuracy: 0.5597\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6127 - accuracy: 0.7429 - val_loss: 0.8982 - val_accuracy: 0.5672\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6239 - accuracy: 0.7247 - val_loss: 0.8722 - val_accuracy: 0.6119\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6237 - accuracy: 0.7267 - val_loss: 0.8998 - val_accuracy: 0.5672\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6173 - accuracy: 0.7368 - val_loss: 0.8771 - val_accuracy: 0.5821\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6115 - accuracy: 0.7308 - val_loss: 0.9082 - val_accuracy: 0.5746\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6166 - accuracy: 0.7105 - val_loss: 0.8872 - val_accuracy: 0.5597\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.6085 - accuracy: 0.7267 - val_loss: 0.9197 - val_accuracy: 0.5746\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.6235 - accuracy: 0.7186 - val_loss: 0.8915 - val_accuracy: 0.5746\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6212 - accuracy: 0.7105 - val_loss: 0.8929 - val_accuracy: 0.5672\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6053 - accuracy: 0.7429 - val_loss: 0.8913 - val_accuracy: 0.5672\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6041 - accuracy: 0.7328 - val_loss: 0.9070 - val_accuracy: 0.5821\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6049 - accuracy: 0.7267 - val_loss: 0.9060 - val_accuracy: 0.5597\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6084 - accuracy: 0.7105 - val_loss: 0.9142 - val_accuracy: 0.5597\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6011 - accuracy: 0.7389 - val_loss: 0.9002 - val_accuracy: 0.5746\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6210 - accuracy: 0.7287 - val_loss: 0.9013 - val_accuracy: 0.5746\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6089 - accuracy: 0.7287 - val_loss: 0.9206 - val_accuracy: 0.5746\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6064 - accuracy: 0.7389 - val_loss: 0.9003 - val_accuracy: 0.5597\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6056 - accuracy: 0.7611 - val_loss: 0.9018 - val_accuracy: 0.5970\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6179 - accuracy: 0.7247 - val_loss: 0.9151 - val_accuracy: 0.5746\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6061 - accuracy: 0.7105 - val_loss: 0.9200 - val_accuracy: 0.5746\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6024 - accuracy: 0.7287 - val_loss: 0.9494 - val_accuracy: 0.5821\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6205 - accuracy: 0.7267 - val_loss: 0.9202 - val_accuracy: 0.5597\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6131 - accuracy: 0.7368 - val_loss: 0.9258 - val_accuracy: 0.5746\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.5898 - accuracy: 0.7470 - val_loss: 0.9053 - val_accuracy: 0.5970\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6163 - accuracy: 0.7166 - val_loss: 0.9048 - val_accuracy: 0.5746\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.5938 - accuracy: 0.7510 - val_loss: 0.9221 - val_accuracy: 0.5597\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.5980 - accuracy: 0.7389 - val_loss: 0.9223 - val_accuracy: 0.5821\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6005 - accuracy: 0.7449 - val_loss: 0.9009 - val_accuracy: 0.5970\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6074 - accuracy: 0.7449 - val_loss: 0.9012 - val_accuracy: 0.5672\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6088 - accuracy: 0.7166 - val_loss: 0.9091 - val_accuracy: 0.5821\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6008 - accuracy: 0.7368 - val_loss: 0.9330 - val_accuracy: 0.5970\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6020 - accuracy: 0.7470 - val_loss: 0.9234 - val_accuracy: 0.5597\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.5941 - accuracy: 0.7368 - val_loss: 0.9117 - val_accuracy: 0.5746\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6070 - accuracy: 0.7186 - val_loss: 0.9392 - val_accuracy: 0.5970\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6032 - accuracy: 0.7308 - val_loss: 0.9607 - val_accuracy: 0.5746\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6324 - accuracy: 0.7085 - val_loss: 0.9564 - val_accuracy: 0.5522\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6060 - accuracy: 0.7247 - val_loss: 0.9238 - val_accuracy: 0.5746\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6126 - accuracy: 0.7166 - val_loss: 0.9604 - val_accuracy: 0.5597\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7510 - val_loss: 0.9659 - val_accuracy: 0.5597\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5972 - accuracy: 0.7389 - val_loss: 0.9500 - val_accuracy: 0.5970\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5961 - accuracy: 0.7490 - val_loss: 0.9381 - val_accuracy: 0.5522\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5703 - accuracy: 0.7551 - val_loss: 0.9569 - val_accuracy: 0.5597\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.5969 - accuracy: 0.7409 - val_loss: 0.9739 - val_accuracy: 0.5672\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6127 - accuracy: 0.7126 - val_loss: 0.9515 - val_accuracy: 0.5746\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6244 - accuracy: 0.7045 - val_loss: 0.9586 - val_accuracy: 0.5746\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.5873 - accuracy: 0.7348 - val_loss: 0.9639 - val_accuracy: 0.5672\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.5702 - accuracy: 0.7389 - val_loss: 0.9769 - val_accuracy: 0.5672\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.5846 - accuracy: 0.7409 - val_loss: 0.9650 - val_accuracy: 0.5821\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.5869 - accuracy: 0.7267 - val_loss: 0.9482 - val_accuracy: 0.5672\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5977 - accuracy: 0.7267 - val_loss: 0.9763 - val_accuracy: 0.5746\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5859 - accuracy: 0.7470 - val_loss: 0.9834 - val_accuracy: 0.5672\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5878 - accuracy: 0.7571 - val_loss: 0.9696 - val_accuracy: 0.5597\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.5996 - accuracy: 0.7267 - val_loss: 0.9622 - val_accuracy: 0.5522\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5752 - accuracy: 0.7490 - val_loss: 0.9456 - val_accuracy: 0.5672\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5845 - accuracy: 0.7551 - val_loss: 0.9772 - val_accuracy: 0.5672\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.5907 - accuracy: 0.7287 - val_loss: 0.9694 - val_accuracy: 0.5597\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.5742 - accuracy: 0.7611 - val_loss: 0.9740 - val_accuracy: 0.5821\n"
     ]
    }
   ],
   "source": [
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=30, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "\n",
    "history3 = model3.fit(X_train_cr, train_5w,\n",
    "                    epochs=100,\n",
    "                    batch_size=50,\n",
    "                    validation_data=(X_val_cr, val_5w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "train accuracy = 77.3279%\n",
      "test accuracy = 44.4444%\n",
      "test error = 35 out of 63 examples\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model:\n",
    "train_loss, train_acc = model3.evaluate(X_train_cr, train_5w,\n",
    "                                       batch_size=M_TRAIN, verbose=0)\n",
    "test_loss, test_acc = model3.evaluate(X_test_cr, test_5w,\n",
    "                                     batch_size=M_TEST, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_23 (LSTM)              (None, 32)                6784      \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,945\n",
      "Trainable params: 6,881\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 2s 34ms/step - loss: 2.7168 - accuracy: 0.5162 - val_loss: 2.4431 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 2.3686 - accuracy: 0.5324 - val_loss: 2.2130 - val_accuracy: 0.5149\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 2.1249 - accuracy: 0.5445 - val_loss: 2.0127 - val_accuracy: 0.4925\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.9280 - accuracy: 0.5830 - val_loss: 1.8371 - val_accuracy: 0.5448\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.7529 - accuracy: 0.5911 - val_loss: 1.6862 - val_accuracy: 0.5970\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.6063 - accuracy: 0.5931 - val_loss: 1.5573 - val_accuracy: 0.5821\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.4772 - accuracy: 0.6012 - val_loss: 1.4461 - val_accuracy: 0.5597\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.3804 - accuracy: 0.5870 - val_loss: 1.3503 - val_accuracy: 0.5597\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.2862 - accuracy: 0.5972 - val_loss: 1.2688 - val_accuracy: 0.5448\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.2038 - accuracy: 0.5972 - val_loss: 1.1971 - val_accuracy: 0.5597\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.1409 - accuracy: 0.6134 - val_loss: 1.1371 - val_accuracy: 0.5299\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.0834 - accuracy: 0.6032 - val_loss: 1.0841 - val_accuracy: 0.5373\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.0335 - accuracy: 0.5972 - val_loss: 1.0384 - val_accuracy: 0.5448\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.9900 - accuracy: 0.6113 - val_loss: 1.0014 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9536 - accuracy: 0.5992 - val_loss: 0.9674 - val_accuracy: 0.5149\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.9128 - accuracy: 0.6053 - val_loss: 0.9377 - val_accuracy: 0.5299\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.8958 - accuracy: 0.5992 - val_loss: 0.9122 - val_accuracy: 0.5299\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.8701 - accuracy: 0.6073 - val_loss: 0.8906 - val_accuracy: 0.5448\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.8456 - accuracy: 0.6174 - val_loss: 0.8717 - val_accuracy: 0.5299\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.8249 - accuracy: 0.6093 - val_loss: 0.8559 - val_accuracy: 0.5075\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.8142 - accuracy: 0.6194 - val_loss: 0.8414 - val_accuracy: 0.5299\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.8039 - accuracy: 0.6073 - val_loss: 0.8290 - val_accuracy: 0.5149\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.7864 - accuracy: 0.6113 - val_loss: 0.8196 - val_accuracy: 0.5149\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.7787 - accuracy: 0.6053 - val_loss: 0.8097 - val_accuracy: 0.5299\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.7680 - accuracy: 0.6194 - val_loss: 0.8029 - val_accuracy: 0.5075\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.7575 - accuracy: 0.6235 - val_loss: 0.7952 - val_accuracy: 0.4925\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.7505 - accuracy: 0.6134 - val_loss: 0.7882 - val_accuracy: 0.5149\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.7501 - accuracy: 0.6073 - val_loss: 0.7833 - val_accuracy: 0.4925\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.7372 - accuracy: 0.6093 - val_loss: 0.7779 - val_accuracy: 0.5373\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.7332 - accuracy: 0.6154 - val_loss: 0.7728 - val_accuracy: 0.4925\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.7331 - accuracy: 0.6154 - val_loss: 0.7696 - val_accuracy: 0.4925\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.7288 - accuracy: 0.6154 - val_loss: 0.7652 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.7231 - accuracy: 0.6174 - val_loss: 0.7624 - val_accuracy: 0.5075\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.7151 - accuracy: 0.6113 - val_loss: 0.7594 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7178 - accuracy: 0.6154 - val_loss: 0.7556 - val_accuracy: 0.5299\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7195 - accuracy: 0.6194 - val_loss: 0.7544 - val_accuracy: 0.5075\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7110 - accuracy: 0.6296 - val_loss: 0.7538 - val_accuracy: 0.4776\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7099 - accuracy: 0.6194 - val_loss: 0.7544 - val_accuracy: 0.4627\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7073 - accuracy: 0.6113 - val_loss: 0.7513 - val_accuracy: 0.4925\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.7107 - accuracy: 0.6235 - val_loss: 0.7500 - val_accuracy: 0.4776\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.7051 - accuracy: 0.6032 - val_loss: 0.7470 - val_accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.7018 - accuracy: 0.6296 - val_loss: 0.7456 - val_accuracy: 0.4925\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6980 - accuracy: 0.6235 - val_loss: 0.7470 - val_accuracy: 0.4701\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7011 - accuracy: 0.6174 - val_loss: 0.7461 - val_accuracy: 0.4925\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6956 - accuracy: 0.6215 - val_loss: 0.7444 - val_accuracy: 0.4925\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6980 - accuracy: 0.6296 - val_loss: 0.7444 - val_accuracy: 0.5075\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6982 - accuracy: 0.5951 - val_loss: 0.7462 - val_accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6951 - accuracy: 0.6316 - val_loss: 0.7429 - val_accuracy: 0.4851\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6998 - accuracy: 0.6154 - val_loss: 0.7428 - val_accuracy: 0.5075\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6954 - accuracy: 0.6053 - val_loss: 0.7447 - val_accuracy: 0.4851\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6916 - accuracy: 0.6174 - val_loss: 0.7445 - val_accuracy: 0.4925\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6851 - accuracy: 0.6275 - val_loss: 0.7435 - val_accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6886 - accuracy: 0.5992 - val_loss: 0.7442 - val_accuracy: 0.4925\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6864 - accuracy: 0.6113 - val_loss: 0.7455 - val_accuracy: 0.4776\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6873 - accuracy: 0.6113 - val_loss: 0.7466 - val_accuracy: 0.4552\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6883 - accuracy: 0.6194 - val_loss: 0.7471 - val_accuracy: 0.4627\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6864 - accuracy: 0.6235 - val_loss: 0.7497 - val_accuracy: 0.4925\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6796 - accuracy: 0.6235 - val_loss: 0.7490 - val_accuracy: 0.4851\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6843 - accuracy: 0.6235 - val_loss: 0.7495 - val_accuracy: 0.4776\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6821 - accuracy: 0.6073 - val_loss: 0.7491 - val_accuracy: 0.4627\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6840 - accuracy: 0.6093 - val_loss: 0.7524 - val_accuracy: 0.4552\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6798 - accuracy: 0.6134 - val_loss: 0.7491 - val_accuracy: 0.4851\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6810 - accuracy: 0.6093 - val_loss: 0.7518 - val_accuracy: 0.4851\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6844 - accuracy: 0.6113 - val_loss: 0.7448 - val_accuracy: 0.4701\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6810 - accuracy: 0.6154 - val_loss: 0.7541 - val_accuracy: 0.4478\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6836 - accuracy: 0.6296 - val_loss: 0.7532 - val_accuracy: 0.4403\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6752 - accuracy: 0.6275 - val_loss: 0.7554 - val_accuracy: 0.4403\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6804 - accuracy: 0.6215 - val_loss: 0.7567 - val_accuracy: 0.4627\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6802 - accuracy: 0.6154 - val_loss: 0.7516 - val_accuracy: 0.4776\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6772 - accuracy: 0.6255 - val_loss: 0.7571 - val_accuracy: 0.4552\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6785 - accuracy: 0.6316 - val_loss: 0.7671 - val_accuracy: 0.4403\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6737 - accuracy: 0.6275 - val_loss: 0.7678 - val_accuracy: 0.4328\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6761 - accuracy: 0.6073 - val_loss: 0.7582 - val_accuracy: 0.4403\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6764 - accuracy: 0.6255 - val_loss: 0.7645 - val_accuracy: 0.4552\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6739 - accuracy: 0.6134 - val_loss: 0.7716 - val_accuracy: 0.4328\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6758 - accuracy: 0.6053 - val_loss: 0.7676 - val_accuracy: 0.4552\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6781 - accuracy: 0.6113 - val_loss: 0.7694 - val_accuracy: 0.4254\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6726 - accuracy: 0.6194 - val_loss: 0.7709 - val_accuracy: 0.4627\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6764 - accuracy: 0.6053 - val_loss: 0.7710 - val_accuracy: 0.4776\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6746 - accuracy: 0.6174 - val_loss: 0.7697 - val_accuracy: 0.4701\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6736 - accuracy: 0.6215 - val_loss: 0.7765 - val_accuracy: 0.4328\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6737 - accuracy: 0.6255 - val_loss: 0.7773 - val_accuracy: 0.4254\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6727 - accuracy: 0.6194 - val_loss: 0.7670 - val_accuracy: 0.4552\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6706 - accuracy: 0.6316 - val_loss: 0.7746 - val_accuracy: 0.4627\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6674 - accuracy: 0.6194 - val_loss: 0.7811 - val_accuracy: 0.4403\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6679 - accuracy: 0.6316 - val_loss: 0.7791 - val_accuracy: 0.4776\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6746 - accuracy: 0.6113 - val_loss: 0.7751 - val_accuracy: 0.4627\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6690 - accuracy: 0.6397 - val_loss: 0.7688 - val_accuracy: 0.4478\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6718 - accuracy: 0.6134 - val_loss: 0.7736 - val_accuracy: 0.4627\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6738 - accuracy: 0.6012 - val_loss: 0.7711 - val_accuracy: 0.4328\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6754 - accuracy: 0.6032 - val_loss: 0.7840 - val_accuracy: 0.4328\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6680 - accuracy: 0.6174 - val_loss: 0.7845 - val_accuracy: 0.4254\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6709 - accuracy: 0.6215 - val_loss: 0.7754 - val_accuracy: 0.4403\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.6686 - accuracy: 0.6113 - val_loss: 0.7756 - val_accuracy: 0.4701\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6675 - accuracy: 0.6073 - val_loss: 0.7715 - val_accuracy: 0.4627\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6696 - accuracy: 0.6154 - val_loss: 0.7773 - val_accuracy: 0.4403\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.6675 - accuracy: 0.6356 - val_loss: 0.7807 - val_accuracy: 0.4403\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6661 - accuracy: 0.6296 - val_loss: 0.7727 - val_accuracy: 0.4403\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6662 - accuracy: 0.6235 - val_loss: 0.7787 - val_accuracy: 0.4179\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6636 - accuracy: 0.6235 - val_loss: 0.7787 - val_accuracy: 0.4552\n"
     ]
    }
   ],
   "source": [
    "n_steps = X_train_cr.shape[1]\n",
    "n_features = X_train_cr.shape[2]\n",
    "\n",
    "# Let's make a list of CONSTANTS for modelling:\n",
    "LAYERS = [32, 32, 32, 1]                # number of units in hidden and output layers\n",
    "M_TRAIN = X_train_cr.shape[0]           # number of training examples (2D)\n",
    "M_TEST = X_test_cr.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = X_train_cr.shape[2]                 # number of features\n",
    "BATCH = M_TRAIN                          # batch size\n",
    "EPOCH = 10                           # number of epochs\n",
    "LR = 5e-2                            # learning rate of the gradient descent\n",
    "LAMBD = 3e-2                         # lambda in L2 regularizaion\n",
    "DP = 0.0                             # dropout rate\n",
    "RDP = 0.0                            # recurrent dropout rate\n",
    "\n",
    "# Build the Model\n",
    "model4 = Sequential()\n",
    "\n",
    "model4.add(LSTM(units=LAYERS[2], input_shape=(n_steps, n_features),\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "model4.compile(loss='binary_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              optimizer=\"adam\")\n",
    "print(model4.summary())\n",
    "\n",
    "history4 = model4.fit(X_train_cr, train_5w,\n",
    "                    epochs=100,\n",
    "                    batch_size=50,\n",
    "                    validation_data=(X_val_cr, val_5w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "train accuracy = 62.5506%\n",
      "test accuracy = 55.5556%\n",
      "test error = 28 out of 63 examples\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model:\n",
    "train_loss, train_acc = model4.evaluate(X_train_cr, train_5w,\n",
    "                                       batch_size=M_TRAIN, verbose=0)\n",
    "test_loss, test_acc = model4.evaluate(X_test_cr, test_5w,\n",
    "                                     batch_size=M_TEST, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Of results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
