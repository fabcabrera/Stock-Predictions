{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aca2cf56",
   "metadata": {},
   "source": [
    "# RNN for UBS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71182113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns   \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn import (\n",
    "    linear_model, metrics, neural_network, pipeline, model_selection\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, InputLayer, SimpleRNN\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Dropout, SimpleRNN, LSTM, TimeDistributed, BatchNormalization\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da4f0a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"UBS_Cleaned_Date.csv\")\n",
    "df.date = pd.to_datetime(df.date)\n",
    "df = df.set_index(\"date\")\n",
    "df = df.iloc[14:, :]\n",
    "df = df.drop([\"Nas_total\", 'Stock_total', 'Dow_total'],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93eaca03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(748, 197)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df = df[~(df.isin([np.inf, -np.inf]).any(axis=1))] \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e5fa192",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['target_1', 'target_2', 'target_4', 'target_5'], axis=1)\n",
    "target_3 = df[\"target_3\"]\n",
    "\n",
    "#splitting into training sets \n",
    "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
    "\n",
    "n = len(df)\n",
    "X_train = df[0:int(n*0.9)]\n",
    "X_val = df[int(n*0.7):int(n*0.9)]\n",
    "X_test = df[int(n*0.9):]\n",
    "\n",
    "y_train = target_3[0:int(n*0.9)]\n",
    "y_val = target_3[int(n*0.7):int(n*0.9)]\n",
    "y_test = target_3[int(n*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b2a3f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mscaler = MinMaxScaler() # keeps binarys at zero and 1 :)\n",
    "\n",
    "X_train = pd.DataFrame(Mscaler.fit_transform(X_train), columns = df.columns)\n",
    "X_val = pd.DataFrame(Mscaler.fit_transform(X_val), columns = df.columns)\n",
    "X_test = pd.DataFrame(Mscaler.fit_transform(X_test), columns = df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "290b15eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_X_y2(df, target, window_size=10): \n",
    "  X = []\n",
    "  y = []\n",
    "  for i in range(len(df)-window_size): # length of data frame - window_size so it does't take empty values at the end, \n",
    "    # does force you to loose the last 5 values, could fix with padding\n",
    "    row = [r for r in df[i:i+window_size]] # grabs row i and all rows above within the window size length\n",
    "    X.append(row) # creates 3 dimentional array, (# obseravtions, # rows in window, # features)\n",
    "    label = target[i+window_size] # pulls the target variable after the window, target varible needs to be column zero in this \n",
    "    y.append(label) # returns (N,) martix of targets i+window_length time periods away\n",
    "  return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc0fecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kbest_creator(k):\n",
    "    \"\"\"\n",
    "    returns list of k best features and the number of efficient principle compents to use with said k features\n",
    "    \"\"\"\n",
    "    # apply SelectKBest class to extract top 40 best features\n",
    "    bestfeatures = SelectKBest(score_func=f_regression, k=k)\n",
    "    best_fit = bestfeatures.fit(X_train, y_train)\n",
    "    best_scores = pd.DataFrame(best_fit.scores_)\n",
    "    best_columns = pd.DataFrame(df.columns)\n",
    "    \n",
    "    # concatenate the dataframes for better visualization\n",
    "    features_score = pd.concat([best_columns, best_scores], axis=1)\n",
    "    features_score.columns = ['Features', 'Score']  # naming the dataframe columns\n",
    "    feats = list(features_score.nlargest(k, 'Score')['Features'])\n",
    "\n",
    "    pca = PCA().fit(X_train[feats])\n",
    "    pca_scores = np.cumsum(pca.explained_variance_ratio_) * 100\n",
    "    res = next(x for x, val in enumerate(pca_scores) if val > 85)\n",
    "    res = res +1\n",
    "    res\n",
    "    \n",
    "    return feats, res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "070e891e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabrizio/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:301: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n"
     ]
    }
   ],
   "source": [
    "feats, pcs = kbest_creator(40)\n",
    "# 9 compenents explain 85% \n",
    "pca_kb = PCA(n_components = pcs).fit(X_train[feats].to_numpy())\n",
    "X_train_kb = pca_kb.transform(X_train[feats].to_numpy())\n",
    "X_val_kb = pca_kb.transform(X_val[feats].to_numpy())\n",
    "X_test_kb = pca_kb.transform(X_test[feats].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44d6a0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to window format, in this case 5 periods\n",
    "X_train_1, train_5w = df_to_X_y2(X_train_kb,y_train)\n",
    "X_val_1, val_5w = df_to_X_y2(X_val_kb, y_val)\n",
    "X_test_1, test_5w = df_to_X_y2(X_test_kb,y_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d68c4ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(663, 10, 10) (663,)\n",
      "(140, 10, 10) (140,)\n",
      "(65, 10, 10) (65,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_1.shape, train_5w.shape)\n",
    "print(X_val_1.shape, val_5w.shape)\n",
    "print(X_test_1.shape, test_5w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874ad248",
   "metadata": {},
   "source": [
    "# Models Using PCA of 40 K Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc68ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = X_train_1.shape[1]\n",
    "n_features = X_train_1.shape[2]\n",
    "\n",
    "# Let's make a list of CONSTANTS for modelling:\n",
    "LAYERS = [8, 8, 8, 1]                # number of units in hidden and output layers\n",
    "M_TRAIN = X_train_1.shape[0]           # number of training examples (2D)\n",
    "M_TEST = X_test_1.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = X_train_1.shape[2]                 # number of features\n",
    "BATCH = M_TRAIN                          # batch size\n",
    "EPOCH = 10                           # number of epochs\n",
    "LR = 5e-2                            # learning rate of the gradient descent\n",
    "LAMBD = 3e-2                         # lambda in L2 regularizaion\n",
    "DP = 0.0                             # dropout rate\n",
    "RDP = 0.0                            # recurrent dropout rate\n",
    "\n",
    "# Build the Model\n",
    "model = Sequential()\n",
    "model.add(LSTM(input_shape=(n_steps, n_features), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid', \n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=LAYERS[3], activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96bb15f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 10, 8)             608       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 10, 8)            32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 10, 8)             544       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 10, 8)            32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 8)                 544       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8)                32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,801\n",
      "Trainable params: 1,753\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              optimizer=\"adam\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73a3f7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 13s 135ms/step - loss: 2.6366 - accuracy: 0.5128 - val_loss: 2.4632 - val_accuracy: 0.5143\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 2.4342 - accuracy: 0.5204 - val_loss: 2.3186 - val_accuracy: 0.5214\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 2.2661 - accuracy: 0.5430 - val_loss: 2.1840 - val_accuracy: 0.5143\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 2.1269 - accuracy: 0.5385 - val_loss: 2.0600 - val_accuracy: 0.5071\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 2.0040 - accuracy: 0.5747 - val_loss: 1.9466 - val_accuracy: 0.5071\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.8899 - accuracy: 0.5837 - val_loss: 1.8439 - val_accuracy: 0.5071\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.7865 - accuracy: 0.5762 - val_loss: 1.7504 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.6894 - accuracy: 0.5807 - val_loss: 1.6651 - val_accuracy: 0.4929\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.6061 - accuracy: 0.5852 - val_loss: 1.5880 - val_accuracy: 0.4857\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.5265 - accuracy: 0.5973 - val_loss: 1.5181 - val_accuracy: 0.4786\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 1.4628 - accuracy: 0.5867 - val_loss: 1.4528 - val_accuracy: 0.4786\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.3945 - accuracy: 0.5882 - val_loss: 1.3936 - val_accuracy: 0.4857\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 1.3411 - accuracy: 0.5867 - val_loss: 1.3401 - val_accuracy: 0.4714\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.2870 - accuracy: 0.5897 - val_loss: 1.2914 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 1.2398 - accuracy: 0.5928 - val_loss: 1.2491 - val_accuracy: 0.4857\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 1.1952 - accuracy: 0.5747 - val_loss: 1.2091 - val_accuracy: 0.4786\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 1.1530 - accuracy: 0.6078 - val_loss: 1.1712 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 1.1200 - accuracy: 0.5747 - val_loss: 1.1374 - val_accuracy: 0.5071\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 1.0867 - accuracy: 0.5988 - val_loss: 1.1075 - val_accuracy: 0.5071\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 1.0523 - accuracy: 0.6154 - val_loss: 1.0808 - val_accuracy: 0.5071\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.0266 - accuracy: 0.6109 - val_loss: 1.0546 - val_accuracy: 0.5143\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 1.0015 - accuracy: 0.6063 - val_loss: 1.0310 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.9807 - accuracy: 0.6018 - val_loss: 1.0090 - val_accuracy: 0.4929\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.9628 - accuracy: 0.5882 - val_loss: 0.9906 - val_accuracy: 0.4929\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.9424 - accuracy: 0.6169 - val_loss: 0.9740 - val_accuracy: 0.5286\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.9213 - accuracy: 0.6290 - val_loss: 0.9555 - val_accuracy: 0.5214\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.9084 - accuracy: 0.6094 - val_loss: 0.9386 - val_accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.8950 - accuracy: 0.6124 - val_loss: 0.9218 - val_accuracy: 0.5714\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.8786 - accuracy: 0.6199 - val_loss: 0.9110 - val_accuracy: 0.5571\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.8675 - accuracy: 0.6154 - val_loss: 0.8986 - val_accuracy: 0.5286\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.8564 - accuracy: 0.6094 - val_loss: 0.8868 - val_accuracy: 0.5500\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.8484 - accuracy: 0.6244 - val_loss: 0.8779 - val_accuracy: 0.5571\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.8374 - accuracy: 0.6229 - val_loss: 0.8684 - val_accuracy: 0.5857\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.8296 - accuracy: 0.6214 - val_loss: 0.8587 - val_accuracy: 0.5714\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.8205 - accuracy: 0.6199 - val_loss: 0.8499 - val_accuracy: 0.5929\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.8152 - accuracy: 0.6214 - val_loss: 0.8455 - val_accuracy: 0.6000\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.8079 - accuracy: 0.6425 - val_loss: 0.8374 - val_accuracy: 0.6143\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.8041 - accuracy: 0.6259 - val_loss: 0.8230 - val_accuracy: 0.6286\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7911 - accuracy: 0.6471 - val_loss: 0.8227 - val_accuracy: 0.6286\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.7899 - accuracy: 0.6169 - val_loss: 0.8161 - val_accuracy: 0.5857\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.7845 - accuracy: 0.6124 - val_loss: 0.8144 - val_accuracy: 0.5929\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7788 - accuracy: 0.6531 - val_loss: 0.8030 - val_accuracy: 0.6071\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7764 - accuracy: 0.6290 - val_loss: 0.7999 - val_accuracy: 0.6071\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.7830 - accuracy: 0.6425 - val_loss: 0.7909 - val_accuracy: 0.6286\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.7655 - accuracy: 0.6410 - val_loss: 0.7787 - val_accuracy: 0.6143\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.7688 - accuracy: 0.6440 - val_loss: 0.7808 - val_accuracy: 0.6214\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.7775 - accuracy: 0.6425 - val_loss: 0.7797 - val_accuracy: 0.6071\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.7579 - accuracy: 0.6425 - val_loss: 0.7667 - val_accuracy: 0.6357\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7588 - accuracy: 0.6531 - val_loss: 0.7658 - val_accuracy: 0.6000\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7556 - accuracy: 0.6320 - val_loss: 0.7547 - val_accuracy: 0.6429\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.7474 - accuracy: 0.6546 - val_loss: 0.7624 - val_accuracy: 0.6286\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.7593 - accuracy: 0.6380 - val_loss: 0.7683 - val_accuracy: 0.6071\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.7525 - accuracy: 0.6275 - val_loss: 0.7521 - val_accuracy: 0.6143\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.7516 - accuracy: 0.6410 - val_loss: 0.7359 - val_accuracy: 0.6571\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.7477 - accuracy: 0.6591 - val_loss: 0.7389 - val_accuracy: 0.6714\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7395 - accuracy: 0.6501 - val_loss: 0.7384 - val_accuracy: 0.6500\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7447 - accuracy: 0.6395 - val_loss: 0.7245 - val_accuracy: 0.6857\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.7337 - accuracy: 0.6486 - val_loss: 0.7252 - val_accuracy: 0.6643\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.7303 - accuracy: 0.6456 - val_loss: 0.7247 - val_accuracy: 0.6500\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7363 - accuracy: 0.6350 - val_loss: 0.7353 - val_accuracy: 0.6571\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.7316 - accuracy: 0.6576 - val_loss: 0.7171 - val_accuracy: 0.6500\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.7442 - accuracy: 0.6169 - val_loss: 0.7369 - val_accuracy: 0.6214\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.7441 - accuracy: 0.6380 - val_loss: 0.7195 - val_accuracy: 0.6857\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.7361 - accuracy: 0.6471 - val_loss: 0.7293 - val_accuracy: 0.6214\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.7282 - accuracy: 0.6471 - val_loss: 0.7146 - val_accuracy: 0.6571\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.7286 - accuracy: 0.6425 - val_loss: 0.7243 - val_accuracy: 0.6643\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.7229 - accuracy: 0.6425 - val_loss: 0.7461 - val_accuracy: 0.6000\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.7326 - accuracy: 0.6395 - val_loss: 0.7306 - val_accuracy: 0.6571\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7260 - accuracy: 0.6606 - val_loss: 0.7409 - val_accuracy: 0.6286\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.7167 - accuracy: 0.6667 - val_loss: 0.7114 - val_accuracy: 0.6857\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.7173 - accuracy: 0.6561 - val_loss: 0.7045 - val_accuracy: 0.6714\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7172 - accuracy: 0.6591 - val_loss: 0.7125 - val_accuracy: 0.6714\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7126 - accuracy: 0.6591 - val_loss: 0.7002 - val_accuracy: 0.6929\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.7311 - accuracy: 0.6380 - val_loss: 0.6991 - val_accuracy: 0.6714\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.7221 - accuracy: 0.6621 - val_loss: 0.7171 - val_accuracy: 0.6500\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7228 - accuracy: 0.6440 - val_loss: 0.6934 - val_accuracy: 0.7143\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.7090 - accuracy: 0.6501 - val_loss: 0.6995 - val_accuracy: 0.6929\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.7085 - accuracy: 0.6712 - val_loss: 0.6975 - val_accuracy: 0.7071\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.7161 - accuracy: 0.6667 - val_loss: 0.7048 - val_accuracy: 0.6643\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.7167 - accuracy: 0.6305 - val_loss: 0.7019 - val_accuracy: 0.6643\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.7078 - accuracy: 0.6471 - val_loss: 0.7126 - val_accuracy: 0.6143\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.7171 - accuracy: 0.6561 - val_loss: 0.6910 - val_accuracy: 0.7214\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.7129 - accuracy: 0.6440 - val_loss: 0.7052 - val_accuracy: 0.6429\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.7071 - accuracy: 0.6652 - val_loss: 0.6949 - val_accuracy: 0.7143\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.7035 - accuracy: 0.6621 - val_loss: 0.6822 - val_accuracy: 0.6929\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.6954 - accuracy: 0.6667 - val_loss: 0.6841 - val_accuracy: 0.6857\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7091 - accuracy: 0.6546 - val_loss: 0.6979 - val_accuracy: 0.6786\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7060 - accuracy: 0.6561 - val_loss: 0.6802 - val_accuracy: 0.7214\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.7045 - accuracy: 0.6471 - val_loss: 0.6829 - val_accuracy: 0.6786\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6956 - accuracy: 0.6591 - val_loss: 0.7336 - val_accuracy: 0.6214\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.6974 - accuracy: 0.6561 - val_loss: 0.6858 - val_accuracy: 0.6786\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.7050 - accuracy: 0.6320 - val_loss: 0.7182 - val_accuracy: 0.6357\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.7124 - accuracy: 0.6410 - val_loss: 0.6919 - val_accuracy: 0.7000\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.7036 - accuracy: 0.6621 - val_loss: 0.6735 - val_accuracy: 0.6786\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.6952 - accuracy: 0.6591 - val_loss: 0.6710 - val_accuracy: 0.7071\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.6902 - accuracy: 0.6561 - val_loss: 0.6660 - val_accuracy: 0.6714\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.6949 - accuracy: 0.6787 - val_loss: 0.6714 - val_accuracy: 0.6857\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7000 - accuracy: 0.6606 - val_loss: 0.6966 - val_accuracy: 0.6857\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.7044 - accuracy: 0.6456 - val_loss: 0.7186 - val_accuracy: 0.6500\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.7038 - accuracy: 0.6456 - val_loss: 0.6723 - val_accuracy: 0.6714\n"
     ]
    }
   ],
   "source": [
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=30, verbose=1, mode='auto',\n",
    "                           baseline=0, restore_best_weights=True)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "\n",
    "history = model.fit(X_train_1, train_5w,\n",
    "                    epochs=100,\n",
    "                    batch_size=50,\n",
    "                    validation_data=(X_val_1, val_5w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00eeeea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "train accuracy = 67.1192%\n",
      "test accuracy = 46.1538%\n",
      "test error = 35 out of 65 examples\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model:\n",
    "train_loss, train_acc = model.evaluate(X_train_1, train_5w,\n",
    "                                       batch_size=M_TRAIN, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(X_test_1, test_5w,\n",
    "                                     batch_size=M_TEST, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ab84ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1296x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss and accuracy curves over epochs:\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(18,6))\n",
    "axs[0].plot(history.history['loss'], color='b', label='Training loss')\n",
    "axs[0].plot(history.history['val_loss'], color='r', label='Validation loss')\n",
    "axs[0].set_title(\"Loss curves\")\n",
    "axs[0].legend(loc='best', shadow=True)\n",
    "axs[1].plot(history.history['accuracy'], color='b', label='Training accuracy')\n",
    "axs[1].plot(history.history['val_accuracy'], color='r', label='Validation accuracy')\n",
    "axs[1].set_title(\"Accuracy curves\")\n",
    "axs[1].legend(loc='best', shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8823196c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 8ms/step\n",
      "2017-01-02 00:00:00 [0.79954416] 1\n",
      "2017-01-03 00:00:00 [0.63565904] 1\n",
      "2017-01-04 00:00:00 [0.3805544] 1\n",
      "2017-01-05 00:00:00 [0.25177002] 0\n",
      "2017-01-06 00:00:00 [0.15970427] 0\n",
      "2017-01-09 00:00:00 [0.16639245] 1\n",
      "2017-01-10 00:00:00 [0.17841834] 1\n",
      "2017-01-11 00:00:00 [0.14532945] 0\n",
      "2017-01-12 00:00:00 [0.33571413] 1\n",
      "2017-01-13 00:00:00 [0.48756525] 1\n",
      "2017-01-16 00:00:00 [0.4374034] 0\n",
      "2017-01-17 00:00:00 [0.27436027] 1\n",
      "2017-01-18 00:00:00 [0.27651188] 1\n",
      "2017-01-19 00:00:00 [0.16473636] 0\n",
      "2017-01-20 00:00:00 [0.19490665] 1\n",
      "2017-01-23 00:00:00 [0.2643879] 0\n",
      "2017-01-24 00:00:00 [0.17826086] 0\n",
      "2017-01-25 00:00:00 [0.30941528] 0\n",
      "2017-01-26 00:00:00 [0.22597456] 0\n",
      "2017-01-27 00:00:00 [0.23358041] 0\n",
      "2017-01-30 00:00:00 [0.3168319] 1\n",
      "2017-01-31 00:00:00 [0.39585602] 0\n",
      "2017-02-01 00:00:00 [0.6102499] 1\n",
      "2017-02-02 00:00:00 [0.60361767] 1\n",
      "2017-02-03 00:00:00 [0.31752217] 1\n",
      "2017-02-06 00:00:00 [0.16871154] 1\n",
      "2017-02-07 00:00:00 [0.16865486] 0\n",
      "2017-02-08 00:00:00 [0.18169507] 1\n",
      "2017-02-09 00:00:00 [0.33270723] 1\n",
      "2017-02-10 00:00:00 [0.5941729] 1\n",
      "2017-02-13 00:00:00 [0.7649125] 1\n",
      "2017-02-14 00:00:00 [0.7883456] 0\n",
      "2017-02-15 00:00:00 [0.7658376] 0\n",
      "2017-02-16 00:00:00 [0.76574856] 0\n",
      "2017-02-17 00:00:00 [0.7866569] 1\n",
      "2017-02-20 00:00:00 [0.840016] 0\n",
      "2017-02-21 00:00:00 [0.7572993] 0\n",
      "2017-02-22 00:00:00 [0.78624326] 0\n",
      "2017-02-23 00:00:00 [0.8310517] 0\n",
      "2017-02-24 00:00:00 [0.79490125] 0\n",
      "2017-02-27 00:00:00 [0.81001544] 0\n",
      "2017-02-28 00:00:00 [0.8397628] 1\n",
      "2017-03-01 00:00:00 [0.77572364] 0\n",
      "2017-03-02 00:00:00 [0.7170708] 0\n",
      "2017-03-03 00:00:00 [0.7101464] 1\n",
      "2017-03-06 00:00:00 [0.7555809] 0\n",
      "2017-03-07 00:00:00 [0.8103657] 0\n",
      "2017-03-08 00:00:00 [0.7529387] 0\n",
      "2017-03-09 00:00:00 [0.778195] 1\n",
      "2017-03-10 00:00:00 [0.8703325] 1\n",
      "2017-03-13 00:00:00 [0.8604187] 0\n",
      "2017-03-14 00:00:00 [0.7498003] 0\n",
      "2017-03-15 00:00:00 [0.6355584] 1\n",
      "2017-03-16 00:00:00 [0.6868071] 1\n",
      "2017-03-17 00:00:00 [0.5204273] 1\n",
      "2017-03-20 00:00:00 [0.39874595] 1\n",
      "2017-03-21 00:00:00 [0.35466588] 1\n",
      "2017-03-22 00:00:00 [0.3065297] 1\n",
      "2017-03-23 00:00:00 [0.392972] 1\n",
      "2017-03-24 00:00:00 [0.38955885] 0\n",
      "2017-03-27 00:00:00 [0.5907041] 1\n",
      "2017-03-28 00:00:00 [0.6322899] 1\n",
      "2017-03-29 00:00:00 [0.6770682] 0\n",
      "2017-03-30 00:00:00 [0.64729106] 1\n",
      "2017-03-31 00:00:00 [0.53516537] 0\n"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict(X_test_1, batch_size=50, verbose=1)\n",
    "#score = sum(y_hat == y_test) / len(y_test)\n",
    "#print(f'Prediction accuracy = {score*100}%')\n",
    "index = pd.date_range(start='2017-01-02', end='2018-06-19', freq='B')\n",
    "for i in range(y_hat.shape[0]):\n",
    "    print(index[i], y_hat[i], test_5w[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53e002dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'True: 0'), Text(0, 1.5, 'True: 1')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display confusion matrix results\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "ax = plt.subplot()\n",
    "predicted = model.predict(X_test_1)\n",
    "predicted = (predicted > 0.5)\n",
    "\n",
    "confusion = confusion_matrix(test_5w, predicted)\n",
    "\n",
    "sns.heatmap(confusion, annot=True, ax=ax)\n",
    "\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels([\"Predicted: 0\", \"Predicted: 1\"])\n",
    "ax.yaxis.set_ticklabels([\"True: 0\", \"True: 1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89d1bd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2\n",
    "n_steps = X_train_1.shape[1]\n",
    "n_features = X_train_1.shape[2]\n",
    "\n",
    "# Let's make a list of CONSTANTS for modeling:\n",
    "LAYERS = [4, 4, 4, 1]                # number of units in hidden and output layers\n",
    "M_TRAIN = X_train_1.shape[0]           # number of training examples (2D)\n",
    "M_TEST = X_test_1.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = X_train_1.shape[2]                 # number of features\n",
    "BATCH = M_TRAIN                          # batch size\n",
    "EPOCH = 10                           # number of epochs\n",
    "LR = 5e-2                            # learning rate of the gradient descent\n",
    "LAMBD = 3e-2                         # lambda in L2 regularizaion\n",
    "DP = 0.0                             # dropout rate\n",
    "RDP = 0.0                            # recurrent dropout rate\n",
    "\n",
    "# Build the Model2\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(input_shape=(n_steps, n_features), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid', \n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dense(12, activation='relu'))\n",
    "model2.add(Dense(units=LAYERS[3], activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa068d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 10, 4)             240       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 10, 4)            16        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 10, 4)             144       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 10, 4)            16        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 4)                 144       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 4)                16        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                60        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 649\n",
      "Trainable params: 625\n",
      "Non-trainable params: 24\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              optimizer=\"adam\")\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18971a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 13s 118ms/step - loss: 1.8292 - accuracy: 0.4796 - val_loss: 1.7365 - val_accuracy: 0.4643\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.7344 - accuracy: 0.4796 - val_loss: 1.6641 - val_accuracy: 0.4357\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 1.6565 - accuracy: 0.4751 - val_loss: 1.5959 - val_accuracy: 0.4500\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 1.5802 - accuracy: 0.4811 - val_loss: 1.5321 - val_accuracy: 0.4571\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 1.5143 - accuracy: 0.4947 - val_loss: 1.4722 - val_accuracy: 0.4643\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.4522 - accuracy: 0.5098 - val_loss: 1.4163 - val_accuracy: 0.4643\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 1.3963 - accuracy: 0.4962 - val_loss: 1.3638 - val_accuracy: 0.4571\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 1.3434 - accuracy: 0.4872 - val_loss: 1.3150 - val_accuracy: 0.4500\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 1.2955 - accuracy: 0.4962 - val_loss: 1.2699 - val_accuracy: 0.4571\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.2478 - accuracy: 0.4992 - val_loss: 1.2276 - val_accuracy: 0.4571\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 1.2064 - accuracy: 0.5038 - val_loss: 1.1880 - val_accuracy: 0.4429\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 1.1686 - accuracy: 0.5143 - val_loss: 1.1514 - val_accuracy: 0.4357\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 1.1324 - accuracy: 0.4932 - val_loss: 1.1175 - val_accuracy: 0.4357\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 1.0983 - accuracy: 0.5158 - val_loss: 1.0859 - val_accuracy: 0.4357\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 1.0667 - accuracy: 0.5324 - val_loss: 1.0564 - val_accuracy: 0.4571\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 1.0368 - accuracy: 0.5475 - val_loss: 1.0288 - val_accuracy: 0.4643\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.0101 - accuracy: 0.5475 - val_loss: 1.0032 - val_accuracy: 0.4786\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.9852 - accuracy: 0.5415 - val_loss: 0.9794 - val_accuracy: 0.4714\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.9613 - accuracy: 0.5445 - val_loss: 0.9573 - val_accuracy: 0.4714\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.9409 - accuracy: 0.5626 - val_loss: 0.9370 - val_accuracy: 0.4929\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.9194 - accuracy: 0.5656 - val_loss: 0.9180 - val_accuracy: 0.5286\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.9010 - accuracy: 0.5671 - val_loss: 0.9006 - val_accuracy: 0.5214\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.8843 - accuracy: 0.5913 - val_loss: 0.8846 - val_accuracy: 0.5429\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.8677 - accuracy: 0.5913 - val_loss: 0.8696 - val_accuracy: 0.5786\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.8532 - accuracy: 0.5882 - val_loss: 0.8560 - val_accuracy: 0.5714\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.8427 - accuracy: 0.5701 - val_loss: 0.8436 - val_accuracy: 0.5643\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.8284 - accuracy: 0.5973 - val_loss: 0.8317 - val_accuracy: 0.5500\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.8170 - accuracy: 0.6078 - val_loss: 0.8206 - val_accuracy: 0.5429\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.8080 - accuracy: 0.5913 - val_loss: 0.8107 - val_accuracy: 0.5643\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.7959 - accuracy: 0.5958 - val_loss: 0.8013 - val_accuracy: 0.5714\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.7875 - accuracy: 0.5913 - val_loss: 0.7923 - val_accuracy: 0.5643\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.7751 - accuracy: 0.5973 - val_loss: 0.7852 - val_accuracy: 0.5571\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7707 - accuracy: 0.5943 - val_loss: 0.7789 - val_accuracy: 0.5714\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.7655 - accuracy: 0.6003 - val_loss: 0.7710 - val_accuracy: 0.5786\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7583 - accuracy: 0.5928 - val_loss: 0.7633 - val_accuracy: 0.5786\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.7525 - accuracy: 0.5882 - val_loss: 0.7580 - val_accuracy: 0.5786\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.7463 - accuracy: 0.6018 - val_loss: 0.7524 - val_accuracy: 0.6000\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.7406 - accuracy: 0.5988 - val_loss: 0.7475 - val_accuracy: 0.6071\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.7381 - accuracy: 0.5807 - val_loss: 0.7420 - val_accuracy: 0.5714\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.7331 - accuracy: 0.6003 - val_loss: 0.7359 - val_accuracy: 0.5714\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.7284 - accuracy: 0.5943 - val_loss: 0.7338 - val_accuracy: 0.5857\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.7266 - accuracy: 0.6018 - val_loss: 0.7296 - val_accuracy: 0.6000\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.7223 - accuracy: 0.6018 - val_loss: 0.7274 - val_accuracy: 0.6143\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.7206 - accuracy: 0.5867 - val_loss: 0.7265 - val_accuracy: 0.6000\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.7164 - accuracy: 0.6109 - val_loss: 0.7233 - val_accuracy: 0.6214\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.7168 - accuracy: 0.5897 - val_loss: 0.7184 - val_accuracy: 0.6357\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.7131 - accuracy: 0.6109 - val_loss: 0.7166 - val_accuracy: 0.6214\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.7140 - accuracy: 0.5807 - val_loss: 0.7141 - val_accuracy: 0.6286\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.7107 - accuracy: 0.5943 - val_loss: 0.7116 - val_accuracy: 0.6429\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.7081 - accuracy: 0.6063 - val_loss: 0.7136 - val_accuracy: 0.6143\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.7046 - accuracy: 0.6033 - val_loss: 0.7118 - val_accuracy: 0.6000\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.7027 - accuracy: 0.6124 - val_loss: 0.7044 - val_accuracy: 0.5857\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.7015 - accuracy: 0.6018 - val_loss: 0.7051 - val_accuracy: 0.5714\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6981 - accuracy: 0.6109 - val_loss: 0.7063 - val_accuracy: 0.5786\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.6962 - accuracy: 0.6094 - val_loss: 0.7037 - val_accuracy: 0.5929\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6940 - accuracy: 0.6229 - val_loss: 0.7072 - val_accuracy: 0.6000\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.6948 - accuracy: 0.6018 - val_loss: 0.7051 - val_accuracy: 0.6071\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.6932 - accuracy: 0.5958 - val_loss: 0.7007 - val_accuracy: 0.5786\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.6912 - accuracy: 0.6094 - val_loss: 0.7040 - val_accuracy: 0.5929\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.6917 - accuracy: 0.6094 - val_loss: 0.6992 - val_accuracy: 0.5571\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.6901 - accuracy: 0.6169 - val_loss: 0.7001 - val_accuracy: 0.5500\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.6872 - accuracy: 0.6063 - val_loss: 0.7021 - val_accuracy: 0.5571\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.6898 - accuracy: 0.5973 - val_loss: 0.6996 - val_accuracy: 0.5714\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.6846 - accuracy: 0.6199 - val_loss: 0.6966 - val_accuracy: 0.5786\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.6872 - accuracy: 0.5973 - val_loss: 0.6939 - val_accuracy: 0.5714\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.6853 - accuracy: 0.6078 - val_loss: 0.6878 - val_accuracy: 0.5857\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.6906 - accuracy: 0.6003 - val_loss: 0.6929 - val_accuracy: 0.5929\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.6861 - accuracy: 0.6259 - val_loss: 0.6943 - val_accuracy: 0.5786\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.6878 - accuracy: 0.5973 - val_loss: 0.6928 - val_accuracy: 0.5929\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.6829 - accuracy: 0.6214 - val_loss: 0.6953 - val_accuracy: 0.6071\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.6832 - accuracy: 0.6078 - val_loss: 0.6999 - val_accuracy: 0.5571\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.6784 - accuracy: 0.6184 - val_loss: 0.6941 - val_accuracy: 0.5714\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.6826 - accuracy: 0.6184 - val_loss: 0.6917 - val_accuracy: 0.5857\n"
     ]
    }
   ],
   "source": [
    "lr_decay = ReduceLROnPlateau(monitor='loss', \n",
    "                             patience=1, verbose=0, \n",
    "                             factor=0.5, min_lr=1e-8)\n",
    "# Define Early Stopping:\n",
    "early_stop = EarlyStopping(patience=7)\n",
    "# Train the model. \n",
    "# The dataset is small for NN - let's use test_data for validation\n",
    "\n",
    "history = model2.fit(X_train_1, train_5w,\n",
    "                    epochs=100,\n",
    "                    batch_size=50,\n",
    "                    validation_data=(X_val_1, val_5w), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98a635fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "train accuracy = 58.5219%\n",
      "test accuracy = 47.6923%\n",
      "test error = 34 out of 65 examples\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model2.evaluate(X_train_1, train_5w,\n",
    "                                       batch_size=M_TRAIN, verbose=0)\n",
    "test_loss, test_acc = model2.evaluate(X_test_1, test_5w,\n",
    "                                     batch_size=M_TEST, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc4bc084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model3\n",
    "n_steps = X_train_1.shape[1]\n",
    "n_features = X_train_1.shape[2]\n",
    "\n",
    "# Let's make a list of CONSTANTS for modeling:\n",
    "LAYERS = [4, 4, 4, 1]                # number of units in hidden and output layers\n",
    "M_TRAIN = X_train_1.shape[0]           # number of training examples (2D)\n",
    "M_TEST = X_test_1.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = X_train_1.shape[2]                 # number of features\n",
    "BATCH = M_TRAIN                          # batch size\n",
    "EPOCH = 10                           # number of epochs\n",
    "LR = 5e-2                            # learning rate of the gradient descent\n",
    "LAMBD = 3e-2                         # lambda in L2 regularizaion\n",
    "DP = 0.0                             # dropout rate\n",
    "RDP = 0.0                            # recurrent dropout rate\n",
    "\n",
    "# Build the Model3\n",
    "model3 = Sequential()\n",
    "\n",
    "model3.add(LSTM(units=LAYERS[2],input_shape=(n_steps, n_features),\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Dense(12, activation='relu'))\n",
    "model3.add(Dense(units=LAYERS[3], activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cc832cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 4)                 240       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 4)                16        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 12)                60        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 321\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model3.compile(loss='binary_crossentropy',\n",
    "              metrics=['BinaryAccuracy'],\n",
    "              optimizer=\"adam\")\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffc2608c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - 4s 34ms/step - loss: 1.1881 - binary_accuracy: 0.4947 - val_loss: 1.1171 - val_binary_accuracy: 0.4786\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.1263 - binary_accuracy: 0.4992 - val_loss: 1.0710 - val_binary_accuracy: 0.4857\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1.0730 - binary_accuracy: 0.5053 - val_loss: 1.0298 - val_binary_accuracy: 0.4643\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.0263 - binary_accuracy: 0.4887 - val_loss: 0.9926 - val_binary_accuracy: 0.4571\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.9849 - binary_accuracy: 0.5219 - val_loss: 0.9584 - val_binary_accuracy: 0.4571\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.9498 - binary_accuracy: 0.5173 - val_loss: 0.9284 - val_binary_accuracy: 0.4571\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.9215 - binary_accuracy: 0.5264 - val_loss: 0.9017 - val_binary_accuracy: 0.4714\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8921 - binary_accuracy: 0.5204 - val_loss: 0.8776 - val_binary_accuracy: 0.4643\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.8709 - binary_accuracy: 0.5098 - val_loss: 0.8566 - val_binary_accuracy: 0.4714\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8470 - binary_accuracy: 0.5249 - val_loss: 0.8371 - val_binary_accuracy: 0.4714\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8292 - binary_accuracy: 0.5339 - val_loss: 0.8195 - val_binary_accuracy: 0.4857\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8110 - binary_accuracy: 0.5324 - val_loss: 0.8046 - val_binary_accuracy: 0.4857\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.7995 - binary_accuracy: 0.5294 - val_loss: 0.7909 - val_binary_accuracy: 0.4929\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7834 - binary_accuracy: 0.5234 - val_loss: 0.7784 - val_binary_accuracy: 0.5286\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.7729 - binary_accuracy: 0.5370 - val_loss: 0.7672 - val_binary_accuracy: 0.5071\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.7609 - binary_accuracy: 0.5354 - val_loss: 0.7578 - val_binary_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.7541 - binary_accuracy: 0.5249 - val_loss: 0.7495 - val_binary_accuracy: 0.5286\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7467 - binary_accuracy: 0.5354 - val_loss: 0.7417 - val_binary_accuracy: 0.5143\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7393 - binary_accuracy: 0.5354 - val_loss: 0.7348 - val_binary_accuracy: 0.5500\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7310 - binary_accuracy: 0.5490 - val_loss: 0.7283 - val_binary_accuracy: 0.5500\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.7258 - binary_accuracy: 0.5475 - val_loss: 0.7230 - val_binary_accuracy: 0.5571\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7219 - binary_accuracy: 0.5234 - val_loss: 0.7188 - val_binary_accuracy: 0.5429\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7174 - binary_accuracy: 0.5460 - val_loss: 0.7141 - val_binary_accuracy: 0.5357\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7135 - binary_accuracy: 0.5566 - val_loss: 0.7103 - val_binary_accuracy: 0.5786\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7108 - binary_accuracy: 0.5385 - val_loss: 0.7079 - val_binary_accuracy: 0.5571\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.7059 - binary_accuracy: 0.5566 - val_loss: 0.7038 - val_binary_accuracy: 0.5714\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7046 - binary_accuracy: 0.5445 - val_loss: 0.7010 - val_binary_accuracy: 0.5786\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.7060 - binary_accuracy: 0.5430 - val_loss: 0.6969 - val_binary_accuracy: 0.6143\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.7002 - binary_accuracy: 0.5475 - val_loss: 0.6970 - val_binary_accuracy: 0.5929\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.6976 - binary_accuracy: 0.5385 - val_loss: 0.6928 - val_binary_accuracy: 0.5857\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6963 - binary_accuracy: 0.5671 - val_loss: 0.6914 - val_binary_accuracy: 0.6071\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.6962 - binary_accuracy: 0.5475 - val_loss: 0.6893 - val_binary_accuracy: 0.5929\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.6940 - binary_accuracy: 0.5490 - val_loss: 0.6886 - val_binary_accuracy: 0.5929\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.6932 - binary_accuracy: 0.5445 - val_loss: 0.6874 - val_binary_accuracy: 0.5929\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.6911 - binary_accuracy: 0.5566 - val_loss: 0.6860 - val_binary_accuracy: 0.6000\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6904 - binary_accuracy: 0.5656 - val_loss: 0.6836 - val_binary_accuracy: 0.6071\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6887 - binary_accuracy: 0.5641 - val_loss: 0.6838 - val_binary_accuracy: 0.5929\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6871 - binary_accuracy: 0.5732 - val_loss: 0.6826 - val_binary_accuracy: 0.5857\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6859 - binary_accuracy: 0.5551 - val_loss: 0.6821 - val_binary_accuracy: 0.6071\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6874 - binary_accuracy: 0.5626 - val_loss: 0.6814 - val_binary_accuracy: 0.6071\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6851 - binary_accuracy: 0.5596 - val_loss: 0.6790 - val_binary_accuracy: 0.6214\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6858 - binary_accuracy: 0.5641 - val_loss: 0.6803 - val_binary_accuracy: 0.6357\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6828 - binary_accuracy: 0.5747 - val_loss: 0.6767 - val_binary_accuracy: 0.6214\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6815 - binary_accuracy: 0.5822 - val_loss: 0.6748 - val_binary_accuracy: 0.6286\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6812 - binary_accuracy: 0.5762 - val_loss: 0.6728 - val_binary_accuracy: 0.6429\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6808 - binary_accuracy: 0.5686 - val_loss: 0.6708 - val_binary_accuracy: 0.6429\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6819 - binary_accuracy: 0.5596 - val_loss: 0.6694 - val_binary_accuracy: 0.6286\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6809 - binary_accuracy: 0.5535 - val_loss: 0.6701 - val_binary_accuracy: 0.6357\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6795 - binary_accuracy: 0.5626 - val_loss: 0.6698 - val_binary_accuracy: 0.6143\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6777 - binary_accuracy: 0.5701 - val_loss: 0.6686 - val_binary_accuracy: 0.6286\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6789 - binary_accuracy: 0.5701 - val_loss: 0.6679 - val_binary_accuracy: 0.6214\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6798 - binary_accuracy: 0.5611 - val_loss: 0.6698 - val_binary_accuracy: 0.6429\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6780 - binary_accuracy: 0.5686 - val_loss: 0.6688 - val_binary_accuracy: 0.6286\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.6770 - binary_accuracy: 0.5792 - val_loss: 0.6704 - val_binary_accuracy: 0.6071\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6742 - binary_accuracy: 0.5822 - val_loss: 0.6684 - val_binary_accuracy: 0.6071\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6775 - binary_accuracy: 0.5716 - val_loss: 0.6692 - val_binary_accuracy: 0.5929\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6738 - binary_accuracy: 0.5762 - val_loss: 0.6647 - val_binary_accuracy: 0.6143\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6731 - binary_accuracy: 0.5701 - val_loss: 0.6622 - val_binary_accuracy: 0.6143\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.6749 - binary_accuracy: 0.5837 - val_loss: 0.6613 - val_binary_accuracy: 0.6286\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.6723 - binary_accuracy: 0.5747 - val_loss: 0.6592 - val_binary_accuracy: 0.6143\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.6724 - binary_accuracy: 0.5897 - val_loss: 0.6604 - val_binary_accuracy: 0.6000\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.6705 - binary_accuracy: 0.5822 - val_loss: 0.6596 - val_binary_accuracy: 0.6000\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.6704 - binary_accuracy: 0.5958 - val_loss: 0.6637 - val_binary_accuracy: 0.6000\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6700 - binary_accuracy: 0.5747 - val_loss: 0.6626 - val_binary_accuracy: 0.6071\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.6715 - binary_accuracy: 0.5928 - val_loss: 0.6594 - val_binary_accuracy: 0.6071\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6642 - binary_accuracy: 0.5928 - val_loss: 0.6602 - val_binary_accuracy: 0.6214\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.6710 - binary_accuracy: 0.5928 - val_loss: 0.6639 - val_binary_accuracy: 0.5929\n"
     ]
    }
   ],
   "source": [
    "history = model3.fit(X_train_1, train_5w,\n",
    "                    epochs=100,\n",
    "                    validation_data=(X_val_1, val_5w), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5dcf0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "train accuracy = 57.4661%\n",
      "test accuracy = 46.1538%\n",
      "test error = 35 out of 65 examples\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model3.evaluate(X_train_1, train_5w,\n",
    "                                       batch_size=M_TRAIN, verbose=0)\n",
    "test_loss, test_acc = model3.evaluate(X_test_1, test_5w,\n",
    "                                     batch_size=M_TEST, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2537d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model4\n",
    "n_steps = X_train_1.shape[1]\n",
    "n_features = X_train_1.shape[2]\n",
    "\n",
    "# Let's make a list of CONSTANTS for modeling:\n",
    "LAYERS = [4, 4, 4, 1]                # number of units in hidden and output layers\n",
    "M_TRAIN = X_train_1.shape[0]           # number of training examples (2D)\n",
    "M_TEST = X_test_1.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = X_train_1.shape[2]                 # number of features\n",
    "BATCH = M_TRAIN                          # batch size\n",
    "EPOCH = 10                           # number of epochs\n",
    "LR = 5e-2                            # learning rate of the gradient descent\n",
    "LAMBD = 3e-2                         # lambda in L2 regularizaion\n",
    "DP = 0.0                             # dropout rate\n",
    "RDP = 0.0                            # recurrent dropout rate\n",
    "\n",
    "# Build the Model4\n",
    "model4 = Sequential()\n",
    "\n",
    "model4.add(LSTM(units=LAYERS[2],input_shape=(n_steps, n_features),\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Dense(units=LAYERS[3], activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90825b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_7 (LSTM)               (None, 4)                 240       \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 4)                16        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 261\n",
      "Trainable params: 253\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model4.compile(loss='binary_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              optimizer=\"adam\")\n",
    "print(model4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ef79213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - 3s 27ms/step - loss: 1.3142 - accuracy: 0.5309 - val_loss: 1.0917 - val_accuracy: 0.5714\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.2392 - accuracy: 0.5354 - val_loss: 1.0513 - val_accuracy: 0.5786\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.1738 - accuracy: 0.5339 - val_loss: 1.0137 - val_accuracy: 0.5857\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.1180 - accuracy: 0.5279 - val_loss: 0.9805 - val_accuracy: 0.5857\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.0649 - accuracy: 0.5475 - val_loss: 0.9503 - val_accuracy: 0.5857\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.0231 - accuracy: 0.5370 - val_loss: 0.9232 - val_accuracy: 0.5857\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.9832 - accuracy: 0.5354 - val_loss: 0.8988 - val_accuracy: 0.5929\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9492 - accuracy: 0.5400 - val_loss: 0.8760 - val_accuracy: 0.5857\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9231 - accuracy: 0.5204 - val_loss: 0.8561 - val_accuracy: 0.5857\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.8926 - accuracy: 0.5415 - val_loss: 0.8380 - val_accuracy: 0.6214\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8685 - accuracy: 0.5400 - val_loss: 0.8219 - val_accuracy: 0.6143\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8556 - accuracy: 0.5249 - val_loss: 0.8072 - val_accuracy: 0.6071\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.8360 - accuracy: 0.5354 - val_loss: 0.7942 - val_accuracy: 0.6000\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8136 - accuracy: 0.5415 - val_loss: 0.7828 - val_accuracy: 0.6143\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.8052 - accuracy: 0.5053 - val_loss: 0.7722 - val_accuracy: 0.6143\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7936 - accuracy: 0.5385 - val_loss: 0.7630 - val_accuracy: 0.6214\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7802 - accuracy: 0.5279 - val_loss: 0.7552 - val_accuracy: 0.6143\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7721 - accuracy: 0.5158 - val_loss: 0.7478 - val_accuracy: 0.6071\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7629 - accuracy: 0.5204 - val_loss: 0.7413 - val_accuracy: 0.6000\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.7581 - accuracy: 0.5219 - val_loss: 0.7360 - val_accuracy: 0.5929\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7470 - accuracy: 0.5385 - val_loss: 0.7310 - val_accuracy: 0.5786\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7414 - accuracy: 0.5415 - val_loss: 0.7263 - val_accuracy: 0.5714\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7361 - accuracy: 0.5279 - val_loss: 0.7220 - val_accuracy: 0.5643\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7305 - accuracy: 0.5279 - val_loss: 0.7189 - val_accuracy: 0.5786\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7277 - accuracy: 0.5370 - val_loss: 0.7165 - val_accuracy: 0.5643\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7248 - accuracy: 0.5354 - val_loss: 0.7134 - val_accuracy: 0.5786\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7182 - accuracy: 0.5339 - val_loss: 0.7121 - val_accuracy: 0.5786\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7160 - accuracy: 0.5354 - val_loss: 0.7086 - val_accuracy: 0.5714\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7163 - accuracy: 0.5490 - val_loss: 0.7068 - val_accuracy: 0.5643\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7120 - accuracy: 0.5385 - val_loss: 0.7051 - val_accuracy: 0.5786\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7125 - accuracy: 0.5385 - val_loss: 0.7041 - val_accuracy: 0.5857\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7069 - accuracy: 0.5354 - val_loss: 0.7032 - val_accuracy: 0.5857\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7081 - accuracy: 0.5279 - val_loss: 0.7022 - val_accuracy: 0.5643\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7051 - accuracy: 0.5445 - val_loss: 0.7024 - val_accuracy: 0.5714\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7044 - accuracy: 0.5370 - val_loss: 0.7001 - val_accuracy: 0.5571\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.7036 - accuracy: 0.5279 - val_loss: 0.7006 - val_accuracy: 0.5500\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.7029 - accuracy: 0.5324 - val_loss: 0.6984 - val_accuracy: 0.5643\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6993 - accuracy: 0.5475 - val_loss: 0.6969 - val_accuracy: 0.5714\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.7002 - accuracy: 0.5581 - val_loss: 0.6974 - val_accuracy: 0.5786\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6985 - accuracy: 0.5566 - val_loss: 0.6972 - val_accuracy: 0.5929\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.6987 - accuracy: 0.5370 - val_loss: 0.6944 - val_accuracy: 0.5929\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.6990 - accuracy: 0.5520 - val_loss: 0.6938 - val_accuracy: 0.6000\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6977 - accuracy: 0.5445 - val_loss: 0.6936 - val_accuracy: 0.5714\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6957 - accuracy: 0.5460 - val_loss: 0.6924 - val_accuracy: 0.5929\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.6960 - accuracy: 0.5385 - val_loss: 0.6922 - val_accuracy: 0.5714\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6963 - accuracy: 0.5520 - val_loss: 0.6954 - val_accuracy: 0.5714\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.6953 - accuracy: 0.5551 - val_loss: 0.6934 - val_accuracy: 0.6000\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6960 - accuracy: 0.5385 - val_loss: 0.6904 - val_accuracy: 0.5714\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6955 - accuracy: 0.5626 - val_loss: 0.6914 - val_accuracy: 0.6071\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6940 - accuracy: 0.5566 - val_loss: 0.6924 - val_accuracy: 0.5929\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.6934 - accuracy: 0.5505 - val_loss: 0.6906 - val_accuracy: 0.6000\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6933 - accuracy: 0.5596 - val_loss: 0.6900 - val_accuracy: 0.5929\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6945 - accuracy: 0.5400 - val_loss: 0.6894 - val_accuracy: 0.6071\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6924 - accuracy: 0.5460 - val_loss: 0.6930 - val_accuracy: 0.5571\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6944 - accuracy: 0.5370 - val_loss: 0.6902 - val_accuracy: 0.5857\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.6920 - accuracy: 0.5505 - val_loss: 0.6910 - val_accuracy: 0.6000\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6918 - accuracy: 0.5370 - val_loss: 0.6898 - val_accuracy: 0.5714\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6920 - accuracy: 0.5520 - val_loss: 0.6912 - val_accuracy: 0.5857\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6908 - accuracy: 0.5656 - val_loss: 0.6939 - val_accuracy: 0.5714\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6918 - accuracy: 0.5807 - val_loss: 0.6911 - val_accuracy: 0.5929\n"
     ]
    }
   ],
   "source": [
    "history = model4.fit(X_train_1, train_5w,\n",
    "                    epochs=100,\n",
    "                    validation_data=(X_val_1, val_5w), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77f8ba86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "train accuracy = 56.8627%\n",
      "test accuracy = 46.1538%\n",
      "test error = 35 out of 65 examples\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model4.evaluate(X_train_1, train_5w,\n",
    "                                       batch_size=M_TRAIN, verbose=0)\n",
    "test_loss, test_acc = model4.evaluate(X_test_1, test_5w,\n",
    "                                     batch_size=M_TEST, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb1b249",
   "metadata": {},
   "source": [
    "# Trying With PCA of 10 k Best Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae650b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabrizio/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:301: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n"
     ]
    }
   ],
   "source": [
    "feats, pcs = kbest_creator(10)\n",
    "# 9 compenents explain 85% \n",
    "pca_kb = PCA(n_components = pcs).fit(X_train[feats].to_numpy())\n",
    "X_train_kb = pca_kb.transform(X_train[feats].to_numpy())\n",
    "X_val_kb = pca_kb.transform(X_val[feats].to_numpy())\n",
    "X_test_kb = pca_kb.transform(X_test[feats].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44d6a0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to window format, in this case 5 periods\n",
    "X_train_2, train_5w = df_to_X_y2(X_train_kb,y_train)\n",
    "X_val_2, val_5w = df_to_X_y2(X_val_kb, y_val)\n",
    "X_test_2, test_5w = df_to_X_y2(X_test_kb,y_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d68c4ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(663, 10, 3) (663,)\n",
      "(140, 10, 3) (140,)\n",
      "(65, 10, 3) (65,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_2.shape, train_5w.shape)\n",
    "print(X_val_2.shape, val_5w.shape)\n",
    "print(X_test_2.shape, test_5w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc68ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = X_train_2.shape[1]\n",
    "n_features = X_train_2.shape[2]\n",
    "\n",
    "# Let's make a list of CONSTANTS for modelling:\n",
    "LAYERS = [8, 8, 8, 1]                # number of units in hidden and output layers\n",
    "M_TRAIN = X_train_2.shape[0]           # number of training examples (2D)\n",
    "M_TEST = X_test_2.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = X_train_2.shape[2]                 # number of features\n",
    "BATCH = M_TRAIN                          # batch size\n",
    "EPOCH = 10                           # number of epochs\n",
    "LR = 5e-2                            # learning rate of the gradient descent\n",
    "LAMBD = 3e-2                         # lambda in L2 regularizaion\n",
    "DP = 0.0                             # dropout rate\n",
    "RDP = 0.0                            # recurrent dropout rate\n",
    "\n",
    "# Build the Model\n",
    "model = Sequential()\n",
    "model.add(LSTM(input_shape=(n_steps, n_features), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid', \n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=LAYERS[3], activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98d34d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 10, 8)             384       \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 10, 8)            32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 10, 8)             544       \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 10, 8)            32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 8)                 544       \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 8)                32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,577\n",
      "Trainable params: 1,529\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              metrics=['BinaryAccuracy'],\n",
    "              optimizer=\"adam\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5d475db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - 7s 76ms/step - loss: 2.4869 - binary_accuracy: 0.5023 - val_loss: 2.2097 - val_binary_accuracy: 0.5571\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2.1752 - binary_accuracy: 0.5113 - val_loss: 2.0358 - val_binary_accuracy: 0.5429\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.9823 - binary_accuracy: 0.5249 - val_loss: 1.8784 - val_binary_accuracy: 0.5429\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8192 - binary_accuracy: 0.5309 - val_loss: 1.7385 - val_binary_accuracy: 0.5357\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.6807 - binary_accuracy: 0.5249 - val_loss: 1.6150 - val_binary_accuracy: 0.5214\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.5630 - binary_accuracy: 0.5294 - val_loss: 1.5074 - val_binary_accuracy: 0.5214\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 1.4570 - binary_accuracy: 0.5370 - val_loss: 1.4128 - val_binary_accuracy: 0.5214\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.3681 - binary_accuracy: 0.5400 - val_loss: 1.3307 - val_binary_accuracy: 0.5214\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 1.2967 - binary_accuracy: 0.5400 - val_loss: 1.2577 - val_binary_accuracy: 0.5429\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.2209 - binary_accuracy: 0.5566 - val_loss: 1.1938 - val_binary_accuracy: 0.5214\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.1585 - binary_accuracy: 0.5596 - val_loss: 1.1387 - val_binary_accuracy: 0.5143\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.1093 - binary_accuracy: 0.5430 - val_loss: 1.0907 - val_binary_accuracy: 0.5357\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.0619 - binary_accuracy: 0.5460 - val_loss: 1.0477 - val_binary_accuracy: 0.5286\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.0242 - binary_accuracy: 0.5581 - val_loss: 1.0102 - val_binary_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.9879 - binary_accuracy: 0.5535 - val_loss: 0.9783 - val_binary_accuracy: 0.5143\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.9603 - binary_accuracy: 0.5656 - val_loss: 0.9488 - val_binary_accuracy: 0.5071\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.9314 - binary_accuracy: 0.5551 - val_loss: 0.9242 - val_binary_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.9071 - binary_accuracy: 0.5716 - val_loss: 0.9028 - val_binary_accuracy: 0.5143\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.8881 - binary_accuracy: 0.5581 - val_loss: 0.8823 - val_binary_accuracy: 0.5071\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.8674 - binary_accuracy: 0.5596 - val_loss: 0.8659 - val_binary_accuracy: 0.4929\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.8557 - binary_accuracy: 0.5445 - val_loss: 0.8503 - val_binary_accuracy: 0.5214\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.8417 - binary_accuracy: 0.5475 - val_loss: 0.8398 - val_binary_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.8280 - binary_accuracy: 0.5656 - val_loss: 0.8261 - val_binary_accuracy: 0.4929\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.8191 - binary_accuracy: 0.5520 - val_loss: 0.8177 - val_binary_accuracy: 0.4643\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.8098 - binary_accuracy: 0.5641 - val_loss: 0.8053 - val_binary_accuracy: 0.5071\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.8012 - binary_accuracy: 0.5445 - val_loss: 0.8007 - val_binary_accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.7912 - binary_accuracy: 0.5596 - val_loss: 0.7913 - val_binary_accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.7844 - binary_accuracy: 0.5415 - val_loss: 0.7849 - val_binary_accuracy: 0.5429\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.7809 - binary_accuracy: 0.5385 - val_loss: 0.7770 - val_binary_accuracy: 0.5214\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.7702 - binary_accuracy: 0.5762 - val_loss: 0.7738 - val_binary_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.7705 - binary_accuracy: 0.5581 - val_loss: 0.7682 - val_binary_accuracy: 0.5500\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.7692 - binary_accuracy: 0.5415 - val_loss: 0.7658 - val_binary_accuracy: 0.5357\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 1s 72ms/step - loss: 0.7604 - binary_accuracy: 0.5581 - val_loss: 0.7583 - val_binary_accuracy: 0.5214\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.7552 - binary_accuracy: 0.5641 - val_loss: 0.7570 - val_binary_accuracy: 0.5500\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.7540 - binary_accuracy: 0.5596 - val_loss: 0.7526 - val_binary_accuracy: 0.5071\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.7493 - binary_accuracy: 0.5309 - val_loss: 0.7609 - val_binary_accuracy: 0.5214\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.7431 - binary_accuracy: 0.5415 - val_loss: 0.7463 - val_binary_accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.7465 - binary_accuracy: 0.5400 - val_loss: 0.7426 - val_binary_accuracy: 0.5500\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.7416 - binary_accuracy: 0.5641 - val_loss: 0.7473 - val_binary_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.7400 - binary_accuracy: 0.5445 - val_loss: 0.7338 - val_binary_accuracy: 0.5929\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.7427 - binary_accuracy: 0.5354 - val_loss: 0.7413 - val_binary_accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.7410 - binary_accuracy: 0.5505 - val_loss: 0.7380 - val_binary_accuracy: 0.5500\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.7344 - binary_accuracy: 0.5400 - val_loss: 0.7327 - val_binary_accuracy: 0.5929\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.7362 - binary_accuracy: 0.5249 - val_loss: 0.7315 - val_binary_accuracy: 0.5286\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.7275 - binary_accuracy: 0.5701 - val_loss: 0.7280 - val_binary_accuracy: 0.6000\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.7310 - binary_accuracy: 0.5475 - val_loss: 0.7247 - val_binary_accuracy: 0.5786\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.7274 - binary_accuracy: 0.5596 - val_loss: 0.7337 - val_binary_accuracy: 0.5071\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.7262 - binary_accuracy: 0.5520 - val_loss: 0.7247 - val_binary_accuracy: 0.5643\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.7278 - binary_accuracy: 0.5490 - val_loss: 0.7178 - val_binary_accuracy: 0.6143\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.7237 - binary_accuracy: 0.5566 - val_loss: 0.7192 - val_binary_accuracy: 0.5857\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.7219 - binary_accuracy: 0.5596 - val_loss: 0.7214 - val_binary_accuracy: 0.5357\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.7218 - binary_accuracy: 0.5264 - val_loss: 0.7115 - val_binary_accuracy: 0.6357\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.7222 - binary_accuracy: 0.5385 - val_loss: 0.7256 - val_binary_accuracy: 0.5214\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.7210 - binary_accuracy: 0.5581 - val_loss: 0.7218 - val_binary_accuracy: 0.5214\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.7173 - binary_accuracy: 0.5671 - val_loss: 0.7095 - val_binary_accuracy: 0.6071\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.7146 - binary_accuracy: 0.5596 - val_loss: 0.7110 - val_binary_accuracy: 0.5929\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.7120 - binary_accuracy: 0.5762 - val_loss: 0.7046 - val_binary_accuracy: 0.5643\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.7162 - binary_accuracy: 0.5475 - val_loss: 0.7059 - val_binary_accuracy: 0.6000\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.7194 - binary_accuracy: 0.5626 - val_loss: 0.7264 - val_binary_accuracy: 0.5143\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.7162 - binary_accuracy: 0.5490 - val_loss: 0.7214 - val_binary_accuracy: 0.5286\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.7193 - binary_accuracy: 0.5400 - val_loss: 0.7039 - val_binary_accuracy: 0.5929\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.7202 - binary_accuracy: 0.5430 - val_loss: 0.7191 - val_binary_accuracy: 0.5500\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.7165 - binary_accuracy: 0.5581 - val_loss: 0.7348 - val_binary_accuracy: 0.4857\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.7151 - binary_accuracy: 0.5339 - val_loss: 0.7114 - val_binary_accuracy: 0.5286\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.7168 - binary_accuracy: 0.5370 - val_loss: 0.7151 - val_binary_accuracy: 0.5143\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.7086 - binary_accuracy: 0.5822 - val_loss: 0.7142 - val_binary_accuracy: 0.5643\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.7106 - binary_accuracy: 0.5505 - val_loss: 0.7198 - val_binary_accuracy: 0.4929\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.7099 - binary_accuracy: 0.5490 - val_loss: 0.7193 - val_binary_accuracy: 0.5143\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_2, train_5w,\n",
    "                    epochs=100,\n",
    "                    validation_data=(X_val_2, val_5w), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6401f42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "train accuracy = 53.6953%\n",
      "test accuracy = 60.0%\n",
      "test error = 26 out of 65 examples\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model.evaluate(X_train_2, train_5w,\n",
    "                                       batch_size=M_TRAIN, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(X_test_2, test_5w,\n",
    "                                     batch_size=M_TEST, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6455f709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_11 (LSTM)              (None, 10, 4)             128       \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 10, 4)            16        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 10, 4)             144       \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 10, 4)            16        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 4)                 144       \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 4)                16        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 469\n",
      "Trainable params: 445\n",
      "Non-trainable params: 24\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "21/21 [==============================] - 8s 71ms/step - loss: 1.6087 - binary_accuracy: 0.5128 - val_loss: 1.5227 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 1.5221 - binary_accuracy: 0.4992 - val_loss: 1.4473 - val_binary_accuracy: 0.5357\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 1.4410 - binary_accuracy: 0.5158 - val_loss: 1.3790 - val_binary_accuracy: 0.5357\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 1.3670 - binary_accuracy: 0.5370 - val_loss: 1.3175 - val_binary_accuracy: 0.5357\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 1.3042 - binary_accuracy: 0.5038 - val_loss: 1.2623 - val_binary_accuracy: 0.5357\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 1.2412 - binary_accuracy: 0.5385 - val_loss: 1.2124 - val_binary_accuracy: 0.5357\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 1.1942 - binary_accuracy: 0.5354 - val_loss: 1.1671 - val_binary_accuracy: 0.5357\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 1.1409 - binary_accuracy: 0.5566 - val_loss: 1.1263 - val_binary_accuracy: 0.5357\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 1.1089 - binary_accuracy: 0.5520 - val_loss: 1.0904 - val_binary_accuracy: 0.5357\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 1.0644 - binary_accuracy: 0.5671 - val_loss: 1.0577 - val_binary_accuracy: 0.5357\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 1.0361 - binary_accuracy: 0.5551 - val_loss: 1.0284 - val_binary_accuracy: 0.5357\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 1.0012 - binary_accuracy: 0.5551 - val_loss: 1.0006 - val_binary_accuracy: 0.5357\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.9772 - binary_accuracy: 0.5535 - val_loss: 0.9757 - val_binary_accuracy: 0.5357\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.9506 - binary_accuracy: 0.5671 - val_loss: 0.9541 - val_binary_accuracy: 0.5357\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.9323 - binary_accuracy: 0.5671 - val_loss: 0.9327 - val_binary_accuracy: 0.5357\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.9065 - binary_accuracy: 0.5641 - val_loss: 0.9142 - val_binary_accuracy: 0.5357\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.8886 - binary_accuracy: 0.5747 - val_loss: 0.8973 - val_binary_accuracy: 0.5357\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.8691 - binary_accuracy: 0.5686 - val_loss: 0.8837 - val_binary_accuracy: 0.5357\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.8560 - binary_accuracy: 0.5656 - val_loss: 0.8702 - val_binary_accuracy: 0.5357\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.8432 - binary_accuracy: 0.5656 - val_loss: 0.8571 - val_binary_accuracy: 0.5357\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.8335 - binary_accuracy: 0.5671 - val_loss: 0.8449 - val_binary_accuracy: 0.5357\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.8264 - binary_accuracy: 0.5505 - val_loss: 0.8327 - val_binary_accuracy: 0.5357\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.8120 - binary_accuracy: 0.5671 - val_loss: 0.8238 - val_binary_accuracy: 0.5357\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.8064 - binary_accuracy: 0.5596 - val_loss: 0.8136 - val_binary_accuracy: 0.5429\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.7931 - binary_accuracy: 0.5837 - val_loss: 0.8047 - val_binary_accuracy: 0.5357\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.7845 - binary_accuracy: 0.5973 - val_loss: 0.7957 - val_binary_accuracy: 0.5571\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.7816 - binary_accuracy: 0.5716 - val_loss: 0.7899 - val_binary_accuracy: 0.5357\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.7704 - binary_accuracy: 0.5762 - val_loss: 0.7843 - val_binary_accuracy: 0.5429\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.7721 - binary_accuracy: 0.5671 - val_loss: 0.7781 - val_binary_accuracy: 0.5286\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.7619 - binary_accuracy: 0.5732 - val_loss: 0.7747 - val_binary_accuracy: 0.5286\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.7610 - binary_accuracy: 0.5520 - val_loss: 0.7673 - val_binary_accuracy: 0.5357\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.7541 - binary_accuracy: 0.5656 - val_loss: 0.7634 - val_binary_accuracy: 0.5500\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.7497 - binary_accuracy: 0.5882 - val_loss: 0.7601 - val_binary_accuracy: 0.5643\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.7476 - binary_accuracy: 0.5656 - val_loss: 0.7538 - val_binary_accuracy: 0.5500\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.7418 - binary_accuracy: 0.5762 - val_loss: 0.7596 - val_binary_accuracy: 0.5500\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.7396 - binary_accuracy: 0.5686 - val_loss: 0.7520 - val_binary_accuracy: 0.5214\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.7344 - binary_accuracy: 0.5701 - val_loss: 0.7511 - val_binary_accuracy: 0.5214\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.7395 - binary_accuracy: 0.5596 - val_loss: 0.7448 - val_binary_accuracy: 0.5571\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.7364 - binary_accuracy: 0.5792 - val_loss: 0.7427 - val_binary_accuracy: 0.5571\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.7321 - binary_accuracy: 0.5822 - val_loss: 0.7401 - val_binary_accuracy: 0.5786\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.7310 - binary_accuracy: 0.5686 - val_loss: 0.7478 - val_binary_accuracy: 0.5286\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.7302 - binary_accuracy: 0.5566 - val_loss: 0.7515 - val_binary_accuracy: 0.5429\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.7291 - binary_accuracy: 0.5716 - val_loss: 0.7334 - val_binary_accuracy: 0.5786\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.7235 - binary_accuracy: 0.5701 - val_loss: 0.7322 - val_binary_accuracy: 0.5857\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.7266 - binary_accuracy: 0.5732 - val_loss: 0.7275 - val_binary_accuracy: 0.5571\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.7247 - binary_accuracy: 0.5686 - val_loss: 0.7503 - val_binary_accuracy: 0.5714\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.7196 - binary_accuracy: 0.5716 - val_loss: 0.7404 - val_binary_accuracy: 0.5429\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.7263 - binary_accuracy: 0.5596 - val_loss: 0.7288 - val_binary_accuracy: 0.5429\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.7262 - binary_accuracy: 0.5520 - val_loss: 0.7255 - val_binary_accuracy: 0.5357\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.7238 - binary_accuracy: 0.5732 - val_loss: 0.7279 - val_binary_accuracy: 0.5571\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.7204 - binary_accuracy: 0.5505 - val_loss: 0.7299 - val_binary_accuracy: 0.5571\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.7160 - binary_accuracy: 0.5928 - val_loss: 0.7305 - val_binary_accuracy: 0.4857\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.7183 - binary_accuracy: 0.5686 - val_loss: 0.7222 - val_binary_accuracy: 0.5429\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.7172 - binary_accuracy: 0.5671 - val_loss: 0.7255 - val_binary_accuracy: 0.5500\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.7181 - binary_accuracy: 0.5551 - val_loss: 0.7261 - val_binary_accuracy: 0.5500\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.7114 - binary_accuracy: 0.5822 - val_loss: 0.7182 - val_binary_accuracy: 0.5571\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.7164 - binary_accuracy: 0.5490 - val_loss: 0.7347 - val_binary_accuracy: 0.5500\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.7163 - binary_accuracy: 0.5596 - val_loss: 0.7164 - val_binary_accuracy: 0.5571\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.7122 - binary_accuracy: 0.5671 - val_loss: 0.7138 - val_binary_accuracy: 0.5714\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.7159 - binary_accuracy: 0.5626 - val_loss: 0.7118 - val_binary_accuracy: 0.5429\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.7129 - binary_accuracy: 0.5732 - val_loss: 0.7262 - val_binary_accuracy: 0.5643\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.7192 - binary_accuracy: 0.5701 - val_loss: 0.7149 - val_binary_accuracy: 0.5714\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.7102 - binary_accuracy: 0.5747 - val_loss: 0.7194 - val_binary_accuracy: 0.5357\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.7102 - binary_accuracy: 0.5626 - val_loss: 0.7267 - val_binary_accuracy: 0.5500\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.7107 - binary_accuracy: 0.5475 - val_loss: 0.7266 - val_binary_accuracy: 0.5429\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.7083 - binary_accuracy: 0.5747 - val_loss: 0.7398 - val_binary_accuracy: 0.5643\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.7042 - binary_accuracy: 0.5897 - val_loss: 0.7442 - val_binary_accuracy: 0.5500\n"
     ]
    }
   ],
   "source": [
    "n_steps = X_train_2.shape[1]\n",
    "n_features = X_train_2.shape[2]\n",
    "\n",
    "# Let's make a list of CONSTANTS for modelling:\n",
    "LAYERS = [4, 4, 4, 1]                # number of units in hidden and output layers\n",
    "M_TRAIN = X_train_2.shape[0]           # number of training examples (2D)\n",
    "M_TEST = X_test_2.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = X_train_2.shape[2]                 # number of features\n",
    "BATCH = M_TRAIN                          # batch size\n",
    "EPOCH = 10                           # number of epochs\n",
    "LR = 5e-2                            # learning rate of the gradient descent\n",
    "LAMBD = 3e-2                         # lambda in L2 regularizaion\n",
    "DP = 0.0                             # dropout rate\n",
    "RDP = 0.0                            # recurrent dropout rate\n",
    "\n",
    "# Build the Model\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(input_shape=(n_steps, n_features), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid', \n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy',\n",
    "              metrics=['BinaryAccuracy'],\n",
    "              optimizer=\"adam\")\n",
    "print(model2.summary())\n",
    "\n",
    "history = model2.fit(X_train_2, train_5w,\n",
    "                    epochs=100,\n",
    "                    validation_data=(X_val_2, val_5w), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98cd623c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "train accuracy = 52.9412%\n",
      "test accuracy = 49.2308%\n",
      "test error = 33 out of 65 examples\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model2.evaluate(X_train_2, train_5w,\n",
    "                                       batch_size=M_TRAIN, verbose=0)\n",
    "test_loss, test_acc = model2.evaluate(X_test_2, test_5w,\n",
    "                                     batch_size=M_TEST, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c643c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_14 (LSTM)              (None, 10, 32)            4608      \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 10, 32)           128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 10, 32)            8320      \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 10, 32)           128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,665\n",
      "Trainable params: 21,473\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "21/21 [==============================] - 9s 65ms/step - loss: 6.1751 - binary_accuracy: 0.5023 - val_loss: 5.3745 - val_binary_accuracy: 0.4643\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 4.8183 - binary_accuracy: 0.5324 - val_loss: 4.2370 - val_binary_accuracy: 0.5357\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 3.8017 - binary_accuracy: 0.5732 - val_loss: 3.3882 - val_binary_accuracy: 0.5357\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 3.0670 - binary_accuracy: 0.5430 - val_loss: 2.7574 - val_binary_accuracy: 0.5357\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 2.5230 - binary_accuracy: 0.5490 - val_loss: 2.2911 - val_binary_accuracy: 0.5357\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 2.1173 - binary_accuracy: 0.5626 - val_loss: 1.9445 - val_binary_accuracy: 0.5357\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 1.8062 - binary_accuracy: 0.5566 - val_loss: 1.6857 - val_binary_accuracy: 0.5357\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 1.5833 - binary_accuracy: 0.5430 - val_loss: 1.4910 - val_binary_accuracy: 0.5357\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 1.4120 - binary_accuracy: 0.5596 - val_loss: 1.3444 - val_binary_accuracy: 0.5357\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 1.2780 - binary_accuracy: 0.5747 - val_loss: 1.2337 - val_binary_accuracy: 0.5357\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 1.1780 - binary_accuracy: 0.5807 - val_loss: 1.1479 - val_binary_accuracy: 0.5357\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 1.1065 - binary_accuracy: 0.5445 - val_loss: 1.0817 - val_binary_accuracy: 0.5357\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 1.0341 - binary_accuracy: 0.5913 - val_loss: 1.0288 - val_binary_accuracy: 0.5357\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 1.0030 - binary_accuracy: 0.5581 - val_loss: 0.9888 - val_binary_accuracy: 0.5357\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.9669 - binary_accuracy: 0.5852 - val_loss: 0.9534 - val_binary_accuracy: 0.5357\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.9385 - binary_accuracy: 0.5400 - val_loss: 0.9288 - val_binary_accuracy: 0.5357\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.9034 - binary_accuracy: 0.5762 - val_loss: 0.9027 - val_binary_accuracy: 0.5357\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.8990 - binary_accuracy: 0.5656 - val_loss: 0.8873 - val_binary_accuracy: 0.5357\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.8750 - binary_accuracy: 0.5551 - val_loss: 0.8700 - val_binary_accuracy: 0.5643\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.8642 - binary_accuracy: 0.5475 - val_loss: 0.8543 - val_binary_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.8368 - binary_accuracy: 0.5656 - val_loss: 0.8392 - val_binary_accuracy: 0.5429\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.8276 - binary_accuracy: 0.5611 - val_loss: 0.8291 - val_binary_accuracy: 0.5357\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.8257 - binary_accuracy: 0.5385 - val_loss: 0.8155 - val_binary_accuracy: 0.5429\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.8061 - binary_accuracy: 0.5581 - val_loss: 0.8116 - val_binary_accuracy: 0.5429\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.7961 - binary_accuracy: 0.5641 - val_loss: 0.7926 - val_binary_accuracy: 0.5571\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.7977 - binary_accuracy: 0.5520 - val_loss: 0.7892 - val_binary_accuracy: 0.5286\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.7820 - binary_accuracy: 0.5626 - val_loss: 0.7782 - val_binary_accuracy: 0.5857\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.7818 - binary_accuracy: 0.5339 - val_loss: 0.7760 - val_binary_accuracy: 0.5786\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.7751 - binary_accuracy: 0.5520 - val_loss: 0.7652 - val_binary_accuracy: 0.5929\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.7647 - binary_accuracy: 0.5762 - val_loss: 0.7671 - val_binary_accuracy: 0.5143\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.7632 - binary_accuracy: 0.5490 - val_loss: 0.7510 - val_binary_accuracy: 0.6500\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.7582 - binary_accuracy: 0.5475 - val_loss: 0.7542 - val_binary_accuracy: 0.4929\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.7510 - binary_accuracy: 0.5611 - val_loss: 0.7414 - val_binary_accuracy: 0.6071\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.7521 - binary_accuracy: 0.5686 - val_loss: 0.7507 - val_binary_accuracy: 0.5286\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.7538 - binary_accuracy: 0.5475 - val_loss: 0.7347 - val_binary_accuracy: 0.5786\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.7478 - binary_accuracy: 0.5385 - val_loss: 0.7370 - val_binary_accuracy: 0.6000\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.7418 - binary_accuracy: 0.5566 - val_loss: 0.7385 - val_binary_accuracy: 0.5571\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.7371 - binary_accuracy: 0.5686 - val_loss: 0.7355 - val_binary_accuracy: 0.5143\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.7372 - binary_accuracy: 0.5460 - val_loss: 0.7342 - val_binary_accuracy: 0.5357\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.7408 - binary_accuracy: 0.5385 - val_loss: 0.7179 - val_binary_accuracy: 0.5714\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.7384 - binary_accuracy: 0.5189 - val_loss: 0.7271 - val_binary_accuracy: 0.5786\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.7335 - binary_accuracy: 0.5535 - val_loss: 0.7079 - val_binary_accuracy: 0.6286\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.7272 - binary_accuracy: 0.5551 - val_loss: 0.7118 - val_binary_accuracy: 0.5929\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.7245 - binary_accuracy: 0.5430 - val_loss: 0.7168 - val_binary_accuracy: 0.5786\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.7202 - binary_accuracy: 0.5520 - val_loss: 0.7083 - val_binary_accuracy: 0.5714\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.7253 - binary_accuracy: 0.5490 - val_loss: 0.7229 - val_binary_accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.7277 - binary_accuracy: 0.5264 - val_loss: 0.7108 - val_binary_accuracy: 0.5643\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.7209 - binary_accuracy: 0.5581 - val_loss: 0.7022 - val_binary_accuracy: 0.5857\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.7211 - binary_accuracy: 0.5596 - val_loss: 0.6982 - val_binary_accuracy: 0.6071\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.7157 - binary_accuracy: 0.5520 - val_loss: 0.7225 - val_binary_accuracy: 0.4929\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.7261 - binary_accuracy: 0.5158 - val_loss: 0.6943 - val_binary_accuracy: 0.6071\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.7266 - binary_accuracy: 0.5475 - val_loss: 0.7147 - val_binary_accuracy: 0.6000\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.7242 - binary_accuracy: 0.5415 - val_loss: 0.7350 - val_binary_accuracy: 0.5286\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.7198 - binary_accuracy: 0.5370 - val_loss: 0.6953 - val_binary_accuracy: 0.6143\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.7274 - binary_accuracy: 0.5158 - val_loss: 0.7043 - val_binary_accuracy: 0.5429\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.7288 - binary_accuracy: 0.5324 - val_loss: 0.7128 - val_binary_accuracy: 0.5214\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.7180 - binary_accuracy: 0.5626 - val_loss: 0.7018 - val_binary_accuracy: 0.6071\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.7137 - binary_accuracy: 0.5475 - val_loss: 0.7179 - val_binary_accuracy: 0.5786\n"
     ]
    }
   ],
   "source": [
    "n_steps = X_train_2.shape[1]\n",
    "n_features = X_train_2.shape[2]\n",
    "\n",
    "# Let's make a list of CONSTANTS for modelling:\n",
    "LAYERS = [32, 32, 32, 1]                # number of units in hidden and output layers\n",
    "M_TRAIN = X_train_2.shape[0]           # number of training examples (2D)\n",
    "M_TEST = X_test_2.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = X_train_2.shape[2]                 # number of features\n",
    "BATCH = M_TRAIN                          # batch size\n",
    "EPOCH = 10                           # number of epochs\n",
    "LR = 5e-2                            # learning rate of the gradient descent\n",
    "LAMBD = 3e-2                         # lambda in L2 regularizaion\n",
    "DP = 0.0                             # dropout rate\n",
    "RDP = 0.0                            # recurrent dropout rate\n",
    "\n",
    "# Build the Model\n",
    "model3 = Sequential()\n",
    "model3.add(LSTM(input_shape=(n_steps, n_features), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid', \n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "model3.compile(loss='binary_crossentropy',\n",
    "              metrics=['BinaryAccuracy'],\n",
    "              optimizer=\"adam\")\n",
    "print(model3.summary())\n",
    "\n",
    "history = model3.fit(X_train_2, train_5w,\n",
    "                    epochs=100,\n",
    "                    validation_data=(X_val_2, val_5w), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc9911c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "train accuracy = 56.4103%\n",
      "test accuracy = 49.2308%\n",
      "test error = 33 out of 65 examples\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model3.evaluate(X_train_2, train_5w,\n",
    "                                       batch_size=M_TRAIN, verbose=0)\n",
    "test_loss, test_acc = model3.evaluate(X_test_2, test_5w,\n",
    "                                     batch_size=M_TEST, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1165b56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_17 (LSTM)              (None, 10, 4)             128       \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 10, 4)            16        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lstm_18 (LSTM)              (None, 4)                 144       \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 4)                16        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 309\n",
      "Trainable params: 293\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "21/21 [==============================] - 6s 86ms/step - loss: 1.3971 - binary_accuracy: 0.4992 - val_loss: 1.2249 - val_binary_accuracy: 0.4929\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 1.3241 - binary_accuracy: 0.4796 - val_loss: 1.1722 - val_binary_accuracy: 0.4429\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 1.2449 - binary_accuracy: 0.4872 - val_loss: 1.1252 - val_binary_accuracy: 0.4571\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 1.1790 - binary_accuracy: 0.5173 - val_loss: 1.0831 - val_binary_accuracy: 0.4500\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.1212 - binary_accuracy: 0.5038 - val_loss: 1.0442 - val_binary_accuracy: 0.4643\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 1.0774 - binary_accuracy: 0.4947 - val_loss: 1.0097 - val_binary_accuracy: 0.4429\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.0286 - binary_accuracy: 0.5008 - val_loss: 0.9790 - val_binary_accuracy: 0.4714\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.9905 - binary_accuracy: 0.4887 - val_loss: 0.9509 - val_binary_accuracy: 0.4714\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.9603 - binary_accuracy: 0.4842 - val_loss: 0.9261 - val_binary_accuracy: 0.4571\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.9297 - binary_accuracy: 0.4887 - val_loss: 0.9033 - val_binary_accuracy: 0.4786\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.9023 - binary_accuracy: 0.4902 - val_loss: 0.8828 - val_binary_accuracy: 0.4571\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.8807 - binary_accuracy: 0.5083 - val_loss: 0.8645 - val_binary_accuracy: 0.4714\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.8586 - binary_accuracy: 0.5309 - val_loss: 0.8479 - val_binary_accuracy: 0.4714\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.8410 - binary_accuracy: 0.5339 - val_loss: 0.8332 - val_binary_accuracy: 0.4857\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.8310 - binary_accuracy: 0.5339 - val_loss: 0.8197 - val_binary_accuracy: 0.4929\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.8126 - binary_accuracy: 0.5339 - val_loss: 0.8076 - val_binary_accuracy: 0.4929\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.7997 - binary_accuracy: 0.5339 - val_loss: 0.7965 - val_binary_accuracy: 0.4929\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.7907 - binary_accuracy: 0.5249 - val_loss: 0.7863 - val_binary_accuracy: 0.4786\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.7804 - binary_accuracy: 0.5324 - val_loss: 0.7775 - val_binary_accuracy: 0.4714\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.7701 - binary_accuracy: 0.5656 - val_loss: 0.7695 - val_binary_accuracy: 0.4643\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.7616 - binary_accuracy: 0.5535 - val_loss: 0.7631 - val_binary_accuracy: 0.4786\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.7572 - binary_accuracy: 0.5400 - val_loss: 0.7566 - val_binary_accuracy: 0.4786\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.7527 - binary_accuracy: 0.5520 - val_loss: 0.7512 - val_binary_accuracy: 0.4929\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.7469 - binary_accuracy: 0.5279 - val_loss: 0.7444 - val_binary_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.7389 - binary_accuracy: 0.5520 - val_loss: 0.7402 - val_binary_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.7360 - binary_accuracy: 0.5430 - val_loss: 0.7367 - val_binary_accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.7326 - binary_accuracy: 0.5400 - val_loss: 0.7332 - val_binary_accuracy: 0.4857\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.7293 - binary_accuracy: 0.5309 - val_loss: 0.7289 - val_binary_accuracy: 0.4857\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.7267 - binary_accuracy: 0.5204 - val_loss: 0.7263 - val_binary_accuracy: 0.5214\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.7206 - binary_accuracy: 0.5505 - val_loss: 0.7234 - val_binary_accuracy: 0.5143\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.7204 - binary_accuracy: 0.5385 - val_loss: 0.7211 - val_binary_accuracy: 0.5071\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.7163 - binary_accuracy: 0.5535 - val_loss: 0.7185 - val_binary_accuracy: 0.5214\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.7144 - binary_accuracy: 0.5490 - val_loss: 0.7167 - val_binary_accuracy: 0.5286\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.7136 - binary_accuracy: 0.5324 - val_loss: 0.7160 - val_binary_accuracy: 0.5214\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.7127 - binary_accuracy: 0.5370 - val_loss: 0.7149 - val_binary_accuracy: 0.5143\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.7128 - binary_accuracy: 0.5324 - val_loss: 0.7123 - val_binary_accuracy: 0.5071\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.7096 - binary_accuracy: 0.5701 - val_loss: 0.7111 - val_binary_accuracy: 0.5214\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.7075 - binary_accuracy: 0.5490 - val_loss: 0.7101 - val_binary_accuracy: 0.5143\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.7080 - binary_accuracy: 0.5400 - val_loss: 0.7090 - val_binary_accuracy: 0.5143\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.7063 - binary_accuracy: 0.5475 - val_loss: 0.7091 - val_binary_accuracy: 0.5286\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.7070 - binary_accuracy: 0.5309 - val_loss: 0.7079 - val_binary_accuracy: 0.5214\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.7060 - binary_accuracy: 0.5445 - val_loss: 0.7093 - val_binary_accuracy: 0.4929\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.7038 - binary_accuracy: 0.5566 - val_loss: 0.7078 - val_binary_accuracy: 0.5143\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.7041 - binary_accuracy: 0.5279 - val_loss: 0.7050 - val_binary_accuracy: 0.5357\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.7030 - binary_accuracy: 0.5415 - val_loss: 0.7055 - val_binary_accuracy: 0.5143\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.7020 - binary_accuracy: 0.5535 - val_loss: 0.7044 - val_binary_accuracy: 0.5286\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.7033 - binary_accuracy: 0.5023 - val_loss: 0.7050 - val_binary_accuracy: 0.5357\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.7028 - binary_accuracy: 0.5385 - val_loss: 0.7033 - val_binary_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.7004 - binary_accuracy: 0.5520 - val_loss: 0.7029 - val_binary_accuracy: 0.5143\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.7003 - binary_accuracy: 0.5581 - val_loss: 0.7030 - val_binary_accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.7005 - binary_accuracy: 0.5324 - val_loss: 0.7022 - val_binary_accuracy: 0.5286\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.6993 - binary_accuracy: 0.5505 - val_loss: 0.7026 - val_binary_accuracy: 0.5429\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.7002 - binary_accuracy: 0.5279 - val_loss: 0.7021 - val_binary_accuracy: 0.5071\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.6997 - binary_accuracy: 0.5294 - val_loss: 0.7019 - val_binary_accuracy: 0.5071\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.6991 - binary_accuracy: 0.5354 - val_loss: 0.7018 - val_binary_accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.7002 - binary_accuracy: 0.5189 - val_loss: 0.7019 - val_binary_accuracy: 0.5000\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.6984 - binary_accuracy: 0.5309 - val_loss: 0.7006 - val_binary_accuracy: 0.5143\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.7001 - binary_accuracy: 0.5264 - val_loss: 0.7027 - val_binary_accuracy: 0.5357\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.6977 - binary_accuracy: 0.5339 - val_loss: 0.7026 - val_binary_accuracy: 0.5286\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.6996 - binary_accuracy: 0.5324 - val_loss: 0.7015 - val_binary_accuracy: 0.5286\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.6965 - binary_accuracy: 0.5520 - val_loss: 0.7010 - val_binary_accuracy: 0.5143\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.6995 - binary_accuracy: 0.5385 - val_loss: 0.7042 - val_binary_accuracy: 0.5071\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6978 - binary_accuracy: 0.5234 - val_loss: 0.6998 - val_binary_accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.6975 - binary_accuracy: 0.5324 - val_loss: 0.7010 - val_binary_accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.6983 - binary_accuracy: 0.5415 - val_loss: 0.7004 - val_binary_accuracy: 0.4857\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.6960 - binary_accuracy: 0.5354 - val_loss: 0.7029 - val_binary_accuracy: 0.5143\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.6972 - binary_accuracy: 0.5400 - val_loss: 0.7016 - val_binary_accuracy: 0.4929\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.6974 - binary_accuracy: 0.5475 - val_loss: 0.6999 - val_binary_accuracy: 0.5286\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.6972 - binary_accuracy: 0.5173 - val_loss: 0.6986 - val_binary_accuracy: 0.5214\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.6969 - binary_accuracy: 0.5520 - val_loss: 0.7007 - val_binary_accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.6964 - binary_accuracy: 0.5385 - val_loss: 0.7006 - val_binary_accuracy: 0.5000\n",
      "Epoch 72/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.6973 - binary_accuracy: 0.5339 - val_loss: 0.7020 - val_binary_accuracy: 0.5143\n",
      "Epoch 73/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.6968 - binary_accuracy: 0.5354 - val_loss: 0.7058 - val_binary_accuracy: 0.4643\n",
      "Epoch 74/100\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6982 - binary_accuracy: 0.5158 - val_loss: 0.7000 - val_binary_accuracy: 0.4929\n",
      "Epoch 75/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.6969 - binary_accuracy: 0.5415 - val_loss: 0.7026 - val_binary_accuracy: 0.5143\n",
      "Epoch 76/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.6965 - binary_accuracy: 0.5370 - val_loss: 0.7013 - val_binary_accuracy: 0.4929\n"
     ]
    }
   ],
   "source": [
    "n_steps = X_train_2.shape[1]\n",
    "n_features = X_train_2.shape[2]\n",
    "\n",
    "# Let's make a list of CONSTANTS for modelling:\n",
    "LAYERS = [4, 8, 4, 1]                # number of units in hidden and output layers\n",
    "M_TRAIN = X_train_2.shape[0]           # number of training examples (2D)\n",
    "M_TEST = X_test_2.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = X_train_2.shape[2]                 # number of features\n",
    "BATCH = M_TRAIN                          # batch size\n",
    "EPOCH = 10                           # number of epochs\n",
    "LR = 5e-2                            # learning rate of the gradient descent\n",
    "LAMBD = 3e-2                         # lambda in L2 regularizaion\n",
    "DP = 0.0                             # dropout rate\n",
    "RDP = 0.0                            # recurrent dropout rate\n",
    "\n",
    "# Build the Model\n",
    "model4 = Sequential()\n",
    "model4.add(LSTM(input_shape=(n_steps, n_features), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model4.add(BatchNormalization())\n",
    "\n",
    "model4.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "model4.compile(loss='binary_crossentropy',\n",
    "              metrics=['BinaryAccuracy'],\n",
    "              optimizer=\"adam\")\n",
    "print(model4.summary())\n",
    "\n",
    "history = model4.fit(X_train_2, train_5w,\n",
    "                    epochs=100,\n",
    "                    validation_data=(X_val_2, val_5w), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99dc3732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "train accuracy = 53.5445%\n",
      "test accuracy = 36.9231%\n",
      "test error = 41 out of 65 examples\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model4.evaluate(X_train_2, train_5w,\n",
    "                                       batch_size=M_TRAIN, verbose=0)\n",
    "test_loss, test_acc = model4.evaluate(X_test_2, test_5w,\n",
    "                                     batch_size=M_TEST, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e8fb2f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_19 (LSTM)              (None, 4)                 128       \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 4)                16        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149\n",
      "Trainable params: 141\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "21/21 [==============================] - 3s 27ms/step - loss: 0.9917 - binary_accuracy: 0.4932 - val_loss: 0.9523 - val_binary_accuracy: 0.5286\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.9563 - binary_accuracy: 0.4736 - val_loss: 0.9260 - val_binary_accuracy: 0.5357\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9251 - binary_accuracy: 0.4751 - val_loss: 0.9027 - val_binary_accuracy: 0.5286\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9021 - binary_accuracy: 0.5008 - val_loss: 0.8817 - val_binary_accuracy: 0.5286\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.8793 - binary_accuracy: 0.4902 - val_loss: 0.8630 - val_binary_accuracy: 0.5286\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.8605 - binary_accuracy: 0.4992 - val_loss: 0.8463 - val_binary_accuracy: 0.5357\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.8450 - binary_accuracy: 0.4691 - val_loss: 0.8312 - val_binary_accuracy: 0.5286\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.8275 - binary_accuracy: 0.5083 - val_loss: 0.8178 - val_binary_accuracy: 0.5286\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.8158 - binary_accuracy: 0.5068 - val_loss: 0.8057 - val_binary_accuracy: 0.5286\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.8038 - binary_accuracy: 0.5098 - val_loss: 0.7949 - val_binary_accuracy: 0.5214\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7925 - binary_accuracy: 0.5068 - val_loss: 0.7850 - val_binary_accuracy: 0.5214\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7841 - binary_accuracy: 0.4857 - val_loss: 0.7763 - val_binary_accuracy: 0.5286\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7774 - binary_accuracy: 0.4781 - val_loss: 0.7683 - val_binary_accuracy: 0.5286\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7689 - binary_accuracy: 0.4947 - val_loss: 0.7613 - val_binary_accuracy: 0.5214\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7607 - binary_accuracy: 0.4947 - val_loss: 0.7551 - val_binary_accuracy: 0.5071\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7555 - binary_accuracy: 0.5249 - val_loss: 0.7493 - val_binary_accuracy: 0.5143\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7476 - binary_accuracy: 0.5219 - val_loss: 0.7443 - val_binary_accuracy: 0.5429\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7441 - binary_accuracy: 0.4947 - val_loss: 0.7393 - val_binary_accuracy: 0.5286\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7400 - binary_accuracy: 0.5173 - val_loss: 0.7355 - val_binary_accuracy: 0.5286\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7359 - binary_accuracy: 0.5023 - val_loss: 0.7317 - val_binary_accuracy: 0.5429\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7330 - binary_accuracy: 0.4887 - val_loss: 0.7283 - val_binary_accuracy: 0.5500\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7284 - binary_accuracy: 0.5204 - val_loss: 0.7253 - val_binary_accuracy: 0.5643\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7264 - binary_accuracy: 0.4962 - val_loss: 0.7230 - val_binary_accuracy: 0.5500\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7230 - binary_accuracy: 0.5158 - val_loss: 0.7197 - val_binary_accuracy: 0.5429\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7214 - binary_accuracy: 0.5038 - val_loss: 0.7174 - val_binary_accuracy: 0.5500\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7192 - binary_accuracy: 0.5053 - val_loss: 0.7153 - val_binary_accuracy: 0.5357\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7161 - binary_accuracy: 0.5068 - val_loss: 0.7136 - val_binary_accuracy: 0.5286\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7144 - binary_accuracy: 0.5324 - val_loss: 0.7118 - val_binary_accuracy: 0.5286\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7121 - binary_accuracy: 0.5279 - val_loss: 0.7106 - val_binary_accuracy: 0.5214\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7117 - binary_accuracy: 0.5204 - val_loss: 0.7093 - val_binary_accuracy: 0.5357\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7095 - binary_accuracy: 0.5068 - val_loss: 0.7080 - val_binary_accuracy: 0.5429\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7097 - binary_accuracy: 0.5158 - val_loss: 0.7076 - val_binary_accuracy: 0.5571\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7065 - binary_accuracy: 0.5294 - val_loss: 0.7060 - val_binary_accuracy: 0.5214\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7063 - binary_accuracy: 0.5249 - val_loss: 0.7053 - val_binary_accuracy: 0.5286\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7062 - binary_accuracy: 0.5370 - val_loss: 0.7042 - val_binary_accuracy: 0.5357\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7065 - binary_accuracy: 0.5249 - val_loss: 0.7036 - val_binary_accuracy: 0.5571\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7039 - binary_accuracy: 0.5370 - val_loss: 0.7027 - val_binary_accuracy: 0.5500\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7058 - binary_accuracy: 0.5038 - val_loss: 0.7029 - val_binary_accuracy: 0.5357\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7031 - binary_accuracy: 0.5309 - val_loss: 0.7022 - val_binary_accuracy: 0.5643\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7030 - binary_accuracy: 0.5143 - val_loss: 0.7009 - val_binary_accuracy: 0.5571\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7025 - binary_accuracy: 0.5143 - val_loss: 0.7010 - val_binary_accuracy: 0.5500\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7014 - binary_accuracy: 0.5370 - val_loss: 0.7011 - val_binary_accuracy: 0.5500\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7012 - binary_accuracy: 0.5294 - val_loss: 0.7006 - val_binary_accuracy: 0.5286\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7013 - binary_accuracy: 0.5143 - val_loss: 0.7004 - val_binary_accuracy: 0.5357\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6996 - binary_accuracy: 0.5415 - val_loss: 0.6996 - val_binary_accuracy: 0.5429\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7009 - binary_accuracy: 0.5309 - val_loss: 0.6993 - val_binary_accuracy: 0.5429\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.6999 - binary_accuracy: 0.5158 - val_loss: 0.6994 - val_binary_accuracy: 0.5429\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7009 - binary_accuracy: 0.5294 - val_loss: 0.6983 - val_binary_accuracy: 0.5786\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.6994 - binary_accuracy: 0.5385 - val_loss: 0.6985 - val_binary_accuracy: 0.5714\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6993 - binary_accuracy: 0.5158 - val_loss: 0.6989 - val_binary_accuracy: 0.5286\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6993 - binary_accuracy: 0.5354 - val_loss: 0.6986 - val_binary_accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6997 - binary_accuracy: 0.5249 - val_loss: 0.6977 - val_binary_accuracy: 0.5143\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6981 - binary_accuracy: 0.5249 - val_loss: 0.6977 - val_binary_accuracy: 0.5500\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.6979 - binary_accuracy: 0.5219 - val_loss: 0.6975 - val_binary_accuracy: 0.5571\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.6982 - binary_accuracy: 0.5219 - val_loss: 0.6973 - val_binary_accuracy: 0.5714\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.6979 - binary_accuracy: 0.5204 - val_loss: 0.6974 - val_binary_accuracy: 0.5429\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6977 - binary_accuracy: 0.5309 - val_loss: 0.6973 - val_binary_accuracy: 0.5357\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.6972 - binary_accuracy: 0.5249 - val_loss: 0.6969 - val_binary_accuracy: 0.5714\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6968 - binary_accuracy: 0.5520 - val_loss: 0.6968 - val_binary_accuracy: 0.5643\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6981 - binary_accuracy: 0.5294 - val_loss: 0.6969 - val_binary_accuracy: 0.5571\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.6980 - binary_accuracy: 0.5219 - val_loss: 0.6962 - val_binary_accuracy: 0.5714\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.6974 - binary_accuracy: 0.5219 - val_loss: 0.6971 - val_binary_accuracy: 0.5929\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6975 - binary_accuracy: 0.5113 - val_loss: 0.6959 - val_binary_accuracy: 0.6000\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.6965 - binary_accuracy: 0.5294 - val_loss: 0.6951 - val_binary_accuracy: 0.5571\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.6980 - binary_accuracy: 0.5098 - val_loss: 0.6960 - val_binary_accuracy: 0.5429\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.6970 - binary_accuracy: 0.5234 - val_loss: 0.6955 - val_binary_accuracy: 0.5429\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6966 - binary_accuracy: 0.5128 - val_loss: 0.6957 - val_binary_accuracy: 0.5357\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6968 - binary_accuracy: 0.5234 - val_loss: 0.6951 - val_binary_accuracy: 0.5429\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6965 - binary_accuracy: 0.5143 - val_loss: 0.6963 - val_binary_accuracy: 0.5429\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6967 - binary_accuracy: 0.5204 - val_loss: 0.6955 - val_binary_accuracy: 0.5429\n",
      "Epoch 71/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6970 - binary_accuracy: 0.5279 - val_loss: 0.6959 - val_binary_accuracy: 0.5286\n"
     ]
    }
   ],
   "source": [
    "n_steps = X_train_2.shape[1]\n",
    "n_features = X_train_2.shape[2]\n",
    "\n",
    "# Let's make a list of CONSTANTS for modelling:\n",
    "LAYERS = [4, 4, 4, 1]                # number of units in hidden and output layers\n",
    "M_TRAIN = X_train_2.shape[0]           # number of training examples (2D)\n",
    "M_TEST = X_test_2.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = X_train_2.shape[2]                 # number of features\n",
    "BATCH = M_TRAIN                          # batch size\n",
    "EPOCH = 10                           # number of epochs\n",
    "LR = 5e-2                            # learning rate of the gradient descent\n",
    "LAMBD = 3e-2                         # lambda in L2 regularizaion\n",
    "DP = 0.0                             # dropout rate\n",
    "RDP = 0.0                            # recurrent dropout rate\n",
    "\n",
    "# Build the Model\n",
    "model5 = Sequential()\n",
    "\n",
    "model5.add(LSTM(units=LAYERS[2], input_shape=(n_steps, n_features),\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "model5.compile(loss='binary_crossentropy',\n",
    "              metrics=['BinaryAccuracy'],\n",
    "              optimizer=\"adam\")\n",
    "print(model5.summary())\n",
    "\n",
    "history = model5.fit(X_train_2, train_5w,\n",
    "                    epochs=100,\n",
    "                    validation_data=(X_val_2, val_5w), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f425e5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "train accuracy = 52.9412%\n",
      "test accuracy = 52.3077%\n",
      "test error = 31 out of 65 examples\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model5.evaluate(X_train_2, train_5w,\n",
    "                                       batch_size=M_TRAIN, verbose=0)\n",
    "test_loss, test_acc = model5.evaluate(X_test_2, test_5w,\n",
    "                                     batch_size=M_TEST, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3847d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_20 (LSTM)              (None, 32)                4608      \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,769\n",
      "Trainable params: 4,705\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "21/21 [==============================] - 3s 28ms/step - loss: 1.7200 - binary_accuracy: 0.5113 - val_loss: 1.5147 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.4065 - binary_accuracy: 0.5234 - val_loss: 1.2842 - val_binary_accuracy: 0.5357\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.2063 - binary_accuracy: 0.4977 - val_loss: 1.1223 - val_binary_accuracy: 0.5357\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0678 - binary_accuracy: 0.4872 - val_loss: 1.0082 - val_binary_accuracy: 0.5357\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.9711 - binary_accuracy: 0.5008 - val_loss: 0.9269 - val_binary_accuracy: 0.5357\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9018 - binary_accuracy: 0.5128 - val_loss: 0.8687 - val_binary_accuracy: 0.5357\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.8487 - binary_accuracy: 0.5385 - val_loss: 0.8268 - val_binary_accuracy: 0.5357\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.8136 - binary_accuracy: 0.5008 - val_loss: 0.7965 - val_binary_accuracy: 0.5286\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7861 - binary_accuracy: 0.5128 - val_loss: 0.7739 - val_binary_accuracy: 0.5357\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7680 - binary_accuracy: 0.5294 - val_loss: 0.7575 - val_binary_accuracy: 0.5357\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7539 - binary_accuracy: 0.5158 - val_loss: 0.7454 - val_binary_accuracy: 0.5357\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7434 - binary_accuracy: 0.4932 - val_loss: 0.7364 - val_binary_accuracy: 0.5357\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7360 - binary_accuracy: 0.4962 - val_loss: 0.7293 - val_binary_accuracy: 0.5357\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7314 - binary_accuracy: 0.5068 - val_loss: 0.7246 - val_binary_accuracy: 0.5357\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7242 - binary_accuracy: 0.5400 - val_loss: 0.7201 - val_binary_accuracy: 0.5357\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7204 - binary_accuracy: 0.5158 - val_loss: 0.7166 - val_binary_accuracy: 0.5357\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7183 - binary_accuracy: 0.5023 - val_loss: 0.7145 - val_binary_accuracy: 0.5357\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7152 - binary_accuracy: 0.5083 - val_loss: 0.7119 - val_binary_accuracy: 0.5357\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7130 - binary_accuracy: 0.5234 - val_loss: 0.7112 - val_binary_accuracy: 0.5357\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7175 - binary_accuracy: 0.4721 - val_loss: 0.7105 - val_binary_accuracy: 0.5214\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7119 - binary_accuracy: 0.5113 - val_loss: 0.7085 - val_binary_accuracy: 0.5286\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7091 - binary_accuracy: 0.5234 - val_loss: 0.7072 - val_binary_accuracy: 0.5357\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7101 - binary_accuracy: 0.4857 - val_loss: 0.7060 - val_binary_accuracy: 0.5286\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7076 - binary_accuracy: 0.5204 - val_loss: 0.7051 - val_binary_accuracy: 0.5286\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7063 - binary_accuracy: 0.5309 - val_loss: 0.7038 - val_binary_accuracy: 0.5357\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7073 - binary_accuracy: 0.4887 - val_loss: 0.7038 - val_binary_accuracy: 0.5357\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7063 - binary_accuracy: 0.5445 - val_loss: 0.7021 - val_binary_accuracy: 0.5357\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7064 - binary_accuracy: 0.5128 - val_loss: 0.7032 - val_binary_accuracy: 0.5357\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7067 - binary_accuracy: 0.5143 - val_loss: 0.7027 - val_binary_accuracy: 0.5357\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7033 - binary_accuracy: 0.5385 - val_loss: 0.7008 - val_binary_accuracy: 0.5357\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7050 - binary_accuracy: 0.5249 - val_loss: 0.7019 - val_binary_accuracy: 0.5357\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7037 - binary_accuracy: 0.5083 - val_loss: 0.7004 - val_binary_accuracy: 0.5357\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7025 - binary_accuracy: 0.5279 - val_loss: 0.7030 - val_binary_accuracy: 0.5214\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7044 - binary_accuracy: 0.5234 - val_loss: 0.7015 - val_binary_accuracy: 0.5286\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7021 - binary_accuracy: 0.5204 - val_loss: 0.7018 - val_binary_accuracy: 0.5357\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7022 - binary_accuracy: 0.5158 - val_loss: 0.6998 - val_binary_accuracy: 0.5286\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7041 - binary_accuracy: 0.5143 - val_loss: 0.7007 - val_binary_accuracy: 0.5143\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7033 - binary_accuracy: 0.5128 - val_loss: 0.7026 - val_binary_accuracy: 0.5357\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7028 - binary_accuracy: 0.5038 - val_loss: 0.6988 - val_binary_accuracy: 0.5286\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7006 - binary_accuracy: 0.4947 - val_loss: 0.6997 - val_binary_accuracy: 0.5357\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7028 - binary_accuracy: 0.5023 - val_loss: 0.7020 - val_binary_accuracy: 0.5357\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7027 - binary_accuracy: 0.5143 - val_loss: 0.6997 - val_binary_accuracy: 0.5357\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7007 - binary_accuracy: 0.5339 - val_loss: 0.6980 - val_binary_accuracy: 0.5571\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7003 - binary_accuracy: 0.5264 - val_loss: 0.6982 - val_binary_accuracy: 0.5357\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7006 - binary_accuracy: 0.5324 - val_loss: 0.7007 - val_binary_accuracy: 0.5357\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6998 - binary_accuracy: 0.4962 - val_loss: 0.6981 - val_binary_accuracy: 0.5286\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6990 - binary_accuracy: 0.4932 - val_loss: 0.6974 - val_binary_accuracy: 0.5286\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6985 - binary_accuracy: 0.5249 - val_loss: 0.6975 - val_binary_accuracy: 0.5429\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7027 - binary_accuracy: 0.4827 - val_loss: 0.6994 - val_binary_accuracy: 0.5357\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7005 - binary_accuracy: 0.5038 - val_loss: 0.6982 - val_binary_accuracy: 0.5143\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6982 - binary_accuracy: 0.5279 - val_loss: 0.6978 - val_binary_accuracy: 0.5357\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6985 - binary_accuracy: 0.5189 - val_loss: 0.6983 - val_binary_accuracy: 0.5429\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6996 - binary_accuracy: 0.5083 - val_loss: 0.6970 - val_binary_accuracy: 0.5357\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.6986 - binary_accuracy: 0.5143 - val_loss: 0.6963 - val_binary_accuracy: 0.5357\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6987 - binary_accuracy: 0.5008 - val_loss: 0.6969 - val_binary_accuracy: 0.5357\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6991 - binary_accuracy: 0.5219 - val_loss: 0.6965 - val_binary_accuracy: 0.5357\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6982 - binary_accuracy: 0.5204 - val_loss: 0.6976 - val_binary_accuracy: 0.5286\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6977 - binary_accuracy: 0.5234 - val_loss: 0.6968 - val_binary_accuracy: 0.5214\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6984 - binary_accuracy: 0.5294 - val_loss: 0.6966 - val_binary_accuracy: 0.5357\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6995 - binary_accuracy: 0.4977 - val_loss: 0.6965 - val_binary_accuracy: 0.5286\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6972 - binary_accuracy: 0.5339 - val_loss: 0.6968 - val_binary_accuracy: 0.5429\n"
     ]
    }
   ],
   "source": [
    "n_steps = X_train_2.shape[1]\n",
    "n_features = X_train_2.shape[2]\n",
    "\n",
    "# Let's make a list of CONSTANTS for modelling:\n",
    "LAYERS = [32, 32, 32, 1]                # number of units in hidden and output layers\n",
    "M_TRAIN = X_train_2.shape[0]           # number of training examples (2D)\n",
    "M_TEST = X_test_2.shape[0]             # number of test examples (2D),full=X_test.shape[0]\n",
    "N = X_train_2.shape[2]                 # number of features\n",
    "BATCH = M_TRAIN                          # batch size\n",
    "EPOCH = 10                           # number of epochs\n",
    "LR = 5e-2                            # learning rate of the gradient descent\n",
    "LAMBD = 3e-2                         # lambda in L2 regularizaion\n",
    "DP = 0.0                             # dropout rate\n",
    "RDP = 0.0                            # recurrent dropout rate\n",
    "\n",
    "# Build the Model\n",
    "model6 = Sequential()\n",
    "\n",
    "model6.add(LSTM(units=LAYERS[2], input_shape=(n_steps, n_features),\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "\n",
    "model6.add(BatchNormalization())\n",
    "model6.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "model6.compile(loss='binary_crossentropy',\n",
    "              metrics=['BinaryAccuracy'],\n",
    "              optimizer=\"adam\")\n",
    "print(model6.summary())\n",
    "\n",
    "history = model6.fit(X_train_2, train_5w,\n",
    "                    epochs=100,\n",
    "                    validation_data=(X_val_2, val_5w), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe0cd3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "train accuracy = 52.7903%\n",
      "test accuracy = 52.3077%\n",
      "test error = 31 out of 65 examples\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model6.evaluate(X_train_2, train_5w,\n",
    "                                       batch_size=M_TRAIN, verbose=0)\n",
    "test_loss, test_acc = model6.evaluate(X_test_2, test_5w,\n",
    "                                     batch_size=M_TEST, verbose=0)\n",
    "print('-'*65)\n",
    "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
    "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
    "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31582b9feba862c420bc95ad7fac43fb721c474490d1710b4e50ac63470f9531"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
